{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saimasharleen/Active-Learning-Strategies-Across-Diverse-Machine-Learning-Models/blob/main/CIFAR_10_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DLzn-z5KNBfJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "621hIz4IOhOh",
        "outputId": "ff45efaf-a6ab-44a0-c0fa-d0535ea1f989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/modAL-python/modAL.git\n",
            "  Cloning https://github.com/modAL-python/modAL.git to /tmp/pip-req-build-77re9q3z\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/modAL-python/modAL.git /tmp/pip-req-build-77re9q3z\n",
            "  Resolved https://github.com/modAL-python/modAL.git to commit bba6f6fd00dbb862b1e09259b78caf6cffa2e755\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.11.4)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.5.3)\n",
            "Collecting skorch==0.9.0 (from modAL-python==0.4.2)\n",
            "  Downloading skorch-0.9.0-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.8/125.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch==0.9.0->modAL-python==0.4.2) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.10/dist-packages (from skorch==0.9.0->modAL-python==0.4.2) (4.66.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->modAL-python==0.4.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->modAL-python==0.4.2) (2023.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->modAL-python==0.4.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->modAL-python==0.4.2) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.0->modAL-python==0.4.2) (1.16.0)\n",
            "Building wheels for collected packages: modAL-python\n",
            "  Building wheel for modAL-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for modAL-python: filename=modAL_python-0.4.2-py3-none-any.whl size=32650 sha256=ae74fc24fce92a8796a9216e76d8a1f52c87dceb589b57efca4b75b27032b709\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cq_o6er8/wheels/d9/fb/59/7deb61b460c1c36394cd093758986ff7d36f71352dcb2e02c5\n",
            "Successfully built modAL-python\n",
            "Installing collected packages: skorch, modAL-python\n",
            "Successfully installed modAL-python-0.4.2 skorch-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/modAL-python/modAL.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWsbO0FiRj5H",
        "outputId": "27f7385c-829f-4636-decc-7b6e91ee7738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 46355088.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to .\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import CIFAR10\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "import collections\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.uncertainty import uncertainty_sampling\n",
        "from torch import nn\n",
        "from skorch import NeuralNetClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "\n",
        "CIFAR_data = CIFAR10('.', download= True, transform = ToTensor())\n",
        "\n",
        "dataloader = DataLoader(CIFAR_data, shuffle=True, batch_size = 50000 )\n",
        "x, y = next(iter(dataloader))\n",
        "\n",
        "x = x.detach().cpu().numpy()\n",
        "y = y.detach().cpu().numpy()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=5000, random_state=0, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bsmJCrq1R4Dg"
      },
      "outputs": [],
      "source": [
        "#cnn model building\n",
        "\n",
        "class Torch_Model(nn.Module):\n",
        "    def __init__( self):\n",
        "        super( Torch_Model , self).__init__()\n",
        "        self.convs = nn.Sequential(\n",
        "            nn.Conv2d(3,32,3), #----- EDIT THE DIMENSION HERE-----\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.25))\n",
        "\n",
        "        self.fcs = nn.Sequential(\n",
        "            nn.Linear(14*14*64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 10))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x\n",
        "        out = self.convs(out)\n",
        "        out = out.view(-1, 14*14*64)\n",
        "        out = self.fcs(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tMRnO-C6Snfr"
      },
      "outputs": [],
      "source": [
        "classifier = NeuralNetClassifier(Torch_Model,\n",
        "    criterion = nn.CrossEntropyLoss,\n",
        "    optimizer = torch.optim.Adam,\n",
        "    train_split = None,\n",
        "    verbose = 1,\n",
        "    device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxZWA8hJSxHE",
        "outputId": "aae0c082-8a1d-4036-b09c-eef1aae79901"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CNN_model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "filename = \"CNN_model.joblib\"\n",
        "joblib.dump(classifier, filename)\n",
        "#loaded_model = joblib.load(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-qN-ybrGS0Ne"
      },
      "outputs": [],
      "source": [
        "def CF_Print(y_test, y_pred):\n",
        "    accuracy = accuracy_score(y_pred, y_test)\n",
        "    CF = confusion_matrix(y_test, y_pred)\n",
        "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "    micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
        "    weighted_f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    print('Confusion Matrix:')\n",
        "    print(CF)\n",
        "    print('Accuracy: ', accuracy)\n",
        "    print('Macro F1-score: ', macro_f1)\n",
        "    print('Micro F1-score: ', micro_f1)\n",
        "    print('Weighted F1-score: ', weighted_f1)\n",
        "    print(\"---------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmkdoZPqS34a"
      },
      "outputs": [],
      "source": [
        "def AL_Retrain(n_initial, n_queries, instances ):\n",
        "    x_initial, x_pool, y_initial,  y_pool = train_test_split(x_train,y_train, train_size=n_initial, random_state=0, stratify=y_train)\n",
        "    filename = \"CNN_model.joblib\"\n",
        "    classifier = joblib.load(filename)\n",
        "    learner = ActiveLearner(\n",
        "    estimator = classifier,\n",
        "    query_strategy = uncertainty_sampling,\n",
        "    X_training = x_initial, y_training = y_initial,\n",
        "    )\n",
        "    print(\"No of initial data: \", n_initial)\n",
        "    print(learner.score(x_test, y_test))\n",
        "    y_pred = learner.predict(x_test)\n",
        "    print('Confusion Matrix After trainig with initial data')\n",
        "    CF_Print(y_test, y_pred)\n",
        "    print(\"---- Train From Scratch with first model-----\")\n",
        "    AL_Train_Scratch(n_initial, learner, (n_initial*2) )\n",
        "\n",
        "    print(\"---- Teach/Retrain with new data-------\")\n",
        "    for idx in range(n_queries):\n",
        "        print('---Query no: ', idx+1, '----')\n",
        "        query_idx, query_instance = learner.query(x_pool, n_instances=instances)\n",
        "        learner.teach(\n",
        "            X=x_pool[query_idx],\n",
        "            y=y_pool[query_idx],\n",
        "        )\n",
        "        print(learner.score(x_test, y_test))\n",
        "        x_pool = np.delete(x_pool, query_idx, axis=0)\n",
        "        y_pool = np.delete(y_pool, query_idx, axis=0)\n",
        "    y_pred = learner.predict(x_test)\n",
        "    print('Confusion Matrix After RE-TRAINGING')\n",
        "    CF_Print(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cJx8WwobS7yH"
      },
      "outputs": [],
      "source": [
        "def AL_Train_Scratch(n_initial, trained_learner, instances):\n",
        "    query_idx, query_instance = trained_learner.query(x_train, n_instances=(instances*2))\n",
        "    distribution=[0]*10\n",
        "    flag=0\n",
        "    data_per_class= int(n_initial/10)\n",
        "    x_initial=[]\n",
        "    y_initial=[]\n",
        "    x_temp= x_train[query_idx]\n",
        "    y_temp=y_train[query_idx]\n",
        "    for data, label in zip(x_temp, y_temp):\n",
        "        if distribution[label]<data_per_class:\n",
        "            x_initial.append(data)\n",
        "            y_initial.append(label)\n",
        "            distribution[label]+=1\n",
        "            if distribution[label]==data_per_class:\n",
        "                flag+=1\n",
        "        if flag==10:\n",
        "            break\n",
        "    del x_temp, y_temp\n",
        "    print(y_initial)\n",
        "    counter = collections.Counter(y_initial)\n",
        "    print(counter)\n",
        "    filename = \"CNN_model.joblib\"\n",
        "    classifier = joblib.load(filename)\n",
        "    x_initial= np.array(x_initial)\n",
        "    y_initial = np.array(y_initial)\n",
        "    new_learner = ActiveLearner(\n",
        "        estimator = classifier,\n",
        "        query_strategy = uncertainty_sampling,\n",
        "        X_training = x_initial, y_training = y_initial,\n",
        "    )\n",
        "    print(new_learner.score(x_test, y_test))\n",
        "    y_pred = new_learner.predict(x_test)\n",
        "    print(\"Confusion Matrix after training the model with most important dataset\")\n",
        "    CF_Print(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8AFi0JHS-uZ",
        "outputId": "9099d552-5598-455e-d6d9-305d3af64858"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3072\u001b[0m  0.5916\n",
            "      2        5.6065  0.2900\n",
            "      3        2.8377  0.2760\n",
            "      4        2.3226  0.3159\n",
            "      5        \u001b[36m2.2881\u001b[0m  0.3793\n",
            "      6        \u001b[36m2.2723\u001b[0m  0.2657\n",
            "      7        \u001b[36m2.2264\u001b[0m  0.2886\n",
            "      8        \u001b[36m2.1715\u001b[0m  0.2754\n",
            "      9        2.2787  0.2643\n",
            "     10        \u001b[36m2.1595\u001b[0m  0.4789\n",
            "No of initial data:  100\n",
            "0.1558\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[  3   0   0  41 276   1  19   0 156   4]\n",
            " [  0   2   0 137 241   2  53   0  48  17]\n",
            " [  0   2   0  23 408   1  35   0  28   3]\n",
            " [  0   1   0  50 393   0  46   1   9   0]\n",
            " [  0   0   0  12 448   0  16   0  23   1]\n",
            " [  1   0   0  48 354   1  87   0   8   1]\n",
            " [  0   0   1  27 416   0  54   0   2   0]\n",
            " [  0   0   0  20 431   0  29   1  18   1]\n",
            " [  2   1   0  72 179   1  29   0 207   9]\n",
            " [  0   2   0  77 298   0  45   0  65  13]]\n",
            "Accuracy:  0.1558\n",
            "Macro F1-score:  0.09089016753066838\n",
            "Micro F1-score:  0.1558\n",
            "Weighted F1-score:  0.09089016753066838\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[1, 7, 3, 9, 1, 2, 2, 1, 9, 0, 3, 0, 6, 9, 8, 0, 1, 9, 0, 9, 5, 9, 8, 9, 8, 1, 2, 1, 3, 1, 9, 1, 2, 1, 9, 1, 9, 2, 0, 5, 7, 6, 8, 3, 3, 6, 6, 2, 7, 3, 0, 2, 2, 7, 8, 8, 3, 8, 5, 7, 0, 4, 0, 7, 8, 0, 3, 6, 5, 0, 8, 3, 5, 5, 4, 3, 8, 4, 2, 2, 7, 7, 5, 5, 5, 7, 4, 6, 5, 6, 6, 7, 6, 6, 4, 4, 4, 4, 4, 4]\n",
            "Counter({1: 10, 7: 10, 3: 10, 9: 10, 2: 10, 0: 10, 6: 10, 8: 10, 5: 10, 4: 10})\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3039\u001b[0m  0.4161\n",
            "      2        7.2775  0.4354\n",
            "      3        6.0783  0.3335\n",
            "      4        2.6161  0.2613\n",
            "      5        2.3102  0.2631\n",
            "      6        \u001b[36m2.2992\u001b[0m  0.2755\n",
            "      7        2.3076  0.2591\n",
            "      8        \u001b[36m2.2914\u001b[0m  0.2722\n",
            "      9        2.2931  0.2575\n",
            "     10        2.2946  0.2774\n",
            "0.1024\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[  0   0   0   0   0   0   0  55   0 445]\n",
            " [  0   0   0   0   0   0   0 134   0 366]\n",
            " [  0   0   0   0   0   0   0  90   0 410]\n",
            " [  0   0   0   0   0   0   0 119   0 381]\n",
            " [  0   0   0   0   0   0   0  92   0 408]\n",
            " [  0   0   0   0   0   0   0 122   0 378]\n",
            " [  0   0   0   0   0   0   0 124   0 376]\n",
            " [  0   0   0   0   0   0   0 146   0 354]\n",
            " [  0   0   0   0   0   0   0  86   0 414]\n",
            " [  0   0   0   0   0   0   0 134   0 366]]\n",
            "Accuracy:  0.1024\n",
            "Macro F1-score:  0.034871145038688\n",
            "Micro F1-score:  0.10239999999999999\n",
            "Weighted F1-score:  0.034871145038687996\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "---Query no:  1 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3010\u001b[0m  0.4828\n",
            "      2        7.3320  0.5035\n",
            "      3        4.1569  0.3681\n",
            "      4        2.3016  0.3092\n",
            "      5        \u001b[36m2.2997\u001b[0m  0.3226\n",
            "      6        2.3666  0.2950\n",
            "      7        \u001b[36m2.2761\u001b[0m  0.3031\n",
            "      8        \u001b[36m2.2360\u001b[0m  0.3164\n",
            "      9        2.2994  0.3043\n",
            "     10        \u001b[36m2.2319\u001b[0m  0.3042\n",
            "0.1076\n",
            "---Query no:  2 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.5522\u001b[0m  0.4368\n",
            "      2       10.8749  0.5900\n",
            "      3        \u001b[36m2.3015\u001b[0m  0.5737\n",
            "      4        2.3019  0.5652\n",
            "      5        2.5134  0.5812\n",
            "      6        \u001b[36m2.2736\u001b[0m  0.4564\n",
            "      7        \u001b[36m2.2157\u001b[0m  0.3880\n",
            "      8        2.5247  0.3768\n",
            "      9        \u001b[36m2.1679\u001b[0m  0.3766\n",
            "     10        \u001b[36m2.1251\u001b[0m  0.4084\n",
            "0.1166\n",
            "---Query no:  3 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.2885\u001b[0m  0.6977\n",
            "      2        7.7347  0.5182\n",
            "      3        \u001b[36m2.3421\u001b[0m  0.4302\n",
            "      4        2.8293  0.4513\n",
            "      5        \u001b[36m2.2889\u001b[0m  0.4294\n",
            "      6        2.2983  0.4366\n",
            "      7        \u001b[36m2.2800\u001b[0m  0.4195\n",
            "      8        2.2810  0.4269\n",
            "      9        2.3133  0.4292\n",
            "     10        2.3194  0.4227\n",
            "0.099\n",
            "---Query no:  4 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.4170\u001b[0m  0.5066\n",
            "      2        \u001b[36m3.1506\u001b[0m  0.4877\n",
            "      3        \u001b[36m2.2946\u001b[0m  0.4874\n",
            "      4        \u001b[36m2.2698\u001b[0m  0.4646\n",
            "      5        \u001b[36m2.2467\u001b[0m  0.4795\n",
            "      6        2.2903  0.4884\n",
            "      7        \u001b[36m2.1643\u001b[0m  0.4814\n",
            "      8        \u001b[36m2.1331\u001b[0m  0.4859\n",
            "      9        \u001b[36m2.0428\u001b[0m  0.4720\n",
            "     10        2.0917  0.4724\n",
            "0.1778\n",
            "---Query no:  5 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.0600\u001b[0m  1.0861\n",
            "      2        \u001b[36m3.9854\u001b[0m  0.8085\n",
            "      3        \u001b[36m2.2996\u001b[0m  0.7907\n",
            "      4        \u001b[36m2.2967\u001b[0m  0.5240\n",
            "      5        \u001b[36m2.2881\u001b[0m  0.5153\n",
            "      6        2.3058  0.5212\n",
            "      7        \u001b[36m2.2657\u001b[0m  0.5139\n",
            "      8        2.3727  0.5272\n",
            "      9        \u001b[36m2.2105\u001b[0m  0.5156\n",
            "     10        2.2943  0.5240\n",
            "0.1176\n",
            "---Query no:  6 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.9322\u001b[0m  0.8010\n",
            "      2        \u001b[36m4.0988\u001b[0m  0.5856\n",
            "      3        \u001b[36m2.3034\u001b[0m  0.5714\n",
            "      4        \u001b[36m2.3006\u001b[0m  0.5885\n",
            "      5        2.3156  0.5727\n",
            "      6        \u001b[36m2.2288\u001b[0m  0.5816\n",
            "      7        \u001b[36m2.1895\u001b[0m  0.5646\n",
            "      8        \u001b[36m2.0987\u001b[0m  0.5853\n",
            "      9        \u001b[36m2.0021\u001b[0m  0.5652\n",
            "     10        2.0494  0.5727\n",
            "0.154\n",
            "---Query no:  7 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.8652\u001b[0m  0.9078\n",
            "      2        \u001b[36m3.0137\u001b[0m  0.6140\n",
            "      3        \u001b[36m2.2875\u001b[0m  0.6175\n",
            "      4        2.2903  0.6117\n",
            "      5        \u001b[36m2.2353\u001b[0m  0.6207\n",
            "      6        2.2370  0.6294\n",
            "      7        2.2795  0.8858\n",
            "      8        \u001b[36m2.1729\u001b[0m  0.9506\n",
            "      9        \u001b[36m2.1448\u001b[0m  0.9323\n",
            "     10        \u001b[36m2.1326\u001b[0m  0.6234\n",
            "0.117\n",
            "---Query no:  8 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.3526\u001b[0m  0.7160\n",
            "      2        \u001b[36m2.3116\u001b[0m  0.6766\n",
            "      3        \u001b[36m2.2570\u001b[0m  0.6646\n",
            "      4        2.4530  0.6735\n",
            "      5        \u001b[36m2.1880\u001b[0m  0.6824\n",
            "      6        2.2148  0.6656\n",
            "      7        \u001b[36m2.1262\u001b[0m  0.6771\n",
            "      8        2.1499  0.6758\n",
            "      9        \u001b[36m1.9817\u001b[0m  0.6700\n",
            "     10        \u001b[36m1.8250\u001b[0m  0.6827\n",
            "0.186\n",
            "---Query no:  9 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.8245\u001b[0m  0.7559\n",
            "      2        \u001b[36m2.3187\u001b[0m  0.7385\n",
            "      3        \u001b[36m2.2950\u001b[0m  0.7371\n",
            "      4        \u001b[36m2.2922\u001b[0m  0.7322\n",
            "      5        \u001b[36m2.2768\u001b[0m  1.0442\n",
            "      6        \u001b[36m2.2302\u001b[0m  1.1150\n",
            "      7        \u001b[36m2.1273\u001b[0m  0.8247\n",
            "      8        \u001b[36m2.0691\u001b[0m  0.7391\n",
            "      9        \u001b[36m2.0619\u001b[0m  0.7304\n",
            "     10        \u001b[36m1.9840\u001b[0m  0.7305\n",
            "0.15\n",
            "---Query no:  10 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m9.4843\u001b[0m  0.8045\n",
            "      2        \u001b[36m2.3297\u001b[0m  0.7883\n",
            "      3        \u001b[36m2.3180\u001b[0m  0.7774\n",
            "      4        2.5379  0.7702\n",
            "      5        \u001b[36m2.3000\u001b[0m  0.7753\n",
            "      6        \u001b[36m2.2966\u001b[0m  0.7807\n",
            "      7        \u001b[36m2.2934\u001b[0m  0.7807\n",
            "      8        \u001b[36m2.2887\u001b[0m  0.7685\n",
            "      9        \u001b[36m2.2780\u001b[0m  0.9863\n",
            "     10        \u001b[36m2.2649\u001b[0m  1.2075\n",
            "0.1152\n",
            "---Query no:  11 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.2170\u001b[0m  0.8516\n",
            "      2        \u001b[36m2.2970\u001b[0m  0.8315\n",
            "      3        \u001b[36m2.2886\u001b[0m  0.8223\n",
            "      4        2.2934  0.8501\n",
            "      5        \u001b[36m2.2195\u001b[0m  0.8186\n",
            "      6        \u001b[36m2.0881\u001b[0m  0.8355\n",
            "      7        2.1944  0.8322\n",
            "      8        2.1328  0.8305\n",
            "      9        \u001b[36m2.0278\u001b[0m  0.8310\n",
            "     10        \u001b[36m2.0009\u001b[0m  0.8165\n",
            "0.232\n",
            "---Query no:  12 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.3557\u001b[0m  1.0055\n",
            "      2        \u001b[36m2.4705\u001b[0m  1.3472\n",
            "      3        \u001b[36m2.3014\u001b[0m  1.0947\n",
            "      4        \u001b[36m2.2958\u001b[0m  0.8689\n",
            "      5        \u001b[36m2.2929\u001b[0m  0.8712\n",
            "      6        2.3052  0.8689\n",
            "      7        \u001b[36m2.2717\u001b[0m  0.8599\n",
            "      8        \u001b[36m2.2620\u001b[0m  0.8635\n",
            "      9        \u001b[36m2.2197\u001b[0m  0.8700\n",
            "     10        \u001b[36m2.2065\u001b[0m  0.8701\n",
            "0.1692\n",
            "---Query no:  13 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.3859\u001b[0m  0.9585\n",
            "      2        \u001b[36m2.3236\u001b[0m  0.9189\n",
            "      3        \u001b[36m2.3060\u001b[0m  0.9159\n",
            "      4        \u001b[36m2.2976\u001b[0m  0.9051\n",
            "      5        \u001b[36m2.2957\u001b[0m  0.9137\n",
            "      6        \u001b[36m2.2942\u001b[0m  0.9188\n",
            "      7        \u001b[36m2.2902\u001b[0m  0.9158\n",
            "      8        2.2912  1.3549\n",
            "      9        \u001b[36m2.2864\u001b[0m  1.3010\n",
            "     10        \u001b[36m2.2858\u001b[0m  0.9162\n",
            "0.1\n",
            "---Query no:  14 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.1485\u001b[0m  0.9988\n",
            "      2        \u001b[36m2.3246\u001b[0m  0.9824\n",
            "      3        \u001b[36m2.2949\u001b[0m  0.9683\n",
            "      4        \u001b[36m2.2375\u001b[0m  0.9749\n",
            "      5        \u001b[36m2.2012\u001b[0m  0.9723\n",
            "      6        \u001b[36m2.1554\u001b[0m  0.9764\n",
            "      7        \u001b[36m2.0404\u001b[0m  0.9755\n",
            "      8        \u001b[36m1.9699\u001b[0m  0.9701\n",
            "      9        \u001b[36m1.8707\u001b[0m  1.3939\n",
            "     10        1.9167  1.3645\n",
            "0.2384\n",
            "---Query no:  15 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m8.4671\u001b[0m  1.0734\n",
            "      2        \u001b[36m2.3289\u001b[0m  1.0195\n",
            "      3        2.3440  1.0283\n",
            "      4        \u001b[36m2.3182\u001b[0m  1.0305\n",
            "      5        \u001b[36m2.2998\u001b[0m  1.0229\n",
            "      6        \u001b[36m2.2389\u001b[0m  1.0240\n",
            "      7        \u001b[36m2.2277\u001b[0m  1.0255\n",
            "      8        \u001b[36m2.1820\u001b[0m  1.2183\n",
            "      9        \u001b[36m2.1119\u001b[0m  1.6151\n",
            "     10        \u001b[36m2.0158\u001b[0m  1.0818\n",
            "0.2066\n",
            "---Query no:  16 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.1213\u001b[0m  2.1965\n",
            "      2        \u001b[36m2.3119\u001b[0m  1.3357\n",
            "      3        \u001b[36m2.3061\u001b[0m  1.4553\n",
            "      4        \u001b[36m2.2895\u001b[0m  1.0946\n",
            "      5        \u001b[36m2.2490\u001b[0m  1.0797\n",
            "      6        2.3293  1.6945\n",
            "      7        2.2934  1.3195\n",
            "      8        2.2953  1.0952\n",
            "      9        2.2984  1.1105\n",
            "     10        2.2944  1.0859\n",
            "0.1\n",
            "---Query no:  17 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.4628\u001b[0m  1.1707\n",
            "      2        \u001b[36m2.3443\u001b[0m  1.1407\n",
            "      3        \u001b[36m2.2923\u001b[0m  1.1266\n",
            "      4        \u001b[36m2.2742\u001b[0m  1.1325\n",
            "      5        \u001b[36m2.1737\u001b[0m  1.1244\n",
            "      6        2.1959  1.1254\n",
            "      7        \u001b[36m2.0837\u001b[0m  1.4464\n",
            "      8        \u001b[36m2.0234\u001b[0m  1.6271\n",
            "      9        \u001b[36m1.9968\u001b[0m  1.1390\n",
            "     10        \u001b[36m1.9634\u001b[0m  1.1251\n",
            "0.227\n",
            "---Query no:  18 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.9716\u001b[0m  1.6511\n",
            "      2        \u001b[36m2.3063\u001b[0m  1.1775\n",
            "      3        \u001b[36m2.3053\u001b[0m  1.1852\n",
            "      4        2.3302  1.1796\n",
            "      5        \u001b[36m2.2995\u001b[0m  1.1744\n",
            "      6        \u001b[36m2.2956\u001b[0m  1.5200\n",
            "      7        \u001b[36m2.2933\u001b[0m  1.6305\n",
            "      8        2.2937  1.1670\n",
            "      9        \u001b[36m2.2911\u001b[0m  1.1733\n",
            "     10        \u001b[36m2.2908\u001b[0m  1.1974\n",
            "0.1\n",
            "---Query no:  19 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.6983\u001b[0m  1.2537\n",
            "      2        \u001b[36m2.3129\u001b[0m  1.2371\n",
            "      3        \u001b[36m2.3016\u001b[0m  1.2242\n",
            "      4        \u001b[36m2.2995\u001b[0m  1.2315\n",
            "      5        \u001b[36m2.2738\u001b[0m  1.3377\n",
            "      6        \u001b[36m2.2480\u001b[0m  1.9234\n",
            "      7        \u001b[36m2.2232\u001b[0m  1.2537\n",
            "      8        \u001b[36m2.1701\u001b[0m  1.2170\n",
            "      9        \u001b[36m2.1214\u001b[0m  1.2190\n",
            "     10        \u001b[36m2.0686\u001b[0m  1.2199\n",
            "0.1844\n",
            "---Query no:  20 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.7167\u001b[0m  1.3308\n",
            "      2        \u001b[36m2.3145\u001b[0m  1.2942\n",
            "      3        \u001b[36m2.3044\u001b[0m  1.2824\n",
            "      4        \u001b[36m2.2824\u001b[0m  1.4249\n",
            "      5        \u001b[36m2.2370\u001b[0m  1.9479\n",
            "      6        \u001b[36m2.2078\u001b[0m  1.2801\n",
            "      7        2.2095  1.2650\n",
            "      8        \u001b[36m2.1458\u001b[0m  1.2744\n",
            "      9        \u001b[36m1.9989\u001b[0m  1.2772\n",
            "     10        \u001b[36m1.8975\u001b[0m  1.2876\n",
            "0.279\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[279  21  10  10  11  19  43   0  85  22]\n",
            " [ 41 122  15  19   8  24  84   0  84 103]\n",
            " [ 92   6  58   5  44  20 240   0  15  20]\n",
            " [ 69  10  45  32  50  67 183   0  16  28]\n",
            " [ 62   2  70   7  53  15 267   1  10  13]\n",
            " [ 73   6  49  29  46 109 155   0  13  20]\n",
            " [ 24   3  41   7  23  21 353   0   1  27]\n",
            " [ 76  10  58  18  37  40 190   1  17  53]\n",
            " [163  32   4  11   6  34  24   1 193  32]\n",
            " [ 61  48   7  14   2   9  84   0  80 195]]\n",
            "Accuracy:  0.279\n",
            "Macro F1-score:  0.24342348228885147\n",
            "Micro F1-score:  0.279\n",
            "Weighted F1-score:  0.24342348228885144\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "AL_Retrain(100, 20, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWo7Jnh_4pU_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import CIFAR10\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "import collections\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.uncertainty import uncertainty_sampling\n",
        "from torch import nn\n",
        "from skorch import NeuralNetClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "\n",
        "CIFAR_data = CIFAR10('.', download= True, transform = ToTensor())\n",
        "\n",
        "dataloader = DataLoader(CIFAR_data, shuffle=True, batch_size = 50000 )\n",
        "x, y = next(iter(dataloader))\n",
        "\n",
        "x = x.detach().cpu().numpy()\n",
        "y = y.detach().cpu().numpy()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=5000, random_state=0, stratify=y)\n",
        "#cnn model building\n",
        "\n",
        "class Torch_Model(nn.Module):\n",
        "    def __init__( self):\n",
        "        super( Torch_Model , self).__init__()\n",
        "        self.convs = nn.Sequential(\n",
        "            nn.Conv2d(3,32,3), #----- EDIT THE DIMENSION HERE-----\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.25))\n",
        "\n",
        "        self.fcs = nn.Sequential(\n",
        "            nn.Linear(14*14*64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 10))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x\n",
        "        out = self.convs(out)\n",
        "        out = out.view(-1, 14*14*64)\n",
        "        out = self.fcs(out)\n",
        "        return out\n",
        "classifier = NeuralNetClassifier(Torch_Model,\n",
        "    criterion = nn.CrossEntropyLoss,\n",
        "    optimizer = torch.optim.Adam,\n",
        "    train_split = None,\n",
        "    verbose = 1,\n",
        "    device = device)\n",
        "filename = \"CNN_model.joblib\"\n",
        "joblib.dump(classifier, filename)\n",
        "#loaded_model = joblib.load(filename)\n",
        "def CF_Print(y_test, y_pred):\n",
        "    accuracy = accuracy_score(y_pred, y_test)\n",
        "    CF = confusion_matrix(y_test, y_pred)\n",
        "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "    micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
        "    weighted_f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    print('Confusion Matrix:')\n",
        "    print(CF)\n",
        "    print('Accuracy: ', accuracy)\n",
        "    print('Macro F1-score: ', macro_f1)\n",
        "    print('Micro F1-score: ', micro_f1)\n",
        "    print('Weighted F1-score: ', weighted_f1)\n",
        "    print(\"---------------------------------\")\n",
        "def AL_Retrain(n_initial, n_queries, instances ):\n",
        "    x_initial, x_pool, y_initial,  y_pool = train_test_split(x_train,y_train, train_size=n_initial, random_state=0, stratify=y_train)\n",
        "    filename = \"CNN_model.joblib\"\n",
        "    classifier = joblib.load(filename)\n",
        "    learner = ActiveLearner(\n",
        "    estimator = classifier,\n",
        "    query_strategy = uncertainty_sampling,\n",
        "    X_training = x_initial, y_training = y_initial,\n",
        "    )\n",
        "    print(\"No of initial data: \", n_initial)\n",
        "    print(learner.score(x_test, y_test))\n",
        "    y_pred = learner.predict(x_test)\n",
        "    print('Confusion Matrix After trainig with initial data')\n",
        "    CF_Print(y_test, y_pred)\n",
        "    print(\"---- Train From Scratch with first model-----\")\n",
        "    AL_Train_Scratch(n_initial, learner, (n_initial*2) )\n",
        "\n",
        "    print(\"---- Teach/Retrain with new data-------\")\n",
        "    for idx in range(n_queries):\n",
        "        print('---Query no: ', idx+1, '----')\n",
        "        query_idx, query_instance = learner.query(x_pool, n_instances=instances)\n",
        "        learner.teach(\n",
        "            X=x_pool[query_idx],\n",
        "            y=y_pool[query_idx],\n",
        "        )\n",
        "        print(learner.score(x_test, y_test))\n",
        "        x_pool = np.delete(x_pool, query_idx, axis=0)\n",
        "        y_pool = np.delete(y_pool, query_idx, axis=0)\n",
        "    y_pred = learner.predict(x_test)\n",
        "    print('Confusion Matrix After RE-TRAINGING')\n",
        "    CF_Print(y_test, y_pred)\n",
        "def AL_Train_Scratch(n_initial, trained_learner, instances):\n",
        "    query_idx, query_instance = trained_learner.query(x_train, n_instances=(instances*2))\n",
        "    distribution=[0]*10\n",
        "    flag=0\n",
        "    data_per_class= int(n_initial/10)\n",
        "    x_initial=[]\n",
        "    y_initial=[]\n",
        "    x_temp= x_train[query_idx]\n",
        "    y_temp=y_train[query_idx]\n",
        "    for data, label in zip(x_temp, y_temp):\n",
        "        if distribution[label]<data_per_class:\n",
        "            x_initial.append(data)\n",
        "            y_initial.append(label)\n",
        "            distribution[label]+=1\n",
        "            if distribution[label]==data_per_class:\n",
        "                flag+=1\n",
        "        if flag==10:\n",
        "            break\n",
        "    del x_temp, y_temp\n",
        "    print(y_initial)\n",
        "    counter = collections.Counter(y_initial)\n",
        "    print(counter)\n",
        "    filename = \"CNN_model.joblib\"\n",
        "    classifier = joblib.load(filename)\n",
        "    x_initial= np.array(x_initial)\n",
        "    y_initial = np.array(y_initial)\n",
        "    new_learner = ActiveLearner(\n",
        "        estimator = classifier,\n",
        "        query_strategy = uncertainty_sampling,\n",
        "        X_training = x_initial, y_training = y_initial,\n",
        "    )\n",
        "    print(new_learner.score(x_test, y_test))\n",
        "    y_pred = new_learner.predict(x_test)\n",
        "    print(\"Confusion Matrix after training the model with most important dataset\")\n",
        "    CF_Print(y_test, y_pred)\n",
        "AL_Retrain(100, 20, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC6yl9M0XtBf",
        "outputId": "92c41e92-5ffb-4abb-f827-760d7d82e7ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3049\u001b[0m  0.2824\n",
            "      2        3.7498  0.2715\n",
            "      3        3.0754  0.2656\n",
            "      4        \u001b[36m2.2980\u001b[0m  0.2738\n",
            "      5        2.3014  0.2711\n",
            "      6        2.2987  0.2666\n",
            "      7        \u001b[36m2.2629\u001b[0m  0.2763\n",
            "      8        \u001b[36m2.1922\u001b[0m  0.2598\n",
            "      9        \u001b[36m2.0924\u001b[0m  0.2731\n",
            "     10        2.1317  0.2590\n",
            "No of initial data:  100\n",
            "0.1616\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[ 26   1  10  20   0   8   0   0 408  27]\n",
            " [ 23   0   6  32   0  49   0   0 256 134]\n",
            " [ 46   0  17  70   2  66   0   0 237  62]\n",
            " [ 46   0   7  60   0 127   0   0 188  72]\n",
            " [ 42   0  29 116   0  88   0   0 169  56]\n",
            " [ 50   0   9  49   1 137   0   0 211  43]\n",
            " [ 42   0  16  73   0 117   0   0 126 126]\n",
            " [ 86   0  17  35   0  88   1   0 191  82]\n",
            " [  7   0   6  19   0  14   0   0 427  27]\n",
            " [ 28   0   2  12   0  19   0   0 298 141]]\n",
            "Accuracy:  0.1616\n",
            "Macro F1-score:  0.09662270490095183\n",
            "Micro F1-score:  0.1616\n",
            "Weighted F1-score:  0.09662270490095183\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[2, 5, 2, 4, 6, 4, 7, 4, 4, 5, 6, 2, 4, 6, 6, 7, 2, 7, 4, 6, 6, 6, 6, 2, 2, 2, 6, 2, 6, 4, 4, 7, 4, 4, 8, 7, 5, 5, 1, 0, 2, 2, 3, 5, 7, 7, 1, 7, 0, 5, 3, 5, 7, 7, 5, 0, 0, 5, 3, 5, 3, 0, 3, 0, 1, 3, 3, 8, 3, 0, 0, 0, 0, 3, 3]\n",
            "Counter({2: 10, 5: 10, 4: 10, 6: 10, 7: 10, 0: 10, 3: 10, 1: 3, 8: 2})\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3108\u001b[0m  0.5343\n",
            "      2        9.2590  0.2144\n",
            "      3        3.9220  0.2090\n",
            "      4        \u001b[36m2.2934\u001b[0m  0.1987\n",
            "      5        2.2952  0.2038\n",
            "      6        \u001b[36m2.2554\u001b[0m  0.1996\n",
            "      7        \u001b[36m2.2114\u001b[0m  0.2121\n",
            "      8        \u001b[36m2.2039\u001b[0m  0.2208\n",
            "      9        \u001b[36m2.1691\u001b[0m  0.3063\n",
            "     10        \u001b[36m2.1652\u001b[0m  0.3178\n",
            "0.0946\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[  0   0 374  17   1 108   0   0   0   0]\n",
            " [  0   0 345  39   6 110   0   0   0   0]\n",
            " [  0   0 278  86   3 133   0   0   0   0]\n",
            " [  0   0 290  59   4 147   0   0   0   0]\n",
            " [  0   0 249 114   8 129   0   0   0   0]\n",
            " [  0   0 328  42   2 128   0   0   0   0]\n",
            " [  0   0 187 170  11 132   0   0   0   0]\n",
            " [  0   0 310  49   6 135   0   0   0   0]\n",
            " [  0   0 398   8   1  93   0   0   0   0]\n",
            " [  0   0 353  22   2 123   0   0   0   0]]\n",
            "Accuracy:  0.0946\n",
            "Macro F1-score:  0.04373296244930386\n",
            "Micro F1-score:  0.0946\n",
            "Weighted F1-score:  0.04373296244930385\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "---Query no:  1 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3531\u001b[0m  0.3708\n",
            "      2       11.4794  0.3611\n",
            "      3        \u001b[36m2.3338\u001b[0m  0.3548\n",
            "      4        \u001b[36m2.2973\u001b[0m  0.3523\n",
            "      5        \u001b[36m2.2877\u001b[0m  0.3519\n",
            "      6        \u001b[36m2.2667\u001b[0m  0.3513\n",
            "      7        2.3474  0.3469\n",
            "      8        2.3819  0.3724\n",
            "      9        2.5629  0.3471\n",
            "     10        2.4042  0.3473\n",
            "0.1082\n",
            "---Query no:  2 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.6530\u001b[0m  0.4556\n",
            "      2        7.7545  0.4274\n",
            "      3        \u001b[36m2.3224\u001b[0m  0.4310\n",
            "      4        2.3471  0.4260\n",
            "      5        2.3547  0.4174\n",
            "      6        \u001b[36m2.2677\u001b[0m  0.4294\n",
            "      7        \u001b[36m2.2542\u001b[0m  0.4180\n",
            "      8        2.2609  0.4333\n",
            "      9        \u001b[36m2.1378\u001b[0m  0.4179\n",
            "     10        \u001b[36m2.1374\u001b[0m  0.4222\n",
            "0.1582\n",
            "---Query no:  3 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.0905\u001b[0m  0.5998\n",
            "      2        4.1508  0.9855\n",
            "      3        \u001b[36m2.2842\u001b[0m  1.1070\n",
            "      4        2.3784  1.1211\n",
            "      5        2.2855  0.9980\n",
            "      6        \u001b[36m2.2410\u001b[0m  1.5398\n",
            "      7        \u001b[36m2.2092\u001b[0m  1.6759\n",
            "      8        2.2549  0.9509\n",
            "      9        \u001b[36m2.0892\u001b[0m  1.0364\n",
            "     10        \u001b[36m2.0105\u001b[0m  0.7527\n",
            "0.2018\n",
            "---Query no:  4 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.4904\u001b[0m  0.5874\n",
            "      2        \u001b[36m4.4266\u001b[0m  0.5851\n",
            "      3        \u001b[36m2.2832\u001b[0m  0.5869\n",
            "      4        2.8579  0.5899\n",
            "      5        2.3064  0.5785\n",
            "      6        2.2949  0.5693\n",
            "      7        2.2969  0.5681\n",
            "      8        2.2927  0.7279\n",
            "      9        \u001b[36m2.2726\u001b[0m  0.8732\n",
            "     10        \u001b[36m2.2654\u001b[0m  0.8900\n",
            "0.1828\n",
            "---Query no:  5 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.2469\u001b[0m  0.6931\n",
            "      2        \u001b[36m2.8114\u001b[0m  0.6526\n",
            "      3        \u001b[36m2.3031\u001b[0m  0.6578\n",
            "      4        \u001b[36m2.2844\u001b[0m  0.6736\n",
            "      5        \u001b[36m2.2659\u001b[0m  0.6450\n",
            "      6        \u001b[36m2.2417\u001b[0m  0.6824\n",
            "      7        \u001b[36m2.2108\u001b[0m  0.6517\n",
            "      8        \u001b[36m2.1758\u001b[0m  0.6554\n",
            "      9        \u001b[36m2.1352\u001b[0m  0.6702\n",
            "     10        2.1593  0.6512\n",
            "0.1636\n",
            "---Query no:  6 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m8.7328\u001b[0m  0.7703\n",
            "      2        \u001b[36m2.3324\u001b[0m  0.7313\n",
            "      3        2.3573  0.7477\n",
            "      4        2.3857  0.7321\n",
            "      5        \u001b[36m2.3077\u001b[0m  0.7325\n",
            "      6        \u001b[36m2.2996\u001b[0m  0.7179\n",
            "      7        2.3010  0.7306\n",
            "      8        \u001b[36m2.2981\u001b[0m  0.7324\n",
            "      9        2.2982  0.7421\n",
            "     10        \u001b[36m2.2972\u001b[0m  0.7266\n",
            "0.1\n",
            "---Query no:  7 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m7.0455\u001b[0m  0.8458\n",
            "      2        \u001b[36m2.3625\u001b[0m  1.2239\n",
            "      3        \u001b[36m2.2980\u001b[0m  1.2781\n",
            "      4        \u001b[36m2.2944\u001b[0m  0.8518\n",
            "      5        \u001b[36m2.2664\u001b[0m  0.8211\n",
            "      6        \u001b[36m2.2291\u001b[0m  0.8287\n",
            "      7        \u001b[36m2.1832\u001b[0m  0.7864\n",
            "      8        \u001b[36m2.1520\u001b[0m  0.8163\n",
            "      9        \u001b[36m2.0719\u001b[0m  0.8076\n",
            "     10        \u001b[36m2.0426\u001b[0m  0.8024\n",
            "0.1966\n",
            "---Query no:  8 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.5496\u001b[0m  0.9118\n",
            "      2        \u001b[36m2.3136\u001b[0m  0.8823\n",
            "      3        2.3488  0.8710\n",
            "      4        \u001b[36m2.2995\u001b[0m  0.8913\n",
            "      5        2.3156  1.1427\n",
            "      6        2.3000  1.3713\n",
            "      7        \u001b[36m2.2949\u001b[0m  1.0385\n",
            "      8        \u001b[36m2.2933\u001b[0m  0.8824\n",
            "      9        \u001b[36m2.2913\u001b[0m  0.8864\n",
            "     10        \u001b[36m2.2909\u001b[0m  0.8893\n",
            "0.1012\n",
            "---Query no:  9 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.6895\u001b[0m  1.3933\n",
            "      2        \u001b[36m2.4550\u001b[0m  1.5134\n",
            "      3        \u001b[36m2.3312\u001b[0m  0.9597\n",
            "      4        \u001b[36m2.3279\u001b[0m  0.9554\n",
            "      5        \u001b[36m2.2936\u001b[0m  0.9508\n",
            "      6        2.2968  0.9500\n",
            "      7        2.2940  0.9594\n",
            "      8        \u001b[36m2.2928\u001b[0m  0.9473\n",
            "      9        \u001b[36m2.2900\u001b[0m  0.9597\n",
            "     10        \u001b[36m2.2868\u001b[0m  0.9533\n",
            "0.1\n",
            "---Query no:  10 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.8281\u001b[0m  1.2036\n",
            "      2        \u001b[36m2.2932\u001b[0m  1.3862\n",
            "      3        2.3360  1.6126\n",
            "      4        \u001b[36m2.2768\u001b[0m  1.0644\n",
            "      5        \u001b[36m2.2544\u001b[0m  1.0694\n",
            "      6        \u001b[36m2.2178\u001b[0m  1.0716\n",
            "      7        \u001b[36m2.1301\u001b[0m  1.0581\n",
            "      8        \u001b[36m2.1132\u001b[0m  1.0503\n",
            "      9        \u001b[36m2.0825\u001b[0m  1.0635\n",
            "     10        \u001b[36m2.0058\u001b[0m  1.0571\n",
            "0.215\n",
            "---Query no:  11 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.3033\u001b[0m  1.7800\n",
            "      2        \u001b[36m2.2990\u001b[0m  1.3601\n",
            "      3        \u001b[36m2.2834\u001b[0m  1.1295\n",
            "      4        \u001b[36m2.2586\u001b[0m  1.1167\n",
            "      5        \u001b[36m2.2469\u001b[0m  1.1169\n",
            "      6        \u001b[36m2.1760\u001b[0m  1.1225\n",
            "      7        \u001b[36m2.1663\u001b[0m  1.1158\n",
            "      8        \u001b[36m2.0868\u001b[0m  1.1132\n",
            "      9        \u001b[36m2.0828\u001b[0m  1.1054\n",
            "     10        \u001b[36m1.9462\u001b[0m  1.0995\n",
            "0.2112\n",
            "---Query no:  12 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m7.6526\u001b[0m  2.4284\n",
            "      2        \u001b[36m2.3020\u001b[0m  1.1880\n",
            "      3        2.3227  1.1955\n",
            "      4        \u001b[36m2.2947\u001b[0m  1.2006\n",
            "      5        \u001b[36m2.2642\u001b[0m  1.1938\n",
            "      6        \u001b[36m2.2508\u001b[0m  1.1905\n",
            "      7        \u001b[36m2.2000\u001b[0m  1.2009\n",
            "      8        \u001b[36m2.0818\u001b[0m  1.2059\n",
            "      9        \u001b[36m1.9379\u001b[0m  1.2180\n",
            "     10        \u001b[36m1.8701\u001b[0m  1.8214\n",
            "0.2142\n",
            "---Query no:  13 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.5304\u001b[0m  1.2997\n",
            "      2        \u001b[36m2.3188\u001b[0m  1.2623\n",
            "      3        \u001b[36m2.3002\u001b[0m  1.2529\n",
            "      4        \u001b[36m2.3002\u001b[0m  1.8348\n",
            "      5        \u001b[36m2.2852\u001b[0m  1.5763\n",
            "      6        2.2931  1.2432\n",
            "      7        2.2933  1.2361\n",
            "      8        2.2923  1.2687\n",
            "      9        2.2912  1.2690\n",
            "     10        2.2886  1.2433\n",
            "0.1\n",
            "---Query no:  14 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.8882\u001b[0m  1.3920\n",
            "      2        \u001b[36m2.3034\u001b[0m  2.0935\n",
            "      3        \u001b[36m2.2864\u001b[0m  1.4812\n",
            "      4        \u001b[36m2.2429\u001b[0m  1.3425\n",
            "      5        \u001b[36m2.2033\u001b[0m  1.3273\n",
            "      6        \u001b[36m2.0783\u001b[0m  1.3539\n",
            "      7        \u001b[36m2.0727\u001b[0m  1.3625\n",
            "      8        \u001b[36m1.9542\u001b[0m  1.3535\n",
            "      9        \u001b[36m1.7885\u001b[0m  1.3315\n",
            "     10        \u001b[36m1.7332\u001b[0m  1.6475\n",
            "0.2838\n",
            "---Query no:  15 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.3461\u001b[0m  2.1402\n",
            "      2        \u001b[36m2.4257\u001b[0m  1.4184\n",
            "      3        \u001b[36m2.3007\u001b[0m  1.4192\n",
            "      4        \u001b[36m2.2985\u001b[0m  1.4138\n",
            "      5        \u001b[36m2.2976\u001b[0m  1.4191\n",
            "      6        \u001b[36m2.2955\u001b[0m  1.3982\n",
            "      7        \u001b[36m2.2946\u001b[0m  1.4106\n",
            "      8        \u001b[36m2.2937\u001b[0m  2.1885\n",
            "      9        2.2947  1.5303\n",
            "     10        2.2969  1.4032\n",
            "0.1\n",
            "---Query no:  16 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.1863\u001b[0m  1.7675\n",
            "      2        \u001b[36m2.3352\u001b[0m  2.1500\n",
            "      3        \u001b[36m2.3002\u001b[0m  1.4795\n",
            "      4        \u001b[36m2.2951\u001b[0m  1.4715\n",
            "      5        \u001b[36m2.2905\u001b[0m  1.4912\n",
            "      6        \u001b[36m2.2720\u001b[0m  1.4787\n",
            "      7        \u001b[36m2.2530\u001b[0m  1.4923\n",
            "      8        \u001b[36m2.2143\u001b[0m  1.4824\n",
            "      9        \u001b[36m2.2035\u001b[0m  1.8666\n",
            "     10        2.2167  1.9802\n",
            "0.1568\n",
            "---Query no:  17 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.3950\u001b[0m  1.5859\n",
            "      2        \u001b[36m2.3461\u001b[0m  1.5505\n",
            "      3        \u001b[36m2.2974\u001b[0m  1.5423\n",
            "      4        \u001b[36m2.2802\u001b[0m  1.5592\n",
            "      5        2.3014  1.5555\n",
            "      6        2.2911  1.5899\n",
            "      7        2.2805  2.3623\n",
            "      8        \u001b[36m2.2354\u001b[0m  1.5301\n",
            "      9        \u001b[36m2.2319\u001b[0m  1.5532\n",
            "     10        \u001b[36m2.1951\u001b[0m  1.5312\n",
            "0.1858\n",
            "---Query no:  18 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.7329\u001b[0m  1.6641\n",
            "      2        \u001b[36m2.2917\u001b[0m  1.6075\n",
            "      3        2.2962  1.6333\n",
            "      4        \u001b[36m2.2846\u001b[0m  1.6050\n",
            "      5        \u001b[36m2.2560\u001b[0m  1.6268\n",
            "      6        \u001b[36m2.2434\u001b[0m  2.0678\n",
            "      7        \u001b[36m2.1763\u001b[0m  1.9590\n",
            "      8        \u001b[36m2.1728\u001b[0m  1.5939\n",
            "      9        \u001b[36m2.1337\u001b[0m  1.6121\n",
            "     10        \u001b[36m2.0617\u001b[0m  1.6108\n",
            "0.1706\n",
            "---Query no:  19 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.9118\u001b[0m  1.7427\n",
            "      2        \u001b[36m2.3057\u001b[0m  1.7221\n",
            "      3        \u001b[36m2.2940\u001b[0m  2.5426\n",
            "      4        \u001b[36m2.2849\u001b[0m  1.6923\n",
            "      5        \u001b[36m2.2577\u001b[0m  1.6876\n",
            "      6        \u001b[36m2.2075\u001b[0m  1.7098\n",
            "      7        \u001b[36m2.1352\u001b[0m  1.6889\n",
            "      8        \u001b[36m2.0983\u001b[0m  1.7122\n",
            "      9        \u001b[36m2.0495\u001b[0m  1.8446\n",
            "     10        \u001b[36m1.9989\u001b[0m  2.3454\n",
            "0.2584\n",
            "---Query no:  20 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.3916\u001b[0m  1.8223\n",
            "      2        \u001b[36m2.3098\u001b[0m  1.8169\n",
            "      3        \u001b[36m2.3094\u001b[0m  1.7964\n",
            "      4        \u001b[36m2.2903\u001b[0m  1.7718\n",
            "      5        \u001b[36m2.2732\u001b[0m  2.1250\n",
            "      6        \u001b[36m2.2328\u001b[0m  2.2924\n",
            "      7        \u001b[36m2.1784\u001b[0m  1.7843\n",
            "      8        \u001b[36m2.1327\u001b[0m  1.7908\n",
            "      9        \u001b[36m2.0891\u001b[0m  1.7862\n",
            "     10        \u001b[36m2.0582\u001b[0m  1.7848\n",
            "0.1918\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[  5  60 119  29 168   4  65  21   7  22]\n",
            " [  5 222  71  19  25   6  58  11  24  59]\n",
            " [  4  31 129  16 221   4  45  26   7  17]\n",
            " [  7  33 138  60 119  11  65  46  12   9]\n",
            " [  5  13 137  13 239   4  44  31   5   9]\n",
            " [  4  27 146  53 146  12  49  42   7  14]\n",
            " [  3  41 129  18 152   7 112   5  16  17]\n",
            " [  3  32 184  34 119   6  47  64   6   5]\n",
            " [  3 129  99  15 105   1  81   8  35  24]\n",
            " [  4 209  70  31  30   3  51   5  16  81]]\n",
            "Accuracy:  0.1918\n",
            "Macro F1-score:  0.1661345827480468\n",
            "Micro F1-score:  0.1918\n",
            "Weighted F1-score:  0.16613458274804677\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "AL_Retrain(100, 20, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eAiXr1V_cg30",
        "outputId": "72cb2d9a-f4bf-4e03-bdcb-15f66233d34b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.8226\u001b[0m  1.4001\n",
            "      2        \u001b[36m2.3034\u001b[0m  1.9829\n",
            "      3        2.3042  1.2764\n",
            "      4        2.3268  1.2762\n",
            "      5        \u001b[36m2.2892\u001b[0m  1.2707\n",
            "      6        \u001b[36m2.2700\u001b[0m  1.2542\n",
            "      7        \u001b[36m2.2406\u001b[0m  1.2613\n",
            "      8        \u001b[36m2.2304\u001b[0m  1.2793\n",
            "      9        \u001b[36m2.2006\u001b[0m  1.2614\n",
            "     10        \u001b[36m2.1955\u001b[0m  1.3281\n",
            "No of initial data:  500\n",
            "0.2026\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[138  68   0   0  77  33   3  57  10 114]\n",
            " [ 16 154   0   0  59  41   3  55   6 166]\n",
            " [ 67  53   0   0  91  93   9 117   6  64]\n",
            " [ 32  52   0   0  84 160   3  95   2  72]\n",
            " [ 28  40   0   0  95 149  10  96   0  82]\n",
            " [ 38  62   0   0  82 176   4  75   2  61]\n",
            " [  9  80   0   0  91 117  19 121   0  63]\n",
            " [ 12  66   0   0  58 104   5 113   0 142]\n",
            " [ 87  85   0   0  46  42   0  35  15 190]\n",
            " [  9  88   0   0  29  16   0  49   6 303]]\n",
            "Accuracy:  0.2026\n",
            "Macro F1-score:  0.1584635099533988\n",
            "Micro F1-score:  0.2026\n",
            "Weighted F1-score:  0.15846350995339878\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[4, 6, 3, 3, 4, 2, 1, 2, 7, 4, 4, 7, 5, 6, 6, 4, 4, 4, 0, 6, 4, 7, 2, 6, 2, 3, 4, 4, 6, 3, 6, 1, 5, 6, 9, 2, 2, 6, 1, 6, 6, 4, 5, 3, 3, 2, 4, 4, 2, 6, 6, 4, 0, 4, 3, 6, 4, 4, 6, 4, 5, 9, 2, 5, 6, 3, 6, 4, 3, 3, 4, 4, 3, 2, 7, 2, 0, 8, 2, 3, 3, 6, 3, 2, 4, 5, 3, 6, 0, 6, 3, 2, 6, 3, 6, 3, 1, 2, 2, 8, 7, 4, 7, 4, 3, 4, 4, 2, 4, 6, 4, 6, 1, 6, 3, 2, 6, 6, 2, 3, 2, 4, 6, 5, 4, 6, 6, 6, 2, 7, 6, 2, 5, 4, 6, 4, 5, 5, 3, 2, 2, 6, 7, 4, 5, 6, 1, 4, 2, 2, 2, 4, 2, 6, 7, 4, 4, 1, 0, 3, 4, 4, 2, 5, 4, 6, 2, 2, 2, 2, 5, 6, 5, 3, 5, 3, 4, 2, 4, 6, 6, 9, 6, 6, 4, 6, 3, 1, 3, 4, 6, 6, 2, 6, 9, 3, 6, 3, 6, 6, 3, 6, 7, 0, 3, 2, 1, 3, 4, 1, 3, 4, 4, 2, 5, 5, 2, 4, 4, 4, 5, 3, 1, 7, 2, 2, 2, 3, 2, 2, 5, 2, 2, 2, 2, 1, 9, 1, 5, 7, 1, 9, 2, 5, 3, 7, 2, 2, 3, 7, 8, 3, 7, 7, 3, 3, 3, 5, 9, 3, 9, 3, 3, 7, 1, 7, 5, 3, 3, 5, 7, 5, 5, 3, 5, 5, 3, 1, 3, 1, 3, 7, 1, 5, 5, 9, 0, 5, 5, 0, 9, 1, 0, 5, 5, 7, 5, 1, 7, 9, 1, 7, 5, 5, 9, 7, 1, 7, 5, 5, 1, 5, 5, 8, 0, 5, 7, 1, 5, 5, 9, 7, 7, 5, 7, 1, 5, 0, 1, 0, 8, 5, 0, 1, 0, 5, 9, 1, 5, 5, 1, 7, 1, 8, 1, 1, 1, 7, 1, 0, 7, 7, 9, 9, 9, 0, 9, 9, 7, 0, 0, 7, 1, 8, 7, 8, 1, 0, 7, 9, 0, 7, 7, 1, 9, 7, 7, 7, 8, 7, 8, 1, 1, 8, 1, 7, 1, 7, 9, 7, 0, 1, 0, 0, 1, 1, 7, 9, 0, 7, 8, 8, 8, 8, 0, 7, 0, 9, 0, 1, 7, 8, 9, 1, 1, 0, 1, 1, 0, 0, 0, 0, 8, 8, 8, 0, 0, 9, 1, 0, 9, 8, 8, 9, 9, 0, 8, 9, 9, 9, 8, 0, 8, 9, 0, 9, 0, 0, 8, 9, 8, 9, 0, 9, 8, 9, 0, 0, 8, 9, 9, 8, 9, 0, 0, 8, 9, 9, 9, 9, 9, 8, 9, 0, 9, 0, 9, 0, 9, 8, 0, 0, 8, 8, 8]\n",
            "Counter({4: 50, 6: 50, 3: 50, 2: 50, 1: 50, 7: 50, 5: 50, 0: 50, 9: 50, 8: 35})\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m7.1953\u001b[0m  1.2766\n",
            "      2        \u001b[36m2.3778\u001b[0m  1.2321\n",
            "      3        \u001b[36m2.3345\u001b[0m  1.2255\n",
            "      4        \u001b[36m2.3110\u001b[0m  1.2166\n",
            "      5        \u001b[36m2.3029\u001b[0m  1.3703\n",
            "      6        \u001b[36m2.2962\u001b[0m  1.8860\n",
            "      7        2.3679  1.2216\n",
            "      8        \u001b[36m2.2919\u001b[0m  1.2294\n",
            "      9        2.3213  1.2287\n",
            "     10        2.3286  1.2106\n",
            "0.0998\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[499   1   0   0   0   0   0   0   0   0]\n",
            " [499   0   0   0   0   1   0   0   0   0]\n",
            " [500   0   0   0   0   0   0   0   0   0]\n",
            " [500   0   0   0   0   0   0   0   0   0]\n",
            " [500   0   0   0   0   0   0   0   0   0]\n",
            " [500   0   0   0   0   0   0   0   0   0]\n",
            " [500   0   0   0   0   0   0   0   0   0]\n",
            " [499   0   0   0   0   1   0   0   0   0]\n",
            " [500   0   0   0   0   0   0   0   0   0]\n",
            " [500   0   0   0   0   0   0   0   0   0]]\n",
            "Accuracy:  0.0998\n",
            "Macro F1-score:  0.01815535746770966\n",
            "Micro F1-score:  0.0998\n",
            "Weighted F1-score:  0.01815535746770966\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "---Query no:  1 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m6.0034\u001b[0m  1.9883\n",
            "      2        \u001b[36m2.3063\u001b[0m  1.4986\n",
            "      3        2.5412  1.3387\n",
            "      4        2.3221  1.3155\n",
            "      5        \u001b[36m2.3044\u001b[0m  1.3118\n",
            "      6        \u001b[36m2.3042\u001b[0m  1.3126\n",
            "      7        \u001b[36m2.2995\u001b[0m  1.3301\n",
            "      8        \u001b[36m2.2977\u001b[0m  1.3101\n",
            "      9        \u001b[36m2.2703\u001b[0m  1.4935\n",
            "     10        2.3028  1.9409\n",
            "0.1136\n",
            "---Query no:  2 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.3382\u001b[0m  1.4187\n",
            "      2        \u001b[36m2.3103\u001b[0m  1.3881\n",
            "      3        2.3840  1.3881\n",
            "      4        \u001b[36m2.3009\u001b[0m  1.3673\n",
            "      5        2.3401  1.3813\n",
            "      6        2.3019  1.3842\n",
            "      7        2.3029  1.5544\n",
            "      8        2.3036  2.0037\n",
            "      9        2.3037  1.3896\n",
            "     10        2.3037  1.3624\n",
            "0.1\n",
            "---Query no:  3 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.2374\u001b[0m  1.4532\n",
            "      2        \u001b[36m2.3284\u001b[0m  1.4206\n",
            "      3        \u001b[36m2.3045\u001b[0m  1.4313\n",
            "      4        \u001b[36m2.3035\u001b[0m  1.4451\n",
            "      5        \u001b[36m2.3003\u001b[0m  1.7760\n",
            "      6        \u001b[36m2.2992\u001b[0m  1.9190\n",
            "      7        \u001b[36m2.2960\u001b[0m  1.4166\n",
            "      8        \u001b[36m2.2926\u001b[0m  1.4202\n",
            "      9        \u001b[36m2.2769\u001b[0m  1.4337\n",
            "     10        \u001b[36m2.2704\u001b[0m  1.4217\n",
            "0.1048\n",
            "---Query no:  4 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.5041\u001b[0m  1.5286\n",
            "      2        \u001b[36m2.3182\u001b[0m  1.6374\n",
            "      3        \u001b[36m2.3038\u001b[0m  2.1437\n",
            "      4        \u001b[36m2.3032\u001b[0m  1.4829\n",
            "      5        \u001b[36m2.3024\u001b[0m  1.4787\n",
            "      6        \u001b[36m2.3024\u001b[0m  1.4923\n",
            "      7        \u001b[36m2.3011\u001b[0m  1.4846\n",
            "      8        \u001b[36m2.3007\u001b[0m  1.4805\n",
            "      9        2.3008  1.4728\n",
            "     10        2.3012  1.8599\n",
            "0.1\n",
            "---Query no:  5 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.7195\u001b[0m  1.8500\n",
            "      2        \u001b[36m2.3260\u001b[0m  1.5317\n",
            "      3        \u001b[36m2.2959\u001b[0m  1.5281\n",
            "      4        \u001b[36m2.2917\u001b[0m  1.5384\n",
            "      5        \u001b[36m2.2743\u001b[0m  1.5201\n",
            "      6        \u001b[36m2.2278\u001b[0m  1.5163\n",
            "      7        \u001b[36m2.2112\u001b[0m  1.6160\n",
            "      8        \u001b[36m2.1718\u001b[0m  2.2295\n",
            "      9        2.1797  1.5317\n",
            "     10        \u001b[36m2.1650\u001b[0m  1.5293\n",
            "0.1966\n",
            "---Query no:  6 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.4139\u001b[0m  1.6079\n",
            "      2        \u001b[36m2.3102\u001b[0m  1.5704\n",
            "      3        \u001b[36m2.2994\u001b[0m  1.5778\n",
            "      4        \u001b[36m2.2689\u001b[0m  1.6604\n",
            "      5        \u001b[36m2.2274\u001b[0m  2.3011\n",
            "      6        \u001b[36m2.1906\u001b[0m  1.5655\n",
            "      7        \u001b[36m2.0705\u001b[0m  1.5819\n",
            "      8        \u001b[36m2.0698\u001b[0m  1.5644\n",
            "      9        \u001b[36m2.0281\u001b[0m  1.5794\n",
            "     10        \u001b[36m1.9164\u001b[0m  1.5629\n",
            "0.2504\n",
            "---Query no:  7 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.1643\u001b[0m  1.8885\n",
            "      2        \u001b[36m2.3074\u001b[0m  2.1960\n",
            "      3        \u001b[36m2.3068\u001b[0m  1.6069\n",
            "      4        \u001b[36m2.3021\u001b[0m  1.6235\n",
            "      5        \u001b[36m2.3013\u001b[0m  1.6344\n",
            "      6        \u001b[36m2.3011\u001b[0m  1.6197\n",
            "      7        \u001b[36m2.3008\u001b[0m  1.6292\n",
            "      8        2.3013  1.8039\n",
            "      9        \u001b[36m2.2997\u001b[0m  2.2306\n",
            "     10        2.3006  1.6227\n",
            "0.1\n",
            "---Query no:  8 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.2227\u001b[0m  1.7191\n",
            "      2        \u001b[36m2.3144\u001b[0m  1.7075\n",
            "      3        \u001b[36m2.2959\u001b[0m  1.6963\n",
            "      4        2.3202  1.6828\n",
            "      5        \u001b[36m2.2352\u001b[0m  2.1996\n",
            "      6        \u001b[36m2.1781\u001b[0m  2.0216\n",
            "      7        2.1833  1.6949\n",
            "      8        2.1950  1.6986\n",
            "      9        \u001b[36m2.1276\u001b[0m  1.6662\n",
            "     10        \u001b[36m2.0166\u001b[0m  1.6913\n",
            "0.256\n",
            "---Query no:  9 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.2423\u001b[0m  1.8152\n",
            "      2        \u001b[36m2.3005\u001b[0m  2.5289\n",
            "      3        2.3050  1.7318\n",
            "      4        \u001b[36m2.2666\u001b[0m  1.7158\n",
            "      5        \u001b[36m2.2058\u001b[0m  1.7278\n",
            "      6        \u001b[36m2.1364\u001b[0m  1.7335\n",
            "      7        \u001b[36m2.0885\u001b[0m  1.7243\n",
            "      8        \u001b[36m2.0303\u001b[0m  2.1690\n",
            "      9        \u001b[36m1.9845\u001b[0m  2.1173\n",
            "     10        \u001b[36m1.9359\u001b[0m  1.7455\n",
            "0.2384\n",
            "---Query no:  10 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m7.1904\u001b[0m  1.8064\n",
            "      2        \u001b[36m2.3062\u001b[0m  1.7975\n",
            "      3        2.3112  1.8028\n",
            "      4        \u001b[36m2.2902\u001b[0m  2.0052\n",
            "      5        \u001b[36m2.2621\u001b[0m  2.3631\n",
            "      6        \u001b[36m2.2178\u001b[0m  1.7810\n",
            "      7        \u001b[36m2.1791\u001b[0m  1.7658\n",
            "      8        \u001b[36m2.0839\u001b[0m  1.7835\n",
            "      9        \u001b[36m1.9890\u001b[0m  1.7723\n",
            "     10        \u001b[36m1.9091\u001b[0m  1.7880\n",
            "0.215\n",
            "---Query no:  11 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.2480\u001b[0m  2.2223\n",
            "      2        \u001b[36m2.3046\u001b[0m  1.8262\n",
            "      3        \u001b[36m2.3026\u001b[0m  1.8346\n",
            "      4        \u001b[36m2.2924\u001b[0m  1.8476\n",
            "      5        \u001b[36m2.2639\u001b[0m  1.8522\n",
            "      6        \u001b[36m2.2363\u001b[0m  2.0695\n",
            "      7        \u001b[36m2.2083\u001b[0m  2.4237\n",
            "      8        \u001b[36m2.1875\u001b[0m  1.8538\n",
            "      9        \u001b[36m2.1567\u001b[0m  1.8768\n",
            "     10        2.1864  1.8159\n",
            "0.2476\n",
            "---Query no:  12 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m7.5782\u001b[0m  1.9295\n",
            "      2        \u001b[36m2.3552\u001b[0m  2.0922\n",
            "      3        \u001b[36m2.2925\u001b[0m  2.4804\n",
            "      4        \u001b[36m2.2793\u001b[0m  1.9058\n",
            "      5        \u001b[36m2.2556\u001b[0m  1.8839\n",
            "      6        \u001b[36m2.2332\u001b[0m  1.8839\n",
            "      7        \u001b[36m2.2019\u001b[0m  1.8736\n",
            "      8        \u001b[36m2.1738\u001b[0m  2.0209\n",
            "      9        \u001b[36m2.1496\u001b[0m  2.5422\n",
            "     10        \u001b[36m2.0932\u001b[0m  1.8653\n",
            "0.1774\n",
            "---Query no:  13 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.2456\u001b[0m  1.9586\n",
            "      2        \u001b[36m2.3286\u001b[0m  1.9289\n",
            "      3        \u001b[36m2.2979\u001b[0m  1.9291\n",
            "      4        \u001b[36m2.2660\u001b[0m  2.2193\n",
            "      5        \u001b[36m2.2045\u001b[0m  2.4442\n",
            "      6        \u001b[36m2.1404\u001b[0m  1.9406\n",
            "      7        \u001b[36m2.0703\u001b[0m  1.9296\n",
            "      8        \u001b[36m1.9916\u001b[0m  1.9255\n",
            "      9        \u001b[36m1.8617\u001b[0m  1.9382\n",
            "     10        \u001b[36m1.7466\u001b[0m  2.3139\n",
            "0.3014\n",
            "---Query no:  14 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.0916\u001b[0m  2.1688\n",
            "      2        \u001b[36m2.3154\u001b[0m  1.9866\n",
            "      3        \u001b[36m2.3034\u001b[0m  1.9931\n",
            "      4        \u001b[36m2.3022\u001b[0m  2.0057\n",
            "      5        \u001b[36m2.3015\u001b[0m  1.9818\n",
            "      6        \u001b[36m2.3011\u001b[0m  2.8111\n",
            "      7        \u001b[36m2.3009\u001b[0m  1.9692\n",
            "      8        2.3011  1.9732\n",
            "      9        2.3015  1.9710\n",
            "     10        2.3020  1.9968\n",
            "0.1\n",
            "---Query no:  15 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m7.0822\u001b[0m  2.2891\n",
            "      2        \u001b[36m2.3045\u001b[0m  2.6205\n",
            "      3        \u001b[36m2.3006\u001b[0m  2.0302\n",
            "      4        \u001b[36m2.2998\u001b[0m  2.0258\n",
            "      5        \u001b[36m2.2988\u001b[0m  2.0540\n",
            "      6        2.3001  2.0374\n",
            "      7        2.3006  2.7002\n",
            "      8        2.3009  2.2019\n",
            "      9        2.3019  2.0563\n",
            "     10        2.3022  2.0366\n",
            "0.1\n",
            "---Query no:  16 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m6.3311\u001b[0m  2.1233\n",
            "      2        \u001b[36m2.3084\u001b[0m  2.0940\n",
            "      3        \u001b[36m2.3026\u001b[0m  2.8671\n",
            "      4        2.3062  2.0855\n",
            "      5        \u001b[36m2.3011\u001b[0m  2.0780\n",
            "      6        \u001b[36m2.3001\u001b[0m  2.0712\n",
            "      7        \u001b[36m2.2990\u001b[0m  2.0618\n",
            "      8        2.3013  2.6333\n",
            "      9        2.2997  2.3079\n",
            "     10        2.3020  2.1090\n",
            "0.1\n",
            "---Query no:  17 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.9356\u001b[0m  2.1659\n",
            "      2        \u001b[36m2.3216\u001b[0m  2.1366\n",
            "      3        \u001b[36m2.3055\u001b[0m  2.7387\n",
            "      4        \u001b[36m2.2682\u001b[0m  2.3678\n",
            "      5        \u001b[36m2.2133\u001b[0m  2.1338\n",
            "      6        \u001b[36m2.1397\u001b[0m  2.1512\n",
            "      7        \u001b[36m2.0938\u001b[0m  2.1437\n",
            "      8        \u001b[36m2.0556\u001b[0m  2.3507\n",
            "      9        \u001b[36m2.0292\u001b[0m  2.7428\n",
            "     10        2.0569  2.1395\n",
            "0.2534\n",
            "---Query no:  18 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.7439\u001b[0m  2.2135\n",
            "      2        \u001b[36m2.2989\u001b[0m  2.1956\n",
            "      3        \u001b[36m2.2065\u001b[0m  2.3144\n",
            "      4        \u001b[36m2.1614\u001b[0m  2.8891\n",
            "      5        \u001b[36m2.1188\u001b[0m  2.1827\n",
            "      6        \u001b[36m2.0539\u001b[0m  2.1764\n",
            "      7        \u001b[36m2.0177\u001b[0m  2.2005\n",
            "      8        \u001b[36m1.9674\u001b[0m  2.1919\n",
            "      9        \u001b[36m1.9383\u001b[0m  3.0072\n",
            "     10        \u001b[36m1.9004\u001b[0m  2.2069\n",
            "0.271\n",
            "---Query no:  19 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.5097\u001b[0m  2.2668\n",
            "      2        \u001b[36m2.3109\u001b[0m  2.2235\n",
            "      3        \u001b[36m2.2911\u001b[0m  2.2150\n",
            "      4        2.3042  3.0519\n",
            "      5        2.3021  2.2203\n",
            "      6        2.3014  2.2225\n",
            "      7        2.3012  2.2140\n",
            "      8        2.3006  2.2266\n",
            "      9        2.2998  3.0385\n",
            "     10        2.3006  2.2596\n",
            "0.1\n",
            "---Query no:  20 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.1258\u001b[0m  2.3413\n",
            "      2        \u001b[36m2.3815\u001b[0m  2.2798\n",
            "      3        \u001b[36m2.3074\u001b[0m  2.2920\n",
            "      4        \u001b[36m2.2969\u001b[0m  3.0943\n",
            "      5        \u001b[36m2.2963\u001b[0m  2.2895\n",
            "      6        \u001b[36m2.2683\u001b[0m  2.2950\n",
            "      7        \u001b[36m2.2050\u001b[0m  2.2905\n",
            "      8        \u001b[36m2.1974\u001b[0m  2.2733\n",
            "      9        \u001b[36m2.1423\u001b[0m  3.0857\n",
            "     10        \u001b[36m2.0637\u001b[0m  2.3012\n",
            "0.2418\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[236  50  34  17   1  25   0  15  70  52]\n",
            " [114 222  23  30   1   1   5   3  11  90]\n",
            " [ 64  61 174  42   2  55  31  29  14  28]\n",
            " [ 32  83 109  98   2  94  18  21   4  39]\n",
            " [ 47  41 244  34   6  36  24  30  13  25]\n",
            " [ 24  65 117  76   3 140  13  25   7  30]\n",
            " [ 19  93 211  70   0  16  59   9   3  20]\n",
            " [ 47  46 138  64   0  63  17  76   6  43]\n",
            " [165 119  13  20   1  10   3   9  60 100]\n",
            " [106 185  12  20   1   2   9   4  23 138]]\n",
            "Accuracy:  0.2418\n",
            "Macro F1-score:  0.22074598961835717\n",
            "Micro F1-score:  0.2418\n",
            "Weighted F1-score:  0.22074598961835717\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "AL_Retrain(500, 20, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4UhpMmBfiCo9",
        "outputId": "115db3d7-8035-4532-d730-efdda533c638"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.8533\u001b[0m  1.2947\n",
            "      2        \u001b[36m2.3080\u001b[0m  1.2721\n",
            "      3        \u001b[36m2.3062\u001b[0m  1.2836\n",
            "      4        \u001b[36m2.2750\u001b[0m  1.2906\n",
            "      5        \u001b[36m2.2544\u001b[0m  1.2680\n",
            "      6        2.2638  1.2771\n",
            "      7        \u001b[36m2.2043\u001b[0m  1.2761\n",
            "      8        \u001b[36m2.1517\u001b[0m  1.8582\n",
            "      9        \u001b[36m2.0162\u001b[0m  1.5069\n",
            "     10        \u001b[36m1.9762\u001b[0m  1.2698\n",
            "No of initial data:  500\n",
            "0.2868\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[228  58   2  14   7  21  20   0 109  41]\n",
            " [ 41 204   3  27   6  28  60   1  52  78]\n",
            " [ 81  32   6  25  48  64 164   7  33  40]\n",
            " [ 51  42   5  53  29 128 124  13  17  38]\n",
            " [ 26  16   3  21  43  87 213   3  45  43]\n",
            " [ 32  35   5  35  25 177 104  11  34  42]\n",
            " [ 10  24   3  27  35  49 312   6   4  30]\n",
            " [ 26  68  10  15  45  64 103  18  28 123]\n",
            " [117  50   1  17   3  42   6   2 204  58]\n",
            " [ 37  99   1  14  13  10  49   6  82 189]]\n",
            "Accuracy:  0.2868\n",
            "Macro F1-score:  0.246772544683648\n",
            "Micro F1-score:  0.2868\n",
            "Weighted F1-score:  0.24677254468364804\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[4, 4, 4, 5, 2, 4, 8, 2, 4, 2, 2, 4, 6, 3, 0, 3, 8, 7, 6, 3, 2, 5, 8, 2, 5, 3, 7, 4, 2, 4, 4, 8, 0, 3, 9, 3, 4, 2, 7, 2, 4, 4, 4, 8, 8, 6, 0, 7, 6, 7, 7, 3, 4, 4, 3, 1, 8, 3, 2, 2, 3, 1, 7, 2, 9, 4, 5, 1, 5, 4, 5, 3, 3, 6, 2, 4, 2, 9, 6, 9, 2, 7, 4, 2, 1, 2, 2, 5, 2, 2, 1, 2, 5, 5, 4, 8, 6, 6, 1, 8, 7, 0, 4, 9, 3, 4, 7, 5, 2, 3, 2, 4, 4, 2, 1, 2, 4, 4, 3, 9, 2, 6, 4, 9, 4, 6, 3, 2, 2, 9, 4, 7, 2, 4, 3, 1, 6, 8, 0, 7, 2, 7, 6, 0, 2, 3, 0, 5, 2, 6, 5, 5, 1, 4, 2, 4, 1, 0, 6, 7, 0, 4, 9, 4, 5, 2, 5, 3, 4, 0, 7, 2, 3, 7, 3, 7, 7, 5, 0, 7, 1, 4, 6, 2, 9, 7, 5, 2, 4, 2, 9, 6, 2, 2, 0, 1, 3, 2, 6, 5, 5, 8, 2, 6, 4, 9, 6, 6, 9, 1, 2, 5, 3, 2, 0, 4, 3, 3, 7, 6, 2, 0, 2, 3, 4, 3, 7, 3, 3, 4, 3, 8, 3, 6, 0, 8, 9, 8, 2, 8, 4, 4, 2, 4, 7, 2, 3, 7, 0, 4, 2, 7, 3, 4, 5, 6, 4, 1, 0, 4, 7, 4, 1, 1, 5, 3, 3, 7, 1, 5, 7, 9, 3, 5, 3, 9, 6, 7, 6, 7, 6, 6, 5, 4, 9, 5, 1, 3, 1, 1, 0, 0, 8, 3, 5, 7, 6, 6, 8, 6, 7, 0, 0, 7, 1, 8, 6, 8, 1, 5, 1, 7, 6, 3, 7, 6, 6, 8, 0, 7, 3, 1, 5, 7, 3, 1, 3, 0, 3, 5, 8, 6, 5, 6, 3, 3, 1, 6, 3, 5, 7, 3, 8, 3, 7, 0, 5, 6, 3, 7, 6, 8, 8, 5, 5, 9, 8, 5, 0, 7, 1, 6, 7, 6, 7, 6, 1, 6, 6, 0, 8, 1, 6, 6, 9, 8, 9, 5, 9, 7, 6, 8, 5, 5, 8, 9, 0, 8, 8, 5, 8, 7, 9, 7, 0, 7, 7, 0, 7, 9, 6, 0, 7, 5, 0, 5, 6, 9, 6, 9, 5, 8, 1, 5, 9, 8, 9, 0, 1, 8, 5, 5, 1, 0, 5, 5, 5, 8, 9, 8, 8, 1, 9, 5, 0, 8, 8, 0, 9, 0, 9, 9, 9, 9, 0, 8, 1, 1, 1, 1, 9, 0, 8, 1, 1, 0, 9, 1, 1, 1, 0, 8, 0, 1, 0, 9, 0, 0, 1, 9, 9, 9, 0, 9, 9, 8, 8, 0, 0, 8, 9, 1, 1, 1, 9, 9, 1, 8, 8, 0, 0, 8, 9, 0, 9, 8, 1, 1, 9, 9]\n",
            "Counter({4: 50, 5: 50, 2: 50, 8: 50, 6: 50, 3: 50, 0: 50, 7: 50, 9: 50, 1: 50})\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m7.1156\u001b[0m  1.3053\n",
            "      2        \u001b[36m2.4173\u001b[0m  1.5817\n",
            "      3        \u001b[36m2.3084\u001b[0m  1.7673\n",
            "      4        \u001b[36m2.3038\u001b[0m  1.2763\n",
            "      5        \u001b[36m2.3029\u001b[0m  1.2648\n",
            "      6        \u001b[36m2.2999\u001b[0m  1.2713\n",
            "      7        \u001b[36m2.2867\u001b[0m  1.2647\n",
            "      8        2.3465  1.2657\n",
            "      9        2.2898  1.2668\n",
            "     10        2.2874  1.2703\n",
            "0.098\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[  4   0   3   0   0   0   1   0  25 467]\n",
            " [  6   2   1   1   0   1   2   0 103 384]\n",
            " [  8   1   5   1   3   2   1   0  30 449]\n",
            " [ 16   1   6   7   4   3   6   0  38 419]\n",
            " [  4   0   4   1   1   4   3   0  24 459]\n",
            " [ 20   0   4   1   6  11   6   0  40 412]\n",
            " [ 18   0   4   5   0   6   7   0  39 421]\n",
            " [  9   0   5   2   4   2   2   0  27 449]\n",
            " [  6   0   3   1   0   2   0   0  54 434]\n",
            " [  6   0   2   2   0   5   0   0  86 399]]\n",
            "Accuracy:  0.098\n",
            "Macro F1-score:  0.041654519376025524\n",
            "Micro F1-score:  0.09800000000000002\n",
            "Weighted F1-score:  0.041654519376025524\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "---Query no:  1 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.8748\u001b[0m  1.3785\n",
            "      2        \u001b[36m2.3108\u001b[0m  1.3564\n",
            "      3        \u001b[36m2.3048\u001b[0m  1.3533\n",
            "      4        \u001b[36m2.3020\u001b[0m  1.3417\n",
            "      5        \u001b[36m2.3014\u001b[0m  1.3657\n",
            "      6        2.3029  2.1797\n",
            "      7        2.3034  2.3185\n",
            "      8        2.3079  1.3454\n",
            "      9        2.3120  1.3596\n",
            "     10        2.3078  1.3686\n",
            "0.1\n",
            "---Query no:  2 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.6466\u001b[0m  1.4703\n",
            "      2        \u001b[36m2.3424\u001b[0m  1.4273\n",
            "      3        \u001b[36m2.2852\u001b[0m  1.4246\n",
            "      4        2.3093  1.5981\n",
            "      5        \u001b[36m2.2615\u001b[0m  2.0682\n",
            "      6        \u001b[36m2.2454\u001b[0m  1.4259\n",
            "      7        \u001b[36m2.2214\u001b[0m  1.4450\n",
            "      8        \u001b[36m2.1733\u001b[0m  1.4110\n",
            "      9        \u001b[36m2.1617\u001b[0m  1.4223\n",
            "     10        \u001b[36m2.1128\u001b[0m  1.4359\n",
            "0.1894\n",
            "---Query no:  3 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.7739\u001b[0m  1.5398\n",
            "      2        \u001b[36m2.3189\u001b[0m  1.9455\n",
            "      3        2.4541  1.8928\n",
            "      4        \u001b[36m2.3003\u001b[0m  1.5039\n",
            "      5        \u001b[36m2.2979\u001b[0m  1.5067\n",
            "      6        \u001b[36m2.2969\u001b[0m  1.4957\n",
            "      7        \u001b[36m2.2916\u001b[0m  1.5162\n",
            "      8        \u001b[36m2.2876\u001b[0m  1.4990\n",
            "      9        2.2937  1.5050\n",
            "     10        \u001b[36m2.2814\u001b[0m  2.2604\n",
            "0.0988\n",
            "---Query no:  4 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.1725\u001b[0m  1.6289\n",
            "      2        \u001b[36m2.3043\u001b[0m  1.5753\n",
            "      3        \u001b[36m2.2963\u001b[0m  1.5998\n",
            "      4        \u001b[36m2.2610\u001b[0m  1.5785\n",
            "      5        \u001b[36m2.1980\u001b[0m  1.5697\n",
            "      6        \u001b[36m2.1845\u001b[0m  1.5838\n",
            "      7        \u001b[36m2.1172\u001b[0m  2.3495\n",
            "      8        \u001b[36m2.0963\u001b[0m  1.6185\n",
            "      9        2.1072  1.5909\n",
            "     10        \u001b[36m2.0459\u001b[0m  1.5772\n",
            "0.2154\n",
            "---Query no:  5 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.3009\u001b[0m  1.6915\n",
            "      2        \u001b[36m2.3308\u001b[0m  1.6459\n",
            "      3        \u001b[36m2.2110\u001b[0m  1.7986\n",
            "      4        2.3394  2.3355\n",
            "      5        2.2417  1.6616\n",
            "      6        \u001b[36m2.1393\u001b[0m  1.6703\n",
            "      7        \u001b[36m2.0450\u001b[0m  1.6377\n",
            "      8        \u001b[36m2.0102\u001b[0m  1.6594\n",
            "      9        \u001b[36m1.9051\u001b[0m  1.6572\n",
            "     10        \u001b[36m1.8994\u001b[0m  1.8889\n",
            "0.3016\n",
            "---Query no:  6 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.1843\u001b[0m  2.0688\n",
            "      2        \u001b[36m2.2931\u001b[0m  1.7399\n",
            "      3        \u001b[36m2.2691\u001b[0m  1.7382\n",
            "      4        2.3143  1.7358\n",
            "      5        \u001b[36m2.2373\u001b[0m  1.7320\n",
            "      6        \u001b[36m2.1679\u001b[0m  1.7489\n",
            "      7        \u001b[36m2.0634\u001b[0m  2.5520\n",
            "      8        2.0886  1.7343\n",
            "      9        \u001b[36m1.9768\u001b[0m  1.7323\n",
            "     10        \u001b[36m1.9234\u001b[0m  1.7233\n",
            "0.2282\n",
            "---Query no:  7 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.9350\u001b[0m  1.8614\n",
            "      2        \u001b[36m2.3152\u001b[0m  1.8169\n",
            "      3        \u001b[36m2.2983\u001b[0m  2.6287\n",
            "      4        2.3092  1.8170\n",
            "      5        2.3057  1.8144\n",
            "      6        2.2997  1.8301\n",
            "      7        2.2996  1.8090\n",
            "      8        2.2993  1.8189\n",
            "      9        2.3001  2.4430\n",
            "     10        \u001b[36m2.2972\u001b[0m  1.9970\n",
            "0.1006\n",
            "---Query no:  8 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m6.5035\u001b[0m  1.8919\n",
            "      2        \u001b[36m2.3207\u001b[0m  1.8798\n",
            "      3        \u001b[36m2.2949\u001b[0m  1.9026\n",
            "      4        \u001b[36m2.2924\u001b[0m  1.9499\n",
            "      5        2.2987  2.6027\n",
            "      6        2.2986  1.8874\n",
            "      7        2.2993  1.8838\n",
            "      8        2.2988  1.8673\n",
            "      9        2.2990  1.8708\n",
            "     10        2.2997  1.8855\n",
            "0.1\n",
            "---Query no:  9 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.5581\u001b[0m  2.7816\n",
            "      2        \u001b[36m2.3030\u001b[0m  1.9587\n",
            "      3        \u001b[36m2.2909\u001b[0m  1.9603\n",
            "      4        \u001b[36m2.2684\u001b[0m  1.9620\n",
            "      5        2.2928  1.9687\n",
            "      6        2.2795  2.1715\n",
            "      7        \u001b[36m2.2515\u001b[0m  2.5700\n",
            "      8        \u001b[36m2.2279\u001b[0m  1.9680\n",
            "      9        2.2279  1.9535\n",
            "     10        \u001b[36m2.1998\u001b[0m  1.9601\n",
            "0.1854\n",
            "---Query no:  10 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m6.4714\u001b[0m  2.0475\n",
            "      2        \u001b[36m2.3129\u001b[0m  2.5757\n",
            "      3        \u001b[36m2.2978\u001b[0m  2.2804\n",
            "      4        2.3009  2.0201\n",
            "      5        \u001b[36m2.2967\u001b[0m  2.0181\n",
            "      6        2.3030  2.0183\n",
            "      7        \u001b[36m2.2874\u001b[0m  2.0166\n",
            "      8        2.2977  2.8518\n",
            "      9        \u001b[36m2.2566\u001b[0m  2.0206\n",
            "     10        \u001b[36m2.2286\u001b[0m  2.0236\n",
            "0.177\n",
            "---Query no:  11 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.7504\u001b[0m  2.1450\n",
            "      2        \u001b[36m2.3110\u001b[0m  2.1164\n",
            "      3        \u001b[36m2.3001\u001b[0m  2.6958\n",
            "      4        \u001b[36m2.2982\u001b[0m  2.3342\n",
            "      5        \u001b[36m2.2958\u001b[0m  2.1118\n",
            "      6        \u001b[36m2.2906\u001b[0m  2.1016\n",
            "      7        \u001b[36m2.2805\u001b[0m  2.0965\n",
            "      8        \u001b[36m2.2751\u001b[0m  2.1752\n",
            "      9        \u001b[36m2.2597\u001b[0m  2.8345\n",
            "     10        2.2606  2.0978\n",
            "0.11\n",
            "---Query no:  12 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.0909\u001b[0m  2.2052\n",
            "      2        \u001b[36m2.2685\u001b[0m  2.1868\n",
            "      3        \u001b[36m2.2486\u001b[0m  2.1676\n",
            "      4        \u001b[36m2.1655\u001b[0m  2.9854\n",
            "      5        \u001b[36m2.1537\u001b[0m  2.1934\n",
            "      6        \u001b[36m2.0879\u001b[0m  2.1933\n",
            "      7        \u001b[36m2.0604\u001b[0m  2.1759\n",
            "      8        \u001b[36m2.0417\u001b[0m  2.1917\n",
            "      9        \u001b[36m2.0070\u001b[0m  2.8796\n",
            "     10        \u001b[36m1.9927\u001b[0m  2.2916\n",
            "0.2558\n",
            "---Query no:  13 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m6.8482\u001b[0m  2.2759\n",
            "      2        \u001b[36m2.2783\u001b[0m  2.2391\n",
            "      3        \u001b[36m2.2692\u001b[0m  2.2421\n",
            "      4        \u001b[36m2.2241\u001b[0m  3.0456\n",
            "      5        \u001b[36m2.1642\u001b[0m  2.3817\n",
            "      6        \u001b[36m2.1105\u001b[0m  2.2345\n",
            "      7        2.1299  2.2340\n",
            "      8        2.1256  2.2482\n",
            "      9        \u001b[36m2.0414\u001b[0m  2.7785\n",
            "     10        \u001b[36m2.0389\u001b[0m  2.4858\n",
            "0.2598\n",
            "---Query no:  14 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.3339\u001b[0m  2.3869\n",
            "      2        \u001b[36m2.3214\u001b[0m  2.3296\n",
            "      3        \u001b[36m2.2984\u001b[0m  2.3309\n",
            "      4        \u001b[36m2.2978\u001b[0m  2.8910\n",
            "      5        \u001b[36m2.2965\u001b[0m  2.5871\n",
            "      6        2.2976  2.3625\n",
            "      7        2.2996  2.3289\n",
            "      8        2.2981  2.3358\n",
            "      9        2.3012  3.0364\n",
            "     10        2.2989  2.4539\n",
            "0.1\n",
            "---Query no:  15 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.2059\u001b[0m  2.4559\n",
            "      2        \u001b[36m2.3073\u001b[0m  2.3781\n",
            "      3        \u001b[36m2.2817\u001b[0m  2.4053\n",
            "      4        \u001b[36m2.2425\u001b[0m  3.2116\n",
            "      5        \u001b[36m2.1560\u001b[0m  2.3981\n",
            "      6        \u001b[36m2.1023\u001b[0m  2.3937\n",
            "      7        \u001b[36m1.9829\u001b[0m  2.4169\n",
            "      8        \u001b[36m1.9399\u001b[0m  2.3987\n",
            "      9        \u001b[36m1.9129\u001b[0m  3.2236\n",
            "     10        1.9177  2.3994\n",
            "0.21\n",
            "---Query no:  16 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.6338\u001b[0m  2.5053\n",
            "      2        \u001b[36m2.3029\u001b[0m  2.4924\n",
            "      3        \u001b[36m2.2976\u001b[0m  2.9588\n",
            "      4        \u001b[36m2.2974\u001b[0m  2.7829\n",
            "      5        \u001b[36m2.2967\u001b[0m  2.5062\n",
            "      6        \u001b[36m2.2950\u001b[0m  2.4736\n",
            "      7        2.2970  2.4814\n",
            "      8        2.2954  3.2926\n",
            "      9        2.2969  2.4658\n",
            "     10        2.2978  2.4883\n",
            "0.1\n",
            "---Query no:  17 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.2202\u001b[0m  2.5707\n",
            "      2        \u001b[36m2.2957\u001b[0m  2.7276\n",
            "      3        2.2983  3.1793\n",
            "      4        2.3004  2.5409\n",
            "      5        2.2994  2.5844\n",
            "      6        2.3000  2.5805\n",
            "      7        2.2996  3.3735\n",
            "      8        2.2974  2.5483\n",
            "      9        2.2978  2.5436\n",
            "     10        2.2959  2.5621\n",
            "0.1004\n",
            "---Query no:  18 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.0015\u001b[0m  2.9607\n",
            "      2        \u001b[36m2.2845\u001b[0m  3.1639\n",
            "      3        \u001b[36m2.2308\u001b[0m  2.6290\n",
            "      4        \u001b[36m2.2300\u001b[0m  2.6402\n",
            "      5        \u001b[36m2.1733\u001b[0m  2.6327\n",
            "      6        \u001b[36m2.0937\u001b[0m  3.4505\n",
            "      7        \u001b[36m2.0517\u001b[0m  2.6211\n",
            "      8        \u001b[36m2.0508\u001b[0m  2.6315\n",
            "      9        \u001b[36m2.0448\u001b[0m  2.6169\n",
            "     10        \u001b[36m1.9397\u001b[0m  3.3780\n",
            "0.2694\n",
            "---Query no:  19 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.6651\u001b[0m  2.8072\n",
            "      2        \u001b[36m2.2999\u001b[0m  2.6998\n",
            "      3        \u001b[36m2.2843\u001b[0m  2.7022\n",
            "      4        \u001b[36m2.2678\u001b[0m  3.1491\n",
            "      5        \u001b[36m2.2301\u001b[0m  3.0831\n",
            "      6        \u001b[36m2.1896\u001b[0m  2.6977\n",
            "      7        \u001b[36m2.1535\u001b[0m  2.6756\n",
            "      8        \u001b[36m2.1194\u001b[0m  2.7672\n",
            "      9        \u001b[36m2.1081\u001b[0m  3.4269\n",
            "     10        \u001b[36m2.0630\u001b[0m  2.7017\n",
            "0.1932\n",
            "---Query no:  20 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.3900\u001b[0m  2.7914\n",
            "      2        \u001b[36m2.3025\u001b[0m  3.0059\n",
            "      3        \u001b[36m2.3006\u001b[0m  3.3322\n",
            "      4        \u001b[36m2.2988\u001b[0m  2.7981\n",
            "      5        \u001b[36m2.2983\u001b[0m  2.7777\n",
            "      6        \u001b[36m2.2973\u001b[0m  2.7862\n",
            "      7        2.2993  3.5481\n",
            "      8        2.2986  2.8056\n",
            "      9        2.2989  2.7657\n",
            "     10        \u001b[36m2.2971\u001b[0m  2.7682\n",
            "0.1\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[  0   0   0 500   0   0   0   0   0   0]\n",
            " [  0   0   0 500   0   0   0   0   0   0]\n",
            " [  0   0   0 500   0   0   0   0   0   0]\n",
            " [  0   0   0 500   0   0   0   0   0   0]\n",
            " [  0   0   0 500   0   0   0   0   0   0]\n",
            " [  0   0   0 500   0   0   0   0   0   0]\n",
            " [  0   0   0 500   0   0   0   0   0   0]\n",
            " [  0   0   0 500   0   0   0   0   0   0]\n",
            " [  0   0   0 500   0   0   0   0   0   0]\n",
            " [  0   0   0 500   0   0   0   0   0   0]]\n",
            "Accuracy:  0.1\n",
            "Macro F1-score:  0.01818181818181818\n",
            "Micro F1-score:  0.10000000000000002\n",
            "Weighted F1-score:  0.01818181818181818\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "AL_Retrain(500, 20,  30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4i3SNoH0iFYv",
        "outputId": "b19abab2-929b-4d52-fc62-8e3e9a2812c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4584\u001b[0m  13.3773\n",
            "      2        \u001b[36m2.2578\u001b[0m  13.4475\n",
            "      3        \u001b[36m2.0809\u001b[0m  13.9700\n",
            "      4        \u001b[36m1.9326\u001b[0m  13.4448\n",
            "      5        \u001b[36m1.8101\u001b[0m  13.3724\n",
            "      6        \u001b[36m1.7354\u001b[0m  13.4063\n",
            "      7        \u001b[36m1.6755\u001b[0m  13.3681\n",
            "      8        \u001b[36m1.5998\u001b[0m  13.4407\n",
            "      9        \u001b[36m1.5699\u001b[0m  13.4212\n",
            "     10        \u001b[36m1.4951\u001b[0m  13.3847\n",
            "No of initial data:  5000\n",
            "0.3948\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[190  36  19   5  11  25  15  42  61  96]\n",
            " [  8 268   2   8   2   8  16  34   3 151]\n",
            " [ 20  19  63  25  79 108  57  83  16  30]\n",
            " [  1  12  20  80  35 149  65  93   7  38]\n",
            " [ 11   5  30  26 117  95  64 107   4  41]\n",
            " [  1  11  24  56  21 211  48 104   8  16]\n",
            " [  1  15  12  51  40  47 249  58   4  23]\n",
            " [  4  12   8  27  25  60  27 288   2  47]\n",
            " [ 65  61   6  11   2  19   9  23 173 131]\n",
            " [  7  72   3  12   3  15  23  24   6 335]]\n",
            "Accuracy:  0.3948\n",
            "Macro F1-score:  0.3811085921322225\n",
            "Micro F1-score:  0.3948\n",
            "Weighted F1-score:  0.3811085921322225\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[1, 6, 4, 8, 2, 2, 7, 2, 7, 6, 7, 6, 3, 1, 4, 5, 3, 1, 8, 0, 8, 2, 5, 3, 3, 3, 6, 4, 4, 6, 1, 1, 4, 3, 3, 5, 0, 4, 4, 0, 3, 4, 2, 2, 2, 7, 3, 3, 4, 4, 3, 1, 7, 1, 1, 5, 6, 8, 2, 4, 4, 3, 3, 1, 4, 0, 0, 0, 5, 2, 7, 4, 8, 9, 2, 0, 5, 0, 3, 1, 7, 3, 6, 4, 5, 2, 2, 6, 5, 4, 8, 0, 8, 3, 4, 2, 5, 6, 1, 3, 7, 4, 0, 0, 4, 0, 4, 4, 2, 8, 2, 3, 6, 2, 7, 2, 8, 6, 6, 4, 0, 8, 4, 2, 2, 3, 9, 8, 5, 4, 3, 2, 3, 0, 4, 4, 2, 6, 7, 4, 6, 2, 2, 2, 0, 2, 2, 6, 8, 2, 0, 9, 5, 1, 7, 6, 6, 5, 0, 5, 3, 4, 9, 3, 6, 2, 5, 2, 2, 1, 4, 3, 2, 3, 2, 4, 4, 3, 4, 5, 7, 5, 9, 8, 3, 6, 0, 2, 5, 0, 1, 4, 8, 9, 3, 1, 9, 4, 6, 8, 8, 3, 4, 0, 6, 6, 3, 2, 5, 3, 2, 0, 5, 2, 3, 2, 4, 8, 5, 2, 2, 2, 6, 2, 5, 5, 0, 7, 4, 0, 3, 8, 1, 2, 8, 3, 0, 2, 7, 7, 2, 8, 7, 1, 5, 7, 6, 8, 0, 9, 2, 5, 3, 4, 5, 4, 2, 1, 0, 5, 7, 2, 5, 1, 7, 8, 0, 3, 7, 4, 3, 7, 4, 8, 0, 4, 7, 5, 4, 4, 6, 9, 6, 3, 6, 3, 4, 3, 4, 3, 0, 3, 9, 6, 4, 6, 2, 5, 4, 3, 4, 6, 6, 7, 2, 5, 4, 4, 2, 0, 3, 5, 8, 9, 2, 6, 0, 1, 5, 9, 8, 0, 4, 4, 7, 4, 2, 8, 7, 4, 0, 2, 1, 2, 1, 8, 8, 2, 9, 6, 2, 6, 7, 4, 2, 5, 0, 5, 2, 2, 4, 3, 5, 2, 8, 4, 3, 3, 3, 2, 2, 3, 0, 2, 2, 5, 2, 8, 2, 2, 3, 4, 7, 0, 6, 4, 5, 8, 4, 8, 0, 6, 4, 5, 7, 5, 2, 8, 0, 3, 9, 2, 2, 4, 8, 4, 0, 0, 5, 8, 0, 6, 8, 6, 6, 0, 6, 0, 6, 2, 4, 6, 6, 3, 7, 9, 0, 8, 0, 8, 4, 3, 7, 1, 4, 2, 2, 7, 6, 5, 5, 3, 9, 4, 5, 5, 8, 4, 8, 7, 4, 4, 0, 0, 9, 3, 2, 8, 5, 4, 2, 3, 2, 2, 3, 9, 3, 4, 7, 6, 0, 6, 2, 1, 6, 9, 8, 6, 0, 0, 2, 6, 0, 5, 5, 2, 8, 6, 4, 5, 4, 5, 6, 2, 3, 8, 6, 0, 2, 4, 2, 5, 6, 3, 3, 4, 0, 3, 7, 1, 7, 1, 9, 4, 6, 7, 8, 5, 0, 8, 0, 7, 4, 8, 7, 8, 5, 6, 7, 2, 6, 5, 4, 4, 3, 4, 0, 7, 7, 2, 0, 1, 2, 2, 7, 2, 7, 9, 0, 8, 0, 6, 7, 3, 5, 4, 2, 6, 2, 0, 3, 8, 4, 6, 5, 5, 2, 2, 5, 7, 6, 5, 2, 6, 6, 7, 5, 6, 6, 2, 6, 1, 7, 2, 6, 4, 3, 2, 7, 0, 1, 6, 6, 5, 4, 3, 4, 6, 7, 2, 6, 1, 6, 7, 7, 8, 7, 8, 7, 5, 9, 3, 7, 1, 9, 3, 8, 6, 0, 5, 2, 8, 8, 6, 3, 7, 2, 9, 6, 0, 6, 2, 2, 3, 9, 2, 2, 4, 4, 8, 0, 3, 4, 3, 6, 6, 3, 6, 5, 8, 8, 6, 3, 5, 3, 5, 7, 0, 6, 2, 2, 8, 8, 6, 5, 8, 7, 6, 4, 8, 1, 4, 6, 0, 9, 0, 6, 8, 6, 6, 9, 7, 7, 2, 5, 3, 9, 9, 6, 0, 2, 0, 5, 6, 4, 2, 2, 5, 2, 3, 0, 6, 2, 8, 7, 0, 2, 2, 7, 8, 2, 8, 5, 8, 2, 6, 4, 4, 0, 0, 2, 3, 0, 3, 5, 5, 2, 4, 2, 3, 5, 2, 0, 2, 6, 3, 5, 8, 8, 6, 3, 5, 3, 5, 5, 3, 4, 6, 2, 0, 2, 3, 6, 4, 6, 8, 4, 5, 7, 7, 4, 3, 3, 4, 9, 2, 2, 2, 2, 7, 7, 2, 9, 5, 5, 7, 0, 3, 3, 7, 6, 2, 5, 3, 3, 3, 4, 1, 2, 6, 7, 1, 0, 2, 6, 4, 3, 4, 4, 1, 3, 5, 6, 4, 2, 5, 3, 6, 2, 2, 4, 6, 2, 0, 5, 5, 0, 2, 0, 0, 2, 5, 6, 1, 8, 2, 6, 4, 3, 8, 6, 8, 8, 2, 7, 6, 1, 3, 2, 6, 3, 6, 8, 8, 6, 7, 2, 3, 3, 5, 5, 6, 2, 6, 4, 3, 3, 7, 4, 7, 2, 4, 2, 7, 4, 2, 0, 9, 2, 3, 7, 3, 0, 2, 6, 8, 3, 0, 2, 6, 3, 5, 7, 2, 0, 2, 4, 9, 1, 4, 3, 9, 4, 5, 5, 5, 3, 7, 7, 6, 6, 2, 6, 4, 5, 0, 3, 5, 8, 0, 6, 9, 8, 0, 0, 5, 7, 2, 3, 7, 3, 2, 4, 1, 4, 5, 6, 9, 1, 6, 2, 5, 4, 5, 7, 0, 7, 4, 3, 2, 2, 7, 5, 8, 5, 8, 2, 6, 2, 0, 4, 8, 0, 4, 2, 1, 3, 2, 2, 2, 2, 4, 3, 1, 2, 1, 6, 2, 3, 4, 8, 7, 4, 2, 2, 3, 4, 9, 4, 6, 3, 4, 4, 2, 2, 2, 2, 6, 0, 8, 6, 4, 3, 2, 6, 9, 4, 8, 3, 1, 4, 8, 5, 9, 3, 7, 9, 6, 3, 8, 0, 9, 4, 2, 4, 6, 1, 5, 2, 4, 3, 1, 2, 6, 6, 7, 8, 6, 3, 4, 5, 2, 6, 2, 5, 7, 2, 6, 0, 6, 2, 6, 7, 5, 3, 2, 8, 1, 2, 6, 0, 2, 7, 7, 3, 8, 7, 6, 8, 6, 6, 2, 5, 3, 2, 9, 8, 0, 4, 2, 4, 6, 6, 4, 7, 2, 6, 5, 0, 2, 2, 2, 2, 4, 6, 2, 8, 2, 2, 7, 4, 2, 1, 1, 6, 0, 2, 7, 2, 6, 4, 2, 7, 4, 1, 4, 6, 4, 7, 9, 2, 1, 3, 3, 5, 5, 2, 1, 3, 7, 5, 5, 5, 4, 2, 7, 8, 4, 4, 0, 3, 4, 0, 4, 6, 7, 2, 2, 8, 1, 5, 2, 3, 5, 5, 2, 0, 9, 0, 4, 4, 9, 3, 2, 2, 3, 2, 4, 6, 8, 7, 4, 1, 3, 0, 5, 5, 0, 6, 1, 6, 4, 4, 6, 4, 2, 2, 6, 4, 2, 4, 2, 4, 4, 0, 5, 2, 2, 6, 4, 4, 2, 7, 6, 3, 4, 4, 0, 2, 2, 8, 7, 3, 4, 5, 0, 6, 4, 4, 2, 2, 2, 9, 1, 4, 3, 6, 1, 2, 8, 7, 7, 4, 6, 0, 6, 5, 2, 3, 8, 3, 1, 5, 3, 4, 9, 3, 4, 5, 6, 0, 4, 3, 4, 4, 3, 1, 4, 0, 9, 5, 2, 4, 6, 2, 8, 1, 0, 3, 5, 1, 4, 5, 0, 2, 5, 0, 2, 5, 4, 1, 3, 2, 6, 0, 2, 4, 3, 5, 7, 3, 4, 9, 2, 2, 2, 4, 4, 6, 0, 2, 2, 8, 6, 6, 7, 4, 5, 6, 6, 5, 6, 5, 4, 3, 4, 2, 3, 4, 5, 4, 0, 3, 1, 2, 4, 6, 0, 1, 4, 1, 3, 4, 6, 3, 3, 6, 4, 9, 2, 0, 8, 6, 0, 3, 0, 4, 2, 6, 6, 4, 4, 0, 6, 5, 0, 3, 5, 6, 4, 1, 8, 4, 2, 3, 5, 3, 2, 7, 2, 6, 4, 0, 6, 2, 0, 0, 9, 6, 0, 2, 8, 1, 6, 8, 1, 4, 3, 5, 9, 1, 3, 8, 8, 2, 5, 1, 3, 1, 5, 2, 4, 2, 2, 4, 0, 3, 8, 4, 5, 2, 8, 3, 4, 2, 2, 5, 0, 3, 6, 1, 8, 3, 5, 8, 4, 4, 0, 2, 5, 6, 2, 6, 0, 7, 3, 5, 3, 2, 8, 2, 3, 8, 2, 8, 9, 4, 8, 0, 1, 4, 0, 0, 8, 7, 0, 2, 6, 4, 9, 2, 0, 4, 4, 4, 8, 5, 0, 8, 2, 3, 6, 0, 0, 1, 8, 2, 0, 6, 0, 1, 0, 0, 2, 2, 4, 6, 7, 6, 4, 5, 4, 0, 6, 4, 4, 8, 7, 0, 3, 0, 3, 9, 1, 7, 8, 3, 2, 9, 4, 5, 5, 0, 2, 4, 4, 2, 2, 5, 7, 9, 4, 8, 4, 2, 4, 0, 0, 2, 5, 8, 6, 6, 6, 2, 3, 8, 3, 2, 1, 4, 4, 4, 7, 4, 6, 9, 3, 8, 9, 0, 2, 0, 1, 8, 0, 5, 0, 8, 7, 8, 8, 8, 8, 1, 5, 2, 4, 1, 7, 3, 9, 5, 4, 6, 0, 0, 4, 9, 4, 8, 6, 0, 2, 5, 8, 5, 2, 5, 6, 6, 5, 2, 5, 0, 2, 2, 3, 8, 0, 0, 9, 0, 5, 9, 4, 7, 6, 6, 4, 6, 2, 0, 4, 7, 6, 7, 2, 6, 3, 8, 2, 6, 0, 4, 2, 0, 6, 3, 1, 0, 6, 2, 2, 9, 8, 2, 5, 4, 5, 4, 1, 4, 6, 4, 0, 8, 1, 3, 3, 7, 6, 4, 1, 1, 9, 5, 3, 4, 5, 2, 2, 4, 3, 7, 0, 6, 2, 0, 8, 2, 5, 2, 3, 6, 6, 3, 8, 4, 7, 9, 3, 0, 3, 9, 6, 2, 6, 3, 1, 0, 0, 9, 6, 5, 2, 5, 6, 2, 9, 2, 4, 3, 7, 5, 3, 4, 4, 7, 6, 8, 2, 9, 7, 2, 4, 2, 6, 0, 2, 1, 6, 5, 4, 4, 6, 6, 4, 4, 7, 6, 9, 8, 0, 6, 9, 9, 0, 6, 6, 4, 6, 8, 2, 0, 0, 4, 4, 2, 7, 4, 2, 7, 0, 0, 5, 2, 1, 9, 8, 0, 0, 3, 6, 4, 8, 7, 3, 3, 2, 7, 1, 4, 4, 1, 4, 2, 2, 4, 8, 3, 3, 2, 3, 4, 0, 9, 9, 6, 5, 2, 9, 3, 9, 7, 2, 8, 6, 7, 0, 4, 0, 6, 1, 4, 1, 6, 2, 8, 0, 4, 5, 7, 7, 0, 7, 4, 3, 0, 8, 8, 0, 8, 4, 7, 2, 4, 3, 1, 2, 6, 3, 4, 7, 1, 4, 6, 2, 2, 5, 8, 7, 9, 4, 7, 4, 0, 0, 6, 4, 9, 0, 3, 3, 3, 5, 4, 2, 0, 1, 2, 6, 8, 0, 6, 3, 8, 6, 6, 4, 8, 0, 8, 4, 9, 2, 6, 6, 2, 6, 1, 2, 2, 2, 2, 2, 3, 8, 6, 2, 0, 1, 9, 6, 0, 2, 0, 3, 2, 8, 0, 4, 5, 8, 4, 4, 9, 4, 0, 4, 6, 1, 3, 3, 3, 2, 2, 3, 3, 1, 8, 5, 2, 0, 9, 8, 5, 3, 6, 0, 4, 4, 0, 2, 2, 9, 6, 6, 2, 5, 4, 5, 9, 0, 2, 2, 4, 5, 8, 5, 4, 7, 7, 0, 2, 1, 9, 2, 9, 0, 8, 3, 6, 2, 7, 8, 1, 6, 6, 2, 4, 8, 1, 1, 3, 3, 5, 4, 1, 0, 3, 6, 7, 4, 0, 4, 7, 8, 4, 7, 6, 4, 7, 3, 2, 2, 9, 5, 3, 8, 3, 3, 9, 4, 9, 6, 3, 3, 4, 0, 7, 3, 5, 0, 5, 4, 4, 6, 3, 6, 1, 3, 7, 5, 2, 6, 2, 4, 1, 8, 9, 7, 2, 4, 2, 1, 6, 7, 0, 4, 6, 4, 6, 2, 5, 5, 6, 5, 5, 0, 2, 4, 7, 4, 0, 6, 2, 6, 3, 1, 4, 6, 2, 6, 3, 6, 0, 7, 0, 5, 6, 6, 0, 2, 8, 9, 9, 8, 3, 4, 5, 2, 9, 0, 5, 7, 5, 0, 0, 2, 0, 2, 0, 8, 4, 8, 2, 9, 6, 2, 6, 8, 9, 8, 4, 7, 0, 4, 9, 7, 3, 2, 2, 6, 3, 4, 8, 4, 5, 5, 6, 3, 8, 6, 3, 6, 6, 3, 6, 3, 4, 4, 2, 7, 6, 8, 5, 1, 3, 3, 3, 3, 9, 8, 8, 8, 2, 0, 6, 6, 5, 2, 5, 2, 5, 3, 0, 6, 2, 9, 4, 6, 2, 2, 7, 4, 6, 5, 5, 2, 9, 1, 7, 3, 7, 1, 2, 1, 8, 9, 0, 9, 2, 0, 0, 8, 6, 7, 4, 2, 5, 3, 8, 8, 4, 2, 5, 1, 7, 3, 3, 4, 6, 1, 0, 5, 3, 3, 3, 4, 7, 4, 9, 6, 7, 2, 6, 8, 6, 6, 2, 3, 4, 4, 4, 4, 3, 5, 7, 1, 3, 3, 9, 7, 2, 2, 0, 0, 4, 1, 5, 9, 7, 3, 0, 9, 7, 8, 5, 5, 6, 2, 3, 4, 4, 2, 8, 5, 5, 2, 5, 2, 3, 3, 4, 8, 8, 8, 2, 2, 0, 3, 3, 6, 0, 2, 4, 6, 5, 9, 3, 5, 5, 6, 2, 7, 0, 4, 4, 5, 0, 6, 8, 0, 3, 5, 3, 4, 8, 4, 3, 3, 3, 9, 7, 2, 5, 9, 0, 5, 9, 1, 8, 6, 6, 3, 5, 9, 6, 9, 3, 6, 5, 4, 6, 8, 6, 3, 8, 7, 6, 5, 5, 4, 9, 8, 7, 4, 3, 8, 6, 7, 7, 3, 1, 2, 6, 1, 7, 4, 5, 3, 3, 4, 0, 3, 8, 4, 5, 3, 3, 3, 2, 4, 6, 7, 7, 5, 4, 3, 7, 7, 3, 3, 1, 4, 3, 0, 0, 3, 4, 4, 8, 2, 4, 2, 5, 4, 8, 8, 7, 6, 8, 2, 1, 8, 1, 5, 4, 2, 8, 5, 4, 5, 4, 2, 6, 8, 2, 9, 0, 8, 8, 6, 2, 8, 0, 3, 2, 6, 6, 6, 6, 6, 8, 6, 5, 6, 3, 8, 9, 3, 4, 3, 0, 2, 7, 2, 2, 5, 9, 5, 2, 3, 8, 3, 0, 8, 9, 7, 2, 6, 3, 0, 5, 3, 5, 5, 8, 3, 4, 6, 2, 8, 8, 2, 2, 5, 5, 0, 3, 5, 0, 2, 5, 4, 5, 5, 1, 2, 0, 3, 2, 3, 1, 3, 2, 2, 4, 4, 8, 3, 0, 2, 7, 4, 8, 6, 4, 6, 6, 1, 3, 3, 4, 5, 2, 9, 4, 4, 0, 3, 6, 6, 2, 4, 5, 3, 0, 7, 3, 0, 2, 4, 3, 2, 6, 5, 4, 0, 0, 9, 6, 4, 9, 6, 2, 2, 2, 4, 0, 8, 6, 2, 2, 3, 5, 8, 0, 4, 8, 1, 5, 4, 0, 8, 5, 0, 2, 8, 8, 4, 8, 8, 4, 0, 2, 3, 4, 8, 0, 3, 8, 0, 7, 3, 6, 4, 6, 6, 9, 6, 2, 9, 4, 5, 9, 4, 8, 0, 2, 4, 6, 4, 1, 3, 4, 8, 2, 0, 4, 2, 0, 9, 6, 5, 6, 5, 2, 0, 2, 0, 2, 3, 3, 8, 0, 0, 2, 3, 6, 3, 6, 3, 6, 4, 3, 3, 4, 3, 6, 7, 5, 6, 8, 7, 4, 0, 6, 7, 4, 4, 8, 9, 7, 8, 8, 9, 0, 5, 5, 6, 1, 7, 8, 3, 2, 3, 0, 9, 0, 0, 0, 2, 4, 2, 9, 5, 5, 2, 4, 2, 2, 2, 6, 7, 3, 2, 4, 3, 0, 6, 2, 6, 7, 2, 6, 7, 6, 4, 2, 7, 3, 2, 3, 8, 5, 7, 0, 7, 7, 0, 8, 3, 3, 4, 4, 3, 2, 5, 5, 7, 4, 5, 3, 9, 4, 6, 2, 0, 4, 3, 6, 8, 4, 4, 6, 6, 2, 2, 8, 4, 2, 9, 4, 0, 3, 2, 0, 0, 4, 0, 2, 5, 5, 1, 4, 6, 0, 2, 0, 8, 0, 0, 5, 2, 7, 8, 7, 4, 8, 0, 0, 4, 2, 6, 1, 2, 9, 5, 6, 8, 4, 3, 1, 2, 4, 8, 4, 0, 6, 0, 4, 0, 2, 2, 3, 4, 3, 4, 4, 0, 8, 6, 7, 4, 9, 3, 6, 5, 4, 0, 2, 2, 6, 4, 4, 2, 7, 8, 3, 5, 3, 3, 3, 8, 4, 8, 3, 6, 8, 6, 0, 5, 0, 6, 8, 7, 0, 4, 2, 6, 5, 8, 4, 2, 9, 3, 0, 8, 3, 7, 3, 2, 6, 0, 3, 9, 0, 4, 4, 0, 3, 9, 4, 6, 6, 5, 4, 9, 7, 2, 0, 7, 6, 1, 0, 4, 5, 7, 7, 6, 3, 0, 2, 4, 2, 2, 0, 2, 2, 7, 8, 7, 5, 2, 6, 5, 2, 4, 2, 0, 6, 3, 5, 6, 4, 2, 3, 6, 4, 4, 9, 4, 4, 5, 9, 5, 0, 9, 6, 3, 2, 8, 3, 6, 0, 6, 7, 4, 6, 6, 6, 1, 2, 6, 4, 2, 2, 9, 5, 2, 9, 4, 5, 4, 1, 7, 4, 3, 2, 2, 1, 4, 6, 2, 5, 8, 5, 5, 0, 6, 5, 6, 3, 4, 5, 6, 2, 4, 6, 0, 7, 0, 5, 8, 0, 1, 4, 2, 3, 5, 8, 8, 0, 1, 9, 3, 7, 3, 2, 3, 2, 5, 6, 4, 0, 3, 0, 0, 8, 6, 4, 4, 3, 4, 5, 5, 2, 1, 9, 8, 0, 2, 3, 4, 9, 0, 3, 3, 4, 5, 3, 2, 2, 6, 1, 4, 8, 1, 3, 5, 4, 7, 0, 1, 8, 2, 5, 5, 6, 9, 3, 0, 8, 4, 2, 6, 3, 0, 6, 4, 5, 4, 9, 4, 4, 2, 2, 3, 1, 6, 2, 1, 2, 3, 4, 5, 8, 2, 2, 4, 7, 0, 0, 3, 0, 2, 6, 2, 2, 0, 7, 2, 2, 5, 0, 3, 2, 0, 8, 8, 3, 2, 4, 2, 2, 0, 7, 4, 4, 3, 4, 0, 3, 2, 7, 3, 0, 0, 6, 6, 2, 4, 3, 4, 5, 9, 3, 2, 0, 2, 3, 6, 5, 3, 8, 3, 4, 0, 3, 8, 2, 2, 6, 1, 9, 5, 0, 6, 4, 4, 6, 0, 5, 3, 6, 3, 3, 2, 3, 4, 4, 3, 3, 1, 8, 5, 4, 0, 9, 6, 0, 6, 3, 6, 7, 7, 7, 3, 4, 8, 9, 1, 4, 0, 0, 3, 8, 5, 6, 4, 3, 5, 8, 1, 6, 1, 6, 6, 7, 4, 4, 1, 5, 3, 5, 7, 6, 4, 6, 1, 5, 4, 8, 5, 5, 7, 3, 3, 3, 8, 6, 4, 4, 3, 7, 8, 1, 8, 5, 7, 3, 8, 4, 7, 4, 0, 0, 4, 7, 7, 0, 5, 3, 7, 9, 5, 4, 5, 6, 3, 8, 3, 0, 4, 0, 6, 5, 6, 4, 0, 6, 5, 3, 3, 0, 6, 5, 6, 7, 6, 7, 8, 6, 4, 6, 7, 8, 5, 0, 7, 6, 6, 9, 6, 9, 4, 9, 5, 7, 4, 8, 6, 7, 9, 0, 4, 5, 0, 9, 1, 3, 4, 8, 5, 3, 4, 8, 3, 0, 7, 6, 5, 0, 6, 6, 4, 7, 7, 6, 5, 0, 4, 4, 3, 5, 6, 6, 5, 0, 6, 7, 7, 3, 5, 3, 9, 4, 4, 7, 8, 7, 6, 6, 1, 3, 1, 8, 3, 3, 4, 4, 8, 5, 0, 5, 0, 1, 6, 7, 0, 8, 6, 4, 6, 0, 6, 6, 9, 5, 9, 3, 6, 9, 4, 1, 4, 8, 4, 7, 6, 3, 5, 4, 3, 0, 4, 6, 5, 5, 5, 5, 0, 5, 6, 5, 0, 8, 7, 0, 4, 5, 5, 4, 4, 4, 4, 4, 5, 3, 3, 6, 6, 8, 4, 3, 5, 4, 9, 4, 0, 8, 6, 9, 5, 7, 3, 4, 9, 0, 6, 7, 6, 8, 3, 8, 1, 7, 0, 5, 3, 0, 6, 0, 3, 7, 6, 3, 7, 1, 5, 1, 3, 8, 5, 3, 3, 9, 7, 8, 3, 3, 0, 7, 5, 8, 6, 1, 8, 3, 8, 7, 6, 3, 3, 9, 5, 3, 5, 0, 5, 5, 5, 6, 8, 8, 6, 6, 5, 3, 8, 0, 0, 3, 3, 5, 7, 0, 8, 3, 9, 3, 0, 6, 3, 3, 6, 5, 6, 0, 7, 8, 3, 9, 0, 7, 6, 5, 6, 9, 3, 3, 1, 6, 8, 3, 3, 5, 9, 3, 5, 8, 6, 8, 9, 3, 9, 8, 6, 7, 0, 9, 6, 9, 6, 0, 0, 0, 6, 1, 0, 7, 6, 1, 8, 3, 5, 5, 7, 0, 6, 5, 3, 3, 6, 5, 8, 0, 8, 8, 1, 6, 3, 1, 1, 5, 8, 5, 0, 3, 5, 8, 1, 7, 1, 3, 9, 9, 8, 6, 7, 6, 5, 5, 5, 3, 0, 7, 0, 5, 7, 1, 0, 3, 7, 3, 1, 5, 3, 7, 7, 5, 6, 6, 3, 9, 9, 5, 3, 3, 5, 7, 1, 9, 6, 3, 3, 5, 3, 6, 1, 5, 8, 5, 7, 1, 6, 6, 7, 3, 0, 6, 0, 5, 6, 6, 6, 1, 8, 8, 5, 7, 3, 3, 6, 5, 5, 3, 3, 7, 5, 9, 8, 3, 3, 8, 5, 6, 8, 6, 3, 6, 5, 1, 0, 9, 7, 0, 7, 3, 6, 1, 1, 0, 3, 1, 6, 9, 7, 6, 3, 8, 0, 3, 3, 5, 5, 6, 5, 3, 3, 9, 8, 6, 3, 6, 7, 9, 5, 7, 5, 8, 6, 1, 5, 0, 1, 0, 9, 8, 5, 5, 6, 7, 5, 7, 6, 5, 0, 3, 5, 5, 5, 8, 8, 9, 7, 7, 8, 6, 3, 6, 3, 7, 9, 3, 9, 5, 8, 0, 1, 3, 3, 9, 1, 8, 8, 3, 0, 6, 7, 3, 6, 0, 7, 0, 3, 5, 7, 6, 8, 8, 3, 8, 6, 9, 8, 8, 0, 6, 0, 8, 8, 9, 5, 5, 8, 3, 1, 5, 6, 3, 6, 3, 5, 8, 5, 6, 0, 0, 3, 1, 3, 3, 3, 5, 8, 5, 0, 6, 5, 8, 3, 6, 9, 5, 1, 1, 3, 9, 8, 0, 0, 5, 0, 9, 9, 6, 8, 5, 5, 0, 5, 1, 6, 5, 7, 0, 6, 8, 8, 0, 1, 6, 3, 5, 6, 5, 3, 1, 5, 3, 3, 6, 9, 1, 6, 1, 3, 1, 0, 3, 5, 8, 0, 9, 5, 3, 0, 7, 8, 5, 9, 3, 5, 7, 3, 0, 9, 5, 8, 0, 5, 7, 8, 7, 7, 8, 9, 0, 3, 3, 0, 9, 8, 8, 0, 0, 5, 9, 0, 5, 1, 3, 3, 1, 7, 5, 3, 5, 5, 0, 8, 7, 1, 9, 5, 0, 7, 8, 0, 0, 9, 7, 0, 0, 9, 5, 7, 5, 5, 0, 5, 7, 5, 5, 5, 9, 9, 1, 1, 0, 0, 0, 7, 1, 0, 7, 0, 0, 7, 1, 0, 7, 7, 0, 8, 9, 5, 8, 0, 8, 7, 1, 0, 7, 0, 0, 7, 1, 0, 9, 8, 8, 5, 5, 1, 5, 0, 0, 9, 8, 7, 9, 5, 8, 0, 8, 1, 7, 8, 5, 9, 0, 1, 0, 0, 0, 7, 0, 8, 5, 9, 8, 7, 8, 0, 9, 0, 5, 9, 8, 1, 8, 0, 0, 0, 0, 5, 0, 5, 5, 9, 5, 5, 1, 8, 0, 5, 0, 0, 7, 9, 7, 0, 0, 0, 9, 5, 0, 5, 8, 0, 0, 7, 9, 7, 0, 5, 5, 8, 9, 8, 7, 0, 9, 8, 9, 5, 5, 7, 7, 7, 1, 0, 7, 0, 9, 8, 5, 1, 1, 9, 0, 5, 5, 5, 5, 8, 5, 9, 1, 8, 0, 5, 5, 5, 9, 5, 0, 7, 0, 5, 7, 9, 0, 5, 1, 7, 1, 9, 8, 7, 0, 0, 0, 1, 9, 7, 9, 0, 0, 5, 0, 5, 0, 1, 7, 8, 1, 7, 5, 5, 0, 5, 0, 9, 0, 7, 9, 8, 1, 0, 5, 8, 5, 0, 5, 5, 8, 0, 0, 9, 0, 8, 5, 0, 5, 9, 5, 1, 5, 0, 5, 1, 5, 0, 5, 0, 8, 9, 5, 9, 5, 5, 0, 0, 5, 8, 9, 1, 9, 9, 8, 1, 5, 5, 7, 0, 7, 0, 5, 1, 0, 5, 5, 5, 7, 1, 8, 1, 0, 0, 9, 0, 8, 8, 0, 1, 9, 9, 0, 1, 5, 5, 9, 0, 7, 1, 8, 7, 1, 1, 1, 0, 5, 5, 5, 7, 7, 1, 8, 7, 8, 1, 9, 1, 7, 5, 5, 5, 8, 5, 7, 8, 5, 5, 8, 9, 7, 7, 8, 5, 5, 9, 7, 8, 7, 5, 5, 8, 1, 7, 5, 8, 9, 9, 7, 8, 9, 1, 7, 9, 8, 7, 8, 8, 8, 8, 8, 7, 9, 7, 1, 7, 7, 7, 7, 8, 1, 7, 8, 9, 7, 9, 7, 9, 8, 8, 7, 9, 7, 8, 1, 7, 7, 9, 7, 1, 8, 1, 1, 8, 7, 1, 8, 1, 8, 1, 9, 7, 9, 7, 8, 8, 9, 7, 7, 1, 7, 9, 1, 7, 9, 8, 7, 8, 1, 7, 9, 7, 1, 8, 7, 8, 7, 7, 7, 7, 9, 7, 8, 9, 7, 7, 9, 1, 9, 7, 8, 7, 9, 1, 7, 8, 8, 9, 7, 8, 7, 8, 9, 8, 1, 7, 7, 1, 8, 8, 1, 8, 1, 8, 8, 9, 8, 7, 9, 8, 7, 8, 9, 7, 7, 7, 7, 9, 9, 8, 8, 1, 7, 8, 8, 8, 7, 7, 8, 7, 9, 8, 7, 9, 8, 9, 1, 8, 7, 1, 7, 1, 1, 1, 8, 8, 7, 8, 7, 9, 7, 7, 8, 7, 7, 9, 8, 7, 8, 7, 1, 7, 7, 1, 8, 1, 8, 9, 7, 9, 8, 1, 8, 7, 7, 9, 9, 7, 8, 1, 8, 9, 7, 8, 9, 8, 8, 9, 9, 9, 8, 9, 8, 8, 1, 1, 7, 8, 7, 1, 8, 7, 8, 9, 7, 8, 7, 8, 7, 7, 8, 7, 7, 1, 9, 9, 7, 1, 7, 7, 8, 9, 1, 8, 9, 1, 7, 9, 1, 9, 1, 7, 7, 7, 9, 7, 8, 7, 7, 1, 9, 7, 7, 7, 1, 7, 7, 7, 8, 8, 9, 9, 8, 9, 7, 8, 7, 9, 1, 7, 7, 8, 1, 1, 9, 1, 8, 8, 7, 8, 9, 7, 7, 1, 1, 9, 8, 7, 9, 1, 8, 8, 8, 9, 8, 7, 7, 7, 7, 8, 8, 7, 8, 8, 8, 7, 7, 7, 7, 8, 8, 8, 7, 7, 9, 9, 8, 8, 7, 7, 7, 1, 7, 7, 8, 7, 8, 7, 7, 9, 1, 7, 7, 8, 8, 9, 7, 9, 8, 8, 7, 1, 1, 8, 7, 9, 1, 7, 7, 1, 7, 7, 7, 7, 7, 1, 9, 1, 7, 1, 7, 9, 9, 9, 9, 1, 9, 9, 7, 7, 7, 9, 1, 9, 7, 7, 9, 1, 7, 1, 1, 7, 7, 1, 7, 7, 7, 7, 1, 7, 1, 1, 1, 7, 9, 1, 1, 7, 1, 1, 7, 1, 1, 9, 1, 9, 7, 7, 7, 7, 7, 9, 1, 9, 7, 1, 7, 1, 7, 1, 9, 9, 9, 9, 1, 9, 9, 1, 9, 9, 9, 9, 1, 1, 1, 1, 1, 9, 9, 9, 9, 1, 9, 1, 9, 1, 9, 1, 9, 1, 1, 9, 9, 1, 9, 9, 1, 1, 9, 1, 9, 1, 9, 1, 1, 1, 9, 1, 1, 9, 1, 1, 9, 9, 1, 9, 9, 9, 1, 1, 1, 9, 9, 9, 1, 9, 9, 1, 9, 1, 9, 1, 9, 9, 1, 1, 1, 9, 1, 1, 1, 1, 9, 9, 1, 9, 9, 9, 9, 1, 1, 9, 1, 9, 9, 1, 1, 9, 1, 9, 1, 9, 9, 9, 9, 9, 9, 1, 9, 1, 9, 1, 1, 9, 9, 9, 9, 1, 1, 9, 1, 1, 1, 1, 9, 9, 9, 9, 1, 9, 9, 1, 1, 9, 9, 9, 9, 1, 9, 1, 9, 9, 9, 1, 1, 1, 1, 1, 9, 1, 9, 9, 9, 9, 1, 9, 1, 1, 1, 9, 1, 9, 9, 1, 9, 1, 1, 1, 1, 9, 1, 1, 9, 1, 1, 1, 1, 9, 9, 9, 9, 1, 1, 1, 9, 9, 9, 9, 9, 9, 9, 1, 9, 9, 9, 1, 9, 1, 9, 1, 1, 9, 9, 1, 1, 9, 1, 9, 1, 9, 1, 1, 9, 9, 9, 1, 1, 9, 9, 9, 1, 1, 9, 1, 1, 9, 1, 9, 1, 1, 1, 1, 9, 9, 9, 9, 9, 1, 9, 9, 9, 9, 9, 9, 1, 9, 1, 9, 9, 9, 9, 1, 1, 1, 9, 9, 9, 9, 9, 1, 9, 9, 9, 1, 1, 1, 9, 9, 9, 9, 1, 9, 1, 9, 1, 1, 1, 1, 1, 9, 9, 1, 1, 1, 1, 9, 9, 9, 9, 1, 9, 9, 9, 9, 9, 1, 9, 9, 1, 1, 9, 1, 9, 9, 9, 9, 9, 1, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Counter({1: 500, 6: 500, 4: 500, 8: 500, 2: 500, 7: 500, 3: 500, 5: 500, 0: 500, 9: 500})\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5364\u001b[0m  13.4675\n",
            "      2        \u001b[36m2.3155\u001b[0m  13.3906\n",
            "      3        \u001b[36m2.3116\u001b[0m  13.3936\n",
            "      4        2.3120  13.4302\n",
            "      5        2.3125  13.5216\n",
            "      6        2.3130  13.4170\n",
            "      7        2.3134  13.5329\n",
            "      8        2.3138  14.1372\n",
            "      9        2.3140  13.4066\n",
            "     10        2.3143  13.4463\n",
            "0.1\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[  0 500   0   0   0   0   0   0   0   0]\n",
            " [  0 500   0   0   0   0   0   0   0   0]\n",
            " [  0 500   0   0   0   0   0   0   0   0]\n",
            " [  0 500   0   0   0   0   0   0   0   0]\n",
            " [  0 500   0   0   0   0   0   0   0   0]\n",
            " [  0 500   0   0   0   0   0   0   0   0]\n",
            " [  0 500   0   0   0   0   0   0   0   0]\n",
            " [  0 500   0   0   0   0   0   0   0   0]\n",
            " [  0 500   0   0   0   0   0   0   0   0]\n",
            " [  0 500   0   0   0   0   0   0   0   0]]\n",
            "Accuracy:  0.1\n",
            "Macro F1-score:  0.01818181818181818\n",
            "Micro F1-score:  0.10000000000000002\n",
            "Weighted F1-score:  0.01818181818181818\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "---Query no:  1 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5388\u001b[0m  13.4930\n",
            "      2        \u001b[36m2.1150\u001b[0m  13.5216\n",
            "      3        \u001b[36m1.9501\u001b[0m  13.4322\n",
            "      4        \u001b[36m1.8314\u001b[0m  13.4089\n",
            "      5        \u001b[36m1.7003\u001b[0m  13.4080\n",
            "      6        \u001b[36m1.6631\u001b[0m  14.0400\n",
            "      7        \u001b[36m1.5716\u001b[0m  13.6945\n",
            "      8        \u001b[36m1.5385\u001b[0m  13.4925\n",
            "      9        \u001b[36m1.5194\u001b[0m  13.4623\n",
            "     10        \u001b[36m1.4418\u001b[0m  13.4140\n",
            "0.424\n",
            "---Query no:  2 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4146\u001b[0m  13.5449\n",
            "      2        \u001b[36m2.3036\u001b[0m  13.5484\n",
            "      3        2.3039  13.5422\n",
            "      4        \u001b[36m2.3036\u001b[0m  13.5437\n",
            "      5        2.3037  13.4898\n",
            "      6        \u001b[36m2.3035\u001b[0m  13.4982\n",
            "      7        \u001b[36m2.3031\u001b[0m  13.5256\n",
            "      8        2.3036  14.0351\n",
            "      9        2.3033  13.7594\n",
            "     10        2.3033  13.4637\n",
            "0.1\n",
            "---Query no:  3 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4358\u001b[0m  14.0665\n",
            "      2        \u001b[36m2.1357\u001b[0m  13.8784\n",
            "      3        \u001b[36m2.0481\u001b[0m  13.5500\n",
            "      4        \u001b[36m2.0243\u001b[0m  14.4464\n",
            "      5        \u001b[36m1.9994\u001b[0m  13.4897\n",
            "      6        \u001b[36m1.9736\u001b[0m  13.5333\n",
            "      7        \u001b[36m1.9356\u001b[0m  13.5767\n",
            "      8        1.9455  13.6142\n",
            "      9        \u001b[36m1.9085\u001b[0m  13.9977\n",
            "     10        \u001b[36m1.8872\u001b[0m  13.9748\n",
            "0.3224\n",
            "---Query no:  4 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4621\u001b[0m  13.5810\n",
            "      2        \u001b[36m2.1377\u001b[0m  14.2273\n",
            "      3        \u001b[36m2.0456\u001b[0m  13.7235\n",
            "      4        2.0542  13.5303\n",
            "      5        \u001b[36m1.9650\u001b[0m  13.4890\n",
            "      6        \u001b[36m1.9309\u001b[0m  13.4952\n",
            "      7        \u001b[36m1.9142\u001b[0m  13.4671\n",
            "      8        1.9190  13.4722\n",
            "      9        \u001b[36m1.8627\u001b[0m  13.5249\n",
            "     10        \u001b[36m1.8441\u001b[0m  13.4883\n",
            "0.3554\n",
            "---Query no:  5 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4321\u001b[0m  13.7026\n",
            "      2        \u001b[36m2.0601\u001b[0m  13.6377\n",
            "      3        \u001b[36m1.9923\u001b[0m  14.3515\n",
            "      4        \u001b[36m1.9129\u001b[0m  13.6237\n",
            "      5        \u001b[36m1.9083\u001b[0m  13.5978\n",
            "      6        \u001b[36m1.8160\u001b[0m  13.6310\n",
            "      7        \u001b[36m1.7775\u001b[0m  13.6821\n",
            "      8        \u001b[36m1.7002\u001b[0m  13.6098\n",
            "      9        \u001b[36m1.6283\u001b[0m  14.5727\n",
            "     10        \u001b[36m1.6127\u001b[0m  13.9172\n",
            "0.4272\n",
            "---Query no:  6 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4433\u001b[0m  13.8144\n",
            "      2        \u001b[36m2.1144\u001b[0m  13.7433\n",
            "      3        \u001b[36m2.0001\u001b[0m  14.5317\n",
            "      4        \u001b[36m1.9259\u001b[0m  13.7893\n",
            "      5        \u001b[36m1.8558\u001b[0m  13.7384\n",
            "      6        \u001b[36m1.8046\u001b[0m  13.7245\n",
            "      7        \u001b[36m1.7664\u001b[0m  13.6845\n",
            "      8        \u001b[36m1.7167\u001b[0m  13.6479\n",
            "      9        \u001b[36m1.7007\u001b[0m  13.7102\n",
            "     10        \u001b[36m1.6597\u001b[0m  13.7036\n",
            "0.3708\n",
            "---Query no:  7 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5431\u001b[0m  13.8274\n",
            "      2        \u001b[36m2.3036\u001b[0m  13.7708\n",
            "      3        \u001b[36m2.3035\u001b[0m  14.0776\n",
            "      4        \u001b[36m2.3034\u001b[0m  14.2440\n",
            "      5        \u001b[36m2.3033\u001b[0m  13.8058\n",
            "      6        \u001b[36m2.3033\u001b[0m  13.8558\n",
            "      7        \u001b[36m2.3032\u001b[0m  13.6852\n",
            "      8        \u001b[36m2.3032\u001b[0m  13.7030\n",
            "      9        2.3033  13.7159\n",
            "     10        2.3033  13.7208\n",
            "0.1\n",
            "---Query no:  8 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5783\u001b[0m  13.8553\n",
            "      2        \u001b[36m2.1867\u001b[0m  13.8550\n",
            "      3        \u001b[36m2.1148\u001b[0m  14.5729\n",
            "      4        \u001b[36m2.0835\u001b[0m  13.9115\n",
            "      5        \u001b[36m2.0283\u001b[0m  13.8741\n",
            "      6        2.0328  13.8060\n",
            "      7        \u001b[36m2.0077\u001b[0m  13.8159\n",
            "      8        2.0241  13.7709\n",
            "      9        \u001b[36m2.0033\u001b[0m  13.8503\n",
            "     10        \u001b[36m1.9829\u001b[0m  14.3410\n",
            "0.3086\n",
            "---Query no:  9 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5663\u001b[0m  13.9750\n",
            "      2        \u001b[36m2.0329\u001b[0m  14.1779\n",
            "      3        \u001b[36m1.8561\u001b[0m  14.4550\n",
            "      4        \u001b[36m1.7513\u001b[0m  13.8538\n",
            "      5        \u001b[36m1.7376\u001b[0m  13.8873\n",
            "      6        \u001b[36m1.6484\u001b[0m  13.9020\n",
            "      7        \u001b[36m1.5785\u001b[0m  13.9088\n",
            "      8        \u001b[36m1.5472\u001b[0m  13.8444\n",
            "      9        \u001b[36m1.4675\u001b[0m  14.0058\n",
            "     10        1.4863  14.5252\n",
            "0.4288\n",
            "---Query no:  10 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5577\u001b[0m  13.9447\n",
            "      2        \u001b[36m2.2205\u001b[0m  14.7754\n",
            "      3        \u001b[36m2.1573\u001b[0m  13.8790\n",
            "      4        \u001b[36m2.0941\u001b[0m  13.9570\n",
            "      5        \u001b[36m2.0657\u001b[0m  14.8524\n",
            "      6        \u001b[36m2.0435\u001b[0m  13.9070\n",
            "      7        \u001b[36m2.0046\u001b[0m  13.8273\n",
            "      8        \u001b[36m1.9913\u001b[0m  14.3604\n",
            "      9        1.9928  14.2019\n",
            "     10        2.0063  13.9016\n",
            "0.3052\n",
            "---Query no:  11 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3974\u001b[0m  14.6410\n",
            "      2        \u001b[36m2.3033\u001b[0m  13.8293\n",
            "      3        2.3035  13.8496\n",
            "      4        2.3037  13.9156\n",
            "      5        \u001b[36m2.3030\u001b[0m  13.9435\n",
            "      6        2.3034  13.9131\n",
            "      7        2.3032  14.2306\n",
            "      8        2.3032  14.4495\n",
            "      9        2.3032  13.9026\n",
            "     10        2.3032  13.8837\n",
            "0.1\n",
            "---Query no:  12 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.7273\u001b[0m  14.0506\n",
            "      2        \u001b[36m2.3034\u001b[0m  13.9867\n",
            "      3        \u001b[36m2.3033\u001b[0m  13.9626\n",
            "      4        \u001b[36m2.3031\u001b[0m  13.9446\n",
            "      5        2.3033  13.9754\n",
            "      6        2.3032  14.3129\n",
            "      7        \u001b[36m2.3030\u001b[0m  14.4061\n",
            "      8        2.3033  13.9509\n",
            "      9        2.3032  14.0830\n",
            "     10        2.3032  13.9238\n",
            "0.1\n",
            "---Query no:  13 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4033\u001b[0m  14.0441\n",
            "      2        \u001b[36m2.3138\u001b[0m  13.9807\n",
            "      3        \u001b[36m2.3035\u001b[0m  13.9742\n",
            "      4        2.3035  14.1079\n",
            "      5        \u001b[36m2.3034\u001b[0m  14.8477\n",
            "      6        \u001b[36m2.3033\u001b[0m  14.0937\n",
            "      7        2.3036  14.0863\n",
            "      8        \u001b[36m2.3033\u001b[0m  14.0506\n",
            "      9        2.3034  14.0001\n",
            "     10        2.3033  14.0087\n",
            "0.1\n",
            "---Query no:  14 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.8395\u001b[0m  14.0508\n",
            "      2        \u001b[36m2.3034\u001b[0m  14.0642\n",
            "      3        \u001b[36m2.3033\u001b[0m  14.9397\n",
            "      4        \u001b[36m2.3029\u001b[0m  14.4748\n",
            "      5        2.3034  14.4494\n",
            "      6        2.3032  14.3875\n",
            "      7        2.3031  14.4256\n",
            "      8        2.3031  14.6374\n",
            "      9        2.3031  14.8999\n",
            "     10        2.3032  14.0436\n",
            "0.1\n",
            "---Query no:  15 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3975\u001b[0m  14.9116\n",
            "      2        \u001b[36m1.9523\u001b[0m  14.1398\n",
            "      3        \u001b[36m1.8548\u001b[0m  15.0814\n",
            "      4        \u001b[36m1.7402\u001b[0m  14.1554\n",
            "      5        \u001b[36m1.7251\u001b[0m  14.1707\n",
            "      6        \u001b[36m1.6441\u001b[0m  14.7871\n",
            "      7        \u001b[36m1.5619\u001b[0m  14.2513\n",
            "      8        \u001b[36m1.5573\u001b[0m  14.1157\n",
            "      9        \u001b[36m1.5396\u001b[0m  14.0921\n",
            "     10        \u001b[36m1.4936\u001b[0m  14.1707\n",
            "0.4136\n",
            "---Query no:  16 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5642\u001b[0m  14.2791\n",
            "      2        \u001b[36m2.1894\u001b[0m  14.2020\n",
            "      3        \u001b[36m2.1334\u001b[0m  14.1580\n",
            "      4        2.1364  14.7222\n",
            "      5        \u001b[36m2.0749\u001b[0m  14.1557\n",
            "      6        \u001b[36m2.0749\u001b[0m  14.2013\n",
            "      7        \u001b[36m2.0430\u001b[0m  14.2568\n",
            "      8        \u001b[36m2.0208\u001b[0m  14.1907\n",
            "      9        \u001b[36m1.9978\u001b[0m  14.2985\n",
            "     10        1.9992  14.8673\n",
            "0.287\n",
            "---Query no:  17 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4772\u001b[0m  14.2404\n",
            "      2        \u001b[36m2.3044\u001b[0m  15.0812\n",
            "      3        \u001b[36m2.3032\u001b[0m  14.1843\n",
            "      4        \u001b[36m2.3031\u001b[0m  14.3056\n",
            "      5        2.3031  14.2891\n",
            "      6        2.3032  14.2476\n",
            "      7        2.3031  14.6244\n",
            "      8        2.3031  15.5122\n",
            "      9        2.3031  14.2295\n",
            "     10        2.3032  14.2556\n",
            "0.1\n",
            "---Query no:  18 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.6339\u001b[0m  14.2612\n",
            "      2        \u001b[36m2.3034\u001b[0m  14.2304\n",
            "      3        \u001b[36m2.3031\u001b[0m  14.2025\n",
            "      4        \u001b[36m2.3030\u001b[0m  14.4443\n",
            "      5        2.3030  14.9327\n",
            "      6        2.3031  14.2958\n",
            "      7        2.3031  14.2745\n",
            "      8        2.3031  14.2797\n",
            "      9        2.3031  14.2628\n",
            "     10        2.3031  14.9410\n",
            "0.1\n",
            "---Query no:  19 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4742\u001b[0m  14.4111\n",
            "      2        \u001b[36m2.1535\u001b[0m  14.8826\n",
            "      3        \u001b[36m2.0852\u001b[0m  14.5322\n",
            "      4        \u001b[36m2.0525\u001b[0m  14.3531\n",
            "      5        \u001b[36m2.0329\u001b[0m  14.3031\n",
            "      6        \u001b[36m2.0215\u001b[0m  14.3188\n",
            "      7        \u001b[36m2.0089\u001b[0m  14.3455\n",
            "      8        \u001b[36m2.0058\u001b[0m  15.0997\n",
            "      9        \u001b[36m1.9397\u001b[0m  14.3320\n",
            "     10        \u001b[36m1.9395\u001b[0m  14.3430\n",
            "0.2728\n",
            "---Query no:  20 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5837\u001b[0m  14.4373\n",
            "      2        \u001b[36m2.0599\u001b[0m  14.3937\n",
            "      3        \u001b[36m1.9444\u001b[0m  14.3709\n",
            "      4        \u001b[36m1.7950\u001b[0m  14.6830\n",
            "      5        \u001b[36m1.7547\u001b[0m  14.9678\n",
            "      6        \u001b[36m1.6964\u001b[0m  14.3606\n",
            "      7        \u001b[36m1.6401\u001b[0m  14.4046\n",
            "      8        \u001b[36m1.5909\u001b[0m  14.3788\n",
            "      9        \u001b[36m1.5431\u001b[0m  14.3545\n",
            "     10        \u001b[36m1.5192\u001b[0m  15.1973\n",
            "0.4382\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[239  25  20  25  21   4  14  26  66  60]\n",
            " [ 13 285   1  15   0   6  24  11  20 125]\n",
            " [ 24  10  77  56 130  35  80  63  13  12]\n",
            " [  7   5  19 164  44  75  96  56   4  30]\n",
            " [ 18   5  22  46 169  30 103  77   7  23]\n",
            " [  3   5  17 116  33 137  70  88   3  28]\n",
            " [  1   4   8  55  58  13 306  40   0  15]\n",
            " [  1   5   9  39  41  47  28 295   2  33]\n",
            " [107  41  13  23  12  19   6  12 198  69]\n",
            " [ 13  53   2  15   2  16  35  24  19 321]]\n",
            "Accuracy:  0.4382\n",
            "Macro F1-score:  0.4288051367446548\n",
            "Micro F1-score:  0.4382\n",
            "Weighted F1-score:  0.4288051367446549\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "AL_Retrain(5000, 20,  20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h-oq8pXFiI7W",
        "outputId": "49b78b49-19aa-4a24-e6e4-addfb3629804"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.6416\u001b[0m  14.0275\n",
            "      2        \u001b[36m1.9722\u001b[0m  13.4369\n",
            "      3        \u001b[36m1.8526\u001b[0m  13.4055\n",
            "      4        \u001b[36m1.7570\u001b[0m  13.3622\n",
            "      5        \u001b[36m1.6858\u001b[0m  13.4675\n",
            "      6        \u001b[36m1.6403\u001b[0m  13.3096\n",
            "      7        \u001b[36m1.5826\u001b[0m  13.3486\n",
            "      8        \u001b[36m1.4838\u001b[0m  13.2987\n",
            "      9        \u001b[36m1.4824\u001b[0m  13.3086\n",
            "     10        \u001b[36m1.4312\u001b[0m  13.3824\n",
            "No of initial data:  5000\n",
            "0.4108\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[298  15  19  18  21  28   2  12  65  22]\n",
            " [ 30 203   4  29   2  30  18  18  36 130]\n",
            " [ 59   2  71  40 139 124  23  25  11   6]\n",
            " [ 11   4  21 132  50 194  35  29   6  18]\n",
            " [ 39   1  32  40 208  94  28  37  16   5]\n",
            " [ 11   1  22  70  46 282  17  35   2  14]\n",
            " [  4   3  12  70  95  97 186  19   2  12]\n",
            " [ 17   6  10  34  57 122  10 212   8  24]\n",
            " [169  21   8  23   5  31   1   4 198  40]\n",
            " [ 18  34   3  44   5  55   6  23  48 264]]\n",
            "Accuracy:  0.4108\n",
            "Macro F1-score:  0.40951528600268744\n",
            "Micro F1-score:  0.41079999999999994\n",
            "Weighted F1-score:  0.40951528600268733\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[9, 6, 4, 3, 2, 2, 0, 2, 2, 2, 7, 3, 5, 6, 7, 3, 2, 9, 5, 1, 9, 2, 4, 2, 9, 8, 0, 0, 1, 5, 9, 9, 4, 9, 9, 4, 6, 7, 1, 1, 5, 4, 5, 4, 5, 3, 9, 9, 7, 0, 2, 4, 4, 0, 1, 5, 5, 3, 3, 4, 7, 1, 3, 6, 4, 4, 7, 6, 4, 2, 8, 2, 3, 4, 2, 2, 8, 1, 3, 7, 0, 4, 9, 6, 4, 9, 2, 0, 6, 4, 8, 4, 5, 5, 5, 3, 8, 6, 4, 0, 7, 4, 7, 5, 2, 3, 5, 9, 9, 7, 6, 9, 6, 8, 8, 1, 5, 6, 2, 3, 0, 1, 8, 8, 3, 2, 4, 7, 3, 4, 8, 3, 2, 0, 4, 4, 4, 3, 4, 1, 3, 4, 8, 2, 7, 1, 2, 0, 6, 4, 3, 6, 4, 1, 5, 6, 6, 6, 0, 5, 5, 6, 8, 2, 7, 5, 1, 9, 5, 1, 2, 5, 4, 5, 2, 6, 1, 4, 1, 5, 0, 0, 5, 0, 9, 3, 4, 2, 2, 0, 7, 6, 8, 2, 3, 5, 4, 6, 0, 9, 1, 3, 5, 6, 2, 5, 1, 9, 1, 3, 7, 2, 5, 9, 3, 2, 5, 8, 5, 2, 6, 4, 6, 0, 7, 5, 3, 6, 4, 7, 0, 0, 9, 0, 5, 7, 0, 2, 0, 1, 7, 4, 6, 1, 2, 4, 4, 6, 3, 6, 7, 6, 2, 4, 5, 7, 2, 6, 0, 8, 7, 2, 0, 7, 7, 4, 6, 3, 5, 3, 3, 7, 3, 2, 5, 1, 7, 9, 3, 4, 4, 9, 2, 7, 6, 3, 4, 3, 4, 0, 0, 8, 6, 0, 9, 0, 5, 7, 4, 7, 4, 7, 9, 2, 2, 5, 6, 4, 6, 2, 2, 4, 5, 6, 2, 5, 2, 1, 1, 0, 9, 7, 3, 6, 6, 2, 0, 2, 7, 4, 1, 3, 2, 1, 6, 7, 3, 4, 7, 9, 7, 0, 1, 4, 2, 4, 7, 4, 8, 4, 4, 6, 4, 4, 9, 4, 1, 3, 9, 2, 2, 7, 1, 4, 3, 5, 1, 5, 3, 2, 5, 4, 8, 0, 6, 5, 2, 7, 2, 1, 4, 6, 9, 7, 9, 9, 1, 0, 4, 2, 9, 1, 4, 6, 5, 5, 8, 8, 3, 2, 5, 5, 8, 3, 7, 1, 9, 6, 6, 6, 6, 4, 0, 8, 5, 9, 0, 2, 0, 7, 4, 1, 9, 9, 5, 8, 4, 4, 2, 5, 9, 0, 7, 3, 0, 5, 4, 2, 5, 2, 6, 4, 6, 6, 6, 3, 1, 7, 1, 4, 9, 9, 1, 1, 6, 5, 3, 1, 3, 6, 1, 6, 0, 6, 6, 5, 8, 6, 2, 2, 5, 6, 7, 5, 1, 6, 3, 9, 6, 5, 6, 6, 0, 2, 4, 6, 4, 2, 4, 2, 4, 7, 0, 5, 4, 1, 6, 4, 2, 3, 5, 7, 3, 1, 9, 7, 4, 5, 9, 5, 6, 1, 4, 7, 7, 1, 9, 9, 7, 3, 0, 7, 2, 1, 9, 3, 2, 4, 4, 6, 9, 7, 9, 4, 7, 2, 3, 8, 9, 8, 9, 3, 3, 3, 5, 4, 2, 0, 6, 0, 5, 2, 9, 3, 5, 1, 4, 5, 8, 4, 8, 2, 1, 6, 6, 4, 5, 6, 6, 8, 1, 2, 3, 5, 6, 4, 3, 1, 5, 6, 1, 6, 1, 2, 4, 2, 8, 9, 6, 9, 2, 4, 9, 9, 7, 3, 0, 8, 1, 5, 4, 7, 7, 1, 9, 8, 9, 0, 8, 5, 5, 4, 2, 6, 2, 3, 1, 5, 6, 4, 8, 6, 2, 3, 0, 9, 2, 1, 0, 5, 4, 4, 2, 6, 6, 6, 7, 7, 5, 8, 8, 2, 3, 2, 2, 6, 7, 8, 2, 7, 9, 2, 4, 3, 5, 1, 2, 4, 8, 1, 5, 7, 4, 3, 6, 2, 9, 0, 1, 9, 5, 6, 8, 4, 1, 4, 9, 9, 2, 8, 3, 7, 6, 3, 4, 9, 5, 5, 2, 2, 1, 6, 2, 8, 7, 9, 3, 4, 4, 3, 3, 6, 9, 3, 8, 2, 2, 0, 9, 6, 5, 6, 1, 3, 0, 5, 5, 4, 2, 3, 2, 6, 0, 5, 5, 0, 1, 1, 5, 4, 8, 2, 8, 2, 1, 1, 4, 4, 6, 1, 3, 4, 6, 7, 7, 9, 0, 5, 4, 6, 4, 1, 6, 6, 9, 6, 8, 2, 4, 7, 8, 7, 0, 9, 2, 2, 3, 4, 2, 4, 8, 3, 6, 1, 6, 1, 1, 2, 2, 9, 7, 3, 2, 6, 2, 7, 1, 2, 4, 0, 0, 4, 5, 4, 0, 3, 8, 3, 2, 7, 0, 6, 2, 5, 5, 1, 4, 1, 1, 9, 2, 1, 0, 0, 3, 4, 6, 4, 3, 6, 9, 2, 5, 2, 3, 2, 2, 5, 2, 2, 3, 1, 7, 7, 6, 1, 2, 4, 3, 4, 8, 5, 7, 6, 4, 1, 3, 7, 0, 3, 2, 7, 0, 7, 4, 5, 0, 5, 2, 4, 7, 2, 0, 4, 9, 7, 8, 0, 0, 6, 2, 0, 3, 0, 2, 2, 5, 7, 4, 6, 7, 4, 2, 4, 7, 0, 4, 4, 7, 2, 6, 3, 8, 0, 5, 4, 3, 5, 8, 2, 6, 9, 8, 2, 9, 5, 2, 2, 3, 0, 5, 2, 2, 7, 4, 5, 6, 9, 3, 6, 7, 8, 4, 4, 2, 6, 8, 1, 4, 4, 6, 7, 3, 7, 7, 1, 6, 5, 2, 9, 7, 9, 2, 3, 3, 5, 3, 6, 2, 7, 4, 5, 2, 3, 3, 1, 6, 6, 7, 4, 3, 3, 4, 6, 1, 4, 4, 9, 5, 0, 1, 0, 9, 9, 7, 7, 4, 0, 8, 0, 7, 9, 2, 2, 8, 9, 4, 4, 3, 7, 4, 7, 5, 7, 3, 0, 6, 2, 3, 3, 1, 1, 4, 3, 3, 5, 8, 8, 2, 1, 2, 5, 3, 5, 4, 6, 5, 9, 3, 4, 4, 4, 4, 1, 2, 7, 4, 6, 0, 1, 7, 4, 7, 6, 1, 3, 2, 2, 2, 6, 3, 0, 3, 9, 0, 8, 7, 6, 0, 6, 7, 7, 2, 2, 1, 0, 2, 2, 4, 6, 8, 2, 7, 3, 8, 2, 6, 8, 6, 2, 0, 4, 2, 4, 8, 2, 2, 8, 9, 3, 6, 9, 7, 6, 2, 3, 2, 8, 8, 7, 5, 2, 2, 0, 5, 5, 8, 5, 7, 5, 2, 1, 3, 3, 3, 6, 4, 5, 7, 7, 6, 5, 2, 4, 4, 7, 4, 0, 6, 7, 4, 6, 0, 4, 6, 6, 3, 8, 8, 1, 5, 2, 7, 8, 4, 1, 0, 2, 4, 4, 8, 3, 9, 8, 2, 3, 0, 4, 0, 1, 7, 9, 6, 3, 4, 8, 4, 7, 9, 1, 4, 2, 5, 4, 2, 2, 4, 1, 4, 3, 3, 4, 2, 4, 9, 5, 3, 1, 2, 2, 2, 1, 4, 7, 6, 9, 6, 9, 3, 2, 8, 0, 3, 2, 4, 3, 7, 4, 4, 3, 2, 4, 6, 9, 0, 6, 5, 1, 3, 1, 7, 6, 1, 7, 2, 7, 7, 5, 7, 2, 2, 7, 2, 4, 4, 9, 6, 2, 2, 6, 0, 8, 3, 1, 8, 2, 3, 1, 4, 2, 3, 2, 4, 2, 4, 6, 3, 7, 6, 3, 2, 1, 5, 0, 1, 2, 2, 1, 1, 7, 1, 5, 2, 3, 0, 1, 6, 1, 6, 9, 3, 4, 5, 2, 2, 6, 7, 4, 4, 4, 9, 4, 9, 1, 6, 7, 4, 9, 6, 4, 5, 7, 2, 5, 9, 1, 2, 5, 9, 2, 1, 9, 2, 8, 3, 4, 1, 2, 6, 9, 6, 6, 8, 2, 1, 3, 6, 4, 9, 9, 8, 0, 7, 8, 8, 1, 5, 5, 6, 6, 7, 4, 6, 6, 3, 7, 3, 8, 5, 3, 8, 3, 4, 7, 3, 5, 3, 2, 7, 3, 9, 3, 1, 4, 6, 7, 1, 2, 3, 4, 6, 7, 5, 0, 1, 1, 8, 3, 7, 2, 3, 5, 3, 6, 5, 3, 1, 8, 1, 6, 5, 5, 2, 7, 7, 0, 6, 7, 4, 4, 5, 8, 0, 6, 6, 4, 5, 2, 4, 6, 4, 7, 3, 9, 3, 6, 4, 7, 7, 1, 6, 6, 6, 2, 5, 3, 5, 5, 4, 1, 8, 9, 8, 4, 4, 9, 7, 3, 6, 2, 6, 4, 4, 0, 6, 0, 4, 3, 4, 3, 6, 4, 9, 4, 6, 6, 8, 0, 8, 4, 6, 1, 7, 9, 3, 7, 6, 7, 6, 0, 1, 1, 7, 0, 1, 9, 6, 7, 9, 1, 2, 6, 2, 1, 2, 4, 4, 3, 3, 4, 2, 2, 6, 2, 7, 1, 6, 0, 1, 4, 3, 3, 1, 2, 2, 9, 2, 1, 3, 3, 9, 4, 7, 4, 2, 4, 0, 6, 0, 5, 1, 6, 6, 5, 5, 6, 8, 4, 8, 3, 4, 4, 8, 5, 4, 6, 9, 4, 4, 9, 1, 5, 9, 1, 3, 0, 0, 2, 8, 3, 2, 4, 5, 4, 3, 4, 3, 7, 4, 7, 2, 7, 4, 3, 2, 7, 0, 1, 9, 1, 0, 4, 3, 0, 6, 3, 9, 2, 5, 4, 5, 6, 8, 6, 9, 2, 2, 2, 9, 6, 3, 0, 7, 3, 5, 2, 7, 2, 1, 8, 6, 6, 2, 2, 0, 6, 7, 6, 1, 6, 7, 1, 1, 2, 4, 2, 3, 4, 5, 0, 3, 2, 6, 0, 9, 0, 7, 2, 3, 5, 7, 6, 6, 5, 8, 6, 0, 2, 2, 9, 0, 7, 2, 9, 1, 3, 6, 3, 4, 2, 6, 6, 8, 9, 7, 0, 9, 5, 0, 6, 1, 4, 8, 2, 9, 7, 7, 2, 6, 3, 5, 6, 6, 8, 7, 3, 6, 6, 3, 6, 2, 3, 0, 3, 4, 2, 8, 6, 8, 1, 9, 2, 0, 4, 8, 3, 5, 1, 5, 1, 1, 9, 0, 9, 0, 2, 2, 4, 8, 2, 3, 9, 7, 1, 7, 6, 4, 5, 7, 6, 6, 6, 3, 9, 5, 9, 3, 0, 5, 6, 6, 0, 5, 3, 1, 9, 2, 4, 2, 2, 4, 2, 7, 8, 9, 6, 3, 0, 2, 4, 0, 1, 6, 4, 4, 4, 1, 3, 1, 1, 0, 7, 5, 6, 1, 7, 9, 0, 5, 8, 3, 5, 5, 6, 4, 4, 0, 7, 3, 8, 9, 2, 3, 3, 6, 4, 2, 3, 2, 3, 3, 4, 3, 4, 3, 7, 1, 7, 6, 7, 7, 1, 6, 3, 2, 7, 9, 3, 8, 1, 3, 3, 3, 1, 9, 2, 6, 1, 0, 5, 4, 4, 0, 5, 4, 4, 9, 5, 2, 4, 3, 5, 9, 4, 8, 4, 0, 6, 2, 8, 9, 1, 2, 0, 3, 6, 7, 0, 1, 2, 2, 6, 8, 0, 1, 0, 0, 6, 0, 5, 6, 6, 0, 0, 2, 0, 4, 6, 6, 7, 9, 2, 3, 8, 2, 7, 4, 8, 4, 9, 3, 1, 0, 3, 8, 3, 2, 7, 3, 1, 0, 2, 9, 3, 2, 6, 4, 3, 7, 1, 0, 1, 4, 3, 0, 2, 6, 3, 3, 6, 6, 9, 2, 0, 9, 1, 7, 3, 7, 0, 4, 3, 6, 3, 2, 9, 9, 4, 7, 5, 9, 7, 0, 1, 2, 5, 2, 5, 7, 3, 6, 4, 3, 2, 3, 1, 4, 2, 9, 4, 6, 6, 3, 1, 9, 4, 9, 5, 1, 7, 8, 8, 0, 0, 4, 9, 4, 7, 6, 0, 3, 3, 7, 2, 0, 8, 7, 5, 2, 9, 2, 4, 4, 4, 6, 6, 0, 3, 3, 8, 3, 3, 3, 3, 6, 3, 3, 2, 6, 0, 3, 3, 5, 2, 8, 6, 4, 7, 1, 4, 2, 3, 7, 5, 2, 4, 6, 3, 5, 2, 1, 1, 5, 9, 9, 0, 2, 7, 7, 1, 5, 0, 1, 6, 4, 9, 0, 5, 9, 7, 2, 8, 7, 4, 4, 3, 0, 2, 2, 5, 0, 8, 2, 6, 6, 5, 0, 7, 2, 9, 3, 5, 1, 7, 2, 5, 8, 5, 4, 3, 6, 3, 9, 2, 9, 7, 1, 0, 0, 2, 9, 3, 8, 8, 5, 3, 4, 2, 4, 2, 1, 4, 3, 7, 5, 6, 2, 4, 1, 4, 7, 3, 0, 2, 6, 4, 2, 4, 1, 4, 6, 3, 8, 6, 7, 6, 6, 6, 6, 5, 4, 5, 2, 7, 7, 3, 9, 1, 7, 3, 5, 2, 6, 4, 2, 2, 2, 7, 3, 0, 1, 9, 2, 0, 5, 3, 8, 9, 4, 3, 1, 7, 7, 6, 1, 4, 2, 1, 9, 8, 4, 2, 6, 0, 5, 6, 3, 5, 8, 2, 6, 3, 4, 3, 4, 7, 9, 8, 7, 3, 8, 7, 7, 3, 9, 3, 4, 5, 3, 8, 4, 7, 1, 5, 6, 8, 3, 4, 6, 6, 5, 9, 9, 2, 1, 3, 9, 2, 6, 4, 7, 1, 6, 4, 2, 4, 1, 2, 5, 7, 7, 3, 7, 7, 2, 7, 3, 9, 4, 7, 1, 7, 7, 2, 7, 6, 5, 5, 4, 8, 4, 5, 3, 4, 3, 0, 6, 3, 6, 1, 9, 7, 7, 2, 9, 5, 7, 2, 2, 0, 3, 3, 1, 6, 0, 9, 9, 6, 3, 7, 5, 0, 3, 2, 7, 6, 0, 4, 4, 5, 3, 6, 0, 1, 3, 6, 1, 4, 8, 5, 0, 8, 4, 4, 2, 9, 4, 4, 8, 5, 7, 5, 0, 7, 6, 2, 6, 1, 3, 4, 4, 6, 6, 4, 8, 3, 9, 2, 7, 7, 2, 4, 5, 1, 9, 0, 7, 1, 4, 8, 8, 4, 7, 3, 7, 6, 7, 5, 3, 7, 4, 3, 3, 9, 5, 2, 4, 4, 5, 0, 2, 3, 5, 4, 1, 6, 7, 5, 8, 3, 1, 6, 3, 0, 4, 7, 4, 2, 5, 3, 4, 9, 7, 2, 6, 6, 2, 4, 1, 3, 7, 5, 7, 3, 3, 7, 2, 9, 9, 8, 4, 5, 3, 1, 4, 5, 6, 2, 1, 6, 0, 3, 8, 2, 8, 9, 8, 5, 5, 6, 6, 6, 4, 0, 8, 6, 3, 4, 1, 8, 4, 3, 1, 3, 0, 3, 7, 1, 3, 3, 6, 2, 0, 5, 9, 5, 7, 9, 8, 9, 2, 5, 3, 1, 6, 5, 9, 5, 9, 1, 7, 6, 5, 5, 0, 1, 1, 4, 5, 6, 3, 4, 4, 9, 5, 9, 6, 7, 5, 9, 6, 1, 7, 5, 9, 5, 4, 4, 4, 2, 1, 3, 0, 2, 1, 6, 2, 9, 7, 4, 1, 8, 3, 9, 3, 2, 5, 8, 7, 5, 0, 2, 7, 5, 4, 8, 5, 1, 9, 6, 4, 0, 2, 4, 8, 2, 6, 7, 7, 1, 2, 8, 7, 5, 9, 8, 3, 2, 1, 1, 7, 5, 6, 2, 6, 3, 5, 8, 5, 1, 3, 3, 1, 6, 8, 0, 9, 7, 2, 7, 4, 7, 5, 4, 6, 4, 2, 3, 7, 0, 0, 6, 7, 2, 7, 4, 2, 3, 6, 0, 6, 6, 2, 9, 6, 1, 5, 8, 8, 8, 2, 7, 2, 6, 2, 3, 2, 2, 2, 5, 2, 8, 6, 3, 6, 5, 0, 0, 9, 5, 1, 6, 4, 4, 3, 0, 4, 3, 4, 1, 6, 3, 6, 3, 1, 4, 3, 3, 3, 0, 4, 7, 4, 2, 6, 9, 3, 3, 6, 9, 5, 3, 9, 3, 6, 3, 3, 9, 6, 2, 2, 2, 1, 6, 8, 2, 5, 3, 0, 5, 3, 2, 7, 2, 4, 2, 9, 2, 5, 4, 7, 3, 2, 2, 6, 7, 4, 5, 4, 9, 4, 7, 1, 6, 2, 1, 6, 7, 6, 4, 5, 3, 1, 1, 3, 3, 6, 7, 0, 8, 7, 0, 3, 7, 8, 2, 7, 5, 3, 9, 8, 7, 4, 3, 6, 6, 3, 4, 8, 9, 6, 3, 2, 2, 2, 9, 3, 6, 3, 8, 6, 3, 3, 8, 3, 7, 5, 3, 5, 5, 6, 9, 2, 6, 5, 1, 3, 4, 5, 9, 0, 5, 3, 7, 8, 2, 7, 2, 2, 4, 3, 7, 2, 6, 1, 3, 1, 2, 0, 4, 7, 7, 9, 1, 1, 2, 1, 8, 1, 8, 7, 5, 7, 3, 7, 9, 5, 7, 3, 1, 4, 2, 8, 2, 6, 6, 3, 3, 4, 4, 2, 0, 2, 0, 0, 8, 1, 1, 2, 5, 3, 4, 4, 0, 0, 8, 4, 4, 3, 6, 4, 6, 0, 5, 2, 7, 4, 8, 1, 0, 2, 5, 8, 2, 0, 8, 6, 2, 5, 8, 4, 2, 2, 3, 9, 0, 4, 9, 6, 1, 0, 1, 6, 6, 7, 3, 5, 8, 4, 9, 1, 3, 6, 6, 4, 4, 3, 7, 6, 3, 9, 5, 5, 6, 6, 8, 2, 6, 4, 2, 6, 1, 9, 7, 0, 2, 0, 4, 0, 5, 2, 3, 9, 4, 5, 6, 3, 7, 3, 7, 4, 4, 1, 4, 6, 2, 8, 5, 3, 7, 5, 8, 1, 5, 9, 9, 3, 7, 2, 4, 0, 2, 5, 1, 9, 3, 2, 9, 2, 7, 3, 6, 9, 7, 5, 6, 4, 4, 7, 2, 6, 8, 2, 7, 2, 3, 5, 3, 5, 2, 4, 6, 3, 4, 6, 0, 1, 6, 5, 2, 7, 4, 8, 1, 5, 2, 6, 9, 5, 2, 4, 6, 9, 6, 8, 1, 4, 3, 2, 3, 7, 5, 5, 4, 9, 4, 7, 6, 2, 5, 8, 6, 4, 4, 5, 4, 0, 7, 2, 1, 2, 3, 3, 4, 4, 7, 9, 7, 6, 1, 2, 9, 7, 8, 2, 9, 9, 4, 9, 0, 8, 0, 4, 2, 9, 6, 5, 2, 4, 1, 6, 9, 1, 8, 0, 8, 2, 8, 9, 4, 3, 4, 7, 0, 1, 6, 6, 1, 3, 7, 1, 9, 3, 0, 2, 4, 7, 5, 2, 2, 2, 6, 6, 8, 6, 2, 5, 3, 6, 6, 4, 4, 6, 2, 7, 9, 7, 3, 6, 5, 7, 4, 1, 2, 4, 2, 3, 7, 7, 7, 4, 3, 2, 9, 9, 2, 6, 6, 8, 9, 6, 1, 3, 9, 3, 1, 5, 6, 3, 2, 3, 2, 2, 9, 1, 4, 8, 2, 4, 0, 3, 2, 2, 2, 2, 0, 6, 6, 2, 5, 4, 2, 0, 4, 5, 9, 7, 1, 2, 5, 7, 6, 2, 2, 3, 0, 9, 2, 8, 3, 6, 7, 3, 1, 8, 4, 3, 7, 6, 5, 5, 2, 3, 6, 6, 9, 5, 6, 5, 1, 5, 2, 8, 6, 4, 4, 8, 7, 8, 7, 3, 2, 4, 5, 1, 5, 4, 2, 6, 3, 2, 1, 2, 7, 6, 4, 1, 9, 1, 3, 6, 3, 8, 5, 0, 2, 3, 2, 5, 0, 7, 4, 4, 8, 3, 8, 1, 7, 0, 2, 3, 5, 7, 5, 5, 4, 6, 7, 2, 2, 9, 8, 6, 0, 5, 8, 9, 4, 1, 7, 2, 5, 4, 8, 0, 3, 4, 8, 9, 5, 2, 4, 4, 2, 2, 4, 9, 4, 6, 3, 6, 8, 4, 3, 0, 3, 5, 1, 7, 0, 6, 8, 9, 4, 0, 9, 6, 9, 4, 8, 8, 2, 4, 0, 2, 7, 6, 3, 9, 3, 1, 4, 3, 0, 4, 4, 9, 7, 6, 4, 3, 2, 1, 3, 5, 3, 9, 6, 1, 1, 8, 5, 5, 3, 6, 2, 9, 3, 7, 9, 6, 2, 3, 6, 2, 6, 2, 4, 0, 6, 7, 5, 2, 4, 5, 6, 2, 4, 3, 3, 7, 4, 4, 7, 3, 5, 2, 7, 8, 7, 2, 1, 3, 2, 0, 2, 2, 9, 2, 3, 0, 6, 6, 2, 7, 3, 5, 6, 6, 9, 4, 0, 4, 3, 3, 6, 2, 1, 6, 5, 6, 0, 0, 6, 7, 6, 2, 6, 1, 2, 6, 7, 7, 4, 1, 8, 6, 9, 5, 1, 4, 8, 5, 9, 7, 0, 1, 9, 1, 3, 2, 2, 2, 1, 5, 2, 1, 7, 4, 7, 6, 5, 9, 0, 9, 3, 6, 4, 2, 7, 4, 3, 2, 6, 4, 4, 3, 2, 5, 3, 6, 5, 1, 0, 4, 3, 2, 7, 4, 1, 8, 6, 5, 1, 7, 6, 1, 2, 4, 8, 5, 1, 5, 5, 3, 2, 1, 9, 6, 2, 4, 3, 8, 1, 9, 0, 3, 3, 9, 5, 2, 7, 2, 0, 6, 1, 3, 2, 7, 9, 1, 2, 3, 9, 4, 9, 4, 3, 2, 2, 1, 9, 8, 8, 1, 5, 1, 9, 0, 6, 3, 2, 6, 6, 7, 2, 6, 4, 0, 0, 5, 2, 5, 5, 6, 3, 8, 1, 7, 5, 7, 4, 2, 7, 7, 6, 0, 5, 6, 2, 8, 2, 8, 8, 1, 4, 6, 5, 7, 2, 3, 2, 8, 8, 9, 7, 2, 3, 6, 4, 9, 5, 9, 3, 0, 2, 2, 8, 3, 7, 4, 6, 7, 2, 2, 1, 1, 2, 6, 0, 9, 9, 3, 5, 9, 2, 0, 3, 6, 9, 0, 5, 2, 6, 5, 4, 8, 2, 6, 2, 0, 3, 3, 0, 5, 2, 7, 3, 0, 7, 7, 0, 5, 6, 4, 5, 9, 3, 3, 8, 8, 6, 1, 8, 2, 1, 5, 9, 5, 8, 4, 1, 4, 9, 0, 6, 6, 0, 4, 6, 9, 7, 7, 6, 1, 3, 4, 5, 7, 6, 7, 0, 4, 7, 9, 2, 3, 4, 2, 4, 3, 7, 7, 3, 6, 5, 7, 9, 1, 8, 8, 7, 5, 4, 6, 7, 4, 5, 3, 1, 5, 7, 3, 6, 0, 5, 6, 7, 7, 5, 1, 0, 8, 7, 4, 3, 7, 1, 9, 1, 9, 6, 7, 7, 9, 1, 5, 0, 5, 1, 3, 0, 3, 8, 4, 3, 3, 7, 5, 5, 9, 3, 3, 7, 4, 4, 6, 4, 3, 4, 7, 3, 9, 6, 5, 4, 5, 4, 9, 5, 4, 7, 9, 6, 0, 6, 1, 9, 8, 7, 4, 7, 0, 3, 1, 7, 3, 5, 9, 9, 6, 1, 1, 5, 6, 6, 5, 5, 4, 4, 7, 0, 9, 0, 3, 1, 8, 6, 8, 7, 9, 6, 4, 3, 9, 7, 6, 4, 9, 6, 5, 5, 7, 4, 6, 8, 6, 5, 7, 1, 7, 1, 7, 5, 7, 7, 8, 1, 4, 1, 5, 5, 9, 6, 3, 1, 4, 7, 1, 5, 8, 3, 5, 7, 6, 1, 0, 9, 5, 1, 6, 8, 4, 7, 9, 8, 0, 6, 6, 8, 9, 6, 5, 0, 4, 8, 9, 7, 7, 7, 0, 7, 8, 4, 7, 6, 1, 0, 5, 0, 5, 5, 4, 1, 7, 0, 4, 8, 8, 5, 5, 3, 0, 9, 4, 1, 0, 3, 3, 0, 1, 1, 1, 6, 1, 3, 8, 9, 1, 4, 7, 7, 6, 5, 4, 5, 9, 6, 4, 9, 7, 4, 5, 6, 8, 5, 0, 1, 4, 3, 8, 5, 3, 9, 0, 1, 1, 3, 5, 6, 8, 5, 6, 5, 9, 0, 3, 5, 5, 7, 0, 9, 5, 8, 6, 5, 3, 9, 1, 3, 7, 6, 5, 7, 6, 0, 3, 5, 8, 1, 6, 5, 5, 6, 6, 8, 1, 5, 0, 3, 7, 3, 6, 0, 0, 0, 6, 1, 7, 5, 7, 1, 9, 1, 3, 3, 7, 0, 7, 6, 8, 6, 9, 9, 3, 6, 6, 6, 5, 3, 8, 1, 3, 1, 1, 6, 9, 8, 6, 6, 3, 8, 0, 3, 3, 6, 7, 1, 0, 5, 9, 6, 5, 5, 9, 1, 6, 6, 3, 9, 3, 6, 9, 0, 6, 9, 1, 7, 3, 0, 5, 5, 7, 5, 1, 8, 7, 7, 0, 9, 0, 0, 0, 3, 9, 1, 7, 5, 0, 3, 5, 3, 7, 5, 3, 3, 3, 1, 0, 1, 0, 3, 5, 9, 8, 1, 3, 3, 5, 0, 7, 3, 7, 5, 5, 0, 7, 5, 9, 0, 9, 3, 1, 8, 3, 7, 7, 1, 3, 7, 0, 5, 9, 3, 7, 7, 3, 5, 0, 7, 9, 8, 0, 9, 3, 1, 3, 8, 7, 1, 9, 5, 7, 8, 0, 3, 9, 5, 9, 1, 1, 8, 7, 3, 8, 3, 5, 3, 3, 5, 0, 9, 5, 3, 8, 5, 1, 9, 7, 1, 5, 5, 8, 0, 9, 9, 0, 7, 8, 8, 7, 9, 7, 0, 5, 9, 1, 7, 1, 0, 0, 0, 9, 1, 8, 8, 8, 9, 1, 0, 0, 5, 0, 0, 7, 7, 7, 7, 7, 1, 1, 5, 1, 7, 8, 5, 1, 8, 7, 5, 9, 1, 9, 9, 7, 9, 7, 5, 9, 1, 5, 9, 9, 9, 5, 5, 7, 1, 5, 7, 8, 9, 1, 5, 0, 1, 9, 9, 7, 9, 5, 0, 5, 1, 9, 9, 7, 0, 8, 8, 5, 9, 1, 9, 5, 5, 8, 0, 9, 8, 1, 9, 9, 9, 9, 7, 0, 5, 0, 5, 5, 1, 5, 1, 1, 9, 7, 5, 1, 9, 5, 8, 5, 9, 9, 1, 7, 9, 9, 1, 5, 5, 8, 8, 9, 9, 5, 0, 9, 1, 0, 1, 7, 5, 9, 7, 9, 0, 5, 7, 5, 7, 1, 1, 8, 7, 7, 5, 1, 5, 9, 5, 7, 5, 9, 1, 5, 8, 7, 0, 0, 5, 7, 5, 8, 9, 0, 9, 9, 1, 7, 9, 1, 5, 5, 1, 5, 7, 5, 8, 9, 0, 0, 7, 8, 1, 1, 9, 1, 8, 1, 5, 1, 9, 5, 5, 5, 5, 5, 5, 0, 8, 5, 9, 1, 8, 9, 0, 0, 1, 5, 0, 1, 7, 8, 1, 5, 9, 8, 8, 7, 0, 5, 1, 0, 5, 7, 9, 8, 1, 8, 1, 8, 7, 9, 1, 9, 5, 1, 0, 9, 0, 9, 5, 0, 0, 5, 9, 7, 0, 0, 5, 5, 1, 7, 1, 8, 0, 9, 8, 8, 5, 5, 9, 5, 5, 9, 1, 5, 7, 1, 7, 9, 9, 1, 1, 1, 0, 7, 1, 5, 1, 0, 5, 5, 0, 8, 0, 8, 7, 0, 7, 1, 5, 7, 1, 5, 5, 0, 5, 0, 5, 7, 5, 5, 1, 7, 7, 7, 0, 7, 8, 9, 5, 5, 0, 7, 7, 9, 9, 9, 8, 1, 0, 7, 1, 5, 7, 5, 5, 7, 1, 7, 9, 1, 5, 5, 7, 5, 5, 5, 5, 1, 1, 9, 8, 9, 7, 7, 0, 9, 1, 7, 9, 5, 7, 0, 8, 0, 1, 7, 8, 7, 9, 7, 0, 1, 7, 7, 9, 9, 0, 9, 9, 0, 7, 9, 9, 9, 7, 1, 1, 1, 9, 9, 7, 7, 1, 0, 7, 7, 7, 0, 9, 0, 9, 9, 1, 8, 8, 9, 1, 0, 9, 9, 1, 1, 8, 1, 8, 8, 8, 1, 9, 8, 9, 1, 9, 9, 9, 8, 0, 9, 1, 9, 9, 0, 0, 8, 1, 8, 1, 1, 8, 9, 9, 8, 0, 1, 1, 1, 1, 1, 9, 9, 1, 1, 1, 1, 9, 0, 1, 9, 1, 8, 0, 9, 0, 0, 1, 8, 9, 1, 8, 0, 9, 8, 0, 8, 1, 1, 1, 1, 0, 9, 9, 9, 1, 1, 0, 8, 9, 0, 1, 8, 1, 8, 9, 9, 1, 8, 8, 8, 0, 9, 1, 9, 9, 9, 1, 0, 8, 1, 0, 0, 0, 0, 9, 9, 1, 0, 1, 1, 8, 9, 9, 9, 0, 0, 1, 0, 0, 9, 1, 1, 1, 1, 9, 9, 8, 8, 1, 0, 1, 1, 9, 0, 8, 1, 9, 9, 0, 0, 0, 1, 1, 9, 1, 0, 0, 9, 8, 1, 1, 9, 1, 0, 8, 8, 1, 9, 1, 8, 8, 1, 0, 9, 0, 8, 1, 1, 9, 0, 9, 8, 8, 0, 8, 0, 9, 9, 1, 8, 8, 1, 8, 9, 1, 8, 0, 1, 1, 0, 0, 0, 8, 9, 0, 1, 8, 1, 0, 0, 0, 0, 9, 8, 9, 0, 0, 8, 8, 9, 8, 8, 9, 0, 9, 8, 9, 9, 9, 0, 9, 8, 9, 9, 9, 8, 0, 8, 0, 0, 9, 8, 9, 0, 8, 9, 9, 0, 9, 0, 9, 8, 0, 8, 0, 0, 8, 9, 9, 8, 8, 0, 9, 9, 0, 9, 0, 0, 0, 9, 9, 9, 9, 8, 8, 8, 0, 0, 8, 0, 8, 0, 0, 0, 0, 8, 8, 0, 8, 8, 0, 0, 0, 8, 8, 8, 8, 8, 8, 8, 0, 8, 0, 8, 0, 0, 8, 0, 0, 0, 0, 8, 8, 0, 8, 0, 8, 0, 0, 0, 8, 0, 8, 8, 0, 0, 8, 8, 0, 8, 8, 0, 0, 8, 8, 0, 0, 8, 0, 0, 8, 0, 8, 0, 0, 0, 8, 8, 0, 8, 0, 0, 8, 8, 8, 0, 8, 0, 0, 0, 0, 0, 0, 8, 8, 0, 0, 0, 0, 8, 8, 8, 8, 0, 8, 8, 0, 8, 0, 0, 8, 8, 0, 8, 0, 8, 8, 0, 0, 8, 8, 0, 8, 8, 0, 8, 0, 0, 8, 0, 0, 8, 0, 0, 0, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
            "Counter({9: 500, 6: 500, 4: 500, 3: 500, 2: 500, 0: 500, 7: 500, 5: 500, 1: 500, 8: 500})\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.6902\u001b[0m  13.4093\n",
            "      2        \u001b[36m2.3078\u001b[0m  13.3295\n",
            "      3        \u001b[36m2.3077\u001b[0m  13.3267\n",
            "      4        2.3084  13.3387\n",
            "      5        2.3091  13.3432\n",
            "      6        2.3097  13.7935\n",
            "      7        2.3102  13.6972\n",
            "      8        2.3106  14.3134\n",
            "      9        2.3109  13.2791\n",
            "     10        2.3111  13.2927\n",
            "0.1\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]]\n",
            "Accuracy:  0.1\n",
            "Macro F1-score:  0.01818181818181818\n",
            "Micro F1-score:  0.10000000000000002\n",
            "Weighted F1-score:  0.01818181818181818\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "---Query no:  1 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4865\u001b[0m  13.5354\n",
            "      2        \u001b[36m2.3046\u001b[0m  13.4558\n",
            "      3        \u001b[36m2.3035\u001b[0m  13.4364\n",
            "      4        \u001b[36m2.3034\u001b[0m  13.5329\n",
            "      5        2.3038  13.6154\n",
            "      6        2.3036  14.0291\n",
            "      7        2.3034  13.3693\n",
            "      8        \u001b[36m2.3032\u001b[0m  13.4273\n",
            "      9        2.3034  13.4284\n",
            "     10        2.3033  13.5224\n",
            "0.1\n",
            "---Query no:  2 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4959\u001b[0m  13.5252\n",
            "      2        \u001b[36m2.3035\u001b[0m  13.4592\n",
            "      3        \u001b[36m2.3034\u001b[0m  13.4744\n",
            "      4        2.3034  13.5009\n",
            "      5        2.3034  13.4905\n",
            "      6        \u001b[36m2.3033\u001b[0m  13.5053\n",
            "      7        2.3033  13.4428\n",
            "      8        \u001b[36m2.3033\u001b[0m  14.2035\n",
            "      9        \u001b[36m2.3032\u001b[0m  13.5462\n",
            "     10        \u001b[36m2.3032\u001b[0m  13.4390\n",
            "0.1\n",
            "---Query no:  3 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4984\u001b[0m  14.2530\n",
            "      2        \u001b[36m2.3031\u001b[0m  14.5695\n",
            "      3        2.3033  13.6930\n",
            "      4        2.3031  13.6124\n",
            "      5        2.3032  13.5997\n",
            "      6        2.3032  13.5812\n",
            "      7        2.3032  13.5887\n",
            "      8        2.3032  13.5971\n",
            "      9        2.3032  13.8883\n",
            "     10        2.3032  14.1086\n",
            "0.1\n",
            "---Query no:  4 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3653\u001b[0m  13.6758\n",
            "      2        \u001b[36m2.1028\u001b[0m  14.2530\n",
            "      3        \u001b[36m1.9151\u001b[0m  14.0438\n",
            "      4        \u001b[36m1.8220\u001b[0m  13.7478\n",
            "      5        \u001b[36m1.7250\u001b[0m  13.7457\n",
            "      6        \u001b[36m1.6988\u001b[0m  13.7908\n",
            "      7        \u001b[36m1.6564\u001b[0m  13.7169\n",
            "      8        \u001b[36m1.6248\u001b[0m  13.7827\n",
            "      9        \u001b[36m1.5449\u001b[0m  13.6765\n",
            "     10        \u001b[36m1.5334\u001b[0m  14.4307\n",
            "0.3778\n",
            "---Query no:  5 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4446\u001b[0m  13.8260\n",
            "      2        \u001b[36m2.3033\u001b[0m  14.0039\n",
            "      3        \u001b[36m2.3032\u001b[0m  14.2680\n",
            "      4        2.3035  13.7148\n",
            "      5        2.3033  13.6755\n",
            "      6        2.3032  13.7627\n",
            "      7        2.3032  13.6851\n",
            "      8        2.3032  13.7392\n",
            "      9        2.3032  13.7296\n",
            "     10        2.3032  15.5174\n",
            "0.1\n",
            "---Query no:  6 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5444\u001b[0m  13.8292\n",
            "      2        \u001b[36m2.3031\u001b[0m  14.2318\n",
            "      3        2.3031  14.3014\n",
            "      4        2.3032  13.9670\n",
            "      5        \u001b[36m2.3030\u001b[0m  14.0388\n",
            "      6        2.3031  13.8622\n",
            "      7        2.3032  13.8780\n",
            "      8        2.3032  13.8147\n",
            "      9        \u001b[36m2.3029\u001b[0m  14.3726\n",
            "     10        2.3035  14.1358\n",
            "0.1\n",
            "---Query no:  7 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.6378\u001b[0m  14.2149\n",
            "      2        \u001b[36m2.3033\u001b[0m  14.5139\n",
            "      3        \u001b[36m2.3030\u001b[0m  14.0172\n",
            "      4        2.3034  13.8868\n",
            "      5        2.3032  13.9137\n",
            "      6        2.3032  13.8502\n",
            "      7        2.3031  13.8801\n",
            "      8        2.3031  14.1016\n",
            "      9        2.3031  14.5315\n",
            "     10        2.3031  13.8387\n",
            "0.1\n",
            "---Query no:  8 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3001\u001b[0m  14.7605\n",
            "      2        \u001b[36m2.0164\u001b[0m  13.9780\n",
            "      3        \u001b[36m1.8771\u001b[0m  13.8888\n",
            "      4        \u001b[36m1.8021\u001b[0m  13.9562\n",
            "      5        \u001b[36m1.7221\u001b[0m  14.9008\n",
            "      6        \u001b[36m1.6723\u001b[0m  13.9040\n",
            "      7        \u001b[36m1.5967\u001b[0m  13.9529\n",
            "      8        \u001b[36m1.5368\u001b[0m  14.5597\n",
            "      9        \u001b[36m1.5166\u001b[0m  14.1316\n",
            "     10        \u001b[36m1.4364\u001b[0m  13.8895\n",
            "0.423\n",
            "---Query no:  9 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4468\u001b[0m  14.5222\n",
            "      2        \u001b[36m1.9719\u001b[0m  14.0882\n",
            "      3        \u001b[36m1.8039\u001b[0m  14.0320\n",
            "      4        1.8046  14.0353\n",
            "      5        \u001b[36m1.7134\u001b[0m  13.9988\n",
            "      6        \u001b[36m1.6679\u001b[0m  14.1868\n",
            "      7        \u001b[36m1.6059\u001b[0m  14.7893\n",
            "      8        \u001b[36m1.5407\u001b[0m  14.0935\n",
            "      9        \u001b[36m1.5358\u001b[0m  14.0400\n",
            "     10        \u001b[36m1.4859\u001b[0m  14.0312\n",
            "0.4312\n",
            "---Query no:  10 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4821\u001b[0m  14.1582\n",
            "      2        \u001b[36m2.3033\u001b[0m  14.1171\n",
            "      3        2.3034  14.1207\n",
            "      4        \u001b[36m2.3033\u001b[0m  14.1221\n",
            "      5        \u001b[36m2.3032\u001b[0m  14.9433\n",
            "      6        \u001b[36m2.3031\u001b[0m  14.1338\n",
            "      7        2.3031  14.1248\n",
            "      8        2.3031  14.1470\n",
            "      9        2.3031  14.1456\n",
            "     10        2.3031  14.1513\n",
            "0.1\n",
            "---Query no:  11 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.7521\u001b[0m  14.3462\n",
            "      2        \u001b[36m2.1998\u001b[0m  14.3914\n",
            "      3        \u001b[36m2.1086\u001b[0m  14.9279\n",
            "      4        \u001b[36m2.0390\u001b[0m  14.2008\n",
            "      5        \u001b[36m2.0126\u001b[0m  14.2730\n",
            "      6        \u001b[36m1.9148\u001b[0m  14.2856\n",
            "      7        \u001b[36m1.8390\u001b[0m  14.3381\n",
            "      8        1.8555  14.7688\n",
            "      9        \u001b[36m1.7693\u001b[0m  14.5962\n",
            "     10        \u001b[36m1.7573\u001b[0m  14.3051\n",
            "0.37\n",
            "---Query no:  12 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5688\u001b[0m  14.8174\n",
            "      2        \u001b[36m2.3030\u001b[0m  14.3697\n",
            "      3        2.3033  14.3914\n",
            "      4        2.3034  14.3918\n",
            "      5        2.3032  14.4395\n",
            "      6        2.3033  15.1966\n",
            "      7        2.3032  14.3444\n",
            "      8        2.3032  14.3802\n",
            "      9        2.3031  14.3745\n",
            "     10        2.3031  14.4124\n",
            "0.1\n",
            "---Query no:  13 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4589\u001b[0m  14.5689\n",
            "      2        \u001b[36m2.3054\u001b[0m  14.4855\n",
            "      3        \u001b[36m2.3039\u001b[0m  15.2845\n",
            "      4        \u001b[36m2.3033\u001b[0m  14.4562\n",
            "      5        \u001b[36m2.3033\u001b[0m  14.5133\n",
            "      6        2.3035  14.4569\n",
            "      7        2.3034  15.4759\n",
            "      8        \u001b[36m2.3032\u001b[0m  15.0736\n",
            "      9        2.3033  14.3309\n",
            "     10        2.3032  14.3837\n",
            "0.1\n",
            "---Query no:  14 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5743\u001b[0m  14.5564\n",
            "      2        \u001b[36m2.1304\u001b[0m  14.4766\n",
            "      3        \u001b[36m1.9652\u001b[0m  14.6957\n",
            "      4        \u001b[36m1.8431\u001b[0m  14.6285\n",
            "      5        \u001b[36m1.8358\u001b[0m  15.2939\n",
            "      6        \u001b[36m1.7645\u001b[0m  14.4336\n",
            "      7        \u001b[36m1.6976\u001b[0m  14.4611\n",
            "      8        \u001b[36m1.6772\u001b[0m  14.5334\n",
            "      9        \u001b[36m1.6131\u001b[0m  14.5421\n",
            "     10        \u001b[36m1.5788\u001b[0m  15.3138\n",
            "0.4278\n",
            "---Query no:  15 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4992\u001b[0m  14.8731\n",
            "      2        \u001b[36m2.2240\u001b[0m  14.9147\n",
            "      3        \u001b[36m2.1360\u001b[0m  14.4605\n",
            "      4        \u001b[36m2.0657\u001b[0m  14.4996\n",
            "      5        \u001b[36m2.0294\u001b[0m  14.5308\n",
            "      6        \u001b[36m2.0135\u001b[0m  14.7110\n",
            "      7        \u001b[36m1.9875\u001b[0m  15.0783\n",
            "      8        \u001b[36m1.9707\u001b[0m  14.4575\n",
            "      9        \u001b[36m1.9607\u001b[0m  14.4881\n",
            "     10        \u001b[36m1.9542\u001b[0m  14.5990\n",
            "0.305\n",
            "---Query no:  16 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3958\u001b[0m  14.6526\n",
            "      2        \u001b[36m2.1985\u001b[0m  15.5523\n",
            "      3        \u001b[36m2.1068\u001b[0m  15.4832\n",
            "      4        2.1198  14.5977\n",
            "      5        \u001b[36m2.0732\u001b[0m  14.5591\n",
            "      6        \u001b[36m2.0037\u001b[0m  14.6312\n",
            "      7        \u001b[36m2.0002\u001b[0m  14.6669\n",
            "      8        \u001b[36m1.9667\u001b[0m  15.4383\n",
            "      9        \u001b[36m1.9635\u001b[0m  14.5661\n",
            "     10        \u001b[36m1.9580\u001b[0m  14.6536\n",
            "0.3146\n",
            "---Query no:  17 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.7301\u001b[0m  14.7212\n",
            "      2        \u001b[36m2.2768\u001b[0m  14.6880\n",
            "      3        \u001b[36m2.1728\u001b[0m  14.7766\n",
            "      4        \u001b[36m2.0962\u001b[0m  15.4524\n",
            "      5        \u001b[36m2.0864\u001b[0m  15.1887\n",
            "      6        \u001b[36m2.0657\u001b[0m  14.9745\n",
            "      7        \u001b[36m1.9742\u001b[0m  14.9994\n",
            "      8        \u001b[36m1.9093\u001b[0m  14.7881\n",
            "      9        1.9201  15.3269\n",
            "     10        \u001b[36m1.8613\u001b[0m  14.6872\n",
            "0.3564\n",
            "---Query no:  18 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3915\u001b[0m  15.1562\n",
            "      2        \u001b[36m2.0677\u001b[0m  14.7705\n",
            "      3        \u001b[36m1.9560\u001b[0m  14.8120\n",
            "      4        \u001b[36m1.8880\u001b[0m  14.7602\n",
            "      5        \u001b[36m1.7913\u001b[0m  15.5704\n",
            "      6        \u001b[36m1.6784\u001b[0m  14.7897\n",
            "      7        \u001b[36m1.6141\u001b[0m  14.7815\n",
            "      8        \u001b[36m1.5818\u001b[0m  14.8135\n",
            "      9        \u001b[36m1.5501\u001b[0m  16.4643\n",
            "     10        \u001b[36m1.5230\u001b[0m  14.8936\n",
            "0.4304\n",
            "---Query no:  19 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5318\u001b[0m  15.6173\n",
            "      2        \u001b[36m2.1511\u001b[0m  14.8567\n",
            "      3        \u001b[36m2.0123\u001b[0m  14.8858\n",
            "      4        \u001b[36m1.9181\u001b[0m  14.8555\n",
            "      5        \u001b[36m1.8637\u001b[0m  15.6806\n",
            "      6        \u001b[36m1.7738\u001b[0m  14.8427\n",
            "      7        \u001b[36m1.6986\u001b[0m  14.8441\n",
            "      8        \u001b[36m1.6630\u001b[0m  14.8450\n",
            "      9        \u001b[36m1.6129\u001b[0m  15.3620\n",
            "     10        \u001b[36m1.6091\u001b[0m  15.1416\n",
            "0.4204\n",
            "---Query no:  20 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.6208\u001b[0m  15.7561\n",
            "      2        \u001b[36m2.1131\u001b[0m  14.9394\n",
            "      3        \u001b[36m1.9346\u001b[0m  14.9124\n",
            "      4        \u001b[36m1.8573\u001b[0m  14.8577\n",
            "      5        \u001b[36m1.8215\u001b[0m  15.6083\n",
            "      6        \u001b[36m1.7687\u001b[0m  15.1476\n",
            "      7        \u001b[36m1.7533\u001b[0m  14.8621\n",
            "      8        \u001b[36m1.7179\u001b[0m  14.9028\n",
            "      9        \u001b[36m1.6889\u001b[0m  15.1144\n",
            "     10        \u001b[36m1.6785\u001b[0m  15.5171\n",
            "0.3372\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[103  13  38  12  49   6  44  26 152  57]\n",
            " [  1 137   5   7   8   8  83  35  28 188]\n",
            " [  6   1  44  22 177  27 157  40  12  14]\n",
            " [  0   3  13  85  95  38 231  16   3  16]\n",
            " [  5   0  13  20 215  12 180  30  10  15]\n",
            " [  1   2  19  97 116  55 170  27   2  11]\n",
            " [  0   1   8  22  90   3 362   9   1   4]\n",
            " [  2   1  15  14  90  15 137 194   3  29]\n",
            " [ 31  22  11  23  33  17  41  17 214  91]\n",
            " [  5  29   8  14  10  12  98  16  31 277]]\n",
            "Accuracy:  0.3372\n",
            "Macro F1-score:  0.3206418782786121\n",
            "Micro F1-score:  0.3372\n",
            "Weighted F1-score:  0.3206418782786121\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "AL_Retrain(5000, 20,  30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bzLvra96iNrO",
        "outputId": "14579bfe-197d-4071-d24d-6300324612c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3057\u001b[0m  26.8425\n",
            "      2        \u001b[36m1.8534\u001b[0m  26.8089\n",
            "      3        \u001b[36m1.7350\u001b[0m  27.6792\n",
            "      4        \u001b[36m1.6930\u001b[0m  27.4294\n",
            "      5        \u001b[36m1.6416\u001b[0m  27.2543\n",
            "      6        \u001b[36m1.6131\u001b[0m  26.8727\n",
            "      7        \u001b[36m1.5726\u001b[0m  26.8667\n",
            "      8        \u001b[36m1.5449\u001b[0m  26.8242\n",
            "      9        \u001b[36m1.5095\u001b[0m  28.4753\n",
            "     10        1.5105  29.0073\n",
            "No of initial data:  10000\n",
            "0.4558\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[280  23  18   9   5   7   4   8 115  31]\n",
            " [ 22 295   1  15   1   3   7   4  53  99]\n",
            " [ 56  12  98  46  79  78  45  36  30  20]\n",
            " [ 16  11  31 120  34 144  38  48  24  34]\n",
            " [ 38   1  50  43 151  66  38  71  22  20]\n",
            " [ 10  18  30  85  32 221  18  50  11  25]\n",
            " [  5  18  24  63  58  25 220  44   9  34]\n",
            " [ 23  13  11  29  16  56  12 275   9  56]\n",
            " [103  35   5   5   0   6   1   2 315  28]\n",
            " [ 20  79   4   7   0  10   8  10  58 304]]\n",
            "Accuracy:  0.4558\n",
            "Macro F1-score:  0.4460572649230509\n",
            "Micro F1-score:  0.4558\n",
            "Weighted F1-score:  0.44605726492305087\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[8, 4, 4, 5, 6, 5, 7, 7, 7, 1, 7, 3, 1, 0, 2, 5, 5, 3, 4, 6, 4, 6, 4, 3, 5, 0, 6, 7, 3, 3, 0, 4, 7, 2, 2, 2, 6, 7, 3, 3, 5, 4, 5, 4, 4, 1, 5, 6, 6, 2, 3, 7, 7, 0, 7, 5, 5, 6, 3, 4, 6, 3, 6, 4, 4, 6, 2, 6, 8, 9, 5, 1, 3, 5, 3, 0, 3, 5, 6, 5, 4, 0, 3, 2, 4, 2, 9, 4, 0, 4, 0, 2, 3, 6, 7, 4, 5, 2, 4, 2, 6, 3, 7, 0, 2, 2, 9, 5, 4, 7, 2, 3, 2, 2, 4, 6, 7, 6, 2, 7, 7, 3, 4, 6, 3, 2, 4, 6, 2, 2, 7, 3, 2, 0, 4, 4, 6, 2, 3, 5, 3, 1, 3, 3, 6, 2, 3, 9, 4, 3, 5, 3, 6, 2, 5, 6, 2, 5, 3, 3, 3, 4, 2, 4, 9, 7, 7, 3, 5, 2, 6, 9, 4, 8, 3, 6, 6, 3, 4, 5, 4, 5, 1, 5, 0, 2, 2, 3, 4, 4, 2, 7, 6, 5, 2, 4, 1, 2, 6, 8, 7, 3, 5, 7, 6, 5, 7, 7, 3, 2, 7, 3, 4, 2, 3, 2, 2, 8, 9, 6, 3, 4, 6, 7, 4, 4, 9, 7, 4, 2, 4, 5, 9, 4, 3, 3, 0, 2, 4, 3, 3, 3, 5, 2, 6, 6, 6, 4, 3, 2, 7, 5, 3, 4, 5, 3, 6, 6, 0, 2, 7, 3, 5, 5, 7, 4, 8, 7, 5, 2, 3, 7, 4, 3, 4, 9, 6, 5, 9, 4, 6, 9, 4, 3, 6, 3, 6, 2, 7, 4, 0, 3, 0, 9, 9, 6, 7, 7, 3, 5, 4, 5, 3, 7, 2, 3, 6, 4, 3, 3, 5, 2, 3, 2, 2, 7, 4, 1, 2, 3, 4, 7, 4, 5, 8, 2, 4, 5, 7, 2, 2, 3, 5, 5, 0, 2, 2, 5, 6, 4, 2, 7, 6, 4, 2, 6, 6, 2, 6, 4, 7, 6, 1, 2, 5, 4, 2, 3, 2, 8, 5, 3, 9, 5, 0, 4, 7, 4, 2, 2, 8, 5, 5, 6, 2, 4, 8, 7, 6, 5, 6, 1, 6, 0, 2, 4, 4, 8, 5, 6, 8, 6, 4, 6, 4, 2, 8, 4, 5, 3, 5, 9, 6, 3, 3, 6, 7, 6, 6, 6, 5, 4, 3, 6, 7, 9, 5, 2, 1, 2, 4, 6, 9, 6, 4, 2, 4, 7, 6, 5, 7, 3, 4, 4, 2, 6, 7, 2, 2, 2, 7, 4, 2, 7, 2, 2, 0, 5, 6, 4, 6, 3, 1, 1, 6, 9, 5, 7, 7, 2, 6, 6, 2, 7, 7, 4, 1, 6, 3, 4, 5, 8, 1, 6, 5, 6, 7, 9, 3, 5, 6, 3, 0, 1, 6, 5, 0, 7, 2, 9, 6, 6, 2, 9, 3, 4, 6, 4, 6, 3, 6, 3, 5, 6, 6, 6, 5, 5, 3, 2, 6, 5, 0, 6, 7, 4, 2, 4, 8, 6, 5, 8, 7, 6, 4, 9, 7, 5, 6, 1, 5, 8, 6, 6, 7, 5, 3, 7, 7, 9, 3, 5, 6, 3, 5, 7, 2, 5, 7, 7, 7, 3, 6, 0, 5, 5, 3, 3, 6, 2, 3, 6, 8, 6, 6, 9, 7, 5, 4, 8, 3, 2, 4, 5, 6, 4, 3, 4, 8, 2, 6, 3, 7, 5, 0, 2, 2, 6, 7, 5, 2, 3, 6, 3, 5, 5, 3, 5, 6, 2, 4, 6, 5, 1, 4, 3, 7, 8, 5, 9, 7, 3, 3, 6, 3, 3, 4, 5, 6, 5, 6, 5, 3, 3, 7, 6, 5, 1, 3, 3, 3, 3, 2, 1, 1, 6, 2, 3, 5, 1, 0, 5, 6, 5, 9, 6, 7, 5, 9, 2, 2, 7, 4, 6, 5, 4, 1, 5, 8, 1, 6, 3, 6, 3, 2, 2, 4, 7, 4, 4, 5, 3, 6, 2, 8, 7, 6, 3, 2, 3, 9, 5, 6, 2, 4, 5, 4, 3, 3, 7, 0, 6, 3, 5, 5, 3, 2, 2, 5, 5, 3, 5, 2, 7, 3, 2, 7, 6, 2, 6, 3, 2, 1, 3, 5, 5, 6, 4, 7, 3, 5, 4, 9, 3, 5, 4, 3, 1, 4, 5, 3, 7, 3, 4, 0, 9, 5, 4, 5, 6, 4, 4, 5, 7, 4, 3, 5, 7, 6, 5, 6, 2, 3, 9, 9, 5, 1, 2, 3, 9, 0, 1, 7, 7, 8, 2, 1, 5, 7, 5, 8, 3, 5, 7, 7, 0, 8, 6, 3, 6, 7, 2, 2, 2, 4, 7, 3, 8, 4, 2, 6, 6, 3, 5, 5, 7, 1, 3, 2, 4, 6, 2, 3, 2, 2, 5, 6, 3, 1, 5, 3, 1, 7, 3, 6, 7, 5, 5, 3, 8, 1, 1, 3, 9, 7, 2, 4, 5, 2, 2, 3, 3, 7, 7, 6, 5, 2, 0, 1, 1, 5, 2, 2, 6, 3, 6, 3, 6, 2, 2, 2, 5, 2, 7, 4, 7, 0, 5, 2, 5, 5, 5, 7, 6, 7, 3, 3, 2, 5, 6, 4, 3, 4, 5, 8, 5, 4, 4, 6, 4, 7, 5, 2, 5, 6, 8, 6, 2, 2, 2, 6, 7, 2, 1, 5, 6, 3, 5, 8, 2, 6, 7, 6, 3, 5, 5, 6, 4, 5, 5, 2, 2, 8, 8, 4, 7, 2, 4, 7, 6, 4, 2, 4, 0, 5, 7, 7, 5, 4, 3, 9, 2, 2, 3, 5, 0, 5, 5, 3, 2, 6, 1, 7, 4, 1, 5, 3, 5, 5, 6, 3, 2, 4, 4, 4, 6, 2, 6, 7, 4, 8, 6, 4, 5, 2, 3, 4, 4, 4, 7, 6, 0, 2, 6, 4, 7, 1, 0, 2, 0, 7, 6, 2, 2, 4, 9, 0, 2, 3, 7, 4, 9, 5, 8, 3, 7, 4, 5, 6, 5, 5, 2, 4, 2, 7, 6, 3, 3, 6, 4, 2, 5, 3, 5, 6, 4, 6, 3, 3, 5, 5, 5, 4, 3, 1, 7, 4, 9, 6, 4, 3, 5, 7, 5, 3, 4, 6, 0, 4, 6, 3, 3, 3, 4, 2, 4, 9, 6, 8, 6, 3, 2, 9, 7, 4, 5, 2, 2, 4, 6, 2, 1, 0, 5, 8, 2, 6, 1, 4, 2, 6, 3, 6, 4, 2, 2, 5, 5, 5, 5, 0, 0, 2, 4, 6, 1, 7, 2, 5, 6, 8, 6, 7, 5, 4, 5, 6, 4, 3, 4, 2, 1, 4, 3, 3, 6, 2, 3, 6, 7, 4, 5, 6, 3, 4, 6, 4, 4, 4, 5, 4, 0, 5, 4, 6, 6, 2, 4, 6, 5, 6, 2, 2, 8, 5, 1, 4, 2, 6, 6, 4, 6, 2, 0, 3, 1, 2, 4, 4, 5, 4, 4, 3, 2, 5, 9, 5, 1, 3, 1, 3, 4, 2, 0, 5, 3, 5, 3, 5, 7, 4, 2, 2, 2, 3, 1, 8, 6, 8, 4, 5, 7, 2, 0, 3, 9, 4, 9, 2, 2, 7, 5, 3, 4, 0, 5, 8, 4, 5, 3, 7, 0, 6, 2, 4, 6, 2, 4, 8, 8, 9, 6, 3, 7, 2, 7, 3, 2, 6, 6, 3, 5, 5, 0, 0, 0, 5, 2, 5, 6, 5, 3, 7, 0, 4, 2, 5, 7, 6, 3, 5, 3, 4, 6, 7, 0, 4, 5, 9, 6, 8, 3, 5, 0, 1, 3, 3, 4, 4, 5, 1, 3, 5, 5, 4, 3, 3, 4, 2, 5, 3, 4, 6, 2, 9, 2, 7, 5, 4, 4, 7, 4, 0, 6, 2, 3, 4, 3, 6, 7, 5, 6, 3, 5, 6, 2, 2, 1, 4, 5, 3, 7, 7, 3, 3, 3, 3, 3, 1, 6, 5, 7, 8, 7, 3, 2, 6, 4, 9, 2, 5, 5, 7, 1, 6, 0, 4, 5, 6, 7, 6, 4, 6, 6, 4, 4, 5, 3, 9, 0, 1, 5, 8, 7, 3, 3, 3, 4, 5, 3, 9, 7, 3, 5, 4, 4, 7, 4, 3, 2, 6, 6, 5, 6, 0, 2, 2, 3, 6, 6, 5, 2, 8, 3, 9, 5, 2, 1, 1, 2, 5, 4, 2, 1, 4, 0, 4, 7, 4, 3, 0, 3, 3, 7, 6, 0, 5, 2, 3, 6, 4, 6, 3, 7, 3, 1, 5, 9, 6, 2, 6, 2, 4, 3, 6, 5, 0, 3, 5, 6, 2, 6, 2, 2, 8, 9, 4, 3, 6, 6, 6, 5, 4, 4, 3, 5, 8, 6, 4, 9, 2, 9, 7, 4, 4, 3, 5, 0, 4, 4, 7, 4, 2, 2, 3, 0, 6, 7, 4, 2, 6, 6, 7, 2, 4, 5, 6, 7, 9, 4, 8, 0, 9, 6, 9, 4, 7, 8, 4, 3, 9, 2, 5, 1, 7, 4, 6, 3, 2, 5, 3, 3, 5, 2, 7, 3, 2, 2, 4, 7, 3, 6, 2, 0, 2, 6, 4, 6, 3, 5, 7, 0, 6, 5, 1, 3, 2, 0, 2, 9, 7, 2, 6, 6, 7, 3, 9, 9, 2, 7, 0, 5, 4, 2, 0, 0, 5, 3, 2, 5, 9, 8, 7, 0, 8, 0, 7, 3, 7, 3, 1, 9, 5, 2, 6, 7, 5, 5, 6, 2, 3, 3, 1, 4, 5, 6, 2, 5, 5, 7, 6, 7, 5, 7, 3, 5, 2, 4, 0, 3, 3, 2, 7, 3, 3, 7, 3, 6, 7, 2, 5, 4, 1, 4, 6, 6, 7, 6, 4, 2, 2, 6, 6, 7, 2, 4, 2, 3, 6, 6, 2, 4, 6, 3, 3, 0, 6, 3, 4, 5, 5, 1, 9, 4, 4, 6, 2, 0, 7, 3, 6, 3, 0, 6, 1, 2, 5, 3, 4, 5, 2, 5, 4, 4, 7, 4, 6, 5, 9, 2, 2, 2, 6, 5, 5, 2, 4, 2, 4, 7, 3, 7, 6, 3, 3, 4, 9, 8, 3, 4, 7, 6, 6, 4, 7, 2, 1, 6, 3, 3, 4, 4, 3, 8, 4, 3, 5, 7, 6, 6, 2, 2, 9, 5, 4, 7, 5, 4, 3, 5, 0, 5, 8, 2, 6, 6, 4, 1, 6, 8, 6, 9, 0, 9, 4, 2, 3, 2, 4, 6, 6, 6, 6, 9, 0, 6, 4, 3, 5, 5, 4, 2, 7, 5, 6, 3, 2, 5, 6, 6, 2, 6, 4, 8, 4, 2, 6, 6, 6, 2, 1, 5, 9, 4, 1, 7, 2, 0, 2, 8, 7, 6, 7, 3, 5, 4, 8, 6, 3, 5, 6, 3, 3, 9, 5, 7, 2, 3, 7, 9, 9, 4, 7, 4, 4, 9, 9, 5, 7, 2, 7, 3, 5, 3, 3, 7, 5, 3, 3, 2, 3, 3, 3, 4, 6, 2, 6, 3, 5, 1, 3, 5, 6, 2, 5, 4, 2, 6, 2, 4, 4, 2, 2, 4, 3, 4, 7, 6, 6, 5, 9, 5, 3, 2, 3, 9, 3, 4, 2, 2, 2, 6, 8, 5, 3, 2, 5, 6, 3, 3, 0, 6, 0, 5, 3, 0, 2, 5, 2, 4, 1, 6, 3, 5, 2, 4, 6, 3, 1, 2, 9, 3, 4, 2, 0, 3, 4, 4, 3, 2, 5, 1, 3, 3, 2, 9, 9, 3, 7, 5, 5, 9, 5, 3, 2, 2, 5, 2, 3, 5, 8, 5, 2, 0, 9, 3, 5, 3, 0, 0, 4, 3, 3, 5, 2, 9, 2, 7, 7, 2, 4, 7, 2, 1, 2, 4, 0, 6, 7, 2, 7, 7, 3, 5, 3, 6, 7, 2, 5, 2, 7, 3, 6, 3, 5, 2, 3, 8, 2, 0, 4, 8, 3, 3, 3, 3, 5, 6, 6, 3, 5, 6, 8, 2, 6, 3, 7, 3, 5, 3, 2, 4, 7, 3, 4, 6, 6, 7, 4, 7, 3, 5, 2, 4, 1, 7, 4, 3, 2, 0, 8, 3, 3, 6, 7, 4, 4, 6, 3, 6, 7, 3, 7, 3, 4, 5, 4, 3, 4, 4, 4, 5, 8, 6, 3, 9, 8, 4, 3, 2, 5, 2, 2, 8, 4, 2, 0, 5, 3, 7, 5, 7, 7, 4, 2, 6, 2, 6, 6, 5, 7, 2, 7, 7, 3, 2, 5, 7, 5, 3, 3, 5, 2, 3, 4, 7, 6, 0, 2, 3, 2, 4, 5, 3, 9, 7, 4, 2, 8, 2, 9, 1, 8, 2, 7, 4, 2, 5, 5, 2, 0, 4, 5, 9, 7, 6, 2, 4, 3, 6, 1, 3, 5, 3, 7, 4, 5, 4, 6, 2, 6, 3, 8, 6, 6, 6, 6, 2, 6, 3, 4, 3, 2, 3, 4, 6, 6, 1, 7, 4, 7, 7, 7, 8, 4, 6, 2, 3, 6, 6, 3, 4, 5, 0, 2, 3, 8, 3, 0, 5, 6, 2, 0, 3, 4, 7, 7, 4, 6, 2, 0, 1, 7, 2, 0, 2, 4, 5, 8, 8, 0, 3, 4, 4, 0, 7, 7, 7, 3, 4, 3, 2, 4, 6, 6, 9, 4, 1, 5, 9, 1, 4, 2, 6, 4, 4, 2, 3, 5, 6, 6, 4, 9, 4, 7, 3, 6, 0, 4, 4, 2, 7, 1, 4, 5, 4, 4, 0, 7, 3, 6, 3, 7, 3, 2, 4, 5, 2, 7, 4, 7, 3, 1, 6, 9, 5, 7, 5, 6, 7, 3, 5, 3, 4, 0, 1, 0, 5, 5, 5, 2, 2, 6, 1, 3, 2, 2, 7, 2, 0, 7, 3, 4, 6, 0, 7, 3, 6, 2, 7, 5, 7, 6, 8, 5, 8, 0, 4, 3, 5, 3, 5, 3, 9, 3, 7, 4, 4, 2, 4, 3, 6, 7, 2, 2, 3, 4, 2, 7, 5, 4, 5, 8, 2, 6, 2, 8, 1, 5, 6, 7, 7, 0, 4, 4, 2, 6, 5, 7, 7, 6, 3, 5, 4, 4, 3, 7, 4, 4, 8, 4, 6, 8, 3, 6, 4, 6, 1, 5, 2, 7, 4, 3, 5, 4, 4, 4, 6, 5, 6, 4, 5, 7, 4, 8, 3, 7, 8, 3, 3, 5, 6, 6, 6, 3, 7, 3, 4, 5, 3, 4, 1, 4, 2, 6, 0, 6, 4, 7, 3, 7, 7, 3, 2, 6, 1, 2, 4, 9, 3, 3, 0, 3, 9, 7, 6, 6, 2, 5, 6, 0, 4, 8, 6, 7, 6, 7, 6, 9, 4, 6, 6, 7, 6, 3, 1, 7, 6, 4, 9, 4, 6, 3, 3, 9, 4, 3, 3, 3, 3, 1, 7, 2, 5, 2, 6, 0, 7, 6, 9, 4, 6, 6, 6, 2, 4, 2, 5, 9, 5, 3, 4, 3, 6, 4, 7, 2, 3, 1, 2, 3, 4, 3, 4, 3, 4, 6, 5, 8, 2, 7, 9, 5, 5, 8, 3, 1, 3, 4, 5, 3, 9, 3, 2, 3, 8, 2, 5, 7, 5, 6, 2, 3, 3, 3, 8, 3, 0, 3, 7, 9, 9, 6, 3, 4, 4, 5, 9, 3, 4, 4, 0, 5, 3, 8, 4, 6, 6, 3, 3, 4, 2, 5, 4, 2, 9, 2, 2, 2, 5, 5, 8, 2, 2, 3, 3, 5, 8, 4, 6, 3, 0, 1, 6, 0, 5, 5, 7, 2, 4, 8, 2, 3, 4, 5, 5, 2, 3, 4, 6, 0, 3, 5, 2, 2, 0, 2, 2, 6, 3, 0, 6, 3, 5, 3, 6, 2, 4, 2, 7, 0, 4, 3, 6, 7, 3, 2, 6, 2, 1, 4, 0, 3, 5, 2, 4, 4, 0, 4, 6, 3, 6, 5, 3, 3, 5, 3, 2, 2, 5, 6, 9, 1, 6, 6, 4, 3, 4, 2, 2, 3, 6, 3, 6, 2, 2, 3, 7, 6, 3, 4, 5, 4, 1, 7, 9, 6, 5, 5, 8, 6, 3, 1, 6, 8, 0, 6, 3, 3, 7, 2, 7, 3, 7, 4, 9, 7, 5, 4, 7, 3, 5, 2, 3, 4, 4, 3, 5, 4, 2, 6, 4, 1, 6, 6, 2, 7, 4, 3, 4, 2, 0, 3, 5, 3, 2, 8, 7, 0, 2, 7, 0, 4, 6, 3, 5, 8, 7, 3, 5, 2, 7, 3, 1, 6, 0, 4, 5, 6, 2, 6, 3, 3, 8, 3, 2, 1, 6, 2, 5, 1, 7, 3, 5, 3, 6, 3, 4, 3, 2, 2, 4, 7, 5, 5, 0, 7, 6, 2, 2, 0, 5, 2, 5, 8, 2, 3, 4, 4, 4, 1, 5, 2, 4, 5, 8, 5, 2, 6, 6, 0, 5, 3, 0, 0, 6, 2, 8, 9, 2, 5, 5, 2, 5, 2, 5, 2, 7, 4, 0, 5, 2, 0, 2, 7, 5, 6, 1, 6, 6, 2, 6, 2, 3, 2, 7, 5, 6, 2, 2, 3, 5, 3, 0, 3, 0, 4, 4, 3, 6, 4, 6, 4, 1, 3, 7, 5, 6, 6, 6, 2, 5, 0, 4, 7, 4, 9, 6, 2, 4, 4, 7, 2, 2, 6, 1, 4, 2, 2, 0, 3, 3, 7, 5, 3, 2, 4, 2, 4, 9, 5, 5, 1, 6, 4, 7, 3, 4, 9, 6, 7, 5, 5, 2, 5, 6, 7, 9, 5, 6, 5, 5, 3, 5, 7, 2, 3, 6, 4, 2, 2, 5, 6, 6, 5, 6, 1, 6, 3, 5, 4, 3, 0, 4, 0, 4, 5, 5, 3, 4, 2, 5, 4, 5, 2, 4, 5, 6, 3, 8, 6, 4, 5, 2, 4, 9, 7, 0, 7, 1, 7, 0, 9, 2, 6, 2, 3, 9, 2, 7, 9, 6, 3, 0, 1, 7, 5, 0, 4, 9, 0, 6, 3, 6, 3, 7, 5, 6, 3, 2, 5, 6, 3, 3, 2, 7, 6, 2, 3, 2, 5, 4, 1, 7, 3, 5, 4, 2, 6, 3, 5, 7, 7, 1, 2, 2, 3, 6, 7, 4, 3, 6, 0, 4, 2, 4, 7, 4, 2, 6, 2, 7, 5, 3, 5, 2, 5, 2, 5, 5, 2, 3, 3, 2, 6, 2, 3, 4, 0, 6, 1, 5, 4, 3, 6, 6, 3, 2, 4, 3, 6, 5, 3, 2, 4, 2, 3, 3, 9, 2, 2, 4, 6, 0, 9, 4, 6, 3, 3, 7, 5, 3, 5, 0, 2, 9, 7, 5, 1, 8, 2, 6, 4, 3, 6, 5, 5, 2, 6, 6, 3, 8, 3, 5, 5, 2, 3, 3, 5, 5, 8, 3, 4, 2, 7, 9, 6, 3, 6, 7, 4, 3, 2, 6, 7, 5, 0, 5, 8, 9, 9, 5, 9, 2, 3, 0, 5, 7, 3, 7, 4, 2, 6, 5, 2, 7, 8, 1, 4, 7, 3, 6, 2, 3, 3, 7, 3, 5, 2, 6, 4, 1, 2, 9, 7, 3, 1, 4, 8, 1, 7, 6, 2, 5, 2, 3, 2, 9, 8, 6, 7, 2, 5, 4, 5, 3, 2, 1, 7, 5, 2, 4, 3, 3, 3, 6, 9, 4, 7, 2, 4, 4, 7, 6, 4, 6, 2, 6, 3, 9, 6, 3, 3, 5, 5, 6, 4, 5, 7, 6, 1, 2, 6, 7, 3, 7, 7, 3, 5, 3, 4, 2, 5, 5, 0, 4, 7, 7, 7, 1, 6, 4, 5, 6, 4, 2, 7, 7, 3, 2, 8, 4, 5, 0, 6, 4, 2, 3, 1, 7, 2, 5, 9, 4, 3, 7, 3, 5, 3, 7, 5, 5, 4, 3, 0, 7, 3, 2, 5, 6, 2, 3, 4, 7, 6, 4, 6, 5, 0, 5, 6, 2, 3, 3, 9, 7, 5, 0, 7, 6, 5, 4, 6, 3, 5, 2, 6, 7, 4, 3, 3, 8, 3, 0, 6, 2, 6, 6, 9, 2, 3, 4, 6, 6, 0, 5, 0, 5, 6, 5, 3, 6, 4, 2, 5, 6, 6, 3, 7, 8, 8, 5, 5, 9, 2, 7, 2, 3, 7, 3, 6, 2, 5, 6, 5, 5, 6, 4, 4, 2, 7, 2, 3, 3, 5, 4, 2, 4, 3, 4, 3, 3, 2, 2, 2, 2, 2, 7, 8, 5, 3, 1, 7, 4, 8, 6, 6, 4, 3, 0, 6, 4, 7, 5, 8, 9, 8, 5, 3, 1, 5, 2, 3, 4, 3, 7, 1, 4, 6, 3, 6, 3, 0, 5, 7, 6, 4, 3, 4, 6, 3, 7, 7, 6, 2, 9, 6, 3, 1, 6, 5, 9, 9, 7, 2, 6, 6, 6, 5, 2, 2, 5, 3, 4, 5, 2, 4, 8, 2, 7, 6, 5, 3, 3, 4, 5, 7, 9, 5, 9, 2, 3, 5, 2, 6, 4, 6, 4, 3, 2, 6, 7, 6, 8, 7, 4, 1, 3, 9, 3, 6, 3, 3, 6, 3, 4, 5, 2, 7, 5, 6, 0, 6, 9, 3, 7, 9, 1, 4, 2, 5, 2, 8, 1, 3, 6, 2, 3, 9, 5, 2, 3, 6, 7, 4, 1, 3, 2, 7, 9, 1, 4, 9, 1, 6, 9, 4, 5, 5, 7, 4, 3, 6, 4, 1, 5, 5, 2, 0, 2, 7, 2, 2, 2, 5, 9, 6, 6, 5, 6, 3, 0, 6, 7, 2, 3, 2, 7, 3, 4, 2, 2, 2, 7, 7, 7, 4, 5, 1, 2, 2, 4, 4, 6, 0, 4, 5, 7, 3, 2, 1, 5, 4, 2, 7, 0, 2, 0, 6, 2, 7, 5, 5, 4, 0, 1, 6, 8, 3, 8, 1, 6, 2, 2, 9, 2, 4, 2, 2, 3, 3, 6, 0, 3, 5, 0, 5, 2, 3, 7, 5, 3, 6, 5, 5, 6, 3, 2, 6, 2, 0, 3, 3, 5, 5, 5, 3, 2, 4, 6, 3, 6, 5, 4, 4, 6, 6, 0, 7, 0, 8, 9, 2, 3, 2, 6, 2, 1, 2, 5, 4, 6, 6, 1, 0, 6, 4, 3, 6, 6, 7, 6, 3, 4, 2, 3, 4, 5, 5, 4, 5, 3, 3, 4, 4, 6, 3, 5, 4, 3, 8, 5, 8, 4, 6, 5, 7, 9, 2, 2, 6, 5, 5, 2, 5, 4, 0, 7, 5, 4, 5, 3, 9, 5, 5, 3, 6, 4, 7, 2, 9, 8, 6, 4, 7, 0, 8, 6, 2, 3, 5, 6, 2, 0, 3, 5, 6, 4, 5, 4, 6, 7, 6, 5, 3, 2, 5, 5, 5, 5, 2, 4, 3, 3, 1, 4, 6, 3, 9, 5, 6, 6, 3, 3, 0, 5, 4, 7, 9, 2, 3, 7, 6, 4, 4, 6, 7, 4, 4, 3, 6, 7, 3, 3, 1, 3, 7, 6, 9, 4, 0, 5, 1, 7, 2, 4, 5, 1, 2, 4, 4, 4, 4, 6, 2, 3, 4, 2, 6, 3, 2, 1, 4, 4, 0, 6, 2, 3, 3, 6, 4, 6, 2, 5, 4, 4, 9, 3, 3, 2, 2, 7, 9, 2, 7, 8, 6, 0, 6, 6, 7, 2, 5, 3, 4, 5, 3, 2, 4, 7, 6, 7, 7, 6, 5, 0, 9, 1, 2, 0, 4, 6, 6, 5, 4, 3, 7, 2, 9, 1, 2, 4, 1, 5, 6, 4, 3, 6, 0, 8, 6, 2, 6, 7, 5, 5, 0, 4, 4, 5, 3, 1, 6, 2, 1, 9, 3, 7, 5, 7, 3, 7, 4, 3, 4, 7, 5, 6, 2, 5, 6, 5, 5, 5, 2, 6, 7, 7, 4, 2, 5, 1, 0, 5, 3, 5, 5, 2, 2, 6, 5, 6, 4, 6, 5, 7, 5, 7, 1, 6, 9, 3, 2, 2, 4, 0, 6, 4, 1, 4, 1, 4, 6, 6, 4, 2, 5, 7, 7, 9, 4, 2, 6, 6, 6, 6, 2, 5, 6, 9, 2, 7, 4, 1, 6, 2, 4, 6, 0, 6, 5, 2, 0, 3, 4, 6, 2, 5, 3, 2, 7, 4, 5, 5, 1, 4, 3, 2, 4, 4, 2, 6, 8, 3, 4, 5, 6, 7, 2, 3, 5, 4, 8, 3, 0, 2, 0, 6, 5, 7, 0, 3, 0, 5, 3, 7, 4, 4, 1, 2, 4, 0, 4, 2, 4, 3, 7, 6, 7, 2, 2, 3, 2, 0, 4, 2, 6, 2, 3, 5, 4, 7, 5, 3, 2, 7, 4, 3, 1, 3, 7, 3, 7, 4, 2, 5, 4, 6, 3, 4, 6, 5, 0, 6, 6, 5, 2, 3, 7, 3, 5, 3, 7, 1, 9, 3, 6, 4, 5, 5, 8, 3, 4, 4, 6, 3, 6, 2, 1, 4, 5, 4, 6, 3, 4, 5, 5, 7, 9, 6, 3, 4, 2, 7, 1, 4, 6, 3, 5, 4, 5, 6, 0, 4, 7, 5, 5, 7, 2, 5, 2, 8, 3, 6, 2, 4, 8, 4, 0, 2, 8, 9, 3, 6, 7, 5, 4, 6, 6, 5, 2, 2, 7, 9, 5, 7, 0, 5, 3, 2, 7, 7, 4, 2, 0, 6, 3, 3, 3, 3, 1, 6, 3, 4, 0, 8, 2, 7, 9, 6, 2, 6, 3, 5, 4, 3, 6, 4, 2, 3, 3, 5, 0, 7, 3, 7, 2, 5, 2, 5, 7, 9, 4, 2, 9, 4, 6, 6, 4, 2, 2, 3, 4, 7, 5, 6, 6, 0, 0, 6, 3, 4, 9, 0, 7, 2, 3, 7, 3, 4, 1, 3, 9, 1, 9, 1, 2, 4, 2, 2, 5, 6, 4, 3, 0, 3, 1, 3, 2, 8, 4, 3, 1, 7, 9, 5, 6, 3, 2, 7, 9, 2, 2, 5, 2, 5, 8, 6, 3, 1, 3, 3, 5, 4, 3, 5, 3, 7, 2, 0, 9, 5, 4, 7, 6, 8, 4, 5, 1, 8, 0, 3, 6, 7, 4, 6, 8, 1, 7, 9, 0, 5, 3, 4, 8, 4, 5, 3, 3, 7, 6, 7, 9, 6, 3, 2, 6, 7, 2, 3, 2, 3, 6, 7, 7, 4, 8, 5, 3, 6, 7, 6, 6, 5, 4, 7, 9, 6, 3, 6, 4, 7, 7, 7, 2, 8, 5, 9, 4, 8, 4, 9, 7, 3, 2, 4, 7, 0, 3, 5, 3, 4, 6, 3, 4, 7, 6, 4, 7, 6, 7, 6, 6, 8, 0, 5, 9, 5, 6, 2, 2, 8, 7, 2, 6, 6, 2, 0, 4, 2, 3, 7, 7, 9, 5, 2, 4, 6, 7, 3, 3, 7, 7, 9, 3, 9, 9, 5, 7, 2, 3, 4, 3, 2, 5, 5, 1, 3, 4, 5, 3, 9, 4, 2, 0, 0, 3, 2, 4, 5, 5, 3, 4, 5, 3, 6, 4, 3, 4, 2, 6, 7, 5, 4, 0, 2, 2, 4, 3, 2, 6, 3, 6, 8, 3, 4, 3, 6, 3, 9, 6, 2, 6, 3, 4, 8, 8, 2, 6, 5, 7, 3, 6, 6, 2, 3, 7, 6, 4, 0, 2, 3, 6, 3, 6, 7, 2, 6, 6, 4, 6, 6, 5, 0, 2, 2, 3, 5, 2, 1, 9, 6, 2, 6, 6, 9, 5, 4, 5, 5, 2, 7, 5, 7, 0, 2, 2, 6, 5, 5, 3, 7, 7, 5, 6, 6, 6, 3, 6, 3, 5, 2, 0, 4, 5, 2, 9, 2, 5, 9, 3, 7, 7, 1, 7, 4, 3, 0, 2, 2, 3, 5, 6, 3, 9, 5, 4, 6, 4, 6, 3, 5, 3, 3, 2, 3, 5, 4, 0, 4, 1, 6, 5, 2, 8, 5, 5, 6, 3, 2, 3, 6, 4, 6, 3, 3, 0, 6, 4, 5, 3, 5, 5, 6, 6, 4, 2, 3, 3, 3, 6, 1, 4, 8, 4, 2, 8, 3, 4, 4, 4, 7, 5, 3, 5, 7, 8, 2, 7, 2, 7, 7, 6, 5, 1, 5, 3, 4, 4, 5, 4, 2, 4, 3, 9, 2, 9, 2, 3, 6, 7, 2, 4, 7, 2, 2, 3, 6, 3, 5, 7, 0, 4, 9, 6, 0, 9, 5, 0, 5, 7, 3, 6, 6, 9, 7, 5, 4, 8, 2, 1, 3, 4, 7, 4, 6, 3, 4, 3, 5, 6, 5, 3, 6, 5, 3, 7, 1, 1, 4, 5, 3, 8, 3, 4, 4, 8, 5, 2, 6, 5, 0, 6, 4, 3, 8, 7, 6, 5, 3, 4, 6, 4, 3, 8, 2, 3, 4, 3, 3, 2, 7, 3, 4, 6, 2, 0, 7, 1, 5, 9, 4, 3, 0, 7, 8, 2, 4, 4, 2, 9, 7, 5, 2, 8, 5, 4, 5, 6, 5, 4, 2, 2, 7, 4, 2, 6, 9, 3, 1, 2, 6, 6, 0, 4, 3, 2, 5, 3, 7, 6, 3, 5, 5, 5, 7, 3, 6, 6, 5, 8, 4, 6, 5, 5, 2, 2, 2, 7, 3, 2, 4, 7, 3, 7, 3, 3, 2, 4, 2, 3, 2, 4, 4, 6, 3, 5, 3, 8, 0, 3, 9, 7, 3, 2, 9, 2, 3, 4, 5, 5, 6, 6, 2, 4, 3, 5, 4, 6, 3, 2, 9, 1, 2, 7, 6, 1, 8, 6, 2, 2, 7, 7, 2, 3, 4, 1, 6, 6, 1, 6, 4, 2, 4, 5, 1, 4, 5, 6, 3, 5, 4, 1, 2, 6, 9, 5, 2, 6, 3, 2, 3, 3, 3, 2, 2, 6, 7, 6, 3, 4, 0, 2, 4, 4, 2, 4, 4, 3, 2, 6, 0, 6, 1, 4, 6, 2, 3, 3, 5, 6, 5, 6, 2, 3, 5, 2, 4, 7, 4, 0, 4, 0, 5, 5, 1, 7, 7, 1, 7, 3, 7, 5, 5, 0, 7, 6, 4, 7, 4, 3, 2, 2, 4, 1, 3, 6, 4, 4, 7, 9, 2, 6, 2, 3, 3, 2, 0, 4, 1, 4, 2, 4, 1, 6, 9, 2, 4, 6, 3, 3, 7, 2, 3, 5, 1, 2, 2, 6, 3, 0, 4, 5, 9, 5, 3, 2, 2, 6, 5, 9, 7, 5, 7, 5, 6, 1, 5, 5, 0, 4, 1, 4, 7, 6, 4, 4, 7, 3, 7, 6, 2, 5, 5, 5, 7, 5, 2, 9, 2, 7, 2, 4, 6, 2, 4, 7, 5, 8, 2, 2, 6, 4, 8, 1, 7, 4, 4, 3, 6, 6, 7, 2, 7, 3, 4, 7, 7, 4, 6, 4, 3, 4, 5, 6, 4, 7, 4, 2, 6, 2, 6, 7, 7, 5, 7, 4, 5, 3, 6, 3, 8, 2, 2, 9, 2, 2, 0, 2, 5, 4, 8, 6, 7, 3, 5, 4, 3, 4, 4, 5, 1, 5, 6, 0, 4, 3, 2, 7, 6, 3, 3, 5, 4, 4, 5, 3, 6, 4, 3, 0, 7, 2, 4, 5, 6, 4, 6, 4, 2, 2, 6, 9, 5, 5, 6, 2, 3, 3, 0, 5, 2, 3, 5, 2, 5, 5, 4, 3, 2, 4, 3, 6, 7, 4, 5, 6, 1, 4, 5, 3, 5, 2, 4, 7, 4, 4, 4, 4, 6, 1, 5, 3, 8, 3, 3, 3, 3, 6, 8, 2, 5, 2, 3, 1, 7, 7, 5, 4, 9, 7, 3, 5, 4, 3, 5, 4, 7, 2, 2, 2, 3, 3, 6, 4, 7, 3, 7, 5, 5, 5, 7, 2, 1, 3, 7, 6, 8, 6, 9, 7, 7, 9, 4, 4, 7, 6, 2, 0, 0, 8, 2, 2, 3, 4, 8, 4, 4, 0, 5, 2, 2, 5, 6, 2, 9, 5, 4, 6, 9, 7, 6, 4, 2, 0, 6, 6, 3, 2, 6, 2, 5, 6, 3, 6, 3, 3, 5, 7, 6, 2, 6, 3, 6, 4, 3, 4, 7, 4, 7, 6, 7, 0, 3, 5, 5, 4, 1, 5, 3, 5, 5, 6, 9, 5, 3, 3, 5, 2, 9, 6, 7, 3, 6, 6, 5, 4, 6, 6, 4, 4, 7, 2, 8, 4, 2, 6, 5, 3, 5, 4, 3, 5, 4, 3, 3, 6, 5, 2, 4, 5, 2, 9, 9, 2, 5, 2, 4, 7, 9, 3, 3, 2, 7, 0, 7, 1, 5, 4, 3, 2, 8, 4, 4, 3, 4, 4, 1, 3, 2, 6, 6, 7, 2, 2, 0, 8, 6, 6, 5, 9, 5, 9, 0, 4, 6, 0, 1, 6, 2, 3, 5, 8, 4, 3, 3, 9, 4, 5, 2, 6, 6, 3, 3, 2, 1, 2, 5, 8, 5, 6, 0, 0, 5, 3, 4, 6, 6, 7, 4, 2, 2, 4, 2, 9, 6, 3, 2, 2, 3, 5, 3, 9, 6, 3, 6, 2, 4, 8, 4, 3, 1, 6, 8, 3, 6, 3, 5, 7, 4, 2, 2, 2, 2, 0, 6, 6, 6, 5, 6, 1, 0, 6, 9, 5, 8, 2, 2, 5, 3, 3, 2, 5, 5, 6, 3, 4, 6, 2, 0, 0, 5, 5, 2, 6, 7, 6, 5, 4, 6, 5, 5, 7, 5, 2, 6, 8, 3, 2, 4, 4, 4, 6, 6, 3, 6, 5, 6, 2, 6, 0, 2, 6, 7, 9, 4, 4, 4, 4, 8, 2, 4, 4, 4, 5, 5, 0, 2, 2, 4, 2, 5, 6, 6, 8, 4, 4, 4, 7, 4, 3, 6, 4, 9, 4, 2, 6, 4, 4, 5, 2, 5, 0, 6, 4, 7, 4, 1, 6, 5, 5, 1, 5, 8, 3, 2, 6, 1, 7, 4, 9, 0, 6, 6, 5, 7, 4, 2, 4, 6, 4, 3, 2, 4, 7, 2, 4, 9, 3, 3, 5, 3, 3, 2, 6, 1, 3, 5, 7, 4, 6, 2, 9, 7, 2, 5, 6, 4, 7, 5, 3, 2, 7, 4, 6, 7, 6, 7, 9, 3, 0, 7, 4, 0, 0, 4, 7, 3, 5, 4, 5, 6, 8, 4, 0, 2, 6, 4, 3, 3, 3, 5, 2, 6, 1, 2, 3, 0, 4, 3, 7, 6, 5, 6, 9, 5, 0, 6, 5, 3, 6, 4, 6, 6, 3, 2, 3, 2, 5, 9, 5, 1, 6, 6, 6, 5, 6, 6, 1, 7, 3, 5, 3, 0, 5, 2, 5, 5, 5, 7, 8, 5, 2, 5, 5, 6, 5, 5, 6, 6, 4, 3, 7, 0, 3, 2, 7, 3, 1, 2, 2, 6, 9, 7, 3, 3, 4, 9, 6, 6, 5, 3, 8, 2, 3, 5, 4, 8, 8, 6, 0, 3, 5, 5, 2, 6, 6, 6, 3, 3, 7, 3, 2, 5, 3, 3, 5, 2, 3, 5, 8, 5, 5, 6, 7, 0, 5, 5, 4, 3, 8, 7, 6, 5, 6, 1, 6, 4, 5, 5, 9, 2, 2, 3, 7, 4, 5, 8, 4, 4, 4, 4, 2, 6, 4, 2, 7, 7, 5, 3, 6, 7, 3, 5, 6, 3, 3, 6, 3, 7, 7, 0, 3, 2, 4, 3, 3, 2, 3, 7, 3, 2, 0, 7, 2, 3, 5, 5, 4, 3, 9, 2, 6, 4, 9, 3, 4, 0, 2, 2, 5, 7, 3, 7, 5, 7, 8, 2, 3, 1, 2, 6, 2, 2, 6, 5, 6, 9, 7, 0, 5, 3, 7, 3, 7, 8, 3, 4, 6, 4, 5, 5, 4, 5, 0, 1, 9, 9, 7, 9, 6, 6, 4, 5, 7, 3, 7, 6, 4, 3, 5, 9, 3, 3, 6, 5, 0, 1, 3, 6, 7, 3, 6, 4, 4, 3, 6, 4, 2, 7, 5, 7, 4, 7, 2, 2, 2, 3, 5, 6, 4, 4, 5, 9, 5, 3, 2, 7, 6, 4, 4, 0, 0, 6, 8, 6, 0, 7, 4, 2, 6, 5, 0, 4, 7, 4, 2, 3, 9, 2, 4, 6, 2, 4, 4, 6, 2, 2, 2, 3, 9, 5, 2, 7, 5, 2, 7, 3, 7, 4, 5, 2, 5, 4, 1, 6, 5, 2, 4, 3, 6, 8, 2, 2, 4, 8, 0, 2, 3, 2, 4, 5, 4, 3, 2, 3, 5, 4, 6, 2, 3, 9, 5, 6, 2, 2, 2, 1, 3, 7, 6, 5, 6, 3, 5, 2, 4, 7, 7, 2, 4, 7, 6, 5, 3, 5, 6, 0, 2, 2, 9, 5, 5, 6, 6, 1, 4, 1, 7, 4, 3, 6, 3, 2, 8, 7, 2, 3, 1, 5, 4, 5, 4, 3, 3, 2, 4, 7, 4, 5, 0, 3, 9, 2, 7, 5, 7, 7, 7, 0, 1, 3, 4, 7, 1, 0, 5, 5, 3, 3, 2, 4, 6, 3, 5, 7, 7, 3, 6, 3, 5, 4, 4, 2, 3, 4, 6, 7, 2, 6, 8, 5, 2, 4, 6, 2, 4, 4, 7, 3, 5, 5, 2, 6, 9, 7, 9, 6, 7, 6, 7, 2, 6, 7, 3, 1, 0, 3, 5, 3, 2, 3, 5, 6, 3, 5, 6, 6, 3, 4, 0, 6, 3, 2, 4, 4, 0, 9, 3, 4, 7, 2, 6, 6, 5, 7, 4, 4, 6, 2, 6, 2, 7, 4, 3, 4, 9, 3, 3, 0, 7, 2, 8, 5, 7, 1, 3, 7, 1, 0, 2, 3, 0, 6, 8, 5, 2, 9, 4, 9, 3, 6, 2, 5, 0, 4, 6, 1, 7, 2, 5, 9, 3, 7, 5, 3, 5, 3, 2, 5, 6, 4, 7, 3, 5, 7, 3, 3, 5, 2, 2, 6, 2, 3, 5, 5, 3, 9, 5, 3, 7, 6, 1, 6, 8, 2, 7, 5, 2, 0, 2, 0, 7, 3, 7, 2, 3, 7, 3, 3, 3, 9, 2, 3, 6, 0, 6, 4, 3, 6, 3, 3, 3, 5, 7, 3, 4, 6, 1, 5, 9, 3, 5, 6, 6, 3, 3, 2, 9, 6, 3, 5, 3, 6, 6, 4, 3, 9, 6, 7, 6, 2, 3, 5, 6, 8, 5, 4, 6, 6, 6, 4, 2, 3, 4, 3, 8, 6, 4, 0, 4, 2, 7, 6, 6, 2, 4, 8, 7, 9, 3, 1, 2, 9, 6, 5, 0, 5, 2, 7, 6, 4, 7, 6, 2, 5, 2, 7, 5, 1, 6, 5, 3, 1, 4, 5, 7, 3, 3, 5, 9, 5, 4, 5, 4, 0, 1, 5, 7, 9, 3, 2, 2, 8, 4, 2, 3, 3, 4, 4, 2, 3, 1, 1, 7, 8, 5, 3, 6, 7, 6, 6, 9, 3, 4, 9, 3, 7, 5, 6, 7, 5, 0, 7, 2, 6, 0, 2, 1, 2, 5, 1, 4, 4, 4, 9, 9, 4, 6, 2, 5, 6, 9, 5, 6, 9, 0, 7, 2, 2, 5, 5, 6, 7, 2, 4, 7, 0, 2, 6, 2, 7, 5, 2, 5, 5, 0, 6, 7, 2, 5, 5, 5, 8, 8, 2, 0, 9, 5, 5, 5, 9, 2, 6, 1, 7, 7, 8, 4, 6, 5, 6, 6, 1, 4, 5, 4, 5, 5, 9, 6, 4, 4, 1, 2, 8, 0, 6, 6, 4, 4, 2, 6, 4, 5, 4, 2, 2, 2, 2, 6, 8, 4, 2, 5, 5, 4, 2, 6, 5, 7, 8, 5, 2, 7, 5, 6, 5, 4, 4, 5, 7, 2, 0, 6, 5, 4, 4, 6, 2, 2, 6, 6, 5, 2, 8, 9, 7, 6, 2, 8, 1, 6, 2, 4, 5, 6, 4, 7, 2, 7, 5, 5, 5, 6, 6, 4, 9, 7, 2, 4, 6, 6, 4, 6, 7, 7, 7, 4, 2, 9, 6, 5, 2, 5, 7, 4, 7, 5, 5, 4, 7, 4, 5, 2, 6, 9, 4, 0, 9, 7, 2, 2, 1, 1, 7, 7, 5, 6, 7, 2, 0, 7, 5, 4, 7, 4, 9, 9, 7, 5, 4, 0, 0, 7, 4, 2, 6, 2, 6, 6, 5, 6, 2, 4, 7, 2, 4, 4, 5, 8, 6, 7, 7, 0, 5, 4, 5, 5, 7, 4, 2, 6, 5, 1, 2, 1, 6, 5, 9, 8, 4, 8, 4, 5, 4, 1, 5, 2, 9, 7, 6, 2, 4, 4, 7, 2, 2, 8, 0, 2, 8, 2, 5, 4, 0, 7, 2, 2, 4, 5, 2, 4, 6, 4, 8, 2, 8, 9, 7, 6, 6, 2, 6, 4, 2, 5, 4, 4, 6, 1, 5, 9, 6, 2, 6, 4, 6, 1, 8, 2, 5, 4, 2, 2, 2, 6, 9, 5, 0, 2, 7, 5, 7, 0, 8, 9, 2, 4, 4, 7, 2, 2, 5, 0, 0, 4, 6, 7, 5, 2, 2, 2, 2, 7, 1, 4, 7, 9, 4, 4, 1, 5, 4, 2, 7, 5, 5, 9, 4, 6, 2, 2, 5, 5, 8, 7, 4, 7, 6, 7, 6, 8, 6, 4, 7, 5, 6, 7, 0, 6, 7, 6, 2, 4, 5, 4, 4, 6, 5, 4, 5, 4, 5, 6, 8, 4, 7, 4, 6, 9, 2, 2, 2, 6, 2, 2, 2, 8, 5, 5, 7, 4, 1, 4, 2, 6, 9, 4, 4, 4, 6, 6, 5, 2, 7, 5, 2, 9, 0, 2, 4, 1, 5, 7, 7, 4, 4, 5, 5, 7, 4, 2, 1, 5, 1, 4, 2, 7, 4, 5, 5, 0, 5, 2, 5, 5, 9, 5, 4, 5, 7, 2, 4, 2, 4, 2, 8, 9, 4, 9, 4, 5, 4, 2, 5, 4, 4, 2, 1, 4, 5, 5, 4, 4, 4, 1, 4, 5, 0, 7, 7, 5, 4, 9, 9, 8, 5, 4, 9, 4, 9, 0, 5, 5, 9, 9, 0, 5, 7, 5, 5, 4, 1, 5, 5, 7, 4, 4, 7, 5, 1, 5, 0, 4, 7, 7, 4, 1, 7, 4, 5, 9, 4, 7, 5, 5, 7, 4, 1, 5, 7, 9, 7, 5, 0, 1, 0, 5, 0, 5, 7, 5, 1, 1, 8, 0, 5, 5, 9, 5, 9, 5, 5, 5, 7, 5, 1, 7, 5, 7, 7, 7, 7, 8, 0, 8, 9, 9, 7, 7, 9, 0, 0, 7, 7, 9, 7, 9, 7, 7, 9, 9, 0, 7, 9, 1, 7, 7, 8, 0, 1, 1, 7, 7, 7, 1, 7, 8, 0, 0, 8, 7, 0, 0, 8, 7, 8, 7, 0, 7, 9, 1, 1, 7, 0, 1, 7, 1, 0, 7, 0, 7, 7, 1, 1, 1, 8, 0, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 0, 1, 8, 0, 0, 1, 1, 7, 8, 1, 7, 9, 0, 7, 7, 7, 9, 9, 7, 1, 9, 7, 7, 8, 7, 0, 7, 7, 1, 7, 7, 7, 9, 7, 8, 7, 9, 1, 9, 7, 9, 0, 0, 8, 7, 0, 7, 0, 9, 7, 7, 8, 1, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 8, 7, 8, 7, 9, 8, 8, 0, 7, 0, 8, 1, 7, 7, 9, 7, 7, 7, 0, 8, 1, 7, 1, 7, 1, 7, 7, 1, 9, 0, 1, 0, 9, 7, 7, 7, 1, 7, 7, 7, 1, 1, 7, 1, 9, 0, 7, 1, 1, 7, 0, 8, 7, 7, 7, 9, 7, 7, 7, 7, 8, 9, 8, 0, 8, 7, 8, 7, 7, 0, 1, 0, 7, 9, 9, 7, 0, 1, 9, 7, 8, 7, 9, 9, 8, 1, 1, 1, 1, 7, 1, 7, 1, 1, 7, 0, 0, 9, 1, 7, 8, 7, 1, 9, 8, 9, 7, 8, 9, 7, 0, 1, 1, 7, 7, 1, 7, 9, 9, 7, 1, 9, 7, 1, 9, 0, 9, 1, 0, 7, 7, 7, 7, 8, 7, 9, 9, 7, 9, 7, 7, 7, 0, 8, 9, 0, 7, 7, 0, 7, 9, 9, 9, 7, 0, 8, 9, 9, 9, 8, 7, 9, 7, 7, 7, 0, 7, 7, 8, 9, 1, 7, 1, 9, 7, 1, 7, 8, 9, 7, 7, 7, 7, 7, 8, 1, 8, 7, 7, 9, 9, 1, 7, 0, 1, 7, 8, 7, 0, 7, 8, 7, 9, 0, 7, 7, 8, 0, 7, 7, 9, 9, 9, 1, 9, 7, 7, 0, 7, 0, 7, 0, 8, 8, 0, 1, 9, 1, 9, 1, 8, 8, 0, 7, 0, 7, 0, 8, 1, 0, 8, 9, 7, 7, 7, 7, 7, 7, 0, 7, 9, 9, 7, 7, 9, 7, 0, 8, 7, 8, 7, 0, 1, 0, 9, 0, 7, 7, 8, 7, 7, 0, 8, 8, 9, 0, 0, 1, 0, 0, 1, 7, 0, 8, 8, 8, 0, 1, 7, 9, 8, 0, 7, 1, 7, 9, 0, 7, 8, 9, 1, 9, 8, 0, 0, 8, 0, 1, 7, 7, 1, 0, 7, 0, 7, 0, 0, 8, 9, 0, 8, 7, 0, 8, 7, 0, 9, 9, 0, 7, 7, 1, 7, 7, 9, 7, 1, 1, 7, 1, 7, 7, 9, 1, 9, 7, 7, 7, 0, 7, 0, 8, 1, 1, 7, 1, 8, 7, 7, 7, 7, 0, 7, 8, 0, 1, 9, 9, 7, 7, 1, 7, 9, 7, 7, 8, 1, 7, 7, 9, 7, 7, 7, 0, 9, 7, 8, 9, 0, 1, 7, 7, 0, 7, 9, 0, 7, 7, 0, 0, 7, 9, 7, 8, 1, 7, 7, 9, 9, 1, 9, 7, 1, 7, 0, 1, 8, 0, 7, 1, 9, 7, 7, 0, 0, 7, 7, 9, 7, 7, 7, 1, 7, 7, 7, 7, 7, 8, 0, 8, 9, 0, 0, 9, 0, 0, 0, 1, 9, 7, 9, 7, 1, 0, 8, 1, 8, 7, 0, 1, 8, 7, 1, 9, 9, 0, 0, 9, 0, 0, 7, 1, 7, 0, 1, 1, 1, 9, 7, 1, 7, 1, 9, 8, 0, 7, 1, 7, 9, 0, 9, 7, 9, 8, 0, 7, 7, 7, 8, 7, 9, 0, 8, 1, 9, 1, 1, 0, 9, 7, 8, 1, 7, 8, 7, 7, 9, 7, 9, 8, 7, 9, 7, 1, 7, 7, 7, 1, 7, 8, 7, 0, 7, 8, 9, 1, 7, 7, 7, 7, 7, 9, 9, 8, 0, 0, 0, 1, 7, 7, 7, 7, 0, 1, 1, 9, 0, 9, 0, 0, 0, 8, 0, 0, 1, 1, 1, 8, 1, 0, 8, 8, 9, 9, 8, 1, 1, 8, 8, 1, 9, 1, 1, 0, 1, 8, 0, 8, 8, 1, 0, 8, 9, 0, 9, 1, 9, 0, 9, 0, 0, 1, 0, 0, 8, 8, 1, 0, 9, 0, 1, 9, 9, 0, 0, 1, 9, 0, 9, 9, 9, 8, 0, 0, 8, 1, 1, 9, 1, 9, 9, 9, 0, 0, 9, 1, 9, 8, 9, 8, 1, 9, 8, 8, 9, 9, 1, 1, 0, 0, 0, 9, 9, 9, 1, 0, 0, 0, 0, 8, 8, 1, 0, 8, 0, 9, 9, 8, 9, 8, 0, 9, 1, 1, 0, 1, 9, 0, 1, 1, 1, 8, 9, 8, 8, 1, 0, 0, 8, 0, 9, 9, 9, 8, 8, 0, 8, 1, 1, 0, 8, 8, 1, 0, 9, 8, 9, 1, 0, 0, 9, 9, 0, 0, 9, 0, 0, 0, 9, 9, 0, 8, 1, 8, 0, 9, 8, 1, 9, 9, 8, 0, 0, 1, 9, 9, 8, 0, 1, 0, 9, 8, 0, 1, 8, 0, 1, 1, 0, 9, 9, 1, 0, 0, 0, 8, 9, 9, 0, 9, 0, 0, 8, 0, 0, 8, 8, 9, 1, 8, 0, 1, 0, 9, 8, 8, 0, 1, 0, 0, 8, 0, 0, 8, 9, 0, 9, 9, 9, 1, 9, 1, 1, 8, 9, 0, 0, 0, 9, 9, 8, 8, 9, 1, 8, 8, 8, 0, 1, 1, 0, 9, 1, 0, 9, 9, 1, 0, 0, 9, 1, 8, 9, 0, 1, 1, 0, 0, 1, 9, 8, 1, 0, 0, 0, 8, 9, 0, 9, 9, 8, 0, 9, 1, 9, 0, 9, 1, 9, 8, 9, 9, 8, 1, 8, 0, 9, 1, 0, 9, 8, 9, 9, 9, 8, 0, 9, 8, 8, 1, 9, 0, 0, 1, 0, 8, 8, 1, 1, 8, 8, 9, 1, 9, 0, 1, 1, 9, 0, 8, 1, 9, 1, 0, 8, 0, 8, 0, 0, 1, 0, 8, 9, 1, 9, 8, 0, 9, 8, 9, 8, 9, 1, 9, 8, 9, 0, 8, 9, 9, 9, 9, 9, 9, 9, 1, 1, 0, 0, 8, 8, 9, 0, 0, 8, 0, 8, 0, 1, 9, 0, 9, 0, 9, 0, 0, 0, 9, 1, 0, 0, 0, 9, 8, 8, 8, 9, 8, 9, 1, 0, 1, 1, 1, 9, 0, 8, 1, 1, 9, 8, 8, 8, 0, 8, 8, 9, 9, 9, 1, 0, 0, 0, 0, 0, 8, 9, 9, 0, 1, 1, 8, 8, 0, 1, 0, 8, 8, 1, 8, 9, 1, 1, 8, 8, 1, 0, 0, 9, 0, 9, 1, 9, 0, 1, 9, 9, 8, 0, 9, 9, 9, 8, 1, 8, 9, 9, 0, 1, 9, 0, 0, 0, 9, 0, 1, 9, 9, 0, 9, 9, 1, 8, 1, 8, 9, 8, 9, 8, 8, 9, 0, 1, 8, 1, 9, 0, 8, 0, 9, 0, 0, 9, 9, 1, 8, 0, 8, 9, 0, 8, 1, 0, 0, 0, 1, 0, 9, 8, 0, 1, 8, 1, 0, 9, 8, 8, 9, 0, 1, 8, 9, 1, 0, 8, 1, 1, 8, 9, 8, 1, 8, 9, 8, 0, 8, 0, 0, 9, 1, 1, 9, 0, 8, 9, 8, 8, 9, 9, 0, 0, 9, 9, 8, 9, 8, 8, 1, 8, 8, 8, 1, 1, 0, 8, 8, 8, 8, 8, 8, 1, 8, 8, 0, 0, 0, 0, 1, 1, 0, 8, 0, 8, 9, 8, 0, 8, 1, 0, 9, 9, 1, 8, 8, 8, 9, 1, 9, 8, 0, 0, 0, 0, 9, 9, 1, 9, 0, 1, 1, 0, 9, 9, 9, 0, 0, 0, 1, 1, 0, 0, 9, 8, 9, 0, 1, 8, 9, 8, 8, 0, 8, 8, 0, 1, 9, 1, 1, 0, 0, 1, 8, 0, 0, 9, 0, 0, 9, 1, 0, 8, 9, 0, 8, 9, 0, 1, 1, 9, 1, 8, 0, 0, 8, 1, 8, 1, 9, 8, 8, 0, 9, 1, 0, 9, 8, 8, 8, 1, 0, 9, 8, 8, 8, 8, 8, 1, 8, 9, 1, 1, 1, 9, 0, 9, 8, 9, 9, 9, 0, 8, 8, 8, 8, 8, 1, 1, 8, 8, 9, 9, 1, 9, 1, 0, 1, 1, 0, 1, 8, 8, 8, 0, 8, 0, 0, 9, 8, 0, 9, 0, 1, 9, 0, 9, 1, 8, 8, 9, 8, 8, 1, 1, 9, 9, 0, 9, 9, 9, 8, 9, 8, 1, 0, 8, 1, 8, 8, 8, 9, 8, 0, 0, 8, 9, 1, 8, 9, 0, 0, 0, 1, 9, 0, 1, 1, 8, 1, 1, 1, 9, 9, 8, 0, 1, 0, 8, 8, 8, 9, 9, 8, 1, 8, 1, 9, 9, 0, 9, 1, 0, 1, 9, 8, 9, 9, 8, 0, 1, 9, 8, 1, 1, 0, 9, 8, 0, 1, 1, 0, 8, 1, 8, 9, 9, 0, 9, 9, 8, 8, 9, 1, 0, 9, 0, 1, 9, 1, 9, 9, 9, 8, 0, 0, 8, 0, 9, 0, 0, 8, 1, 9, 9, 9, 0, 1, 8, 8, 0, 9, 1, 1, 8, 9, 9, 9, 8, 1, 0, 9, 0, 0, 9, 9, 9, 1, 9, 8, 8, 1, 0, 8, 1, 9, 0, 9, 8, 1, 0, 0, 1, 8, 9, 9, 0, 9, 8, 9, 9, 8, 1, 9, 8, 9, 1, 8, 9, 1, 8, 8, 1, 9, 8, 1, 9, 8, 9, 9, 8, 1, 1, 8, 1, 0, 0, 9, 0, 1, 0, 9, 0, 0, 0, 8, 1, 1, 8, 8, 0, 0, 8, 0, 9, 1, 8, 0, 9, 8, 8, 9, 1, 0, 1, 9, 0, 9, 9, 1, 0, 1, 1, 0, 8, 1, 0, 0, 9, 0, 1, 8, 0, 1, 0, 8, 0, 8, 0, 8, 9, 1, 0, 1, 0, 9, 9, 0, 1, 1, 9, 0, 0, 9, 8, 8, 1, 1, 0, 0, 8, 1, 0, 0, 1, 0, 0, 8, 9, 9, 9, 8, 0, 1, 8, 0, 8, 9, 0, 1, 8, 1, 0, 8, 1, 0, 8, 0, 0, 8, 1, 8, 0, 1, 0, 9, 1, 9, 0, 9, 1, 8, 9, 8, 1, 9, 0, 1, 8, 8, 8, 1, 9, 8, 9, 8, 9, 9, 1, 1, 8, 9, 1, 8, 8, 1, 9, 8, 0, 1, 8, 0, 9, 0, 9, 1, 0, 0, 8, 1, 0, 1, 8, 9, 0, 0, 1, 9, 1, 0, 8, 8, 9, 9, 1, 1, 8, 9, 1, 0, 1, 8, 8, 8, 1, 1, 1, 0, 0, 8, 9, 0, 8, 1, 9, 1, 8, 8, 8, 9, 8, 0, 0, 0, 8, 0, 9, 0, 9, 1, 8, 9, 9, 8, 1, 1, 1, 9, 8, 9, 1, 0, 9, 0, 0, 9, 9, 0, 9, 0, 1, 0, 1, 0, 9, 8, 8, 1, 8, 1, 1, 8, 9, 1, 0, 0, 9, 8, 1, 8, 0, 0, 9, 0, 8, 8, 9, 1, 0, 9, 8, 1, 0, 8, 0, 1, 1, 1, 1, 0, 0, 9, 9, 1, 9, 8, 9, 0, 9, 1, 0, 0, 0, 9, 9, 9, 1, 9, 9, 8, 8, 8, 0, 8, 0, 8, 9, 1, 1, 0, 9, 9, 1, 9, 1, 1, 9, 8, 0, 1, 9, 9, 0, 8, 8, 8, 8, 1, 9, 8, 0, 8, 0, 9, 0, 9, 9, 1, 0, 1, 1, 9, 1, 1, 0, 9, 0, 0, 1, 0, 0, 9, 9, 0, 1, 8, 0, 1, 8, 8, 8, 8, 1, 0, 0, 9, 1, 9, 0, 1, 0, 8, 9, 0, 8, 9, 9, 8, 1, 9, 1, 9, 9, 1, 9, 9, 8, 9, 8, 1, 8, 0, 9, 1, 0, 0, 1, 0, 8, 1, 1, 8, 8, 9, 0, 0, 1, 9, 9, 9, 8, 9, 1, 0, 8, 9, 8, 1, 9, 1, 0, 0, 0, 9, 9, 0, 1, 8, 8, 9, 9, 9, 9, 0, 9, 0, 0, 9, 9, 1, 9, 1, 9, 9, 8, 1, 8, 8, 8, 9, 0, 0, 9, 0, 0, 9, 0, 9, 9, 1, 0, 0, 0, 0, 8, 8, 1, 0, 0, 0, 8, 1, 9, 1, 0, 0, 0, 9, 8, 0, 1, 9, 1, 8, 0, 1, 1, 9, 1, 9, 1, 9, 8, 9, 0, 8, 1, 8, 9, 8, 1, 0, 9, 0, 9, 1, 9, 8, 8, 8, 8, 9, 1, 9, 0, 0, 9, 9, 9, 9, 0, 8, 1, 1, 8, 9, 0, 0, 8, 1, 0, 8, 1, 1, 1, 1, 9, 9, 9, 0, 1, 8, 8, 9, 9, 1, 0, 9, 8, 0, 0, 8, 1, 9, 0, 0, 8, 9, 9, 0, 8, 0, 0, 9, 9, 8, 0, 1, 0, 8, 9, 9, 9, 9, 1, 0, 1, 9, 8, 9, 8, 9, 0, 8, 0, 9, 8, 1, 9, 9, 9, 9, 0, 1, 1, 9, 1, 0, 1, 9, 1, 8, 8, 0, 0, 0, 8, 9, 9, 8, 8, 0, 0, 8, 1, 1, 0, 9, 9, 1, 1, 8, 8, 9, 9, 9, 8, 0, 0, 0, 9, 1, 8, 1, 1, 9, 9, 9, 0, 9, 8, 1, 0, 1, 0, 8, 9, 1, 1, 0, 9, 8, 1, 8, 8, 8, 1, 0, 0, 1, 0, 8, 8, 0, 1, 0, 1, 9, 9, 9, 1, 0, 8, 1, 1, 1, 1, 9, 8, 9, 1, 1, 9, 1, 9, 0, 9, 0, 9, 0, 9, 0, 1, 0, 1, 1, 8, 1, 9, 9, 1, 9, 0, 1, 1, 9, 0, 1, 9, 8, 0, 8, 9, 8, 1, 0, 9, 8, 1, 1, 1, 1, 1, 8, 8, 1, 0, 9, 1, 9, 0, 8, 1, 9, 0, 8, 8, 9, 0, 8, 1, 8, 8, 0, 1, 8, 8, 1, 1, 9, 9, 8, 9, 0, 1, 8, 0, 1, 1, 1, 1, 1, 1, 0, 0, 9, 8, 9, 8, 9, 8, 1, 1, 0, 1, 9, 8, 1, 1, 8, 8, 1, 8, 0, 8, 0, 8, 8, 1, 0, 0, 0, 9, 9, 9, 0, 9, 1, 1, 8, 1, 1, 1, 8, 9, 0, 0, 1, 8, 0, 0, 8, 1, 0, 1, 0, 9, 1, 0, 9, 1, 9, 9, 9, 9, 8, 0, 9, 1, 1, 9, 8, 0, 8, 8, 1, 8, 1, 8, 9, 8, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 8, 0, 8, 1, 8, 1, 8, 0, 8, 0, 1, 0, 9, 9, 0, 0, 9, 8, 0, 8, 1, 8, 9, 9, 0, 8, 0, 1, 8, 0, 8, 0, 9, 8, 8, 0, 0, 9, 0, 0, 9, 0, 8, 9, 1, 0, 1, 8, 1, 8, 8, 9, 8, 8, 1, 8, 1, 9, 9, 0, 1, 0, 8, 0, 0, 9, 8, 8, 9, 1, 0, 9, 0, 9, 9, 8, 1, 0, 1, 1, 9, 8, 8, 9, 1, 9, 1, 0, 9, 9, 9, 8, 8, 8, 8, 9, 0, 0, 0, 0, 0, 9, 0, 0, 8, 1, 0, 1, 8, 8, 0, 8, 0, 9, 9, 9, 8, 8, 9, 9, 1, 8, 1, 1, 9, 0, 9, 0, 0, 1, 1, 8, 8, 9, 8, 9, 1, 1, 8, 9, 0, 0, 1, 0, 9, 0, 9, 8, 0, 1, 8, 1, 8, 9, 8, 0, 8, 9, 9, 0, 1, 1, 0, 1, 8, 9, 8, 0, 1, 9, 8, 9, 8, 8, 9, 8, 1, 8, 1, 1, 8, 8, 9, 9, 1, 9, 8, 8, 8, 1, 0, 9, 9, 1, 1, 1, 8, 9, 1, 9, 1, 8, 9, 8, 0, 9, 8, 0, 1, 0, 9, 1, 9, 9, 8, 9, 9, 0, 1, 8, 1, 1, 1, 9, 8, 1, 1, 9, 8, 1, 8, 8, 8, 8, 0, 1, 9, 0, 0, 1, 9, 1, 8, 8, 8, 8, 9, 1, 9, 9, 0, 1, 0, 9, 1, 0, 1, 0, 8, 0, 9, 0, 1, 0, 1, 9, 8, 8, 8, 1, 8, 9, 8, 9, 8, 9, 1, 8, 1, 9, 1, 8, 0, 0, 0, 9, 0, 8, 0, 8, 8, 1, 9, 0, 9, 8, 9, 9, 8, 8, 0, 8, 0, 9, 9, 0, 1, 9, 0, 1, 0, 1, 1, 9, 8, 9, 1, 9, 0, 0, 8, 8, 0, 8, 9, 8, 0, 0, 1, 9, 0, 9, 9, 1, 8, 9, 0, 1, 8, 1, 0, 8, 0, 1, 1, 8, 9, 8, 0, 1, 1, 8, 0, 0, 1, 9, 1, 1, 8, 9, 0, 0, 9, 1, 8, 0, 1, 9, 8, 1, 8, 8, 9, 1, 8, 8, 9, 1, 9, 8, 9, 1, 1, 8, 9, 1, 9, 8, 8, 8, 1, 9, 8, 8, 9, 8, 8, 8, 1, 1, 1, 8, 1, 8, 1, 1, 8, 8, 1, 1, 8, 1, 8, 8, 8, 1, 8, 8, 1, 8, 8, 8, 1, 8, 1, 8, 8, 1, 8, 1, 8, 8, 1, 8, 8, 8, 1, 1, 8, 1, 1, 1, 1, 1, 1, 8, 8, 1, 1, 1, 1, 1, 8, 1, 8, 1, 1, 1, 8, 1, 1, 1, 8, 1, 8, 1, 1, 8, 1, 1, 1, 8, 8, 1, 1, 1, 1, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 8, 8, 8, 1, 8, 1, 8, 1, 1, 1, 1, 1, 1, 8, 1, 1, 8, 1, 8, 8, 1, 8, 8, 8, 8, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 8, 8, 1, 8, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 8, 8, 1, 8, 1, 1, 1, 1, 8, 1, 1, 8, 1, 8, 8, 1, 8, 1, 8, 1, 1, 1, 1, 1, 1, 8, 1, 8, 1, 1, 1, 8, 1, 8, 8, 8, 1, 8, 8, 8, 8, 8, 8, 1, 8, 1, 1, 1, 8, 1, 8, 8, 1, 8, 8, 1, 8, 8, 8, 1, 8, 8, 1, 1, 1, 8, 1, 8, 1, 8, 1, 1, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
            "Counter({8: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 1: 1000, 3: 1000, 0: 1000, 2: 1000, 9: 1000})\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2614\u001b[0m  26.9467\n",
            "      2        2.4531  26.7878\n",
            "      3        2.3441  26.7491\n",
            "      4        2.3389  26.6259\n",
            "      5        2.3373  27.6095\n",
            "      6        2.3366  26.7492\n",
            "      7        2.2908  26.8445\n",
            "      8        2.3519  26.7588\n",
            "      9        2.3505  27.5319\n",
            "     10        2.3413  30.8937\n",
            "0.1002\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[  0   1   0   0   0   0   0   0 499   0]\n",
            " [  0   1   0   0   0   0   0   0 499   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]]\n",
            "Accuracy:  0.1002\n",
            "Macro F1-score:  0.018586838531650045\n",
            "Micro F1-score:  0.1002\n",
            "Weighted F1-score:  0.01858683853165004\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "---Query no:  1 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2924\u001b[0m  27.5497\n",
            "      2        \u001b[36m1.8860\u001b[0m  26.7830\n",
            "      3        \u001b[36m1.7832\u001b[0m  26.9118\n",
            "      4        \u001b[36m1.7344\u001b[0m  26.8536\n",
            "      5        \u001b[36m1.7031\u001b[0m  27.3919\n",
            "      6        \u001b[36m1.6610\u001b[0m  27.6475\n",
            "      7        \u001b[36m1.6338\u001b[0m  26.9749\n",
            "      8        \u001b[36m1.6302\u001b[0m  26.8789\n",
            "      9        \u001b[36m1.6246\u001b[0m  27.7276\n",
            "     10        \u001b[36m1.5949\u001b[0m  30.0004\n",
            "0.4074\n",
            "---Query no:  2 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3727\u001b[0m  27.0755\n",
            "      2        \u001b[36m2.3036\u001b[0m  27.7147\n",
            "      3        \u001b[36m2.3035\u001b[0m  26.9427\n",
            "      4        \u001b[36m2.3035\u001b[0m  26.9745\n",
            "      5        \u001b[36m2.3035\u001b[0m  28.0402\n",
            "      6        2.3035  27.4192\n",
            "      7        2.3035  27.2246\n",
            "      8        2.3035  26.9122\n",
            "      9        2.3035  27.8391\n",
            "     10        2.3035  29.9866\n",
            "0.1\n",
            "---Query no:  3 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2763\u001b[0m  26.9557\n",
            "      2        \u001b[36m2.0550\u001b[0m  26.9614\n",
            "      3        \u001b[36m2.0075\u001b[0m  27.5939\n",
            "      4        \u001b[36m1.8814\u001b[0m  27.0808\n",
            "      5        \u001b[36m1.7911\u001b[0m  26.9218\n",
            "      6        \u001b[36m1.7410\u001b[0m  27.1130\n",
            "      7        \u001b[36m1.6989\u001b[0m  26.8641\n",
            "      8        \u001b[36m1.6246\u001b[0m  27.7272\n",
            "      9        \u001b[36m1.6181\u001b[0m  27.6568\n",
            "     10        \u001b[36m1.6032\u001b[0m  29.1019\n",
            "0.4078\n",
            "---Query no:  4 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5805\u001b[0m  28.0118\n",
            "      2        \u001b[36m1.9782\u001b[0m  26.9088\n",
            "      3        \u001b[36m1.8357\u001b[0m  27.0151\n",
            "      4        \u001b[36m1.7600\u001b[0m  27.4698\n",
            "      5        \u001b[36m1.7170\u001b[0m  27.4440\n",
            "      6        \u001b[36m1.6860\u001b[0m  27.0320\n",
            "      7        \u001b[36m1.6657\u001b[0m  26.9800\n",
            "      8        \u001b[36m1.6131\u001b[0m  27.0315\n",
            "      9        \u001b[36m1.5838\u001b[0m  28.5121\n",
            "     10        \u001b[36m1.5606\u001b[0m  29.1865\n",
            "0.4354\n",
            "---Query no:  5 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3356\u001b[0m  27.9569\n",
            "      2        \u001b[36m1.9408\u001b[0m  27.0320\n",
            "      3        \u001b[36m1.8055\u001b[0m  27.0468\n",
            "      4        \u001b[36m1.7316\u001b[0m  27.0534\n",
            "      5        \u001b[36m1.6660\u001b[0m  27.3009\n",
            "      6        \u001b[36m1.6183\u001b[0m  27.7323\n",
            "      7        \u001b[36m1.6029\u001b[0m  27.0190\n",
            "      8        1.6395  27.9891\n",
            "      9        \u001b[36m1.5918\u001b[0m  28.0055\n",
            "     10        \u001b[36m1.5763\u001b[0m  30.1148\n",
            "0.4302\n",
            "---Query no:  6 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2910\u001b[0m  27.4852\n",
            "      2        \u001b[36m2.0877\u001b[0m  28.0741\n",
            "      3        \u001b[36m2.0305\u001b[0m  27.1207\n",
            "      4        \u001b[36m1.9831\u001b[0m  27.0757\n",
            "      5        1.9853  27.0278\n",
            "      6        \u001b[36m1.9678\u001b[0m  27.5388\n",
            "      7        \u001b[36m1.9662\u001b[0m  27.6020\n",
            "      8        \u001b[36m1.9476\u001b[0m  27.1268\n",
            "      9        \u001b[36m1.9383\u001b[0m  28.2030\n",
            "     10        1.9479  30.2759\n",
            "0.3132\n",
            "---Query no:  7 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3543\u001b[0m  27.3038\n",
            "      2        \u001b[36m2.1032\u001b[0m  27.2066\n",
            "      3        \u001b[36m2.0185\u001b[0m  29.0486\n",
            "      4        \u001b[36m1.9128\u001b[0m  27.1441\n",
            "      5        \u001b[36m1.8243\u001b[0m  27.0991\n",
            "      6        \u001b[36m1.7712\u001b[0m  27.1399\n",
            "      7        \u001b[36m1.7544\u001b[0m  27.7146\n",
            "      8        \u001b[36m1.6997\u001b[0m  27.5378\n",
            "      9        \u001b[36m1.6726\u001b[0m  28.1640\n",
            "     10        \u001b[36m1.6517\u001b[0m  30.0429\n",
            "0.4006\n",
            "---Query no:  8 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2081\u001b[0m  27.3200\n",
            "      2        \u001b[36m1.8062\u001b[0m  27.1857\n",
            "      3        \u001b[36m1.7057\u001b[0m  27.5697\n",
            "      4        \u001b[36m1.6543\u001b[0m  27.6363\n",
            "      5        \u001b[36m1.5834\u001b[0m  27.2035\n",
            "      6        \u001b[36m1.5275\u001b[0m  27.2396\n",
            "      7        \u001b[36m1.4945\u001b[0m  27.1686\n",
            "      8        \u001b[36m1.4555\u001b[0m  27.9463\n",
            "      9        \u001b[36m1.4273\u001b[0m  28.2055\n",
            "     10        \u001b[36m1.4070\u001b[0m  29.5776\n",
            "0.4606\n",
            "---Query no:  9 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4669\u001b[0m  27.2051\n",
            "      2        \u001b[36m1.9911\u001b[0m  27.3915\n",
            "      3        \u001b[36m1.8702\u001b[0m  27.7069\n",
            "      4        \u001b[36m1.8116\u001b[0m  27.5225\n",
            "      5        \u001b[36m1.7736\u001b[0m  27.1984\n",
            "      6        \u001b[36m1.7321\u001b[0m  27.2196\n",
            "      7        \u001b[36m1.7234\u001b[0m  27.4497\n",
            "      8        \u001b[36m1.6978\u001b[0m  27.8912\n",
            "      9        1.7038  28.3990\n",
            "     10        \u001b[36m1.6938\u001b[0m  30.1261\n",
            "0.3938\n",
            "---Query no:  10 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.1752\u001b[0m  27.4294\n",
            "      2        \u001b[36m1.8043\u001b[0m  27.3292\n",
            "      3        \u001b[36m1.6996\u001b[0m  27.6706\n",
            "      4        \u001b[36m1.6396\u001b[0m  27.8280\n",
            "      5        \u001b[36m1.5875\u001b[0m  27.3931\n",
            "      6        \u001b[36m1.5405\u001b[0m  27.4751\n",
            "      7        \u001b[36m1.5170\u001b[0m  29.2004\n",
            "      8        \u001b[36m1.4562\u001b[0m  27.4485\n",
            "      9        \u001b[36m1.4255\u001b[0m  28.5839\n",
            "     10        \u001b[36m1.4223\u001b[0m  30.6063\n",
            "0.472\n",
            "---Query no:  11 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5668\u001b[0m  27.5299\n",
            "      2        \u001b[36m2.1075\u001b[0m  27.5838\n",
            "      3        \u001b[36m2.0443\u001b[0m  28.3025\n",
            "      4        \u001b[36m1.9903\u001b[0m  27.6671\n",
            "      5        \u001b[36m1.9692\u001b[0m  27.7149\n",
            "      6        \u001b[36m1.9260\u001b[0m  28.0440\n",
            "      7        \u001b[36m1.8163\u001b[0m  27.8583\n",
            "      8        \u001b[36m1.7739\u001b[0m  27.4002\n",
            "      9        \u001b[36m1.7323\u001b[0m  28.4369\n",
            "     10        \u001b[36m1.6945\u001b[0m  30.6493\n",
            "0.3848\n",
            "---Query no:  12 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2758\u001b[0m  27.4162\n",
            "      2        \u001b[36m1.9383\u001b[0m  28.2097\n",
            "      3        \u001b[36m1.8623\u001b[0m  28.3805\n",
            "      4        \u001b[36m1.7933\u001b[0m  27.4015\n",
            "      5        \u001b[36m1.7653\u001b[0m  27.3155\n",
            "      6        \u001b[36m1.7388\u001b[0m  28.1105\n",
            "      7        \u001b[36m1.6975\u001b[0m  27.3739\n",
            "      8        \u001b[36m1.6692\u001b[0m  27.3604\n",
            "      9        \u001b[36m1.6192\u001b[0m  28.8005\n",
            "     10        \u001b[36m1.5794\u001b[0m  30.0915\n",
            "0.4248\n",
            "---Query no:  13 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.1887\u001b[0m  28.1544\n",
            "      2        \u001b[36m1.7755\u001b[0m  27.7901\n",
            "      3        \u001b[36m1.6913\u001b[0m  27.5051\n",
            "      4        \u001b[36m1.6464\u001b[0m  27.5175\n",
            "      5        \u001b[36m1.5843\u001b[0m  28.3041\n",
            "      6        \u001b[36m1.5336\u001b[0m  27.4708\n",
            "      7        \u001b[36m1.5286\u001b[0m  27.4412\n",
            "      8        \u001b[36m1.4974\u001b[0m  27.5960\n",
            "      9        \u001b[36m1.4471\u001b[0m  29.4978\n",
            "     10        1.4492  30.8367\n",
            "0.4458\n",
            "---Query no:  14 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2857\u001b[0m  27.6302\n",
            "      2        \u001b[36m1.8901\u001b[0m  27.5118\n",
            "      3        \u001b[36m1.8236\u001b[0m  27.4913\n",
            "      4        \u001b[36m1.7558\u001b[0m  28.3190\n",
            "      5        \u001b[36m1.7297\u001b[0m  27.5061\n",
            "      6        \u001b[36m1.6824\u001b[0m  27.6026\n",
            "      7        \u001b[36m1.6459\u001b[0m  27.5462\n",
            "      8        1.6505  28.2711\n",
            "      9        \u001b[36m1.6234\u001b[0m  28.9145\n",
            "     10        \u001b[36m1.6007\u001b[0m  30.7416\n",
            "0.4586\n",
            "---Query no:  15 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3615\u001b[0m  27.7241\n",
            "      2        \u001b[36m1.9037\u001b[0m  27.5974\n",
            "      3        \u001b[36m1.8180\u001b[0m  28.4683\n",
            "      4        \u001b[36m1.7714\u001b[0m  27.5326\n",
            "      5        \u001b[36m1.7302\u001b[0m  27.5675\n",
            "      6        \u001b[36m1.6999\u001b[0m  28.9126\n",
            "      7        \u001b[36m1.6606\u001b[0m  28.0004\n",
            "      8        \u001b[36m1.6453\u001b[0m  27.5636\n",
            "      9        \u001b[36m1.5952\u001b[0m  28.7311\n",
            "     10        1.6055  30.6958\n",
            "0.3996\n",
            "---Query no:  16 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5147\u001b[0m  27.6425\n",
            "      2        \u001b[36m2.3033\u001b[0m  28.4541\n",
            "      3        2.3034  27.5820\n",
            "      4        2.3035  27.6311\n",
            "      5        2.3035  28.0577\n",
            "      6        2.3035  27.9360\n",
            "      7        2.3035  27.6312\n",
            "      8        2.3035  27.7776\n",
            "      9        2.3035  29.7423\n",
            "     10        2.3035  30.0515\n",
            "0.1\n",
            "---Query no:  17 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4045\u001b[0m  28.4662\n",
            "      2        \u001b[36m1.9055\u001b[0m  28.6296\n",
            "      3        \u001b[36m1.8355\u001b[0m  27.5847\n",
            "      4        \u001b[36m1.7739\u001b[0m  28.4256\n",
            "      5        \u001b[36m1.7462\u001b[0m  28.1153\n",
            "      6        \u001b[36m1.7054\u001b[0m  27.7797\n",
            "      7        \u001b[36m1.6844\u001b[0m  28.3301\n",
            "      8        \u001b[36m1.6593\u001b[0m  27.7945\n",
            "      9        \u001b[36m1.6572\u001b[0m  28.8573\n",
            "     10        \u001b[36m1.6219\u001b[0m  30.8708\n",
            "0.445\n",
            "---Query no:  18 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2789\u001b[0m  27.7066\n",
            "      2        \u001b[36m1.9326\u001b[0m  28.1132\n",
            "      3        \u001b[36m1.8289\u001b[0m  28.1926\n",
            "      4        \u001b[36m1.7556\u001b[0m  27.5967\n",
            "      5        \u001b[36m1.7131\u001b[0m  27.6049\n",
            "      6        \u001b[36m1.6616\u001b[0m  28.5508\n",
            "      7        \u001b[36m1.6295\u001b[0m  27.7212\n",
            "      8        \u001b[36m1.5793\u001b[0m  27.7271\n",
            "      9        \u001b[36m1.5618\u001b[0m  30.7269\n",
            "     10        \u001b[36m1.5583\u001b[0m  30.3461\n",
            "0.4232\n",
            "---Query no:  19 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3553\u001b[0m  28.6045\n",
            "      2        \u001b[36m1.8963\u001b[0m  27.6976\n",
            "      3        \u001b[36m1.7123\u001b[0m  27.7290\n",
            "      4        \u001b[36m1.6490\u001b[0m  28.0958\n",
            "      5        \u001b[36m1.5910\u001b[0m  28.2579\n",
            "      6        \u001b[36m1.5371\u001b[0m  27.7328\n",
            "      7        \u001b[36m1.4725\u001b[0m  27.7437\n",
            "      8        \u001b[36m1.4289\u001b[0m  28.6361\n",
            "      9        \u001b[36m1.4230\u001b[0m  29.0365\n",
            "     10        \u001b[36m1.4005\u001b[0m  30.5432\n",
            "0.4376\n",
            "---Query no:  20 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4752\u001b[0m  27.7698\n",
            "      2        \u001b[36m2.0589\u001b[0m  27.7478\n",
            "      3        \u001b[36m2.0264\u001b[0m  28.5224\n",
            "      4        \u001b[36m1.9917\u001b[0m  27.7999\n",
            "      5        2.0047  28.9075\n",
            "      6        \u001b[36m1.9502\u001b[0m  28.5687\n",
            "      7        1.9514  27.8342\n",
            "      8        \u001b[36m1.9386\u001b[0m  27.9059\n",
            "      9        \u001b[36m1.9047\u001b[0m  29.8923\n",
            "     10        \u001b[36m1.8806\u001b[0m  30.2956\n",
            "0.3426\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[263  55   7  10   9   9   4  13  82  48]\n",
            " [ 40 257   5  21   0  11   7  13  85  61]\n",
            " [ 58  31  26  84 104  43  48  61  29  16]\n",
            " [ 27  29  29 197  30  43  53  34  31  27]\n",
            " [ 33  18  12  71 166  23  60  64  34  19]\n",
            " [ 17  36  24 147  29 101  39  38  45  24]\n",
            " [  2  19  13 138 109  26 135  35  13  10]\n",
            " [ 29  41  24  44  33  24  18 204  29  54]\n",
            " [193  54   4  19   0  10   1   6 168  45]\n",
            " [ 48  96   5  29   3  13   4  13  93 196]]\n",
            "Accuracy:  0.3426\n",
            "Macro F1-score:  0.32908752323229573\n",
            "Micro F1-score:  0.3426\n",
            "Weighted F1-score:  0.32908752323229573\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "AL_Retrain(10000, 20, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTBCnTveiTIs"
      },
      "outputs": [],
      "source": [
        "AL_Retrain(10000, 20, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v64WwYjniUAJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTBA6TiJi2Pb8O/vd9EEL0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}