{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saimasharleen/Active-Learning-Strategies-Across-Diverse-Machine-Learning-Models/blob/main/CIFAR_10_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DLzn-z5KNBfJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "621hIz4IOhOh",
        "outputId": "14f032ec-0fd6-4ab0-ba55-43e21ccc33e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/modAL-python/modAL.git\n",
            "  Cloning https://github.com/modAL-python/modAL.git to /tmp/pip-req-build-_gff7y7s\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/modAL-python/modAL.git /tmp/pip-req-build-_gff7y7s\n",
            "  Resolved https://github.com/modAL-python/modAL.git to commit bba6f6fd00dbb862b1e09259b78caf6cffa2e755\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.11.4)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.5.3)\n",
            "Collecting skorch==0.9.0 (from modAL-python==0.4.2)\n",
            "  Downloading skorch-0.9.0-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.8/125.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch==0.9.0->modAL-python==0.4.2) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.10/dist-packages (from skorch==0.9.0->modAL-python==0.4.2) (4.66.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->modAL-python==0.4.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->modAL-python==0.4.2) (2023.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->modAL-python==0.4.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->modAL-python==0.4.2) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.0->modAL-python==0.4.2) (1.16.0)\n",
            "Building wheels for collected packages: modAL-python\n",
            "  Building wheel for modAL-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for modAL-python: filename=modAL_python-0.4.2-py3-none-any.whl size=32650 sha256=39feb243e2b19d0ff6b402778e224dfb5bbb6a02cd4064b3ba4dd277cf7cd1ab\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d7pm44ri/wheels/d9/fb/59/7deb61b460c1c36394cd093758986ff7d36f71352dcb2e02c5\n",
            "Successfully built modAL-python\n",
            "Installing collected packages: skorch, modAL-python\n",
            "Successfully installed modAL-python-0.4.2 skorch-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/modAL-python/modAL.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWsbO0FiRj5H",
        "outputId": "7b1bf584-5c68-4a0e-b91a-11c0742d47a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 48024933.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to .\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import CIFAR10\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "import collections\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.uncertainty import uncertainty_sampling\n",
        "from torch import nn\n",
        "from skorch import NeuralNetClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "\n",
        "CIFAR_data = CIFAR10('.', download= True, transform = ToTensor())\n",
        "\n",
        "dataloader = DataLoader(CIFAR_data, shuffle=True, batch_size = 50000 )\n",
        "x, y = next(iter(dataloader))\n",
        "\n",
        "x = x.detach().cpu().numpy()\n",
        "y = y.detach().cpu().numpy()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=5000, random_state=0, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bsmJCrq1R4Dg"
      },
      "outputs": [],
      "source": [
        "#cnn model building\n",
        "\n",
        "class Torch_Model(nn.Module):\n",
        "    def __init__( self):\n",
        "        super( Torch_Model , self).__init__()\n",
        "        self.convs = nn.Sequential(\n",
        "            nn.Conv2d(3,32,3), #----- EDIT THE DIMENSION HERE-----\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.25))\n",
        "\n",
        "        self.fcs = nn.Sequential(\n",
        "            nn.Linear(14*14*64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 10))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x\n",
        "        out = self.convs(out)\n",
        "        out = out.view(-1, 14*14*64)\n",
        "        out = self.fcs(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tMRnO-C6Snfr"
      },
      "outputs": [],
      "source": [
        "classifier = NeuralNetClassifier(Torch_Model,\n",
        "    criterion = nn.CrossEntropyLoss,\n",
        "    optimizer = torch.optim.Adam,\n",
        "    train_split = None,\n",
        "    verbose = 1,\n",
        "    device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxZWA8hJSxHE",
        "outputId": "27b5c4ac-9ddf-45ec-ab9d-5bdc98a2b3d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CNN_model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "filename = \"CNN_model.joblib\"\n",
        "joblib.dump(classifier, filename)\n",
        "#loaded_model = joblib.load(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-qN-ybrGS0Ne"
      },
      "outputs": [],
      "source": [
        "def CF_Print(y_test, y_pred):\n",
        "    accuracy = accuracy_score(y_pred, y_test)\n",
        "    CF = confusion_matrix(y_test, y_pred)\n",
        "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "    micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
        "    weighted_f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    print('Confusion Matrix:')\n",
        "    print(CF)\n",
        "    print('Accuracy: ', accuracy)\n",
        "    print('Macro F1-score: ', macro_f1)\n",
        "    print('Micro F1-score: ', micro_f1)\n",
        "    print('Weighted F1-score: ', weighted_f1)\n",
        "    print(\"---------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OmkdoZPqS34a"
      },
      "outputs": [],
      "source": [
        "def AL_Retrain(n_initial, n_queries, instances ):\n",
        "    x_initial, x_pool, y_initial,  y_pool = train_test_split(x_train,y_train, train_size=n_initial, random_state=0, stratify=y_train)\n",
        "    filename = \"CNN_model.joblib\"\n",
        "    classifier = joblib.load(filename)\n",
        "    learner = ActiveLearner(\n",
        "    estimator = classifier,\n",
        "    query_strategy = uncertainty_sampling,\n",
        "    X_training = x_initial, y_training = y_initial,\n",
        "    )\n",
        "    print(\"No of initial data: \", n_initial)\n",
        "    print(learner.score(x_test, y_test))\n",
        "    y_pred = learner.predict(x_test)\n",
        "    print('Confusion Matrix After trainig with initial data')\n",
        "    CF_Print(y_test, y_pred)\n",
        "    print(\"---- Train From Scratch with first model-----\")\n",
        "    AL_Train_Scratch(n_initial, learner, (n_initial*2) )\n",
        "\n",
        "    print(\"---- Teach/Retrain with new data-------\")\n",
        "    for idx in range(n_queries):\n",
        "        print('---Query no: ', idx+1, '----')\n",
        "        query_idx, query_instance = learner.query(x_pool, n_instances=instances)\n",
        "        learner.teach(\n",
        "            X=x_pool[query_idx],\n",
        "            y=y_pool[query_idx],\n",
        "        )\n",
        "        print(learner.score(x_test, y_test))\n",
        "        x_pool = np.delete(x_pool, query_idx, axis=0)\n",
        "        y_pool = np.delete(y_pool, query_idx, axis=0)\n",
        "    y_pred = learner.predict(x_test)\n",
        "    print('Confusion Matrix After RE-TRAINGING')\n",
        "    CF_Print(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cJx8WwobS7yH"
      },
      "outputs": [],
      "source": [
        "def AL_Train_Scratch(n_initial, trained_learner, instances):\n",
        "    query_idx, query_instance = trained_learner.query(x_train, n_instances=(instances*2))\n",
        "    distribution=[0]*10\n",
        "    flag=0\n",
        "    data_per_class= int(n_initial/10)\n",
        "    x_initial=[]\n",
        "    y_initial=[]\n",
        "    x_temp= x_train[query_idx]\n",
        "    y_temp=y_train[query_idx]\n",
        "    for data, label in zip(x_temp, y_temp):\n",
        "        if distribution[label]<data_per_class:\n",
        "            x_initial.append(data)\n",
        "            y_initial.append(label)\n",
        "            distribution[label]+=1\n",
        "            if distribution[label]==data_per_class:\n",
        "                flag+=1\n",
        "        if flag==10:\n",
        "            break\n",
        "    del x_temp, y_temp\n",
        "    print(y_initial)\n",
        "    counter = collections.Counter(y_initial)\n",
        "    print(counter)\n",
        "    filename = \"CNN_model.joblib\"\n",
        "    classifier = joblib.load(filename)\n",
        "    x_initial= np.array(x_initial)\n",
        "    y_initial = np.array(y_initial)\n",
        "    new_learner = ActiveLearner(\n",
        "        estimator = classifier,\n",
        "        query_strategy = uncertainty_sampling,\n",
        "        X_training = x_initial, y_training = y_initial,\n",
        "    )\n",
        "    print(new_learner.score(x_test, y_test))\n",
        "    y_pred = new_learner.predict(x_test)\n",
        "    print(\"Confusion Matrix after training the model with most important dataset\")\n",
        "    CF_Print(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8AFi0JHS-uZ",
        "outputId": "3c61f7e0-fb14-43c8-a86d-8f6d9c1009a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3129\u001b[0m  0.8155\n",
            "      2        5.0641  0.2776\n",
            "      3        3.2865  0.2780\n",
            "      4        \u001b[36m2.2843\u001b[0m  0.4395\n",
            "      5        2.3019  0.2680\n",
            "      6        \u001b[36m2.2522\u001b[0m  0.2623\n",
            "      7        \u001b[36m2.1954\u001b[0m  0.2647\n",
            "      8        \u001b[36m2.1477\u001b[0m  0.2802\n",
            "      9        \u001b[36m2.0666\u001b[0m  0.2740\n",
            "     10        \u001b[36m1.9766\u001b[0m  0.4262\n",
            "No of initial data:  100\n",
            "0.2004\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[ 99 107   0  46   0   8  44  68  20 108]\n",
            " [  3 191   1  85   0   2 100   5   2 111]\n",
            " [ 35  40   0 116   1   7 124  96   4  77]\n",
            " [ 13  29   0 176   5   5 143  45  11  73]\n",
            " [ 12  37   0 180   2   1 143  46   4  75]\n",
            " [  9  45   0 208   4   8  98  50   9  69]\n",
            " [  2  28   0 133   0   2 217  36   5  77]\n",
            " [  5  39   0 161   1   1 104  85   2 102]\n",
            " [ 40 194   0  38   1   1  47  20  17 142]\n",
            " [  1 146   0  38   0   0  84  21   3 207]]\n",
            "Accuracy:  0.2004\n",
            "Macro F1-score:  0.15772340789480924\n",
            "Micro F1-score:  0.2004\n",
            "Weighted F1-score:  0.15772340789480924\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[2, 4, 4, 2, 2, 0, 3, 4, 4, 4, 8, 4, 4, 2, 3, 7, 2, 0, 3, 2, 5, 3, 8, 3, 4, 0, 4, 4, 2, 5, 5, 3, 2, 8, 2, 3, 6, 2, 6, 0, 0, 0, 0, 5, 3, 3, 7, 0, 6, 7, 7, 3, 8, 0, 6, 6, 7, 7, 0, 8, 6, 5, 5, 5, 7, 8, 6, 5, 8, 5, 7, 5, 6, 8, 6, 6, 8, 8, 7, 7, 1, 9]\n",
            "Counter({2: 10, 4: 10, 0: 10, 3: 10, 8: 10, 7: 10, 5: 10, 6: 10, 1: 1, 9: 1})\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2948\u001b[0m  0.2321\n",
            "      2       16.2876  0.2245\n",
            "      3        5.8340  0.2207\n",
            "      4        \u001b[36m2.2487\u001b[0m  0.2216\n",
            "      5        2.2737  0.2313\n",
            "      6        2.2650  0.2172\n",
            "      7        \u001b[36m2.1911\u001b[0m  0.2182\n",
            "      8        2.2066  0.2235\n",
            "      9        \u001b[36m2.1728\u001b[0m  0.2334\n",
            "     10        2.2016  0.2150\n",
            "0.1\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[  0   0   0   0   0   0  19   1 480   0]\n",
            " [  0   0   0   0   0   0   1   0 499   0]\n",
            " [  0   0   0   0   0   0   6   1 493   0]\n",
            " [  0   0   0   0   0   0  15   0 485   0]\n",
            " [  0   0   0   0   0   0   7   2 491   0]\n",
            " [  0   0   0   0   0   0   8   2 490   0]\n",
            " [  0   0   0   0   0   0   6   0 494   0]\n",
            " [  0   0   0   0   0   0  15   1 484   0]\n",
            " [  0   0   0   0   0   0   7   0 493   0]\n",
            " [  0   0   0   0   0   0   2   0 498   0]]\n",
            "Accuracy:  0.1\n",
            "Macro F1-score:  0.020677879379474982\n",
            "Micro F1-score:  0.10000000000000002\n",
            "Weighted F1-score:  0.020677879379474982\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "---Query no:  1 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2993\u001b[0m  0.4949\n",
            "      2       11.5311  0.4784\n",
            "      3        4.4345  0.4750\n",
            "      4        2.3055  0.5117\n",
            "      5        2.2999  0.4184\n",
            "      6        \u001b[36m2.2980\u001b[0m  0.3101\n",
            "      7        2.3788  0.3174\n",
            "      8        2.3083  0.3058\n",
            "      9        \u001b[36m2.2870\u001b[0m  0.3080\n",
            "     10        \u001b[36m2.2738\u001b[0m  0.3181\n",
            "0.137\n",
            "---Query no:  2 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.4809\u001b[0m  0.4090\n",
            "      2        7.0668  0.3974\n",
            "      3        \u001b[36m2.3099\u001b[0m  0.3710\n",
            "      4        \u001b[36m2.2676\u001b[0m  0.3915\n",
            "      5        2.4214  0.3698\n",
            "      6        2.4072  0.3667\n",
            "      7        2.4200  0.3936\n",
            "      8        \u001b[36m2.2405\u001b[0m  0.3671\n",
            "      9        \u001b[36m2.2140\u001b[0m  0.3771\n",
            "     10        2.3822  0.3820\n",
            "0.123\n",
            "---Query no:  3 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.8192\u001b[0m  0.4527\n",
            "      2        2.9251  0.4303\n",
            "      3        \u001b[36m2.2978\u001b[0m  0.5518\n",
            "      4        2.3182  0.6653\n",
            "      5        \u001b[36m2.2257\u001b[0m  0.6502\n",
            "      6        2.2502  0.6646\n",
            "      7        \u001b[36m2.1135\u001b[0m  0.5241\n",
            "      8        \u001b[36m2.0474\u001b[0m  0.4210\n",
            "      9        2.1742  0.4256\n",
            "     10        2.1174  0.4285\n",
            "0.1784\n",
            "---Query no:  4 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.3767\u001b[0m  0.4891\n",
            "      2        \u001b[36m2.7138\u001b[0m  0.4770\n",
            "      3        \u001b[36m2.2909\u001b[0m  0.4756\n",
            "      4        \u001b[36m2.2475\u001b[0m  0.4661\n",
            "      5        \u001b[36m2.2008\u001b[0m  0.4734\n",
            "      6        \u001b[36m2.1611\u001b[0m  0.4668\n",
            "      7        \u001b[36m2.0545\u001b[0m  0.4822\n",
            "      8        2.0830  0.4694\n",
            "      9        \u001b[36m2.0521\u001b[0m  0.4847\n",
            "     10        \u001b[36m1.9909\u001b[0m  0.4623\n",
            "0.1328\n",
            "---Query no:  5 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.5619\u001b[0m  0.5416\n",
            "      2        \u001b[36m3.5241\u001b[0m  0.5307\n",
            "      3        \u001b[36m2.3017\u001b[0m  0.6263\n",
            "      4        \u001b[36m2.2922\u001b[0m  0.8011\n",
            "      5        \u001b[36m2.2723\u001b[0m  0.8165\n",
            "      6        \u001b[36m2.2498\u001b[0m  0.6557\n",
            "      7        2.2660  0.5125\n",
            "      8        2.2542  0.5222\n",
            "      9        \u001b[36m2.2232\u001b[0m  0.5239\n",
            "     10        \u001b[36m2.1819\u001b[0m  0.5237\n",
            "0.1636\n",
            "---Query no:  6 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.3934\u001b[0m  0.5816\n",
            "      2        \u001b[36m2.5934\u001b[0m  0.5811\n",
            "      3        \u001b[36m2.3004\u001b[0m  0.5636\n",
            "      4        \u001b[36m2.2720\u001b[0m  0.5869\n",
            "      5        2.2886  0.5599\n",
            "      6        \u001b[36m2.2621\u001b[0m  0.5765\n",
            "      7        \u001b[36m2.1915\u001b[0m  0.5614\n",
            "      8        2.1994  0.5714\n",
            "      9        \u001b[36m2.1071\u001b[0m  0.5738\n",
            "     10        \u001b[36m2.0142\u001b[0m  0.5574\n",
            "0.1526\n",
            "---Query no:  7 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.8386\u001b[0m  0.9600\n",
            "      2        \u001b[36m2.8016\u001b[0m  0.9656\n",
            "      3        \u001b[36m2.2913\u001b[0m  0.7334\n",
            "      4        2.2991  0.6204\n",
            "      5        \u001b[36m2.2203\u001b[0m  0.6177\n",
            "      6        \u001b[36m2.1257\u001b[0m  0.6204\n",
            "      7        2.1388  0.6089\n",
            "      8        \u001b[36m1.9809\u001b[0m  0.6232\n",
            "      9        \u001b[36m1.9164\u001b[0m  0.6134\n",
            "     10        \u001b[36m1.8556\u001b[0m  0.6126\n",
            "0.2344\n",
            "---Query no:  8 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.9014\u001b[0m  0.7147\n",
            "      2        \u001b[36m2.3358\u001b[0m  0.7075\n",
            "      3        2.4431  0.6915\n",
            "      4        \u001b[36m2.3099\u001b[0m  0.6816\n",
            "      5        \u001b[36m2.3053\u001b[0m  0.6899\n",
            "      6        2.3071  0.7779\n",
            "      7        2.3084  1.0402\n",
            "      8        2.3092  1.0417\n",
            "      9        2.3108  0.6735\n",
            "     10        2.3134  0.6771\n",
            "0.1\n",
            "---Query no:  9 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m9.8942\u001b[0m  0.7613\n",
            "      2        \u001b[36m2.3135\u001b[0m  0.7175\n",
            "      3        \u001b[36m2.2969\u001b[0m  0.7322\n",
            "      4        \u001b[36m2.2747\u001b[0m  0.7379\n",
            "      5        2.5016  0.7430\n",
            "      6        2.2792  0.7372\n",
            "      7        \u001b[36m2.2592\u001b[0m  0.7339\n",
            "      8        \u001b[36m2.2289\u001b[0m  0.7300\n",
            "      9        \u001b[36m2.1985\u001b[0m  0.7217\n",
            "     10        2.2323  0.7275\n",
            "0.1612\n",
            "---Query no:  10 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.8146\u001b[0m  1.2323\n",
            "      2        \u001b[36m2.2980\u001b[0m  1.1214\n",
            "      3        2.8811  0.7885\n",
            "      4        \u001b[36m2.2893\u001b[0m  0.7917\n",
            "      5        \u001b[36m2.2833\u001b[0m  0.7757\n",
            "      6        \u001b[36m2.2452\u001b[0m  0.7829\n",
            "      7        \u001b[36m2.2254\u001b[0m  0.7837\n",
            "      8        \u001b[36m2.2053\u001b[0m  0.7950\n",
            "      9        \u001b[36m2.1728\u001b[0m  0.7722\n",
            "     10        2.1793  0.7771\n",
            "0.1516\n",
            "---Query no:  11 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.8295\u001b[0m  0.8537\n",
            "      2        \u001b[36m2.3179\u001b[0m  0.8221\n",
            "      3        2.3816  0.8323\n",
            "      4        \u001b[36m2.2843\u001b[0m  1.0847\n",
            "      5        \u001b[36m2.2523\u001b[0m  1.2681\n",
            "      6        \u001b[36m2.2290\u001b[0m  0.9206\n",
            "      7        \u001b[36m2.1751\u001b[0m  0.8182\n",
            "      8        \u001b[36m2.1102\u001b[0m  0.8098\n",
            "      9        \u001b[36m2.0698\u001b[0m  0.8314\n",
            "     10        \u001b[36m1.9682\u001b[0m  0.8485\n",
            "0.2032\n",
            "---Query no:  12 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m11.3982\u001b[0m  0.9142\n",
            "      2        \u001b[36m2.3863\u001b[0m  0.8842\n",
            "      3        \u001b[36m2.3274\u001b[0m  0.8832\n",
            "      4        \u001b[36m2.2763\u001b[0m  0.8690\n",
            "      5        2.2845  0.8722\n",
            "      6        2.2835  0.9052\n",
            "      7        \u001b[36m2.2157\u001b[0m  1.3454\n",
            "      8        \u001b[36m2.1896\u001b[0m  1.2156\n",
            "      9        \u001b[36m2.1401\u001b[0m  0.8651\n",
            "     10        \u001b[36m2.0794\u001b[0m  0.8821\n",
            "0.2126\n",
            "---Query no:  13 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m8.3796\u001b[0m  0.9523\n",
            "      2        \u001b[36m2.3116\u001b[0m  0.9259\n",
            "      3        2.3387  0.9275\n",
            "      4        \u001b[36m2.2904\u001b[0m  0.9221\n",
            "      5        \u001b[36m2.2802\u001b[0m  0.9189\n",
            "      6        \u001b[36m2.2419\u001b[0m  0.9015\n",
            "      7        \u001b[36m2.2042\u001b[0m  1.0985\n",
            "      8        \u001b[36m2.1484\u001b[0m  1.4220\n",
            "      9        \u001b[36m2.1407\u001b[0m  1.0586\n",
            "     10        \u001b[36m2.0980\u001b[0m  0.9197\n",
            "0.1832\n",
            "---Query no:  14 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.3139\u001b[0m  1.0193\n",
            "      2        \u001b[36m2.3145\u001b[0m  0.9646\n",
            "      3        \u001b[36m2.3044\u001b[0m  0.9727\n",
            "      4        \u001b[36m2.2822\u001b[0m  0.9744\n",
            "      5        \u001b[36m2.2370\u001b[0m  0.9831\n",
            "      6        \u001b[36m2.1643\u001b[0m  1.0240\n",
            "      7        \u001b[36m2.1614\u001b[0m  0.9714\n",
            "      8        \u001b[36m2.0231\u001b[0m  0.9676\n",
            "      9        \u001b[36m1.9051\u001b[0m  1.4892\n",
            "     10        \u001b[36m1.7561\u001b[0m  1.2503\n",
            "0.261\n",
            "---Query no:  15 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m8.6810\u001b[0m  1.0734\n",
            "      2        \u001b[36m2.3116\u001b[0m  1.0341\n",
            "      3        \u001b[36m2.3097\u001b[0m  1.0320\n",
            "      4        \u001b[36m2.3040\u001b[0m  1.0329\n",
            "      5        \u001b[36m2.2982\u001b[0m  1.0280\n",
            "      6        2.3256  1.0365\n",
            "      7        2.3018  1.0231\n",
            "      8        2.3084  1.0493\n",
            "      9        2.2991  1.6160\n",
            "     10        \u001b[36m2.2974\u001b[0m  1.2660\n",
            "0.1024\n",
            "---Query no:  16 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.6629\u001b[0m  1.1154\n",
            "      2        \u001b[36m2.3021\u001b[0m  1.0893\n",
            "      3        2.3803  1.0857\n",
            "      4        2.3128  1.0802\n",
            "      5        \u001b[36m2.2900\u001b[0m  1.0713\n",
            "      6        \u001b[36m2.2880\u001b[0m  1.0750\n",
            "      7        \u001b[36m2.2693\u001b[0m  1.0768\n",
            "      8        2.2835  1.0998\n",
            "      9        \u001b[36m2.2429\u001b[0m  1.5856\n",
            "     10        \u001b[36m2.2399\u001b[0m  1.4362\n",
            "0.1926\n",
            "---Query no:  17 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.2737\u001b[0m  1.1528\n",
            "      2        \u001b[36m2.3089\u001b[0m  1.1284\n",
            "      3        \u001b[36m2.3015\u001b[0m  1.1266\n",
            "      4        \u001b[36m2.2987\u001b[0m  1.1279\n",
            "      5        \u001b[36m2.2951\u001b[0m  1.1311\n",
            "      6        2.2967  1.1273\n",
            "      7        2.3067  1.1484\n",
            "      8        \u001b[36m2.2876\u001b[0m  1.2125\n",
            "      9        2.5375  1.7380\n",
            "     10        2.2927  1.2347\n",
            "0.1\n",
            "---Query no:  18 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.4500\u001b[0m  1.2083\n",
            "      2        \u001b[36m2.3115\u001b[0m  1.1871\n",
            "      3        \u001b[36m2.2581\u001b[0m  1.1971\n",
            "      4        \u001b[36m2.1904\u001b[0m  1.1849\n",
            "      5        2.2774  1.1865\n",
            "      6        2.2720  1.1786\n",
            "      7        2.1986  1.1812\n",
            "      8        2.2499  1.5881\n",
            "      9        \u001b[36m2.1882\u001b[0m  1.6007\n",
            "     10        \u001b[36m2.1846\u001b[0m  1.1724\n",
            "0.1982\n",
            "---Query no:  19 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.9224\u001b[0m  1.2596\n",
            "      2        \u001b[36m2.3024\u001b[0m  1.2299\n",
            "      3        \u001b[36m2.2659\u001b[0m  1.2241\n",
            "      4        2.2675  1.2238\n",
            "      5        \u001b[36m2.2267\u001b[0m  1.2239\n",
            "      6        \u001b[36m2.1530\u001b[0m  1.2326\n",
            "      7        2.1879  1.6973\n",
            "      8        2.1638  1.5382\n",
            "      9        \u001b[36m2.1370\u001b[0m  1.2265\n",
            "     10        \u001b[36m2.0796\u001b[0m  1.2192\n",
            "0.196\n",
            "---Query no:  20 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.3961\u001b[0m  1.3111\n",
            "      2        \u001b[36m2.3116\u001b[0m  1.2800\n",
            "      3        \u001b[36m2.2969\u001b[0m  1.2902\n",
            "      4        \u001b[36m2.2945\u001b[0m  1.2774\n",
            "      5        \u001b[36m2.2763\u001b[0m  1.6970\n",
            "      6        \u001b[36m2.2621\u001b[0m  1.6525\n",
            "      7        \u001b[36m2.2371\u001b[0m  1.2888\n",
            "      8        \u001b[36m2.1894\u001b[0m  1.2632\n",
            "      9        2.1904  1.2766\n",
            "     10        \u001b[36m2.1224\u001b[0m  1.2554\n",
            "0.183\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[  6  37 349  48   5   0   0   0   1  54]\n",
            " [  1 187  92  79   3   0   0   0   2 136]\n",
            " [  6  37 247 130   7   0   0   1   1  71]\n",
            " [  1  62 131 235   8   2   0   0   0  61]\n",
            " [  3  27 209 163  10   0   0   0   0  88]\n",
            " [  1  43 129 250   4   0   0   0   0  73]\n",
            " [  2  75 103 187  12   0   0   1   0 120]\n",
            " [  4  30 130 199  13   0   0   2   0 122]\n",
            " [  2  75 315  27   7   0   0   0   0  74]\n",
            " [  0 132  92  42   5   0   0   1   0 228]]\n",
            "Accuracy:  0.183\n",
            "Macro F1-score:  0.11423271821301764\n",
            "Micro F1-score:  0.183\n",
            "Weighted F1-score:  0.11423271821301761\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "AL_Retrain(100, 20, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VC6yl9M0XtBf"
      },
      "outputs": [],
      "source": [
        "AL_Retrain(100, 20, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAiXr1V_cg30",
        "outputId": "503c42d4-9816-44ff-8d43-9d6c63250aa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.8226\u001b[0m  1.4001\n",
            "      2        \u001b[36m2.3034\u001b[0m  1.9829\n",
            "      3        2.3042  1.2764\n",
            "      4        2.3268  1.2762\n",
            "      5        \u001b[36m2.2892\u001b[0m  1.2707\n",
            "      6        \u001b[36m2.2700\u001b[0m  1.2542\n",
            "      7        \u001b[36m2.2406\u001b[0m  1.2613\n",
            "      8        \u001b[36m2.2304\u001b[0m  1.2793\n",
            "      9        \u001b[36m2.2006\u001b[0m  1.2614\n",
            "     10        \u001b[36m2.1955\u001b[0m  1.3281\n",
            "No of initial data:  500\n",
            "0.2026\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[138  68   0   0  77  33   3  57  10 114]\n",
            " [ 16 154   0   0  59  41   3  55   6 166]\n",
            " [ 67  53   0   0  91  93   9 117   6  64]\n",
            " [ 32  52   0   0  84 160   3  95   2  72]\n",
            " [ 28  40   0   0  95 149  10  96   0  82]\n",
            " [ 38  62   0   0  82 176   4  75   2  61]\n",
            " [  9  80   0   0  91 117  19 121   0  63]\n",
            " [ 12  66   0   0  58 104   5 113   0 142]\n",
            " [ 87  85   0   0  46  42   0  35  15 190]\n",
            " [  9  88   0   0  29  16   0  49   6 303]]\n",
            "Accuracy:  0.2026\n",
            "Macro F1-score:  0.1584635099533988\n",
            "Micro F1-score:  0.2026\n",
            "Weighted F1-score:  0.15846350995339878\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[4, 6, 3, 3, 4, 2, 1, 2, 7, 4, 4, 7, 5, 6, 6, 4, 4, 4, 0, 6, 4, 7, 2, 6, 2, 3, 4, 4, 6, 3, 6, 1, 5, 6, 9, 2, 2, 6, 1, 6, 6, 4, 5, 3, 3, 2, 4, 4, 2, 6, 6, 4, 0, 4, 3, 6, 4, 4, 6, 4, 5, 9, 2, 5, 6, 3, 6, 4, 3, 3, 4, 4, 3, 2, 7, 2, 0, 8, 2, 3, 3, 6, 3, 2, 4, 5, 3, 6, 0, 6, 3, 2, 6, 3, 6, 3, 1, 2, 2, 8, 7, 4, 7, 4, 3, 4, 4, 2, 4, 6, 4, 6, 1, 6, 3, 2, 6, 6, 2, 3, 2, 4, 6, 5, 4, 6, 6, 6, 2, 7, 6, 2, 5, 4, 6, 4, 5, 5, 3, 2, 2, 6, 7, 4, 5, 6, 1, 4, 2, 2, 2, 4, 2, 6, 7, 4, 4, 1, 0, 3, 4, 4, 2, 5, 4, 6, 2, 2, 2, 2, 5, 6, 5, 3, 5, 3, 4, 2, 4, 6, 6, 9, 6, 6, 4, 6, 3, 1, 3, 4, 6, 6, 2, 6, 9, 3, 6, 3, 6, 6, 3, 6, 7, 0, 3, 2, 1, 3, 4, 1, 3, 4, 4, 2, 5, 5, 2, 4, 4, 4, 5, 3, 1, 7, 2, 2, 2, 3, 2, 2, 5, 2, 2, 2, 2, 1, 9, 1, 5, 7, 1, 9, 2, 5, 3, 7, 2, 2, 3, 7, 8, 3, 7, 7, 3, 3, 3, 5, 9, 3, 9, 3, 3, 7, 1, 7, 5, 3, 3, 5, 7, 5, 5, 3, 5, 5, 3, 1, 3, 1, 3, 7, 1, 5, 5, 9, 0, 5, 5, 0, 9, 1, 0, 5, 5, 7, 5, 1, 7, 9, 1, 7, 5, 5, 9, 7, 1, 7, 5, 5, 1, 5, 5, 8, 0, 5, 7, 1, 5, 5, 9, 7, 7, 5, 7, 1, 5, 0, 1, 0, 8, 5, 0, 1, 0, 5, 9, 1, 5, 5, 1, 7, 1, 8, 1, 1, 1, 7, 1, 0, 7, 7, 9, 9, 9, 0, 9, 9, 7, 0, 0, 7, 1, 8, 7, 8, 1, 0, 7, 9, 0, 7, 7, 1, 9, 7, 7, 7, 8, 7, 8, 1, 1, 8, 1, 7, 1, 7, 9, 7, 0, 1, 0, 0, 1, 1, 7, 9, 0, 7, 8, 8, 8, 8, 0, 7, 0, 9, 0, 1, 7, 8, 9, 1, 1, 0, 1, 1, 0, 0, 0, 0, 8, 8, 8, 0, 0, 9, 1, 0, 9, 8, 8, 9, 9, 0, 8, 9, 9, 9, 8, 0, 8, 9, 0, 9, 0, 0, 8, 9, 8, 9, 0, 9, 8, 9, 0, 0, 8, 9, 9, 8, 9, 0, 0, 8, 9, 9, 9, 9, 9, 8, 9, 0, 9, 0, 9, 0, 9, 8, 0, 0, 8, 8, 8]\n",
            "Counter({4: 50, 6: 50, 3: 50, 2: 50, 1: 50, 7: 50, 5: 50, 0: 50, 9: 50, 8: 35})\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m7.1953\u001b[0m  1.2766\n",
            "      2        \u001b[36m2.3778\u001b[0m  1.2321\n",
            "      3        \u001b[36m2.3345\u001b[0m  1.2255\n",
            "      4        \u001b[36m2.3110\u001b[0m  1.2166\n",
            "      5        \u001b[36m2.3029\u001b[0m  1.3703\n",
            "      6        \u001b[36m2.2962\u001b[0m  1.8860\n",
            "      7        2.3679  1.2216\n",
            "      8        \u001b[36m2.2919\u001b[0m  1.2294\n",
            "      9        2.3213  1.2287\n",
            "     10        2.3286  1.2106\n",
            "0.0998\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[499   1   0   0   0   0   0   0   0   0]\n",
            " [499   0   0   0   0   1   0   0   0   0]\n",
            " [500   0   0   0   0   0   0   0   0   0]\n",
            " [500   0   0   0   0   0   0   0   0   0]\n",
            " [500   0   0   0   0   0   0   0   0   0]\n",
            " [500   0   0   0   0   0   0   0   0   0]\n",
            " [500   0   0   0   0   0   0   0   0   0]\n",
            " [499   0   0   0   0   1   0   0   0   0]\n",
            " [500   0   0   0   0   0   0   0   0   0]\n",
            " [500   0   0   0   0   0   0   0   0   0]]\n",
            "Accuracy:  0.0998\n",
            "Macro F1-score:  0.01815535746770966\n",
            "Micro F1-score:  0.0998\n",
            "Weighted F1-score:  0.01815535746770966\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "---Query no:  1 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m6.0034\u001b[0m  1.9883\n",
            "      2        \u001b[36m2.3063\u001b[0m  1.4986\n",
            "      3        2.5412  1.3387\n",
            "      4        2.3221  1.3155\n",
            "      5        \u001b[36m2.3044\u001b[0m  1.3118\n",
            "      6        \u001b[36m2.3042\u001b[0m  1.3126\n",
            "      7        \u001b[36m2.2995\u001b[0m  1.3301\n",
            "      8        \u001b[36m2.2977\u001b[0m  1.3101\n",
            "      9        \u001b[36m2.2703\u001b[0m  1.4935\n",
            "     10        2.3028  1.9409\n",
            "0.1136\n",
            "---Query no:  2 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.3382\u001b[0m  1.4187\n",
            "      2        \u001b[36m2.3103\u001b[0m  1.3881\n",
            "      3        2.3840  1.3881\n",
            "      4        \u001b[36m2.3009\u001b[0m  1.3673\n",
            "      5        2.3401  1.3813\n",
            "      6        2.3019  1.3842\n",
            "      7        2.3029  1.5544\n",
            "      8        2.3036  2.0037\n",
            "      9        2.3037  1.3896\n",
            "     10        2.3037  1.3624\n",
            "0.1\n",
            "---Query no:  3 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.2374\u001b[0m  1.4532\n",
            "      2        \u001b[36m2.3284\u001b[0m  1.4206\n",
            "      3        \u001b[36m2.3045\u001b[0m  1.4313\n",
            "      4        \u001b[36m2.3035\u001b[0m  1.4451\n",
            "      5        \u001b[36m2.3003\u001b[0m  1.7760\n",
            "      6        \u001b[36m2.2992\u001b[0m  1.9190\n",
            "      7        \u001b[36m2.2960\u001b[0m  1.4166\n",
            "      8        \u001b[36m2.2926\u001b[0m  1.4202\n",
            "      9        \u001b[36m2.2769\u001b[0m  1.4337\n",
            "     10        \u001b[36m2.2704\u001b[0m  1.4217\n",
            "0.1048\n",
            "---Query no:  4 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.5041\u001b[0m  1.5286\n",
            "      2        \u001b[36m2.3182\u001b[0m  1.6374\n",
            "      3        \u001b[36m2.3038\u001b[0m  2.1437\n",
            "      4        \u001b[36m2.3032\u001b[0m  1.4829\n",
            "      5        \u001b[36m2.3024\u001b[0m  1.4787\n",
            "      6        \u001b[36m2.3024\u001b[0m  1.4923\n",
            "      7        \u001b[36m2.3011\u001b[0m  1.4846\n",
            "      8        \u001b[36m2.3007\u001b[0m  1.4805\n",
            "      9        2.3008  1.4728\n",
            "     10        2.3012  1.8599\n",
            "0.1\n",
            "---Query no:  5 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.7195\u001b[0m  1.8500\n",
            "      2        \u001b[36m2.3260\u001b[0m  1.5317\n",
            "      3        \u001b[36m2.2959\u001b[0m  1.5281\n",
            "      4        \u001b[36m2.2917\u001b[0m  1.5384\n",
            "      5        \u001b[36m2.2743\u001b[0m  1.5201\n",
            "      6        \u001b[36m2.2278\u001b[0m  1.5163\n",
            "      7        \u001b[36m2.2112\u001b[0m  1.6160\n",
            "      8        \u001b[36m2.1718\u001b[0m  2.2295\n",
            "      9        2.1797  1.5317\n",
            "     10        \u001b[36m2.1650\u001b[0m  1.5293\n",
            "0.1966\n",
            "---Query no:  6 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.4139\u001b[0m  1.6079\n",
            "      2        \u001b[36m2.3102\u001b[0m  1.5704\n",
            "      3        \u001b[36m2.2994\u001b[0m  1.5778\n",
            "      4        \u001b[36m2.2689\u001b[0m  1.6604\n",
            "      5        \u001b[36m2.2274\u001b[0m  2.3011\n",
            "      6        \u001b[36m2.1906\u001b[0m  1.5655\n",
            "      7        \u001b[36m2.0705\u001b[0m  1.5819\n",
            "      8        \u001b[36m2.0698\u001b[0m  1.5644\n",
            "      9        \u001b[36m2.0281\u001b[0m  1.5794\n",
            "     10        \u001b[36m1.9164\u001b[0m  1.5629\n",
            "0.2504\n",
            "---Query no:  7 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.1643\u001b[0m  1.8885\n",
            "      2        \u001b[36m2.3074\u001b[0m  2.1960\n",
            "      3        \u001b[36m2.3068\u001b[0m  1.6069\n",
            "      4        \u001b[36m2.3021\u001b[0m  1.6235\n",
            "      5        \u001b[36m2.3013\u001b[0m  1.6344\n",
            "      6        \u001b[36m2.3011\u001b[0m  1.6197\n",
            "      7        \u001b[36m2.3008\u001b[0m  1.6292\n",
            "      8        2.3013  1.8039\n",
            "      9        \u001b[36m2.2997\u001b[0m  2.2306\n",
            "     10        2.3006  1.6227\n",
            "0.1\n",
            "---Query no:  8 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.2227\u001b[0m  1.7191\n",
            "      2        \u001b[36m2.3144\u001b[0m  1.7075\n",
            "      3        \u001b[36m2.2959\u001b[0m  1.6963\n",
            "      4        2.3202  1.6828\n",
            "      5        \u001b[36m2.2352\u001b[0m  2.1996\n",
            "      6        \u001b[36m2.1781\u001b[0m  2.0216\n",
            "      7        2.1833  1.6949\n",
            "      8        2.1950  1.6986\n",
            "      9        \u001b[36m2.1276\u001b[0m  1.6662\n",
            "     10        \u001b[36m2.0166\u001b[0m  1.6913\n",
            "0.256\n",
            "---Query no:  9 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.2423\u001b[0m  1.8152\n",
            "      2        \u001b[36m2.3005\u001b[0m  2.5289\n",
            "      3        2.3050  1.7318\n",
            "      4        \u001b[36m2.2666\u001b[0m  1.7158\n",
            "      5        \u001b[36m2.2058\u001b[0m  1.7278\n",
            "      6        \u001b[36m2.1364\u001b[0m  1.7335\n",
            "      7        \u001b[36m2.0885\u001b[0m  1.7243\n",
            "      8        \u001b[36m2.0303\u001b[0m  2.1690\n",
            "      9        \u001b[36m1.9845\u001b[0m  2.1173\n",
            "     10        \u001b[36m1.9359\u001b[0m  1.7455\n",
            "0.2384\n",
            "---Query no:  10 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m7.1904\u001b[0m  1.8064\n",
            "      2        \u001b[36m2.3062\u001b[0m  1.7975\n",
            "      3        2.3112  1.8028\n",
            "      4        \u001b[36m2.2902\u001b[0m  2.0052\n",
            "      5        \u001b[36m2.2621\u001b[0m  2.3631\n",
            "      6        \u001b[36m2.2178\u001b[0m  1.7810\n",
            "      7        \u001b[36m2.1791\u001b[0m  1.7658\n",
            "      8        \u001b[36m2.0839\u001b[0m  1.7835\n",
            "      9        \u001b[36m1.9890\u001b[0m  1.7723\n",
            "     10        \u001b[36m1.9091\u001b[0m  1.7880\n",
            "0.215\n",
            "---Query no:  11 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.2480\u001b[0m  2.2223\n",
            "      2        \u001b[36m2.3046\u001b[0m  1.8262\n",
            "      3        \u001b[36m2.3026\u001b[0m  1.8346\n",
            "      4        \u001b[36m2.2924\u001b[0m  1.8476\n",
            "      5        \u001b[36m2.2639\u001b[0m  1.8522\n",
            "      6        \u001b[36m2.2363\u001b[0m  2.0695\n",
            "      7        \u001b[36m2.2083\u001b[0m  2.4237\n",
            "      8        \u001b[36m2.1875\u001b[0m  1.8538\n",
            "      9        \u001b[36m2.1567\u001b[0m  1.8768\n",
            "     10        2.1864  1.8159\n",
            "0.2476\n",
            "---Query no:  12 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m7.5782\u001b[0m  1.9295\n",
            "      2        \u001b[36m2.3552\u001b[0m  2.0922\n",
            "      3        \u001b[36m2.2925\u001b[0m  2.4804\n",
            "      4        \u001b[36m2.2793\u001b[0m  1.9058\n",
            "      5        \u001b[36m2.2556\u001b[0m  1.8839\n",
            "      6        \u001b[36m2.2332\u001b[0m  1.8839\n",
            "      7        \u001b[36m2.2019\u001b[0m  1.8736\n",
            "      8        \u001b[36m2.1738\u001b[0m  2.0209\n",
            "      9        \u001b[36m2.1496\u001b[0m  2.5422\n",
            "     10        \u001b[36m2.0932\u001b[0m  1.8653\n",
            "0.1774\n",
            "---Query no:  13 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.2456\u001b[0m  1.9586\n",
            "      2        \u001b[36m2.3286\u001b[0m  1.9289\n",
            "      3        \u001b[36m2.2979\u001b[0m  1.9291\n",
            "      4        \u001b[36m2.2660\u001b[0m  2.2193\n",
            "      5        \u001b[36m2.2045\u001b[0m  2.4442\n",
            "      6        \u001b[36m2.1404\u001b[0m  1.9406\n",
            "      7        \u001b[36m2.0703\u001b[0m  1.9296\n",
            "      8        \u001b[36m1.9916\u001b[0m  1.9255\n",
            "      9        \u001b[36m1.8617\u001b[0m  1.9382\n",
            "     10        \u001b[36m1.7466\u001b[0m  2.3139\n",
            "0.3014\n",
            "---Query no:  14 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.0916\u001b[0m  2.1688\n",
            "      2        \u001b[36m2.3154\u001b[0m  1.9866\n",
            "      3        \u001b[36m2.3034\u001b[0m  1.9931\n",
            "      4        \u001b[36m2.3022\u001b[0m  2.0057\n",
            "      5        \u001b[36m2.3015\u001b[0m  1.9818\n",
            "      6        \u001b[36m2.3011\u001b[0m  2.8111\n",
            "      7        \u001b[36m2.3009\u001b[0m  1.9692\n",
            "      8        2.3011  1.9732\n",
            "      9        2.3015  1.9710\n",
            "     10        2.3020  1.9968\n",
            "0.1\n",
            "---Query no:  15 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m7.0822\u001b[0m  2.2891\n",
            "      2        \u001b[36m2.3045\u001b[0m  2.6205\n",
            "      3        \u001b[36m2.3006\u001b[0m  2.0302\n",
            "      4        \u001b[36m2.2998\u001b[0m  2.0258\n",
            "      5        \u001b[36m2.2988\u001b[0m  2.0540\n",
            "      6        2.3001  2.0374\n",
            "      7        2.3006  2.7002\n",
            "      8        2.3009  2.2019\n",
            "      9        2.3019  2.0563\n",
            "     10        2.3022  2.0366\n",
            "0.1\n",
            "---Query no:  16 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m6.3311\u001b[0m  2.1233\n",
            "      2        \u001b[36m2.3084\u001b[0m  2.0940\n",
            "      3        \u001b[36m2.3026\u001b[0m  2.8671\n",
            "      4        2.3062  2.0855\n",
            "      5        \u001b[36m2.3011\u001b[0m  2.0780\n",
            "      6        \u001b[36m2.3001\u001b[0m  2.0712\n",
            "      7        \u001b[36m2.2990\u001b[0m  2.0618\n",
            "      8        2.3013  2.6333\n",
            "      9        2.2997  2.3079\n",
            "     10        2.3020  2.1090\n",
            "0.1\n",
            "---Query no:  17 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.9356\u001b[0m  2.1659\n",
            "      2        \u001b[36m2.3216\u001b[0m  2.1366\n",
            "      3        \u001b[36m2.3055\u001b[0m  2.7387\n",
            "      4        \u001b[36m2.2682\u001b[0m  2.3678\n",
            "      5        \u001b[36m2.2133\u001b[0m  2.1338\n",
            "      6        \u001b[36m2.1397\u001b[0m  2.1512\n",
            "      7        \u001b[36m2.0938\u001b[0m  2.1437\n",
            "      8        \u001b[36m2.0556\u001b[0m  2.3507\n",
            "      9        \u001b[36m2.0292\u001b[0m  2.7428\n",
            "     10        2.0569  2.1395\n",
            "0.2534\n",
            "---Query no:  18 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.7439\u001b[0m  2.2135\n",
            "      2        \u001b[36m2.2989\u001b[0m  2.1956\n",
            "      3        \u001b[36m2.2065\u001b[0m  2.3144\n",
            "      4        \u001b[36m2.1614\u001b[0m  2.8891\n",
            "      5        \u001b[36m2.1188\u001b[0m  2.1827\n",
            "      6        \u001b[36m2.0539\u001b[0m  2.1764\n",
            "      7        \u001b[36m2.0177\u001b[0m  2.2005\n",
            "      8        \u001b[36m1.9674\u001b[0m  2.1919\n",
            "      9        \u001b[36m1.9383\u001b[0m  3.0072\n",
            "     10        \u001b[36m1.9004\u001b[0m  2.2069\n",
            "0.271\n",
            "---Query no:  19 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.5097\u001b[0m  2.2668\n",
            "      2        \u001b[36m2.3109\u001b[0m  2.2235\n",
            "      3        \u001b[36m2.2911\u001b[0m  2.2150\n",
            "      4        2.3042  3.0519\n",
            "      5        2.3021  2.2203\n",
            "      6        2.3014  2.2225\n",
            "      7        2.3012  2.2140\n",
            "      8        2.3006  2.2266\n",
            "      9        2.2998  3.0385\n",
            "     10        2.3006  2.2596\n",
            "0.1\n",
            "---Query no:  20 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.1258\u001b[0m  2.3413\n",
            "      2        \u001b[36m2.3815\u001b[0m  2.2798\n",
            "      3        \u001b[36m2.3074\u001b[0m  2.2920\n",
            "      4        \u001b[36m2.2969\u001b[0m  3.0943\n",
            "      5        \u001b[36m2.2963\u001b[0m  2.2895\n",
            "      6        \u001b[36m2.2683\u001b[0m  2.2950\n",
            "      7        \u001b[36m2.2050\u001b[0m  2.2905\n",
            "      8        \u001b[36m2.1974\u001b[0m  2.2733\n",
            "      9        \u001b[36m2.1423\u001b[0m  3.0857\n",
            "     10        \u001b[36m2.0637\u001b[0m  2.3012\n",
            "0.2418\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[236  50  34  17   1  25   0  15  70  52]\n",
            " [114 222  23  30   1   1   5   3  11  90]\n",
            " [ 64  61 174  42   2  55  31  29  14  28]\n",
            " [ 32  83 109  98   2  94  18  21   4  39]\n",
            " [ 47  41 244  34   6  36  24  30  13  25]\n",
            " [ 24  65 117  76   3 140  13  25   7  30]\n",
            " [ 19  93 211  70   0  16  59   9   3  20]\n",
            " [ 47  46 138  64   0  63  17  76   6  43]\n",
            " [165 119  13  20   1  10   3   9  60 100]\n",
            " [106 185  12  20   1   2   9   4  23 138]]\n",
            "Accuracy:  0.2418\n",
            "Macro F1-score:  0.22074598961835717\n",
            "Micro F1-score:  0.2418\n",
            "Weighted F1-score:  0.22074598961835717\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "AL_Retrain(500, 20, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UhpMmBfiCo9",
        "outputId": "b6a83965-641d-4356-d61b-6657f0f88cf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.8533\u001b[0m  1.2947\n",
            "      2        \u001b[36m2.3080\u001b[0m  1.2721\n",
            "      3        \u001b[36m2.3062\u001b[0m  1.2836\n",
            "      4        \u001b[36m2.2750\u001b[0m  1.2906\n",
            "      5        \u001b[36m2.2544\u001b[0m  1.2680\n",
            "      6        2.2638  1.2771\n",
            "      7        \u001b[36m2.2043\u001b[0m  1.2761\n",
            "      8        \u001b[36m2.1517\u001b[0m  1.8582\n",
            "      9        \u001b[36m2.0162\u001b[0m  1.5069\n",
            "     10        \u001b[36m1.9762\u001b[0m  1.2698\n",
            "No of initial data:  500\n",
            "0.2868\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[228  58   2  14   7  21  20   0 109  41]\n",
            " [ 41 204   3  27   6  28  60   1  52  78]\n",
            " [ 81  32   6  25  48  64 164   7  33  40]\n",
            " [ 51  42   5  53  29 128 124  13  17  38]\n",
            " [ 26  16   3  21  43  87 213   3  45  43]\n",
            " [ 32  35   5  35  25 177 104  11  34  42]\n",
            " [ 10  24   3  27  35  49 312   6   4  30]\n",
            " [ 26  68  10  15  45  64 103  18  28 123]\n",
            " [117  50   1  17   3  42   6   2 204  58]\n",
            " [ 37  99   1  14  13  10  49   6  82 189]]\n",
            "Accuracy:  0.2868\n",
            "Macro F1-score:  0.246772544683648\n",
            "Micro F1-score:  0.2868\n",
            "Weighted F1-score:  0.24677254468364804\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[4, 4, 4, 5, 2, 4, 8, 2, 4, 2, 2, 4, 6, 3, 0, 3, 8, 7, 6, 3, 2, 5, 8, 2, 5, 3, 7, 4, 2, 4, 4, 8, 0, 3, 9, 3, 4, 2, 7, 2, 4, 4, 4, 8, 8, 6, 0, 7, 6, 7, 7, 3, 4, 4, 3, 1, 8, 3, 2, 2, 3, 1, 7, 2, 9, 4, 5, 1, 5, 4, 5, 3, 3, 6, 2, 4, 2, 9, 6, 9, 2, 7, 4, 2, 1, 2, 2, 5, 2, 2, 1, 2, 5, 5, 4, 8, 6, 6, 1, 8, 7, 0, 4, 9, 3, 4, 7, 5, 2, 3, 2, 4, 4, 2, 1, 2, 4, 4, 3, 9, 2, 6, 4, 9, 4, 6, 3, 2, 2, 9, 4, 7, 2, 4, 3, 1, 6, 8, 0, 7, 2, 7, 6, 0, 2, 3, 0, 5, 2, 6, 5, 5, 1, 4, 2, 4, 1, 0, 6, 7, 0, 4, 9, 4, 5, 2, 5, 3, 4, 0, 7, 2, 3, 7, 3, 7, 7, 5, 0, 7, 1, 4, 6, 2, 9, 7, 5, 2, 4, 2, 9, 6, 2, 2, 0, 1, 3, 2, 6, 5, 5, 8, 2, 6, 4, 9, 6, 6, 9, 1, 2, 5, 3, 2, 0, 4, 3, 3, 7, 6, 2, 0, 2, 3, 4, 3, 7, 3, 3, 4, 3, 8, 3, 6, 0, 8, 9, 8, 2, 8, 4, 4, 2, 4, 7, 2, 3, 7, 0, 4, 2, 7, 3, 4, 5, 6, 4, 1, 0, 4, 7, 4, 1, 1, 5, 3, 3, 7, 1, 5, 7, 9, 3, 5, 3, 9, 6, 7, 6, 7, 6, 6, 5, 4, 9, 5, 1, 3, 1, 1, 0, 0, 8, 3, 5, 7, 6, 6, 8, 6, 7, 0, 0, 7, 1, 8, 6, 8, 1, 5, 1, 7, 6, 3, 7, 6, 6, 8, 0, 7, 3, 1, 5, 7, 3, 1, 3, 0, 3, 5, 8, 6, 5, 6, 3, 3, 1, 6, 3, 5, 7, 3, 8, 3, 7, 0, 5, 6, 3, 7, 6, 8, 8, 5, 5, 9, 8, 5, 0, 7, 1, 6, 7, 6, 7, 6, 1, 6, 6, 0, 8, 1, 6, 6, 9, 8, 9, 5, 9, 7, 6, 8, 5, 5, 8, 9, 0, 8, 8, 5, 8, 7, 9, 7, 0, 7, 7, 0, 7, 9, 6, 0, 7, 5, 0, 5, 6, 9, 6, 9, 5, 8, 1, 5, 9, 8, 9, 0, 1, 8, 5, 5, 1, 0, 5, 5, 5, 8, 9, 8, 8, 1, 9, 5, 0, 8, 8, 0, 9, 0, 9, 9, 9, 9, 0, 8, 1, 1, 1, 1, 9, 0, 8, 1, 1, 0, 9, 1, 1, 1, 0, 8, 0, 1, 0, 9, 0, 0, 1, 9, 9, 9, 0, 9, 9, 8, 8, 0, 0, 8, 9, 1, 1, 1, 9, 9, 1, 8, 8, 0, 0, 8, 9, 0, 9, 8, 1, 1, 9, 9]\n",
            "Counter({4: 50, 5: 50, 2: 50, 8: 50, 6: 50, 3: 50, 0: 50, 7: 50, 9: 50, 1: 50})\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m7.1156\u001b[0m  1.3053\n",
            "      2        \u001b[36m2.4173\u001b[0m  1.5817\n",
            "      3        \u001b[36m2.3084\u001b[0m  1.7673\n",
            "      4        \u001b[36m2.3038\u001b[0m  1.2763\n",
            "      5        \u001b[36m2.3029\u001b[0m  1.2648\n",
            "      6        \u001b[36m2.2999\u001b[0m  1.2713\n",
            "      7        \u001b[36m2.2867\u001b[0m  1.2647\n",
            "      8        2.3465  1.2657\n",
            "      9        2.2898  1.2668\n",
            "     10        2.2874  1.2703\n",
            "0.098\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[  4   0   3   0   0   0   1   0  25 467]\n",
            " [  6   2   1   1   0   1   2   0 103 384]\n",
            " [  8   1   5   1   3   2   1   0  30 449]\n",
            " [ 16   1   6   7   4   3   6   0  38 419]\n",
            " [  4   0   4   1   1   4   3   0  24 459]\n",
            " [ 20   0   4   1   6  11   6   0  40 412]\n",
            " [ 18   0   4   5   0   6   7   0  39 421]\n",
            " [  9   0   5   2   4   2   2   0  27 449]\n",
            " [  6   0   3   1   0   2   0   0  54 434]\n",
            " [  6   0   2   2   0   5   0   0  86 399]]\n",
            "Accuracy:  0.098\n",
            "Macro F1-score:  0.041654519376025524\n",
            "Micro F1-score:  0.09800000000000002\n",
            "Weighted F1-score:  0.041654519376025524\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "---Query no:  1 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.8748\u001b[0m  1.3785\n",
            "      2        \u001b[36m2.3108\u001b[0m  1.3564\n",
            "      3        \u001b[36m2.3048\u001b[0m  1.3533\n",
            "      4        \u001b[36m2.3020\u001b[0m  1.3417\n",
            "      5        \u001b[36m2.3014\u001b[0m  1.3657\n",
            "      6        2.3029  2.1797\n",
            "      7        2.3034  2.3185\n",
            "      8        2.3079  1.3454\n",
            "      9        2.3120  1.3596\n",
            "     10        2.3078  1.3686\n",
            "0.1\n",
            "---Query no:  2 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.6466\u001b[0m  1.4703\n",
            "      2        \u001b[36m2.3424\u001b[0m  1.4273\n",
            "      3        \u001b[36m2.2852\u001b[0m  1.4246\n",
            "      4        2.3093  1.5981\n",
            "      5        \u001b[36m2.2615\u001b[0m  2.0682\n",
            "      6        \u001b[36m2.2454\u001b[0m  1.4259\n",
            "      7        \u001b[36m2.2214\u001b[0m  1.4450\n",
            "      8        \u001b[36m2.1733\u001b[0m  1.4110\n",
            "      9        \u001b[36m2.1617\u001b[0m  1.4223\n",
            "     10        \u001b[36m2.1128\u001b[0m  1.4359\n",
            "0.1894\n",
            "---Query no:  3 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.7739\u001b[0m  1.5398\n",
            "      2        \u001b[36m2.3189\u001b[0m  1.9455\n",
            "      3        2.4541  1.8928\n",
            "      4        \u001b[36m2.3003\u001b[0m  1.5039\n",
            "      5        \u001b[36m2.2979\u001b[0m  1.5067\n",
            "      6        \u001b[36m2.2969\u001b[0m  1.4957\n",
            "      7        \u001b[36m2.2916\u001b[0m  1.5162\n",
            "      8        \u001b[36m2.2876\u001b[0m  1.4990\n",
            "      9        2.2937  1.5050\n",
            "     10        \u001b[36m2.2814\u001b[0m  2.2604\n",
            "0.0988\n",
            "---Query no:  4 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.1725\u001b[0m  1.6289\n",
            "      2        \u001b[36m2.3043\u001b[0m  1.5753\n",
            "      3        \u001b[36m2.2963\u001b[0m  1.5998\n",
            "      4        \u001b[36m2.2610\u001b[0m  1.5785\n",
            "      5        \u001b[36m2.1980\u001b[0m  1.5697\n",
            "      6        \u001b[36m2.1845\u001b[0m  1.5838\n",
            "      7        \u001b[36m2.1172\u001b[0m  2.3495\n",
            "      8        \u001b[36m2.0963\u001b[0m  1.6185\n",
            "      9        2.1072  1.5909\n",
            "     10        \u001b[36m2.0459\u001b[0m  1.5772\n",
            "0.2154\n",
            "---Query no:  5 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m5.3009\u001b[0m  1.6915\n",
            "      2        \u001b[36m2.3308\u001b[0m  1.6459\n",
            "      3        \u001b[36m2.2110\u001b[0m  1.7986\n",
            "      4        2.3394  2.3355\n",
            "      5        2.2417  1.6616\n",
            "      6        \u001b[36m2.1393\u001b[0m  1.6703\n",
            "      7        \u001b[36m2.0450\u001b[0m  1.6377\n",
            "      8        \u001b[36m2.0102\u001b[0m  1.6594\n",
            "      9        \u001b[36m1.9051\u001b[0m  1.6572\n",
            "     10        \u001b[36m1.8994\u001b[0m  1.8889\n",
            "0.3016\n",
            "---Query no:  6 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.1843\u001b[0m  2.0688\n",
            "      2        \u001b[36m2.2931\u001b[0m  1.7399\n",
            "      3        \u001b[36m2.2691\u001b[0m  1.7382\n",
            "      4        2.3143  1.7358\n",
            "      5        \u001b[36m2.2373\u001b[0m  1.7320\n",
            "      6        \u001b[36m2.1679\u001b[0m  1.7489\n",
            "      7        \u001b[36m2.0634\u001b[0m  2.5520\n",
            "      8        2.0886  1.7343\n",
            "      9        \u001b[36m1.9768\u001b[0m  1.7323\n",
            "     10        \u001b[36m1.9234\u001b[0m  1.7233\n",
            "0.2282\n",
            "---Query no:  7 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.9350\u001b[0m  1.8614\n",
            "      2        \u001b[36m2.3152\u001b[0m  1.8169\n",
            "      3        \u001b[36m2.2983\u001b[0m  2.6287\n",
            "      4        2.3092  1.8170\n",
            "      5        2.3057  1.8144\n",
            "      6        2.2997  1.8301\n",
            "      7        2.2996  1.8090\n",
            "      8        2.2993  1.8189\n",
            "      9        2.3001  2.4430\n",
            "     10        \u001b[36m2.2972\u001b[0m  1.9970\n",
            "0.1006\n",
            "---Query no:  8 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m6.5035\u001b[0m  1.8919\n",
            "      2        \u001b[36m2.3207\u001b[0m  1.8798\n",
            "      3        \u001b[36m2.2949\u001b[0m  1.9026\n",
            "      4        \u001b[36m2.2924\u001b[0m  1.9499\n",
            "      5        2.2987  2.6027\n",
            "      6        2.2986  1.8874\n",
            "      7        2.2993  1.8838\n",
            "      8        2.2988  1.8673\n",
            "      9        2.2990  1.8708\n",
            "     10        2.2997  1.8855\n",
            "0.1\n",
            "---Query no:  9 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.5581\u001b[0m  2.7816\n",
            "      2        \u001b[36m2.3030\u001b[0m  1.9587\n",
            "      3        \u001b[36m2.2909\u001b[0m  1.9603\n",
            "      4        \u001b[36m2.2684\u001b[0m  1.9620\n",
            "      5        2.2928  1.9687\n",
            "      6        2.2795  2.1715\n",
            "      7        \u001b[36m2.2515\u001b[0m  2.5700\n",
            "      8        \u001b[36m2.2279\u001b[0m  1.9680\n",
            "      9        2.2279  1.9535\n",
            "     10        \u001b[36m2.1998\u001b[0m  1.9601\n",
            "0.1854\n",
            "---Query no:  10 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m6.4714\u001b[0m  2.0475\n",
            "      2        \u001b[36m2.3129\u001b[0m  2.5757\n",
            "      3        \u001b[36m2.2978\u001b[0m  2.2804\n",
            "      4        2.3009  2.0201\n",
            "      5        \u001b[36m2.2967\u001b[0m  2.0181\n",
            "      6        2.3030  2.0183\n",
            "      7        \u001b[36m2.2874\u001b[0m  2.0166\n",
            "      8        2.2977  2.8518\n",
            "      9        \u001b[36m2.2566\u001b[0m  2.0206\n",
            "     10        \u001b[36m2.2286\u001b[0m  2.0236\n",
            "0.177\n",
            "---Query no:  11 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.7504\u001b[0m  2.1450\n",
            "      2        \u001b[36m2.3110\u001b[0m  2.1164\n",
            "      3        \u001b[36m2.3001\u001b[0m  2.6958\n",
            "      4        \u001b[36m2.2982\u001b[0m  2.3342\n",
            "      5        \u001b[36m2.2958\u001b[0m  2.1118\n",
            "      6        \u001b[36m2.2906\u001b[0m  2.1016\n",
            "      7        \u001b[36m2.2805\u001b[0m  2.0965\n",
            "      8        \u001b[36m2.2751\u001b[0m  2.1752\n",
            "      9        \u001b[36m2.2597\u001b[0m  2.8345\n",
            "     10        2.2606  2.0978\n",
            "0.11\n",
            "---Query no:  12 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.0909\u001b[0m  2.2052\n",
            "      2        \u001b[36m2.2685\u001b[0m  2.1868\n",
            "      3        \u001b[36m2.2486\u001b[0m  2.1676\n",
            "      4        \u001b[36m2.1655\u001b[0m  2.9854\n",
            "      5        \u001b[36m2.1537\u001b[0m  2.1934\n",
            "      6        \u001b[36m2.0879\u001b[0m  2.1933\n",
            "      7        \u001b[36m2.0604\u001b[0m  2.1759\n",
            "      8        \u001b[36m2.0417\u001b[0m  2.1917\n",
            "      9        \u001b[36m2.0070\u001b[0m  2.8796\n",
            "     10        \u001b[36m1.9927\u001b[0m  2.2916\n",
            "0.2558\n",
            "---Query no:  13 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m6.8482\u001b[0m  2.2759\n",
            "      2        \u001b[36m2.2783\u001b[0m  2.2391\n",
            "      3        \u001b[36m2.2692\u001b[0m  2.2421\n",
            "      4        \u001b[36m2.2241\u001b[0m  3.0456\n",
            "      5        \u001b[36m2.1642\u001b[0m  2.3817\n",
            "      6        \u001b[36m2.1105\u001b[0m  2.2345\n",
            "      7        2.1299  2.2340\n",
            "      8        2.1256  2.2482\n",
            "      9        \u001b[36m2.0414\u001b[0m  2.7785\n",
            "     10        \u001b[36m2.0389\u001b[0m  2.4858\n",
            "0.2598\n",
            "---Query no:  14 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.3339\u001b[0m  2.3869\n",
            "      2        \u001b[36m2.3214\u001b[0m  2.3296\n",
            "      3        \u001b[36m2.2984\u001b[0m  2.3309\n",
            "      4        \u001b[36m2.2978\u001b[0m  2.8910\n",
            "      5        \u001b[36m2.2965\u001b[0m  2.5871\n",
            "      6        2.2976  2.3625\n",
            "      7        2.2996  2.3289\n",
            "      8        2.2981  2.3358\n",
            "      9        2.3012  3.0364\n",
            "     10        2.2989  2.4539\n",
            "0.1\n",
            "---Query no:  15 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.2059\u001b[0m  2.4559\n",
            "      2        \u001b[36m2.3073\u001b[0m  2.3781\n",
            "      3        \u001b[36m2.2817\u001b[0m  2.4053\n",
            "      4        \u001b[36m2.2425\u001b[0m  3.2116\n",
            "      5        \u001b[36m2.1560\u001b[0m  2.3981\n",
            "      6        \u001b[36m2.1023\u001b[0m  2.3937\n",
            "      7        \u001b[36m1.9829\u001b[0m  2.4169\n",
            "      8        \u001b[36m1.9399\u001b[0m  2.3987\n",
            "      9        \u001b[36m1.9129\u001b[0m  3.2236\n",
            "     10        1.9177  2.3994\n",
            "0.21\n",
            "---Query no:  16 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.6338\u001b[0m  2.5053\n",
            "      2        \u001b[36m2.3029\u001b[0m  2.4924\n",
            "      3        \u001b[36m2.2976\u001b[0m  2.9588\n",
            "      4        \u001b[36m2.2974\u001b[0m  2.7829\n",
            "      5        \u001b[36m2.2967\u001b[0m  2.5062\n",
            "      6        \u001b[36m2.2950\u001b[0m  2.4736\n",
            "      7        2.2970  2.4814\n",
            "      8        2.2954  3.2926\n",
            "      9        2.2969  2.4658\n",
            "     10        2.2978  2.4883\n",
            "0.1\n",
            "---Query no:  17 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.2202\u001b[0m  2.5707\n",
            "      2        \u001b[36m2.2957\u001b[0m  2.7276\n",
            "      3        2.2983  3.1793\n",
            "      4        2.3004  2.5409\n",
            "      5        2.2994  2.5844\n",
            "      6        2.3000  2.5805\n",
            "      7        2.2996  3.3735\n",
            "      8        2.2974  2.5483\n",
            "      9        2.2978  2.5436\n",
            "     10        2.2959  2.5621\n",
            "0.1004\n",
            "---Query no:  18 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.0015\u001b[0m  2.9607\n",
            "      2        \u001b[36m2.2845\u001b[0m  3.1639\n",
            "      3        \u001b[36m2.2308\u001b[0m  2.6290\n",
            "      4        \u001b[36m2.2300\u001b[0m  2.6402\n",
            "      5        \u001b[36m2.1733\u001b[0m  2.6327\n",
            "      6        \u001b[36m2.0937\u001b[0m  3.4505\n",
            "      7        \u001b[36m2.0517\u001b[0m  2.6211\n",
            "      8        \u001b[36m2.0508\u001b[0m  2.6315\n",
            "      9        \u001b[36m2.0448\u001b[0m  2.6169\n",
            "     10        \u001b[36m1.9397\u001b[0m  3.3780\n",
            "0.2694\n",
            "---Query no:  19 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.6651\u001b[0m  2.8072\n",
            "      2        \u001b[36m2.2999\u001b[0m  2.6998\n",
            "      3        \u001b[36m2.2843\u001b[0m  2.7022\n",
            "      4        \u001b[36m2.2678\u001b[0m  3.1491\n",
            "      5        \u001b[36m2.2301\u001b[0m  3.0831\n",
            "      6        \u001b[36m2.1896\u001b[0m  2.6977\n",
            "      7        \u001b[36m2.1535\u001b[0m  2.6756\n",
            "      8        \u001b[36m2.1194\u001b[0m  2.7672\n",
            "      9        \u001b[36m2.1081\u001b[0m  3.4269\n",
            "     10        \u001b[36m2.0630\u001b[0m  2.7017\n",
            "0.1932\n",
            "---Query no:  20 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.3900\u001b[0m  2.7914\n",
            "      2        \u001b[36m2.3025\u001b[0m  3.0059\n",
            "      3        \u001b[36m2.3006\u001b[0m  3.3322\n",
            "      4        \u001b[36m2.2988\u001b[0m  2.7981\n",
            "      5        \u001b[36m2.2983\u001b[0m  2.7777\n",
            "      6        \u001b[36m2.2973\u001b[0m  2.7862\n",
            "      7        2.2993  3.5481\n",
            "      8        2.2986  2.8056\n",
            "      9        2.2989  2.7657\n",
            "     10        \u001b[36m2.2971\u001b[0m  2.7682\n",
            "0.1\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[  0   0   0 500   0   0   0   0   0   0]\n",
            " [  0   0   0 500   0   0   0   0   0   0]\n",
            " [  0   0   0 500   0   0   0   0   0   0]\n",
            " [  0   0   0 500   0   0   0   0   0   0]\n",
            " [  0   0   0 500   0   0   0   0   0   0]\n",
            " [  0   0   0 500   0   0   0   0   0   0]\n",
            " [  0   0   0 500   0   0   0   0   0   0]\n",
            " [  0   0   0 500   0   0   0   0   0   0]\n",
            " [  0   0   0 500   0   0   0   0   0   0]\n",
            " [  0   0   0 500   0   0   0   0   0   0]]\n",
            "Accuracy:  0.1\n",
            "Macro F1-score:  0.01818181818181818\n",
            "Micro F1-score:  0.10000000000000002\n",
            "Weighted F1-score:  0.01818181818181818\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "AL_Retrain(500, 20,  30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i3SNoH0iFYv",
        "outputId": "b0c2bf27-bab8-4280-c621-b91a4ee94fa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4584\u001b[0m  13.3773\n",
            "      2        \u001b[36m2.2578\u001b[0m  13.4475\n",
            "      3        \u001b[36m2.0809\u001b[0m  13.9700\n",
            "      4        \u001b[36m1.9326\u001b[0m  13.4448\n",
            "      5        \u001b[36m1.8101\u001b[0m  13.3724\n",
            "      6        \u001b[36m1.7354\u001b[0m  13.4063\n",
            "      7        \u001b[36m1.6755\u001b[0m  13.3681\n",
            "      8        \u001b[36m1.5998\u001b[0m  13.4407\n",
            "      9        \u001b[36m1.5699\u001b[0m  13.4212\n",
            "     10        \u001b[36m1.4951\u001b[0m  13.3847\n",
            "No of initial data:  5000\n",
            "0.3948\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[190  36  19   5  11  25  15  42  61  96]\n",
            " [  8 268   2   8   2   8  16  34   3 151]\n",
            " [ 20  19  63  25  79 108  57  83  16  30]\n",
            " [  1  12  20  80  35 149  65  93   7  38]\n",
            " [ 11   5  30  26 117  95  64 107   4  41]\n",
            " [  1  11  24  56  21 211  48 104   8  16]\n",
            " [  1  15  12  51  40  47 249  58   4  23]\n",
            " [  4  12   8  27  25  60  27 288   2  47]\n",
            " [ 65  61   6  11   2  19   9  23 173 131]\n",
            " [  7  72   3  12   3  15  23  24   6 335]]\n",
            "Accuracy:  0.3948\n",
            "Macro F1-score:  0.3811085921322225\n",
            "Micro F1-score:  0.3948\n",
            "Weighted F1-score:  0.3811085921322225\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[1, 6, 4, 8, 2, 2, 7, 2, 7, 6, 7, 6, 3, 1, 4, 5, 3, 1, 8, 0, 8, 2, 5, 3, 3, 3, 6, 4, 4, 6, 1, 1, 4, 3, 3, 5, 0, 4, 4, 0, 3, 4, 2, 2, 2, 7, 3, 3, 4, 4, 3, 1, 7, 1, 1, 5, 6, 8, 2, 4, 4, 3, 3, 1, 4, 0, 0, 0, 5, 2, 7, 4, 8, 9, 2, 0, 5, 0, 3, 1, 7, 3, 6, 4, 5, 2, 2, 6, 5, 4, 8, 0, 8, 3, 4, 2, 5, 6, 1, 3, 7, 4, 0, 0, 4, 0, 4, 4, 2, 8, 2, 3, 6, 2, 7, 2, 8, 6, 6, 4, 0, 8, 4, 2, 2, 3, 9, 8, 5, 4, 3, 2, 3, 0, 4, 4, 2, 6, 7, 4, 6, 2, 2, 2, 0, 2, 2, 6, 8, 2, 0, 9, 5, 1, 7, 6, 6, 5, 0, 5, 3, 4, 9, 3, 6, 2, 5, 2, 2, 1, 4, 3, 2, 3, 2, 4, 4, 3, 4, 5, 7, 5, 9, 8, 3, 6, 0, 2, 5, 0, 1, 4, 8, 9, 3, 1, 9, 4, 6, 8, 8, 3, 4, 0, 6, 6, 3, 2, 5, 3, 2, 0, 5, 2, 3, 2, 4, 8, 5, 2, 2, 2, 6, 2, 5, 5, 0, 7, 4, 0, 3, 8, 1, 2, 8, 3, 0, 2, 7, 7, 2, 8, 7, 1, 5, 7, 6, 8, 0, 9, 2, 5, 3, 4, 5, 4, 2, 1, 0, 5, 7, 2, 5, 1, 7, 8, 0, 3, 7, 4, 3, 7, 4, 8, 0, 4, 7, 5, 4, 4, 6, 9, 6, 3, 6, 3, 4, 3, 4, 3, 0, 3, 9, 6, 4, 6, 2, 5, 4, 3, 4, 6, 6, 7, 2, 5, 4, 4, 2, 0, 3, 5, 8, 9, 2, 6, 0, 1, 5, 9, 8, 0, 4, 4, 7, 4, 2, 8, 7, 4, 0, 2, 1, 2, 1, 8, 8, 2, 9, 6, 2, 6, 7, 4, 2, 5, 0, 5, 2, 2, 4, 3, 5, 2, 8, 4, 3, 3, 3, 2, 2, 3, 0, 2, 2, 5, 2, 8, 2, 2, 3, 4, 7, 0, 6, 4, 5, 8, 4, 8, 0, 6, 4, 5, 7, 5, 2, 8, 0, 3, 9, 2, 2, 4, 8, 4, 0, 0, 5, 8, 0, 6, 8, 6, 6, 0, 6, 0, 6, 2, 4, 6, 6, 3, 7, 9, 0, 8, 0, 8, 4, 3, 7, 1, 4, 2, 2, 7, 6, 5, 5, 3, 9, 4, 5, 5, 8, 4, 8, 7, 4, 4, 0, 0, 9, 3, 2, 8, 5, 4, 2, 3, 2, 2, 3, 9, 3, 4, 7, 6, 0, 6, 2, 1, 6, 9, 8, 6, 0, 0, 2, 6, 0, 5, 5, 2, 8, 6, 4, 5, 4, 5, 6, 2, 3, 8, 6, 0, 2, 4, 2, 5, 6, 3, 3, 4, 0, 3, 7, 1, 7, 1, 9, 4, 6, 7, 8, 5, 0, 8, 0, 7, 4, 8, 7, 8, 5, 6, 7, 2, 6, 5, 4, 4, 3, 4, 0, 7, 7, 2, 0, 1, 2, 2, 7, 2, 7, 9, 0, 8, 0, 6, 7, 3, 5, 4, 2, 6, 2, 0, 3, 8, 4, 6, 5, 5, 2, 2, 5, 7, 6, 5, 2, 6, 6, 7, 5, 6, 6, 2, 6, 1, 7, 2, 6, 4, 3, 2, 7, 0, 1, 6, 6, 5, 4, 3, 4, 6, 7, 2, 6, 1, 6, 7, 7, 8, 7, 8, 7, 5, 9, 3, 7, 1, 9, 3, 8, 6, 0, 5, 2, 8, 8, 6, 3, 7, 2, 9, 6, 0, 6, 2, 2, 3, 9, 2, 2, 4, 4, 8, 0, 3, 4, 3, 6, 6, 3, 6, 5, 8, 8, 6, 3, 5, 3, 5, 7, 0, 6, 2, 2, 8, 8, 6, 5, 8, 7, 6, 4, 8, 1, 4, 6, 0, 9, 0, 6, 8, 6, 6, 9, 7, 7, 2, 5, 3, 9, 9, 6, 0, 2, 0, 5, 6, 4, 2, 2, 5, 2, 3, 0, 6, 2, 8, 7, 0, 2, 2, 7, 8, 2, 8, 5, 8, 2, 6, 4, 4, 0, 0, 2, 3, 0, 3, 5, 5, 2, 4, 2, 3, 5, 2, 0, 2, 6, 3, 5, 8, 8, 6, 3, 5, 3, 5, 5, 3, 4, 6, 2, 0, 2, 3, 6, 4, 6, 8, 4, 5, 7, 7, 4, 3, 3, 4, 9, 2, 2, 2, 2, 7, 7, 2, 9, 5, 5, 7, 0, 3, 3, 7, 6, 2, 5, 3, 3, 3, 4, 1, 2, 6, 7, 1, 0, 2, 6, 4, 3, 4, 4, 1, 3, 5, 6, 4, 2, 5, 3, 6, 2, 2, 4, 6, 2, 0, 5, 5, 0, 2, 0, 0, 2, 5, 6, 1, 8, 2, 6, 4, 3, 8, 6, 8, 8, 2, 7, 6, 1, 3, 2, 6, 3, 6, 8, 8, 6, 7, 2, 3, 3, 5, 5, 6, 2, 6, 4, 3, 3, 7, 4, 7, 2, 4, 2, 7, 4, 2, 0, 9, 2, 3, 7, 3, 0, 2, 6, 8, 3, 0, 2, 6, 3, 5, 7, 2, 0, 2, 4, 9, 1, 4, 3, 9, 4, 5, 5, 5, 3, 7, 7, 6, 6, 2, 6, 4, 5, 0, 3, 5, 8, 0, 6, 9, 8, 0, 0, 5, 7, 2, 3, 7, 3, 2, 4, 1, 4, 5, 6, 9, 1, 6, 2, 5, 4, 5, 7, 0, 7, 4, 3, 2, 2, 7, 5, 8, 5, 8, 2, 6, 2, 0, 4, 8, 0, 4, 2, 1, 3, 2, 2, 2, 2, 4, 3, 1, 2, 1, 6, 2, 3, 4, 8, 7, 4, 2, 2, 3, 4, 9, 4, 6, 3, 4, 4, 2, 2, 2, 2, 6, 0, 8, 6, 4, 3, 2, 6, 9, 4, 8, 3, 1, 4, 8, 5, 9, 3, 7, 9, 6, 3, 8, 0, 9, 4, 2, 4, 6, 1, 5, 2, 4, 3, 1, 2, 6, 6, 7, 8, 6, 3, 4, 5, 2, 6, 2, 5, 7, 2, 6, 0, 6, 2, 6, 7, 5, 3, 2, 8, 1, 2, 6, 0, 2, 7, 7, 3, 8, 7, 6, 8, 6, 6, 2, 5, 3, 2, 9, 8, 0, 4, 2, 4, 6, 6, 4, 7, 2, 6, 5, 0, 2, 2, 2, 2, 4, 6, 2, 8, 2, 2, 7, 4, 2, 1, 1, 6, 0, 2, 7, 2, 6, 4, 2, 7, 4, 1, 4, 6, 4, 7, 9, 2, 1, 3, 3, 5, 5, 2, 1, 3, 7, 5, 5, 5, 4, 2, 7, 8, 4, 4, 0, 3, 4, 0, 4, 6, 7, 2, 2, 8, 1, 5, 2, 3, 5, 5, 2, 0, 9, 0, 4, 4, 9, 3, 2, 2, 3, 2, 4, 6, 8, 7, 4, 1, 3, 0, 5, 5, 0, 6, 1, 6, 4, 4, 6, 4, 2, 2, 6, 4, 2, 4, 2, 4, 4, 0, 5, 2, 2, 6, 4, 4, 2, 7, 6, 3, 4, 4, 0, 2, 2, 8, 7, 3, 4, 5, 0, 6, 4, 4, 2, 2, 2, 9, 1, 4, 3, 6, 1, 2, 8, 7, 7, 4, 6, 0, 6, 5, 2, 3, 8, 3, 1, 5, 3, 4, 9, 3, 4, 5, 6, 0, 4, 3, 4, 4, 3, 1, 4, 0, 9, 5, 2, 4, 6, 2, 8, 1, 0, 3, 5, 1, 4, 5, 0, 2, 5, 0, 2, 5, 4, 1, 3, 2, 6, 0, 2, 4, 3, 5, 7, 3, 4, 9, 2, 2, 2, 4, 4, 6, 0, 2, 2, 8, 6, 6, 7, 4, 5, 6, 6, 5, 6, 5, 4, 3, 4, 2, 3, 4, 5, 4, 0, 3, 1, 2, 4, 6, 0, 1, 4, 1, 3, 4, 6, 3, 3, 6, 4, 9, 2, 0, 8, 6, 0, 3, 0, 4, 2, 6, 6, 4, 4, 0, 6, 5, 0, 3, 5, 6, 4, 1, 8, 4, 2, 3, 5, 3, 2, 7, 2, 6, 4, 0, 6, 2, 0, 0, 9, 6, 0, 2, 8, 1, 6, 8, 1, 4, 3, 5, 9, 1, 3, 8, 8, 2, 5, 1, 3, 1, 5, 2, 4, 2, 2, 4, 0, 3, 8, 4, 5, 2, 8, 3, 4, 2, 2, 5, 0, 3, 6, 1, 8, 3, 5, 8, 4, 4, 0, 2, 5, 6, 2, 6, 0, 7, 3, 5, 3, 2, 8, 2, 3, 8, 2, 8, 9, 4, 8, 0, 1, 4, 0, 0, 8, 7, 0, 2, 6, 4, 9, 2, 0, 4, 4, 4, 8, 5, 0, 8, 2, 3, 6, 0, 0, 1, 8, 2, 0, 6, 0, 1, 0, 0, 2, 2, 4, 6, 7, 6, 4, 5, 4, 0, 6, 4, 4, 8, 7, 0, 3, 0, 3, 9, 1, 7, 8, 3, 2, 9, 4, 5, 5, 0, 2, 4, 4, 2, 2, 5, 7, 9, 4, 8, 4, 2, 4, 0, 0, 2, 5, 8, 6, 6, 6, 2, 3, 8, 3, 2, 1, 4, 4, 4, 7, 4, 6, 9, 3, 8, 9, 0, 2, 0, 1, 8, 0, 5, 0, 8, 7, 8, 8, 8, 8, 1, 5, 2, 4, 1, 7, 3, 9, 5, 4, 6, 0, 0, 4, 9, 4, 8, 6, 0, 2, 5, 8, 5, 2, 5, 6, 6, 5, 2, 5, 0, 2, 2, 3, 8, 0, 0, 9, 0, 5, 9, 4, 7, 6, 6, 4, 6, 2, 0, 4, 7, 6, 7, 2, 6, 3, 8, 2, 6, 0, 4, 2, 0, 6, 3, 1, 0, 6, 2, 2, 9, 8, 2, 5, 4, 5, 4, 1, 4, 6, 4, 0, 8, 1, 3, 3, 7, 6, 4, 1, 1, 9, 5, 3, 4, 5, 2, 2, 4, 3, 7, 0, 6, 2, 0, 8, 2, 5, 2, 3, 6, 6, 3, 8, 4, 7, 9, 3, 0, 3, 9, 6, 2, 6, 3, 1, 0, 0, 9, 6, 5, 2, 5, 6, 2, 9, 2, 4, 3, 7, 5, 3, 4, 4, 7, 6, 8, 2, 9, 7, 2, 4, 2, 6, 0, 2, 1, 6, 5, 4, 4, 6, 6, 4, 4, 7, 6, 9, 8, 0, 6, 9, 9, 0, 6, 6, 4, 6, 8, 2, 0, 0, 4, 4, 2, 7, 4, 2, 7, 0, 0, 5, 2, 1, 9, 8, 0, 0, 3, 6, 4, 8, 7, 3, 3, 2, 7, 1, 4, 4, 1, 4, 2, 2, 4, 8, 3, 3, 2, 3, 4, 0, 9, 9, 6, 5, 2, 9, 3, 9, 7, 2, 8, 6, 7, 0, 4, 0, 6, 1, 4, 1, 6, 2, 8, 0, 4, 5, 7, 7, 0, 7, 4, 3, 0, 8, 8, 0, 8, 4, 7, 2, 4, 3, 1, 2, 6, 3, 4, 7, 1, 4, 6, 2, 2, 5, 8, 7, 9, 4, 7, 4, 0, 0, 6, 4, 9, 0, 3, 3, 3, 5, 4, 2, 0, 1, 2, 6, 8, 0, 6, 3, 8, 6, 6, 4, 8, 0, 8, 4, 9, 2, 6, 6, 2, 6, 1, 2, 2, 2, 2, 2, 3, 8, 6, 2, 0, 1, 9, 6, 0, 2, 0, 3, 2, 8, 0, 4, 5, 8, 4, 4, 9, 4, 0, 4, 6, 1, 3, 3, 3, 2, 2, 3, 3, 1, 8, 5, 2, 0, 9, 8, 5, 3, 6, 0, 4, 4, 0, 2, 2, 9, 6, 6, 2, 5, 4, 5, 9, 0, 2, 2, 4, 5, 8, 5, 4, 7, 7, 0, 2, 1, 9, 2, 9, 0, 8, 3, 6, 2, 7, 8, 1, 6, 6, 2, 4, 8, 1, 1, 3, 3, 5, 4, 1, 0, 3, 6, 7, 4, 0, 4, 7, 8, 4, 7, 6, 4, 7, 3, 2, 2, 9, 5, 3, 8, 3, 3, 9, 4, 9, 6, 3, 3, 4, 0, 7, 3, 5, 0, 5, 4, 4, 6, 3, 6, 1, 3, 7, 5, 2, 6, 2, 4, 1, 8, 9, 7, 2, 4, 2, 1, 6, 7, 0, 4, 6, 4, 6, 2, 5, 5, 6, 5, 5, 0, 2, 4, 7, 4, 0, 6, 2, 6, 3, 1, 4, 6, 2, 6, 3, 6, 0, 7, 0, 5, 6, 6, 0, 2, 8, 9, 9, 8, 3, 4, 5, 2, 9, 0, 5, 7, 5, 0, 0, 2, 0, 2, 0, 8, 4, 8, 2, 9, 6, 2, 6, 8, 9, 8, 4, 7, 0, 4, 9, 7, 3, 2, 2, 6, 3, 4, 8, 4, 5, 5, 6, 3, 8, 6, 3, 6, 6, 3, 6, 3, 4, 4, 2, 7, 6, 8, 5, 1, 3, 3, 3, 3, 9, 8, 8, 8, 2, 0, 6, 6, 5, 2, 5, 2, 5, 3, 0, 6, 2, 9, 4, 6, 2, 2, 7, 4, 6, 5, 5, 2, 9, 1, 7, 3, 7, 1, 2, 1, 8, 9, 0, 9, 2, 0, 0, 8, 6, 7, 4, 2, 5, 3, 8, 8, 4, 2, 5, 1, 7, 3, 3, 4, 6, 1, 0, 5, 3, 3, 3, 4, 7, 4, 9, 6, 7, 2, 6, 8, 6, 6, 2, 3, 4, 4, 4, 4, 3, 5, 7, 1, 3, 3, 9, 7, 2, 2, 0, 0, 4, 1, 5, 9, 7, 3, 0, 9, 7, 8, 5, 5, 6, 2, 3, 4, 4, 2, 8, 5, 5, 2, 5, 2, 3, 3, 4, 8, 8, 8, 2, 2, 0, 3, 3, 6, 0, 2, 4, 6, 5, 9, 3, 5, 5, 6, 2, 7, 0, 4, 4, 5, 0, 6, 8, 0, 3, 5, 3, 4, 8, 4, 3, 3, 3, 9, 7, 2, 5, 9, 0, 5, 9, 1, 8, 6, 6, 3, 5, 9, 6, 9, 3, 6, 5, 4, 6, 8, 6, 3, 8, 7, 6, 5, 5, 4, 9, 8, 7, 4, 3, 8, 6, 7, 7, 3, 1, 2, 6, 1, 7, 4, 5, 3, 3, 4, 0, 3, 8, 4, 5, 3, 3, 3, 2, 4, 6, 7, 7, 5, 4, 3, 7, 7, 3, 3, 1, 4, 3, 0, 0, 3, 4, 4, 8, 2, 4, 2, 5, 4, 8, 8, 7, 6, 8, 2, 1, 8, 1, 5, 4, 2, 8, 5, 4, 5, 4, 2, 6, 8, 2, 9, 0, 8, 8, 6, 2, 8, 0, 3, 2, 6, 6, 6, 6, 6, 8, 6, 5, 6, 3, 8, 9, 3, 4, 3, 0, 2, 7, 2, 2, 5, 9, 5, 2, 3, 8, 3, 0, 8, 9, 7, 2, 6, 3, 0, 5, 3, 5, 5, 8, 3, 4, 6, 2, 8, 8, 2, 2, 5, 5, 0, 3, 5, 0, 2, 5, 4, 5, 5, 1, 2, 0, 3, 2, 3, 1, 3, 2, 2, 4, 4, 8, 3, 0, 2, 7, 4, 8, 6, 4, 6, 6, 1, 3, 3, 4, 5, 2, 9, 4, 4, 0, 3, 6, 6, 2, 4, 5, 3, 0, 7, 3, 0, 2, 4, 3, 2, 6, 5, 4, 0, 0, 9, 6, 4, 9, 6, 2, 2, 2, 4, 0, 8, 6, 2, 2, 3, 5, 8, 0, 4, 8, 1, 5, 4, 0, 8, 5, 0, 2, 8, 8, 4, 8, 8, 4, 0, 2, 3, 4, 8, 0, 3, 8, 0, 7, 3, 6, 4, 6, 6, 9, 6, 2, 9, 4, 5, 9, 4, 8, 0, 2, 4, 6, 4, 1, 3, 4, 8, 2, 0, 4, 2, 0, 9, 6, 5, 6, 5, 2, 0, 2, 0, 2, 3, 3, 8, 0, 0, 2, 3, 6, 3, 6, 3, 6, 4, 3, 3, 4, 3, 6, 7, 5, 6, 8, 7, 4, 0, 6, 7, 4, 4, 8, 9, 7, 8, 8, 9, 0, 5, 5, 6, 1, 7, 8, 3, 2, 3, 0, 9, 0, 0, 0, 2, 4, 2, 9, 5, 5, 2, 4, 2, 2, 2, 6, 7, 3, 2, 4, 3, 0, 6, 2, 6, 7, 2, 6, 7, 6, 4, 2, 7, 3, 2, 3, 8, 5, 7, 0, 7, 7, 0, 8, 3, 3, 4, 4, 3, 2, 5, 5, 7, 4, 5, 3, 9, 4, 6, 2, 0, 4, 3, 6, 8, 4, 4, 6, 6, 2, 2, 8, 4, 2, 9, 4, 0, 3, 2, 0, 0, 4, 0, 2, 5, 5, 1, 4, 6, 0, 2, 0, 8, 0, 0, 5, 2, 7, 8, 7, 4, 8, 0, 0, 4, 2, 6, 1, 2, 9, 5, 6, 8, 4, 3, 1, 2, 4, 8, 4, 0, 6, 0, 4, 0, 2, 2, 3, 4, 3, 4, 4, 0, 8, 6, 7, 4, 9, 3, 6, 5, 4, 0, 2, 2, 6, 4, 4, 2, 7, 8, 3, 5, 3, 3, 3, 8, 4, 8, 3, 6, 8, 6, 0, 5, 0, 6, 8, 7, 0, 4, 2, 6, 5, 8, 4, 2, 9, 3, 0, 8, 3, 7, 3, 2, 6, 0, 3, 9, 0, 4, 4, 0, 3, 9, 4, 6, 6, 5, 4, 9, 7, 2, 0, 7, 6, 1, 0, 4, 5, 7, 7, 6, 3, 0, 2, 4, 2, 2, 0, 2, 2, 7, 8, 7, 5, 2, 6, 5, 2, 4, 2, 0, 6, 3, 5, 6, 4, 2, 3, 6, 4, 4, 9, 4, 4, 5, 9, 5, 0, 9, 6, 3, 2, 8, 3, 6, 0, 6, 7, 4, 6, 6, 6, 1, 2, 6, 4, 2, 2, 9, 5, 2, 9, 4, 5, 4, 1, 7, 4, 3, 2, 2, 1, 4, 6, 2, 5, 8, 5, 5, 0, 6, 5, 6, 3, 4, 5, 6, 2, 4, 6, 0, 7, 0, 5, 8, 0, 1, 4, 2, 3, 5, 8, 8, 0, 1, 9, 3, 7, 3, 2, 3, 2, 5, 6, 4, 0, 3, 0, 0, 8, 6, 4, 4, 3, 4, 5, 5, 2, 1, 9, 8, 0, 2, 3, 4, 9, 0, 3, 3, 4, 5, 3, 2, 2, 6, 1, 4, 8, 1, 3, 5, 4, 7, 0, 1, 8, 2, 5, 5, 6, 9, 3, 0, 8, 4, 2, 6, 3, 0, 6, 4, 5, 4, 9, 4, 4, 2, 2, 3, 1, 6, 2, 1, 2, 3, 4, 5, 8, 2, 2, 4, 7, 0, 0, 3, 0, 2, 6, 2, 2, 0, 7, 2, 2, 5, 0, 3, 2, 0, 8, 8, 3, 2, 4, 2, 2, 0, 7, 4, 4, 3, 4, 0, 3, 2, 7, 3, 0, 0, 6, 6, 2, 4, 3, 4, 5, 9, 3, 2, 0, 2, 3, 6, 5, 3, 8, 3, 4, 0, 3, 8, 2, 2, 6, 1, 9, 5, 0, 6, 4, 4, 6, 0, 5, 3, 6, 3, 3, 2, 3, 4, 4, 3, 3, 1, 8, 5, 4, 0, 9, 6, 0, 6, 3, 6, 7, 7, 7, 3, 4, 8, 9, 1, 4, 0, 0, 3, 8, 5, 6, 4, 3, 5, 8, 1, 6, 1, 6, 6, 7, 4, 4, 1, 5, 3, 5, 7, 6, 4, 6, 1, 5, 4, 8, 5, 5, 7, 3, 3, 3, 8, 6, 4, 4, 3, 7, 8, 1, 8, 5, 7, 3, 8, 4, 7, 4, 0, 0, 4, 7, 7, 0, 5, 3, 7, 9, 5, 4, 5, 6, 3, 8, 3, 0, 4, 0, 6, 5, 6, 4, 0, 6, 5, 3, 3, 0, 6, 5, 6, 7, 6, 7, 8, 6, 4, 6, 7, 8, 5, 0, 7, 6, 6, 9, 6, 9, 4, 9, 5, 7, 4, 8, 6, 7, 9, 0, 4, 5, 0, 9, 1, 3, 4, 8, 5, 3, 4, 8, 3, 0, 7, 6, 5, 0, 6, 6, 4, 7, 7, 6, 5, 0, 4, 4, 3, 5, 6, 6, 5, 0, 6, 7, 7, 3, 5, 3, 9, 4, 4, 7, 8, 7, 6, 6, 1, 3, 1, 8, 3, 3, 4, 4, 8, 5, 0, 5, 0, 1, 6, 7, 0, 8, 6, 4, 6, 0, 6, 6, 9, 5, 9, 3, 6, 9, 4, 1, 4, 8, 4, 7, 6, 3, 5, 4, 3, 0, 4, 6, 5, 5, 5, 5, 0, 5, 6, 5, 0, 8, 7, 0, 4, 5, 5, 4, 4, 4, 4, 4, 5, 3, 3, 6, 6, 8, 4, 3, 5, 4, 9, 4, 0, 8, 6, 9, 5, 7, 3, 4, 9, 0, 6, 7, 6, 8, 3, 8, 1, 7, 0, 5, 3, 0, 6, 0, 3, 7, 6, 3, 7, 1, 5, 1, 3, 8, 5, 3, 3, 9, 7, 8, 3, 3, 0, 7, 5, 8, 6, 1, 8, 3, 8, 7, 6, 3, 3, 9, 5, 3, 5, 0, 5, 5, 5, 6, 8, 8, 6, 6, 5, 3, 8, 0, 0, 3, 3, 5, 7, 0, 8, 3, 9, 3, 0, 6, 3, 3, 6, 5, 6, 0, 7, 8, 3, 9, 0, 7, 6, 5, 6, 9, 3, 3, 1, 6, 8, 3, 3, 5, 9, 3, 5, 8, 6, 8, 9, 3, 9, 8, 6, 7, 0, 9, 6, 9, 6, 0, 0, 0, 6, 1, 0, 7, 6, 1, 8, 3, 5, 5, 7, 0, 6, 5, 3, 3, 6, 5, 8, 0, 8, 8, 1, 6, 3, 1, 1, 5, 8, 5, 0, 3, 5, 8, 1, 7, 1, 3, 9, 9, 8, 6, 7, 6, 5, 5, 5, 3, 0, 7, 0, 5, 7, 1, 0, 3, 7, 3, 1, 5, 3, 7, 7, 5, 6, 6, 3, 9, 9, 5, 3, 3, 5, 7, 1, 9, 6, 3, 3, 5, 3, 6, 1, 5, 8, 5, 7, 1, 6, 6, 7, 3, 0, 6, 0, 5, 6, 6, 6, 1, 8, 8, 5, 7, 3, 3, 6, 5, 5, 3, 3, 7, 5, 9, 8, 3, 3, 8, 5, 6, 8, 6, 3, 6, 5, 1, 0, 9, 7, 0, 7, 3, 6, 1, 1, 0, 3, 1, 6, 9, 7, 6, 3, 8, 0, 3, 3, 5, 5, 6, 5, 3, 3, 9, 8, 6, 3, 6, 7, 9, 5, 7, 5, 8, 6, 1, 5, 0, 1, 0, 9, 8, 5, 5, 6, 7, 5, 7, 6, 5, 0, 3, 5, 5, 5, 8, 8, 9, 7, 7, 8, 6, 3, 6, 3, 7, 9, 3, 9, 5, 8, 0, 1, 3, 3, 9, 1, 8, 8, 3, 0, 6, 7, 3, 6, 0, 7, 0, 3, 5, 7, 6, 8, 8, 3, 8, 6, 9, 8, 8, 0, 6, 0, 8, 8, 9, 5, 5, 8, 3, 1, 5, 6, 3, 6, 3, 5, 8, 5, 6, 0, 0, 3, 1, 3, 3, 3, 5, 8, 5, 0, 6, 5, 8, 3, 6, 9, 5, 1, 1, 3, 9, 8, 0, 0, 5, 0, 9, 9, 6, 8, 5, 5, 0, 5, 1, 6, 5, 7, 0, 6, 8, 8, 0, 1, 6, 3, 5, 6, 5, 3, 1, 5, 3, 3, 6, 9, 1, 6, 1, 3, 1, 0, 3, 5, 8, 0, 9, 5, 3, 0, 7, 8, 5, 9, 3, 5, 7, 3, 0, 9, 5, 8, 0, 5, 7, 8, 7, 7, 8, 9, 0, 3, 3, 0, 9, 8, 8, 0, 0, 5, 9, 0, 5, 1, 3, 3, 1, 7, 5, 3, 5, 5, 0, 8, 7, 1, 9, 5, 0, 7, 8, 0, 0, 9, 7, 0, 0, 9, 5, 7, 5, 5, 0, 5, 7, 5, 5, 5, 9, 9, 1, 1, 0, 0, 0, 7, 1, 0, 7, 0, 0, 7, 1, 0, 7, 7, 0, 8, 9, 5, 8, 0, 8, 7, 1, 0, 7, 0, 0, 7, 1, 0, 9, 8, 8, 5, 5, 1, 5, 0, 0, 9, 8, 7, 9, 5, 8, 0, 8, 1, 7, 8, 5, 9, 0, 1, 0, 0, 0, 7, 0, 8, 5, 9, 8, 7, 8, 0, 9, 0, 5, 9, 8, 1, 8, 0, 0, 0, 0, 5, 0, 5, 5, 9, 5, 5, 1, 8, 0, 5, 0, 0, 7, 9, 7, 0, 0, 0, 9, 5, 0, 5, 8, 0, 0, 7, 9, 7, 0, 5, 5, 8, 9, 8, 7, 0, 9, 8, 9, 5, 5, 7, 7, 7, 1, 0, 7, 0, 9, 8, 5, 1, 1, 9, 0, 5, 5, 5, 5, 8, 5, 9, 1, 8, 0, 5, 5, 5, 9, 5, 0, 7, 0, 5, 7, 9, 0, 5, 1, 7, 1, 9, 8, 7, 0, 0, 0, 1, 9, 7, 9, 0, 0, 5, 0, 5, 0, 1, 7, 8, 1, 7, 5, 5, 0, 5, 0, 9, 0, 7, 9, 8, 1, 0, 5, 8, 5, 0, 5, 5, 8, 0, 0, 9, 0, 8, 5, 0, 5, 9, 5, 1, 5, 0, 5, 1, 5, 0, 5, 0, 8, 9, 5, 9, 5, 5, 0, 0, 5, 8, 9, 1, 9, 9, 8, 1, 5, 5, 7, 0, 7, 0, 5, 1, 0, 5, 5, 5, 7, 1, 8, 1, 0, 0, 9, 0, 8, 8, 0, 1, 9, 9, 0, 1, 5, 5, 9, 0, 7, 1, 8, 7, 1, 1, 1, 0, 5, 5, 5, 7, 7, 1, 8, 7, 8, 1, 9, 1, 7, 5, 5, 5, 8, 5, 7, 8, 5, 5, 8, 9, 7, 7, 8, 5, 5, 9, 7, 8, 7, 5, 5, 8, 1, 7, 5, 8, 9, 9, 7, 8, 9, 1, 7, 9, 8, 7, 8, 8, 8, 8, 8, 7, 9, 7, 1, 7, 7, 7, 7, 8, 1, 7, 8, 9, 7, 9, 7, 9, 8, 8, 7, 9, 7, 8, 1, 7, 7, 9, 7, 1, 8, 1, 1, 8, 7, 1, 8, 1, 8, 1, 9, 7, 9, 7, 8, 8, 9, 7, 7, 1, 7, 9, 1, 7, 9, 8, 7, 8, 1, 7, 9, 7, 1, 8, 7, 8, 7, 7, 7, 7, 9, 7, 8, 9, 7, 7, 9, 1, 9, 7, 8, 7, 9, 1, 7, 8, 8, 9, 7, 8, 7, 8, 9, 8, 1, 7, 7, 1, 8, 8, 1, 8, 1, 8, 8, 9, 8, 7, 9, 8, 7, 8, 9, 7, 7, 7, 7, 9, 9, 8, 8, 1, 7, 8, 8, 8, 7, 7, 8, 7, 9, 8, 7, 9, 8, 9, 1, 8, 7, 1, 7, 1, 1, 1, 8, 8, 7, 8, 7, 9, 7, 7, 8, 7, 7, 9, 8, 7, 8, 7, 1, 7, 7, 1, 8, 1, 8, 9, 7, 9, 8, 1, 8, 7, 7, 9, 9, 7, 8, 1, 8, 9, 7, 8, 9, 8, 8, 9, 9, 9, 8, 9, 8, 8, 1, 1, 7, 8, 7, 1, 8, 7, 8, 9, 7, 8, 7, 8, 7, 7, 8, 7, 7, 1, 9, 9, 7, 1, 7, 7, 8, 9, 1, 8, 9, 1, 7, 9, 1, 9, 1, 7, 7, 7, 9, 7, 8, 7, 7, 1, 9, 7, 7, 7, 1, 7, 7, 7, 8, 8, 9, 9, 8, 9, 7, 8, 7, 9, 1, 7, 7, 8, 1, 1, 9, 1, 8, 8, 7, 8, 9, 7, 7, 1, 1, 9, 8, 7, 9, 1, 8, 8, 8, 9, 8, 7, 7, 7, 7, 8, 8, 7, 8, 8, 8, 7, 7, 7, 7, 8, 8, 8, 7, 7, 9, 9, 8, 8, 7, 7, 7, 1, 7, 7, 8, 7, 8, 7, 7, 9, 1, 7, 7, 8, 8, 9, 7, 9, 8, 8, 7, 1, 1, 8, 7, 9, 1, 7, 7, 1, 7, 7, 7, 7, 7, 1, 9, 1, 7, 1, 7, 9, 9, 9, 9, 1, 9, 9, 7, 7, 7, 9, 1, 9, 7, 7, 9, 1, 7, 1, 1, 7, 7, 1, 7, 7, 7, 7, 1, 7, 1, 1, 1, 7, 9, 1, 1, 7, 1, 1, 7, 1, 1, 9, 1, 9, 7, 7, 7, 7, 7, 9, 1, 9, 7, 1, 7, 1, 7, 1, 9, 9, 9, 9, 1, 9, 9, 1, 9, 9, 9, 9, 1, 1, 1, 1, 1, 9, 9, 9, 9, 1, 9, 1, 9, 1, 9, 1, 9, 1, 1, 9, 9, 1, 9, 9, 1, 1, 9, 1, 9, 1, 9, 1, 1, 1, 9, 1, 1, 9, 1, 1, 9, 9, 1, 9, 9, 9, 1, 1, 1, 9, 9, 9, 1, 9, 9, 1, 9, 1, 9, 1, 9, 9, 1, 1, 1, 9, 1, 1, 1, 1, 9, 9, 1, 9, 9, 9, 9, 1, 1, 9, 1, 9, 9, 1, 1, 9, 1, 9, 1, 9, 9, 9, 9, 9, 9, 1, 9, 1, 9, 1, 1, 9, 9, 9, 9, 1, 1, 9, 1, 1, 1, 1, 9, 9, 9, 9, 1, 9, 9, 1, 1, 9, 9, 9, 9, 1, 9, 1, 9, 9, 9, 1, 1, 1, 1, 1, 9, 1, 9, 9, 9, 9, 1, 9, 1, 1, 1, 9, 1, 9, 9, 1, 9, 1, 1, 1, 1, 9, 1, 1, 9, 1, 1, 1, 1, 9, 9, 9, 9, 1, 1, 1, 9, 9, 9, 9, 9, 9, 9, 1, 9, 9, 9, 1, 9, 1, 9, 1, 1, 9, 9, 1, 1, 9, 1, 9, 1, 9, 1, 1, 9, 9, 9, 1, 1, 9, 9, 9, 1, 1, 9, 1, 1, 9, 1, 9, 1, 1, 1, 1, 9, 9, 9, 9, 9, 1, 9, 9, 9, 9, 9, 9, 1, 9, 1, 9, 9, 9, 9, 1, 1, 1, 9, 9, 9, 9, 9, 1, 9, 9, 9, 1, 1, 1, 9, 9, 9, 9, 1, 9, 1, 9, 1, 1, 1, 1, 1, 9, 9, 1, 1, 1, 1, 9, 9, 9, 9, 1, 9, 9, 9, 9, 9, 1, 9, 9, 1, 1, 9, 1, 9, 9, 9, 9, 9, 1, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Counter({1: 500, 6: 500, 4: 500, 8: 500, 2: 500, 7: 500, 3: 500, 5: 500, 0: 500, 9: 500})\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5364\u001b[0m  13.4675\n",
            "      2        \u001b[36m2.3155\u001b[0m  13.3906\n",
            "      3        \u001b[36m2.3116\u001b[0m  13.3936\n",
            "      4        2.3120  13.4302\n",
            "      5        2.3125  13.5216\n",
            "      6        2.3130  13.4170\n",
            "      7        2.3134  13.5329\n",
            "      8        2.3138  14.1372\n",
            "      9        2.3140  13.4066\n",
            "     10        2.3143  13.4463\n",
            "0.1\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[  0 500   0   0   0   0   0   0   0   0]\n",
            " [  0 500   0   0   0   0   0   0   0   0]\n",
            " [  0 500   0   0   0   0   0   0   0   0]\n",
            " [  0 500   0   0   0   0   0   0   0   0]\n",
            " [  0 500   0   0   0   0   0   0   0   0]\n",
            " [  0 500   0   0   0   0   0   0   0   0]\n",
            " [  0 500   0   0   0   0   0   0   0   0]\n",
            " [  0 500   0   0   0   0   0   0   0   0]\n",
            " [  0 500   0   0   0   0   0   0   0   0]\n",
            " [  0 500   0   0   0   0   0   0   0   0]]\n",
            "Accuracy:  0.1\n",
            "Macro F1-score:  0.01818181818181818\n",
            "Micro F1-score:  0.10000000000000002\n",
            "Weighted F1-score:  0.01818181818181818\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "---Query no:  1 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5388\u001b[0m  13.4930\n",
            "      2        \u001b[36m2.1150\u001b[0m  13.5216\n",
            "      3        \u001b[36m1.9501\u001b[0m  13.4322\n",
            "      4        \u001b[36m1.8314\u001b[0m  13.4089\n",
            "      5        \u001b[36m1.7003\u001b[0m  13.4080\n",
            "      6        \u001b[36m1.6631\u001b[0m  14.0400\n",
            "      7        \u001b[36m1.5716\u001b[0m  13.6945\n",
            "      8        \u001b[36m1.5385\u001b[0m  13.4925\n",
            "      9        \u001b[36m1.5194\u001b[0m  13.4623\n",
            "     10        \u001b[36m1.4418\u001b[0m  13.4140\n",
            "0.424\n",
            "---Query no:  2 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4146\u001b[0m  13.5449\n",
            "      2        \u001b[36m2.3036\u001b[0m  13.5484\n",
            "      3        2.3039  13.5422\n",
            "      4        \u001b[36m2.3036\u001b[0m  13.5437\n",
            "      5        2.3037  13.4898\n",
            "      6        \u001b[36m2.3035\u001b[0m  13.4982\n",
            "      7        \u001b[36m2.3031\u001b[0m  13.5256\n",
            "      8        2.3036  14.0351\n",
            "      9        2.3033  13.7594\n",
            "     10        2.3033  13.4637\n",
            "0.1\n",
            "---Query no:  3 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4358\u001b[0m  14.0665\n",
            "      2        \u001b[36m2.1357\u001b[0m  13.8784\n",
            "      3        \u001b[36m2.0481\u001b[0m  13.5500\n",
            "      4        \u001b[36m2.0243\u001b[0m  14.4464\n",
            "      5        \u001b[36m1.9994\u001b[0m  13.4897\n",
            "      6        \u001b[36m1.9736\u001b[0m  13.5333\n",
            "      7        \u001b[36m1.9356\u001b[0m  13.5767\n",
            "      8        1.9455  13.6142\n",
            "      9        \u001b[36m1.9085\u001b[0m  13.9977\n",
            "     10        \u001b[36m1.8872\u001b[0m  13.9748\n",
            "0.3224\n",
            "---Query no:  4 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4621\u001b[0m  13.5810\n",
            "      2        \u001b[36m2.1377\u001b[0m  14.2273\n",
            "      3        \u001b[36m2.0456\u001b[0m  13.7235\n",
            "      4        2.0542  13.5303\n",
            "      5        \u001b[36m1.9650\u001b[0m  13.4890\n",
            "      6        \u001b[36m1.9309\u001b[0m  13.4952\n",
            "      7        \u001b[36m1.9142\u001b[0m  13.4671\n",
            "      8        1.9190  13.4722\n",
            "      9        \u001b[36m1.8627\u001b[0m  13.5249\n",
            "     10        \u001b[36m1.8441\u001b[0m  13.4883\n",
            "0.3554\n",
            "---Query no:  5 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4321\u001b[0m  13.7026\n",
            "      2        \u001b[36m2.0601\u001b[0m  13.6377\n",
            "      3        \u001b[36m1.9923\u001b[0m  14.3515\n",
            "      4        \u001b[36m1.9129\u001b[0m  13.6237\n",
            "      5        \u001b[36m1.9083\u001b[0m  13.5978\n",
            "      6        \u001b[36m1.8160\u001b[0m  13.6310\n",
            "      7        \u001b[36m1.7775\u001b[0m  13.6821\n",
            "      8        \u001b[36m1.7002\u001b[0m  13.6098\n",
            "      9        \u001b[36m1.6283\u001b[0m  14.5727\n",
            "     10        \u001b[36m1.6127\u001b[0m  13.9172\n",
            "0.4272\n",
            "---Query no:  6 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4433\u001b[0m  13.8144\n",
            "      2        \u001b[36m2.1144\u001b[0m  13.7433\n",
            "      3        \u001b[36m2.0001\u001b[0m  14.5317\n",
            "      4        \u001b[36m1.9259\u001b[0m  13.7893\n",
            "      5        \u001b[36m1.8558\u001b[0m  13.7384\n",
            "      6        \u001b[36m1.8046\u001b[0m  13.7245\n",
            "      7        \u001b[36m1.7664\u001b[0m  13.6845\n",
            "      8        \u001b[36m1.7167\u001b[0m  13.6479\n",
            "      9        \u001b[36m1.7007\u001b[0m  13.7102\n",
            "     10        \u001b[36m1.6597\u001b[0m  13.7036\n",
            "0.3708\n",
            "---Query no:  7 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5431\u001b[0m  13.8274\n",
            "      2        \u001b[36m2.3036\u001b[0m  13.7708\n",
            "      3        \u001b[36m2.3035\u001b[0m  14.0776\n",
            "      4        \u001b[36m2.3034\u001b[0m  14.2440\n",
            "      5        \u001b[36m2.3033\u001b[0m  13.8058\n",
            "      6        \u001b[36m2.3033\u001b[0m  13.8558\n",
            "      7        \u001b[36m2.3032\u001b[0m  13.6852\n",
            "      8        \u001b[36m2.3032\u001b[0m  13.7030\n",
            "      9        2.3033  13.7159\n",
            "     10        2.3033  13.7208\n",
            "0.1\n",
            "---Query no:  8 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5783\u001b[0m  13.8553\n",
            "      2        \u001b[36m2.1867\u001b[0m  13.8550\n",
            "      3        \u001b[36m2.1148\u001b[0m  14.5729\n",
            "      4        \u001b[36m2.0835\u001b[0m  13.9115\n",
            "      5        \u001b[36m2.0283\u001b[0m  13.8741\n",
            "      6        2.0328  13.8060\n",
            "      8        2.0241  13.7709\n",
            "      9        \u001b[36m2.0033\u001b[0m  13.8503\n",
            "     10        \u001b[36m1.9829\u001b[0m  14.3410\n",
            "0.3086\n",
            "---Query no:  9 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5663\u001b[0m  13.9750\n",
            "      2        \u001b[36m2.0329\u001b[0m  14.1779\n",
            "      3        \u001b[36m1.8561\u001b[0m  14.4550\n",
            "      4        \u001b[36m1.7513\u001b[0m  13.8538\n",
            "      5        \u001b[36m1.7376\u001b[0m  13.8873\n",
            "      6        \u001b[36m1.6484\u001b[0m  13.9020\n",
            "      7        \u001b[36m1.5785\u001b[0m  13.9088\n",
            "      8        \u001b[36m1.5472\u001b[0m  13.8444\n",
            "      9        \u001b[36m1.4675\u001b[0m  14.0058\n",
            "     10        1.4863  14.5252\n",
            "0.4288\n",
            "---Query no:  10 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5577\u001b[0m  13.9447\n",
            "      2        \u001b[36m2.2205\u001b[0m  14.7754\n",
            "      3        \u001b[36m2.1573\u001b[0m  13.8790\n",
            "      4        \u001b[36m2.0941\u001b[0m  13.9570\n",
            "      5        \u001b[36m2.0657\u001b[0m  14.8524\n"
          ]
        }
      ],
      "source": [
        "AL_Retrain(5000, 20,  20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-oq8pXFiI7W",
        "outputId": "60d14ab2-7b61-485f-f4e1-3a71d812bee6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.6416\u001b[0m  14.0275\n",
            "      2        \u001b[36m1.9722\u001b[0m  13.4369\n",
            "      3        \u001b[36m1.8526\u001b[0m  13.4055\n",
            "      4        \u001b[36m1.7570\u001b[0m  13.3622\n",
            "      5        \u001b[36m1.6858\u001b[0m  13.4675\n",
            "      6        \u001b[36m1.6403\u001b[0m  13.3096\n",
            "      7        \u001b[36m1.5826\u001b[0m  13.3486\n",
            "      8        \u001b[36m1.4838\u001b[0m  13.2987\n",
            "      9        \u001b[36m1.4824\u001b[0m  13.3086\n",
            "     10        \u001b[36m1.4312\u001b[0m  13.3824\n",
            "No of initial data:  5000\n",
            "0.4108\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[298  15  19  18  21  28   2  12  65  22]\n",
            " [ 30 203   4  29   2  30  18  18  36 130]\n",
            " [ 59   2  71  40 139 124  23  25  11   6]\n",
            " [ 11   4  21 132  50 194  35  29   6  18]\n",
            " [ 39   1  32  40 208  94  28  37  16   5]\n",
            " [ 11   1  22  70  46 282  17  35   2  14]\n",
            " [  4   3  12  70  95  97 186  19   2  12]\n",
            " [ 17   6  10  34  57 122  10 212   8  24]\n",
            " [169  21   8  23   5  31   1   4 198  40]\n",
            " [ 18  34   3  44   5  55   6  23  48 264]]\n",
            "Accuracy:  0.4108\n",
            "Macro F1-score:  0.40951528600268744\n",
            "Micro F1-score:  0.41079999999999994\n",
            "Weighted F1-score:  0.40951528600268733\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[9, 6, 4, 3, 2, 2, 0, 2, 2, 2, 7, 3, 5, 6, 7, 3, 2, 9, 5, 1, 9, 2, 4, 2, 9, 8, 0, 0, 1, 5, 9, 9, 4, 9, 9, 4, 6, 7, 1, 1, 5, 4, 5, 4, 5, 3, 9, 9, 7, 0, 2, 4, 4, 0, 1, 5, 5, 3, 3, 4, 7, 1, 3, 6, 4, 4, 7, 6, 4, 2, 8, 2, 3, 4, 2, 2, 8, 1, 3, 7, 0, 4, 9, 6, 4, 9, 2, 0, 6, 4, 8, 4, 5, 5, 5, 3, 8, 6, 4, 0, 7, 4, 7, 5, 2, 3, 5, 9, 9, 7, 6, 9, 6, 8, 8, 1, 5, 6, 2, 3, 0, 1, 8, 8, 3, 2, 4, 7, 3, 4, 8, 3, 2, 0, 4, 4, 4, 3, 4, 1, 3, 4, 8, 2, 7, 1, 2, 0, 6, 4, 3, 6, 4, 1, 5, 6, 6, 6, 0, 5, 5, 6, 8, 2, 7, 5, 1, 9, 5, 1, 2, 5, 4, 5, 2, 6, 1, 4, 1, 5, 0, 0, 5, 0, 9, 3, 4, 2, 2, 0, 7, 6, 8, 2, 3, 5, 4, 6, 0, 9, 1, 3, 5, 6, 2, 5, 1, 9, 1, 3, 7, 2, 5, 9, 3, 2, 5, 8, 5, 2, 6, 4, 6, 0, 7, 5, 3, 6, 4, 7, 0, 0, 9, 0, 5, 7, 0, 2, 0, 1, 7, 4, 6, 1, 2, 4, 4, 6, 3, 6, 7, 6, 2, 4, 5, 7, 2, 6, 0, 8, 7, 2, 0, 7, 7, 4, 6, 3, 5, 3, 3, 7, 3, 2, 5, 1, 7, 9, 3, 4, 4, 9, 2, 7, 6, 3, 4, 3, 4, 0, 0, 8, 6, 0, 9, 0, 5, 7, 4, 7, 4, 7, 9, 2, 2, 5, 6, 4, 6, 2, 2, 4, 5, 6, 2, 5, 2, 1, 1, 0, 9, 7, 3, 6, 6, 2, 0, 2, 7, 4, 1, 3, 2, 1, 6, 7, 3, 4, 7, 9, 7, 0, 1, 4, 2, 4, 7, 4, 8, 4, 4, 6, 4, 4, 9, 4, 1, 3, 9, 2, 2, 7, 1, 4, 3, 5, 1, 5, 3, 2, 5, 4, 8, 0, 6, 5, 2, 7, 2, 1, 4, 6, 9, 7, 9, 9, 1, 0, 4, 2, 9, 1, 4, 6, 5, 5, 8, 8, 3, 2, 5, 5, 8, 3, 7, 1, 9, 6, 6, 6, 6, 4, 0, 8, 5, 9, 0, 2, 0, 7, 4, 1, 9, 9, 5, 8, 4, 4, 2, 5, 9, 0, 7, 3, 0, 5, 4, 2, 5, 2, 6, 4, 6, 6, 6, 3, 1, 7, 1, 4, 9, 9, 1, 1, 6, 5, 3, 1, 3, 6, 1, 6, 0, 6, 6, 5, 8, 6, 2, 2, 5, 6, 7, 5, 1, 6, 3, 9, 6, 5, 6, 6, 0, 2, 4, 6, 4, 2, 4, 2, 4, 7, 0, 5, 4, 1, 6, 4, 2, 3, 5, 7, 3, 1, 9, 7, 4, 5, 9, 5, 6, 1, 4, 7, 7, 1, 9, 9, 7, 3, 0, 7, 2, 1, 9, 3, 2, 4, 4, 6, 9, 7, 9, 4, 7, 2, 3, 8, 9, 8, 9, 3, 3, 3, 5, 4, 2, 0, 6, 0, 5, 2, 9, 3, 5, 1, 4, 5, 8, 4, 8, 2, 1, 6, 6, 4, 5, 6, 6, 8, 1, 2, 3, 5, 6, 4, 3, 1, 5, 6, 1, 6, 1, 2, 4, 2, 8, 9, 6, 9, 2, 4, 9, 9, 7, 3, 0, 8, 1, 5, 4, 7, 7, 1, 9, 8, 9, 0, 8, 5, 5, 4, 2, 6, 2, 3, 1, 5, 6, 4, 8, 6, 2, 3, 0, 9, 2, 1, 0, 5, 4, 4, 2, 6, 6, 6, 7, 7, 5, 8, 8, 2, 3, 2, 2, 6, 7, 8, 2, 7, 9, 2, 4, 3, 5, 1, 2, 4, 8, 1, 5, 7, 4, 3, 6, 2, 9, 0, 1, 9, 5, 6, 8, 4, 1, 4, 9, 9, 2, 8, 3, 7, 6, 3, 4, 9, 5, 5, 2, 2, 1, 6, 2, 8, 7, 9, 3, 4, 4, 3, 3, 6, 9, 3, 8, 2, 2, 0, 9, 6, 5, 6, 1, 3, 0, 5, 5, 4, 2, 3, 2, 6, 0, 5, 5, 0, 1, 1, 5, 4, 8, 2, 8, 2, 1, 1, 4, 4, 6, 1, 3, 4, 6, 7, 7, 9, 0, 5, 4, 6, 4, 1, 6, 6, 9, 6, 8, 2, 4, 7, 8, 7, 0, 9, 2, 2, 3, 4, 2, 4, 8, 3, 6, 1, 6, 1, 1, 2, 2, 9, 7, 3, 2, 6, 2, 7, 1, 2, 4, 0, 0, 4, 5, 4, 0, 3, 8, 3, 2, 7, 0, 6, 2, 5, 5, 1, 4, 1, 1, 9, 2, 1, 0, 0, 3, 4, 6, 4, 3, 6, 9, 2, 5, 2, 3, 2, 2, 5, 2, 2, 3, 1, 7, 7, 6, 1, 2, 4, 3, 4, 8, 5, 7, 6, 4, 1, 3, 7, 0, 3, 2, 7, 0, 7, 4, 5, 0, 5, 2, 4, 7, 2, 0, 4, 9, 7, 8, 0, 0, 6, 2, 0, 3, 0, 2, 2, 5, 7, 4, 6, 7, 4, 2, 4, 7, 0, 4, 4, 7, 2, 6, 3, 8, 0, 5, 4, 3, 5, 8, 2, 6, 9, 8, 2, 9, 5, 2, 2, 3, 0, 5, 2, 2, 7, 4, 5, 6, 9, 3, 6, 7, 8, 4, 4, 2, 6, 8, 1, 4, 4, 6, 7, 3, 7, 7, 1, 6, 5, 2, 9, 7, 9, 2, 3, 3, 5, 3, 6, 2, 7, 4, 5, 2, 3, 3, 1, 6, 6, 7, 4, 3, 3, 4, 6, 1, 4, 4, 9, 5, 0, 1, 0, 9, 9, 7, 7, 4, 0, 8, 0, 7, 9, 2, 2, 8, 9, 4, 4, 3, 7, 4, 7, 5, 7, 3, 0, 6, 2, 3, 3, 1, 1, 4, 3, 3, 5, 8, 8, 2, 1, 2, 5, 3, 5, 4, 6, 5, 9, 3, 4, 4, 4, 4, 1, 2, 7, 4, 6, 0, 1, 7, 4, 7, 6, 1, 3, 2, 2, 2, 6, 3, 0, 3, 9, 0, 8, 7, 6, 0, 6, 7, 7, 2, 2, 1, 0, 2, 2, 4, 6, 8, 2, 7, 3, 8, 2, 6, 8, 6, 2, 0, 4, 2, 4, 8, 2, 2, 8, 9, 3, 6, 9, 7, 6, 2, 3, 2, 8, 8, 7, 5, 2, 2, 0, 5, 5, 8, 5, 7, 5, 2, 1, 3, 3, 3, 6, 4, 5, 7, 7, 6, 5, 2, 4, 4, 7, 4, 0, 6, 7, 4, 6, 0, 4, 6, 6, 3, 8, 8, 1, 5, 2, 7, 8, 4, 1, 0, 2, 4, 4, 8, 3, 9, 8, 2, 3, 0, 4, 0, 1, 7, 9, 6, 3, 4, 8, 4, 7, 9, 1, 4, 2, 5, 4, 2, 2, 4, 1, 4, 3, 3, 4, 2, 4, 9, 5, 3, 1, 2, 2, 2, 1, 4, 7, 6, 9, 6, 9, 3, 2, 8, 0, 3, 2, 4, 3, 7, 4, 4, 3, 2, 4, 6, 9, 0, 6, 5, 1, 3, 1, 7, 6, 1, 7, 2, 7, 7, 5, 7, 2, 2, 7, 2, 4, 4, 9, 6, 2, 2, 6, 0, 8, 3, 1, 8, 2, 3, 1, 4, 2, 3, 2, 4, 2, 4, 6, 3, 7, 6, 3, 2, 1, 5, 0, 1, 2, 2, 1, 1, 7, 1, 5, 2, 3, 0, 1, 6, 1, 6, 9, 3, 4, 5, 2, 2, 6, 7, 4, 4, 4, 9, 4, 9, 1, 6, 7, 4, 9, 6, 4, 5, 7, 2, 5, 9, 1, 2, 5, 9, 2, 1, 9, 2, 8, 3, 4, 1, 2, 6, 9, 6, 6, 8, 2, 1, 3, 6, 4, 9, 9, 8, 0, 7, 8, 8, 1, 5, 5, 6, 6, 7, 4, 6, 6, 3, 7, 3, 8, 5, 3, 8, 3, 4, 7, 3, 5, 3, 2, 7, 3, 9, 3, 1, 4, 6, 7, 1, 2, 3, 4, 6, 7, 5, 0, 1, 1, 8, 3, 7, 2, 3, 5, 3, 6, 5, 3, 1, 8, 1, 6, 5, 5, 2, 7, 7, 0, 6, 7, 4, 4, 5, 8, 0, 6, 6, 4, 5, 2, 4, 6, 4, 7, 3, 9, 3, 6, 4, 7, 7, 1, 6, 6, 6, 2, 5, 3, 5, 5, 4, 1, 8, 9, 8, 4, 4, 9, 7, 3, 6, 2, 6, 4, 4, 0, 6, 0, 4, 3, 4, 3, 6, 4, 9, 4, 6, 6, 8, 0, 8, 4, 6, 1, 7, 9, 3, 7, 6, 7, 6, 0, 1, 1, 7, 0, 1, 9, 6, 7, 9, 1, 2, 6, 2, 1, 2, 4, 4, 3, 3, 4, 2, 2, 6, 2, 7, 1, 6, 0, 1, 4, 3, 3, 1, 2, 2, 9, 2, 1, 3, 3, 9, 4, 7, 4, 2, 4, 0, 6, 0, 5, 1, 6, 6, 5, 5, 6, 8, 4, 8, 3, 4, 4, 8, 5, 4, 6, 9, 4, 4, 9, 1, 5, 9, 1, 3, 0, 0, 2, 8, 3, 2, 4, 5, 4, 3, 4, 3, 7, 4, 7, 2, 7, 4, 3, 2, 7, 0, 1, 9, 1, 0, 4, 3, 0, 6, 3, 9, 2, 5, 4, 5, 6, 8, 6, 9, 2, 2, 2, 9, 6, 3, 0, 7, 3, 5, 2, 7, 2, 1, 8, 6, 6, 2, 2, 0, 6, 7, 6, 1, 6, 7, 1, 1, 2, 4, 2, 3, 4, 5, 0, 3, 2, 6, 0, 9, 0, 7, 2, 3, 5, 7, 6, 6, 5, 8, 6, 0, 2, 2, 9, 0, 7, 2, 9, 1, 3, 6, 3, 4, 2, 6, 6, 8, 9, 7, 0, 9, 5, 0, 6, 1, 4, 8, 2, 9, 7, 7, 2, 6, 3, 5, 6, 6, 8, 7, 3, 6, 6, 3, 6, 2, 3, 0, 3, 4, 2, 8, 6, 8, 1, 9, 2, 0, 4, 8, 3, 5, 1, 5, 1, 1, 9, 0, 9, 0, 2, 2, 4, 8, 2, 3, 9, 7, 1, 7, 6, 4, 5, 7, 6, 6, 6, 3, 9, 5, 9, 3, 0, 5, 6, 6, 0, 5, 3, 1, 9, 2, 4, 2, 2, 4, 2, 7, 8, 9, 6, 3, 0, 2, 4, 0, 1, 6, 4, 4, 4, 1, 3, 1, 1, 0, 7, 5, 6, 1, 7, 9, 0, 5, 8, 3, 5, 5, 6, 4, 4, 0, 7, 3, 8, 9, 2, 3, 3, 6, 4, 2, 3, 2, 3, 3, 4, 3, 4, 3, 7, 1, 7, 6, 7, 7, 1, 6, 3, 2, 7, 9, 3, 8, 1, 3, 3, 3, 1, 9, 2, 6, 1, 0, 5, 4, 4, 0, 5, 4, 4, 9, 5, 2, 4, 3, 5, 9, 4, 8, 4, 0, 6, 2, 8, 9, 1, 2, 0, 3, 6, 7, 0, 1, 2, 2, 6, 8, 0, 1, 0, 0, 6, 0, 5, 6, 6, 0, 0, 2, 0, 4, 6, 6, 7, 9, 2, 3, 8, 2, 7, 4, 8, 4, 9, 3, 1, 0, 3, 8, 3, 2, 7, 3, 1, 0, 2, 9, 3, 2, 6, 4, 3, 7, 1, 0, 1, 4, 3, 0, 2, 6, 3, 3, 6, 6, 9, 2, 0, 9, 1, 7, 3, 7, 0, 4, 3, 6, 3, 2, 9, 9, 4, 7, 5, 9, 7, 0, 1, 2, 5, 2, 5, 7, 3, 6, 4, 3, 2, 3, 1, 4, 2, 9, 4, 6, 6, 3, 1, 9, 4, 9, 5, 1, 7, 8, 8, 0, 0, 4, 9, 4, 7, 6, 0, 3, 3, 7, 2, 0, 8, 7, 5, 2, 9, 2, 4, 4, 4, 6, 6, 0, 3, 3, 8, 3, 3, 3, 3, 6, 3, 3, 2, 6, 0, 3, 3, 5, 2, 8, 6, 4, 7, 1, 4, 2, 3, 7, 5, 2, 4, 6, 3, 5, 2, 1, 1, 5, 9, 9, 0, 2, 7, 7, 1, 5, 0, 1, 6, 4, 9, 0, 5, 9, 7, 2, 8, 7, 4, 4, 3, 0, 2, 2, 5, 0, 8, 2, 6, 6, 5, 0, 7, 2, 9, 3, 5, 1, 7, 2, 5, 8, 5, 4, 3, 6, 3, 9, 2, 9, 7, 1, 0, 0, 2, 9, 3, 8, 8, 5, 3, 4, 2, 4, 2, 1, 4, 3, 7, 5, 6, 2, 4, 1, 4, 7, 3, 0, 2, 6, 4, 2, 4, 1, 4, 6, 3, 8, 6, 7, 6, 6, 6, 6, 5, 4, 5, 2, 7, 7, 3, 9, 1, 7, 3, 5, 2, 6, 4, 2, 2, 2, 7, 3, 0, 1, 9, 2, 0, 5, 3, 8, 9, 4, 3, 1, 7, 7, 6, 1, 4, 2, 1, 9, 8, 4, 2, 6, 0, 5, 6, 3, 5, 8, 2, 6, 3, 4, 3, 4, 7, 9, 8, 7, 3, 8, 7, 7, 3, 9, 3, 4, 5, 3, 8, 4, 7, 1, 5, 6, 8, 3, 4, 6, 6, 5, 9, 9, 2, 1, 3, 9, 2, 6, 4, 7, 1, 6, 4, 2, 4, 1, 2, 5, 7, 7, 3, 7, 7, 2, 7, 3, 9, 4, 7, 1, 7, 7, 2, 7, 6, 5, 5, 4, 8, 4, 5, 3, 4, 3, 0, 6, 3, 6, 1, 9, 7, 7, 2, 9, 5, 7, 2, 2, 0, 3, 3, 1, 6, 0, 9, 9, 6, 3, 7, 5, 0, 3, 2, 7, 6, 0, 4, 4, 5, 3, 6, 0, 1, 3, 6, 1, 4, 8, 5, 0, 8, 4, 4, 2, 9, 4, 4, 8, 5, 7, 5, 0, 7, 6, 2, 6, 1, 3, 4, 4, 6, 6, 4, 8, 3, 9, 2, 7, 7, 2, 4, 5, 1, 9, 0, 7, 1, 4, 8, 8, 4, 7, 3, 7, 6, 7, 5, 3, 7, 4, 3, 3, 9, 5, 2, 4, 4, 5, 0, 2, 3, 5, 4, 1, 6, 7, 5, 8, 3, 1, 6, 3, 0, 4, 7, 4, 2, 5, 3, 4, 9, 7, 2, 6, 6, 2, 4, 1, 3, 7, 5, 7, 3, 3, 7, 2, 9, 9, 8, 4, 5, 3, 1, 4, 5, 6, 2, 1, 6, 0, 3, 8, 2, 8, 9, 8, 5, 5, 6, 6, 6, 4, 0, 8, 6, 3, 4, 1, 8, 4, 3, 1, 3, 0, 3, 7, 1, 3, 3, 6, 2, 0, 5, 9, 5, 7, 9, 8, 9, 2, 5, 3, 1, 6, 5, 9, 5, 9, 1, 7, 6, 5, 5, 0, 1, 1, 4, 5, 6, 3, 4, 4, 9, 5, 9, 6, 7, 5, 9, 6, 1, 7, 5, 9, 5, 4, 4, 4, 2, 1, 3, 0, 2, 1, 6, 2, 9, 7, 4, 1, 8, 3, 9, 3, 2, 5, 8, 7, 5, 0, 2, 7, 5, 4, 8, 5, 1, 9, 6, 4, 0, 2, 4, 8, 2, 6, 7, 7, 1, 2, 8, 7, 5, 9, 8, 3, 2, 1, 1, 7, 5, 6, 2, 6, 3, 5, 8, 5, 1, 3, 3, 1, 6, 8, 0, 9, 7, 2, 7, 4, 7, 5, 4, 6, 4, 2, 3, 7, 0, 0, 6, 7, 2, 7, 4, 2, 3, 6, 0, 6, 6, 2, 9, 6, 1, 5, 8, 8, 8, 2, 7, 2, 6, 2, 3, 2, 2, 2, 5, 2, 8, 6, 3, 6, 5, 0, 0, 9, 5, 1, 6, 4, 4, 3, 0, 4, 3, 4, 1, 6, 3, 6, 3, 1, 4, 3, 3, 3, 0, 4, 7, 4, 2, 6, 9, 3, 3, 6, 9, 5, 3, 9, 3, 6, 3, 3, 9, 6, 2, 2, 2, 1, 6, 8, 2, 5, 3, 0, 5, 3, 2, 7, 2, 4, 2, 9, 2, 5, 4, 7, 3, 2, 2, 6, 7, 4, 5, 4, 9, 4, 7, 1, 6, 2, 1, 6, 7, 6, 4, 5, 3, 1, 1, 3, 3, 6, 7, 0, 8, 7, 0, 3, 7, 8, 2, 7, 5, 3, 9, 8, 7, 4, 3, 6, 6, 3, 4, 8, 9, 6, 3, 2, 2, 2, 9, 3, 6, 3, 8, 6, 3, 3, 8, 3, 7, 5, 3, 5, 5, 6, 9, 2, 6, 5, 1, 3, 4, 5, 9, 0, 5, 3, 7, 8, 2, 7, 2, 2, 4, 3, 7, 2, 6, 1, 3, 1, 2, 0, 4, 7, 7, 9, 1, 1, 2, 1, 8, 1, 8, 7, 5, 7, 3, 7, 9, 5, 7, 3, 1, 4, 2, 8, 2, 6, 6, 3, 3, 4, 4, 2, 0, 2, 0, 0, 8, 1, 1, 2, 5, 3, 4, 4, 0, 0, 8, 4, 4, 3, 6, 4, 6, 0, 5, 2, 7, 4, 8, 1, 0, 2, 5, 8, 2, 0, 8, 6, 2, 5, 8, 4, 2, 2, 3, 9, 0, 4, 9, 6, 1, 0, 1, 6, 6, 7, 3, 5, 8, 4, 9, 1, 3, 6, 6, 4, 4, 3, 7, 6, 3, 9, 5, 5, 6, 6, 8, 2, 6, 4, 2, 6, 1, 9, 7, 0, 2, 0, 4, 0, 5, 2, 3, 9, 4, 5, 6, 3, 7, 3, 7, 4, 4, 1, 4, 6, 2, 8, 5, 3, 7, 5, 8, 1, 5, 9, 9, 3, 7, 2, 4, 0, 2, 5, 1, 9, 3, 2, 9, 2, 7, 3, 6, 9, 7, 5, 6, 4, 4, 7, 2, 6, 8, 2, 7, 2, 3, 5, 3, 5, 2, 4, 6, 3, 4, 6, 0, 1, 6, 5, 2, 7, 4, 8, 1, 5, 2, 6, 9, 5, 2, 4, 6, 9, 6, 8, 1, 4, 3, 2, 3, 7, 5, 5, 4, 9, 4, 7, 6, 2, 5, 8, 6, 4, 4, 5, 4, 0, 7, 2, 1, 2, 3, 3, 4, 4, 7, 9, 7, 6, 1, 2, 9, 7, 8, 2, 9, 9, 4, 9, 0, 8, 0, 4, 2, 9, 6, 5, 2, 4, 1, 6, 9, 1, 8, 0, 8, 2, 8, 9, 4, 3, 4, 7, 0, 1, 6, 6, 1, 3, 7, 1, 9, 3, 0, 2, 4, 7, 5, 2, 2, 2, 6, 6, 8, 6, 2, 5, 3, 6, 6, 4, 4, 6, 2, 7, 9, 7, 3, 6, 5, 7, 4, 1, 2, 4, 2, 3, 7, 7, 7, 4, 3, 2, 9, 9, 2, 6, 6, 8, 9, 6, 1, 3, 9, 3, 1, 5, 6, 3, 2, 3, 2, 2, 9, 1, 4, 8, 2, 4, 0, 3, 2, 2, 2, 2, 0, 6, 6, 2, 5, 4, 2, 0, 4, 5, 9, 7, 1, 2, 5, 7, 6, 2, 2, 3, 0, 9, 2, 8, 3, 6, 7, 3, 1, 8, 4, 3, 7, 6, 5, 5, 2, 3, 6, 6, 9, 5, 6, 5, 1, 5, 2, 8, 6, 4, 4, 8, 7, 8, 7, 3, 2, 4, 5, 1, 5, 4, 2, 6, 3, 2, 1, 2, 7, 6, 4, 1, 9, 1, 3, 6, 3, 8, 5, 0, 2, 3, 2, 5, 0, 7, 4, 4, 8, 3, 8, 1, 7, 0, 2, 3, 5, 7, 5, 5, 4, 6, 7, 2, 2, 9, 8, 6, 0, 5, 8, 9, 4, 1, 7, 2, 5, 4, 8, 0, 3, 4, 8, 9, 5, 2, 4, 4, 2, 2, 4, 9, 4, 6, 3, 6, 8, 4, 3, 0, 3, 5, 1, 7, 0, 6, 8, 9, 4, 0, 9, 6, 9, 4, 8, 8, 2, 4, 0, 2, 7, 6, 3, 9, 3, 1, 4, 3, 0, 4, 4, 9, 7, 6, 4, 3, 2, 1, 3, 5, 3, 9, 6, 1, 1, 8, 5, 5, 3, 6, 2, 9, 3, 7, 9, 6, 2, 3, 6, 2, 6, 2, 4, 0, 6, 7, 5, 2, 4, 5, 6, 2, 4, 3, 3, 7, 4, 4, 7, 3, 5, 2, 7, 8, 7, 2, 1, 3, 2, 0, 2, 2, 9, 2, 3, 0, 6, 6, 2, 7, 3, 5, 6, 6, 9, 4, 0, 4, 3, 3, 6, 2, 1, 6, 5, 6, 0, 0, 6, 7, 6, 2, 6, 1, 2, 6, 7, 7, 4, 1, 8, 6, 9, 5, 1, 4, 8, 5, 9, 7, 0, 1, 9, 1, 3, 2, 2, 2, 1, 5, 2, 1, 7, 4, 7, 6, 5, 9, 0, 9, 3, 6, 4, 2, 7, 4, 3, 2, 6, 4, 4, 3, 2, 5, 3, 6, 5, 1, 0, 4, 3, 2, 7, 4, 1, 8, 6, 5, 1, 7, 6, 1, 2, 4, 8, 5, 1, 5, 5, 3, 2, 1, 9, 6, 2, 4, 3, 8, 1, 9, 0, 3, 3, 9, 5, 2, 7, 2, 0, 6, 1, 3, 2, 7, 9, 1, 2, 3, 9, 4, 9, 4, 3, 2, 2, 1, 9, 8, 8, 1, 5, 1, 9, 0, 6, 3, 2, 6, 6, 7, 2, 6, 4, 0, 0, 5, 2, 5, 5, 6, 3, 8, 1, 7, 5, 7, 4, 2, 7, 7, 6, 0, 5, 6, 2, 8, 2, 8, 8, 1, 4, 6, 5, 7, 2, 3, 2, 8, 8, 9, 7, 2, 3, 6, 4, 9, 5, 9, 3, 0, 2, 2, 8, 3, 7, 4, 6, 7, 2, 2, 1, 1, 2, 6, 0, 9, 9, 3, 5, 9, 2, 0, 3, 6, 9, 0, 5, 2, 6, 5, 4, 8, 2, 6, 2, 0, 3, 3, 0, 5, 2, 7, 3, 0, 7, 7, 0, 5, 6, 4, 5, 9, 3, 3, 8, 8, 6, 1, 8, 2, 1, 5, 9, 5, 8, 4, 1, 4, 9, 0, 6, 6, 0, 4, 6, 9, 7, 7, 6, 1, 3, 4, 5, 7, 6, 7, 0, 4, 7, 9, 2, 3, 4, 2, 4, 3, 7, 7, 3, 6, 5, 7, 9, 1, 8, 8, 7, 5, 4, 6, 7, 4, 5, 3, 1, 5, 7, 3, 6, 0, 5, 6, 7, 7, 5, 1, 0, 8, 7, 4, 3, 7, 1, 9, 1, 9, 6, 7, 7, 9, 1, 5, 0, 5, 1, 3, 0, 3, 8, 4, 3, 3, 7, 5, 5, 9, 3, 3, 7, 4, 4, 6, 4, 3, 4, 7, 3, 9, 6, 5, 4, 5, 4, 9, 5, 4, 7, 9, 6, 0, 6, 1, 9, 8, 7, 4, 7, 0, 3, 1, 7, 3, 5, 9, 9, 6, 1, 1, 5, 6, 6, 5, 5, 4, 4, 7, 0, 9, 0, 3, 1, 8, 6, 8, 7, 9, 6, 4, 3, 9, 7, 6, 4, 9, 6, 5, 5, 7, 4, 6, 8, 6, 5, 7, 1, 7, 1, 7, 5, 7, 7, 8, 1, 4, 1, 5, 5, 9, 6, 3, 1, 4, 7, 1, 5, 8, 3, 5, 7, 6, 1, 0, 9, 5, 1, 6, 8, 4, 7, 9, 8, 0, 6, 6, 8, 9, 6, 5, 0, 4, 8, 9, 7, 7, 7, 0, 7, 8, 4, 7, 6, 1, 0, 5, 0, 5, 5, 4, 1, 7, 0, 4, 8, 8, 5, 5, 3, 0, 9, 4, 1, 0, 3, 3, 0, 1, 1, 1, 6, 1, 3, 8, 9, 1, 4, 7, 7, 6, 5, 4, 5, 9, 6, 4, 9, 7, 4, 5, 6, 8, 5, 0, 1, 4, 3, 8, 5, 3, 9, 0, 1, 1, 3, 5, 6, 8, 5, 6, 5, 9, 0, 3, 5, 5, 7, 0, 9, 5, 8, 6, 5, 3, 9, 1, 3, 7, 6, 5, 7, 6, 0, 3, 5, 8, 1, 6, 5, 5, 6, 6, 8, 1, 5, 0, 3, 7, 3, 6, 0, 0, 0, 6, 1, 7, 5, 7, 1, 9, 1, 3, 3, 7, 0, 7, 6, 8, 6, 9, 9, 3, 6, 6, 6, 5, 3, 8, 1, 3, 1, 1, 6, 9, 8, 6, 6, 3, 8, 0, 3, 3, 6, 7, 1, 0, 5, 9, 6, 5, 5, 9, 1, 6, 6, 3, 9, 3, 6, 9, 0, 6, 9, 1, 7, 3, 0, 5, 5, 7, 5, 1, 8, 7, 7, 0, 9, 0, 0, 0, 3, 9, 1, 7, 5, 0, 3, 5, 3, 7, 5, 3, 3, 3, 1, 0, 1, 0, 3, 5, 9, 8, 1, 3, 3, 5, 0, 7, 3, 7, 5, 5, 0, 7, 5, 9, 0, 9, 3, 1, 8, 3, 7, 7, 1, 3, 7, 0, 5, 9, 3, 7, 7, 3, 5, 0, 7, 9, 8, 0, 9, 3, 1, 3, 8, 7, 1, 9, 5, 7, 8, 0, 3, 9, 5, 9, 1, 1, 8, 7, 3, 8, 3, 5, 3, 3, 5, 0, 9, 5, 3, 8, 5, 1, 9, 7, 1, 5, 5, 8, 0, 9, 9, 0, 7, 8, 8, 7, 9, 7, 0, 5, 9, 1, 7, 1, 0, 0, 0, 9, 1, 8, 8, 8, 9, 1, 0, 0, 5, 0, 0, 7, 7, 7, 7, 7, 1, 1, 5, 1, 7, 8, 5, 1, 8, 7, 5, 9, 1, 9, 9, 7, 9, 7, 5, 9, 1, 5, 9, 9, 9, 5, 5, 7, 1, 5, 7, 8, 9, 1, 5, 0, 1, 9, 9, 7, 9, 5, 0, 5, 1, 9, 9, 7, 0, 8, 8, 5, 9, 1, 9, 5, 5, 8, 0, 9, 8, 1, 9, 9, 9, 9, 7, 0, 5, 0, 5, 5, 1, 5, 1, 1, 9, 7, 5, 1, 9, 5, 8, 5, 9, 9, 1, 7, 9, 9, 1, 5, 5, 8, 8, 9, 9, 5, 0, 9, 1, 0, 1, 7, 5, 9, 7, 9, 0, 5, 7, 5, 7, 1, 1, 8, 7, 7, 5, 1, 5, 9, 5, 7, 5, 9, 1, 5, 8, 7, 0, 0, 5, 7, 5, 8, 9, 0, 9, 9, 1, 7, 9, 1, 5, 5, 1, 5, 7, 5, 8, 9, 0, 0, 7, 8, 1, 1, 9, 1, 8, 1, 5, 1, 9, 5, 5, 5, 5, 5, 5, 0, 8, 5, 9, 1, 8, 9, 0, 0, 1, 5, 0, 1, 7, 8, 1, 5, 9, 8, 8, 7, 0, 5, 1, 0, 5, 7, 9, 8, 1, 8, 1, 8, 7, 9, 1, 9, 5, 1, 0, 9, 0, 9, 5, 0, 0, 5, 9, 7, 0, 0, 5, 5, 1, 7, 1, 8, 0, 9, 8, 8, 5, 5, 9, 5, 5, 9, 1, 5, 7, 1, 7, 9, 9, 1, 1, 1, 0, 7, 1, 5, 1, 0, 5, 5, 0, 8, 0, 8, 7, 0, 7, 1, 5, 7, 1, 5, 5, 0, 5, 0, 5, 7, 5, 5, 1, 7, 7, 7, 0, 7, 8, 9, 5, 5, 0, 7, 7, 9, 9, 9, 8, 1, 0, 7, 1, 5, 7, 5, 5, 7, 1, 7, 9, 1, 5, 5, 7, 5, 5, 5, 5, 1, 1, 9, 8, 9, 7, 7, 0, 9, 1, 7, 9, 5, 7, 0, 8, 0, 1, 7, 8, 7, 9, 7, 0, 1, 7, 7, 9, 9, 0, 9, 9, 0, 7, 9, 9, 9, 7, 1, 1, 1, 9, 9, 7, 7, 1, 0, 7, 7, 7, 0, 9, 0, 9, 9, 1, 8, 8, 9, 1, 0, 9, 9, 1, 1, 8, 1, 8, 8, 8, 1, 9, 8, 9, 1, 9, 9, 9, 8, 0, 9, 1, 9, 9, 0, 0, 8, 1, 8, 1, 1, 8, 9, 9, 8, 0, 1, 1, 1, 1, 1, 9, 9, 1, 1, 1, 1, 9, 0, 1, 9, 1, 8, 0, 9, 0, 0, 1, 8, 9, 1, 8, 0, 9, 8, 0, 8, 1, 1, 1, 1, 0, 9, 9, 9, 1, 1, 0, 8, 9, 0, 1, 8, 1, 8, 9, 9, 1, 8, 8, 8, 0, 9, 1, 9, 9, 9, 1, 0, 8, 1, 0, 0, 0, 0, 9, 9, 1, 0, 1, 1, 8, 9, 9, 9, 0, 0, 1, 0, 0, 9, 1, 1, 1, 1, 9, 9, 8, 8, 1, 0, 1, 1, 9, 0, 8, 1, 9, 9, 0, 0, 0, 1, 1, 9, 1, 0, 0, 9, 8, 1, 1, 9, 1, 0, 8, 8, 1, 9, 1, 8, 8, 1, 0, 9, 0, 8, 1, 1, 9, 0, 9, 8, 8, 0, 8, 0, 9, 9, 1, 8, 8, 1, 8, 9, 1, 8, 0, 1, 1, 0, 0, 0, 8, 9, 0, 1, 8, 1, 0, 0, 0, 0, 9, 8, 9, 0, 0, 8, 8, 9, 8, 8, 9, 0, 9, 8, 9, 9, 9, 0, 9, 8, 9, 9, 9, 8, 0, 8, 0, 0, 9, 8, 9, 0, 8, 9, 9, 0, 9, 0, 9, 8, 0, 8, 0, 0, 8, 9, 9, 8, 8, 0, 9, 9, 0, 9, 0, 0, 0, 9, 9, 9, 9, 8, 8, 8, 0, 0, 8, 0, 8, 0, 0, 0, 0, 8, 8, 0, 8, 8, 0, 0, 0, 8, 8, 8, 8, 8, 8, 8, 0, 8, 0, 8, 0, 0, 8, 0, 0, 0, 0, 8, 8, 0, 8, 0, 8, 0, 0, 0, 8, 0, 8, 8, 0, 0, 8, 8, 0, 8, 8, 0, 0, 8, 8, 0, 0, 8, 0, 0, 8, 0, 8, 0, 0, 0, 8, 8, 0, 8, 0, 0, 8, 8, 8, 0, 8, 0, 0, 0, 0, 0, 0, 8, 8, 0, 0, 0, 0, 8, 8, 8, 8, 0, 8, 8, 0, 8, 0, 0, 8, 8, 0, 8, 0, 8, 8, 0, 0, 8, 8, 0, 8, 8, 0, 8, 0, 0, 8, 0, 0, 8, 0, 0, 0, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
            "Counter({9: 500, 6: 500, 4: 500, 3: 500, 2: 500, 0: 500, 7: 500, 5: 500, 1: 500, 8: 500})\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.6902\u001b[0m  13.4093\n",
            "      2        \u001b[36m2.3078\u001b[0m  13.3295\n",
            "      3        \u001b[36m2.3077\u001b[0m  13.3267\n",
            "      4        2.3084  13.3387\n",
            "      5        2.3091  13.3432\n",
            "      6        2.3097  13.7935\n",
            "      7        2.3102  13.6972\n",
            "      8        2.3106  14.3134\n",
            "      9        2.3109  13.2791\n",
            "     10        2.3111  13.2927\n",
            "0.1\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]]\n",
            "Accuracy:  0.1\n",
            "Macro F1-score:  0.01818181818181818\n",
            "Micro F1-score:  0.10000000000000002\n",
            "Weighted F1-score:  0.01818181818181818\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "---Query no:  1 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4865\u001b[0m  13.5354\n",
            "      2        \u001b[36m2.3046\u001b[0m  13.4558\n",
            "      3        \u001b[36m2.3035\u001b[0m  13.4364\n",
            "      4        \u001b[36m2.3034\u001b[0m  13.5329\n",
            "      5        2.3038  13.6154\n",
            "      6        2.3036  14.0291\n",
            "      7        2.3034  13.3693\n",
            "      8        \u001b[36m2.3032\u001b[0m  13.4273\n",
            "      9        2.3034  13.4284\n",
            "     10        2.3033  13.5224\n",
            "0.1\n",
            "---Query no:  2 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4959\u001b[0m  13.5252\n",
            "      2        \u001b[36m2.3035\u001b[0m  13.4592\n",
            "      3        \u001b[36m2.3034\u001b[0m  13.4744\n",
            "      4        2.3034  13.5009\n",
            "      5        2.3034  13.4905\n",
            "      6        \u001b[36m2.3033\u001b[0m  13.5053\n",
            "      7        2.3033  13.4428\n",
            "      8        \u001b[36m2.3033\u001b[0m  14.2035\n",
            "      9        \u001b[36m2.3032\u001b[0m  13.5462\n",
            "     10        \u001b[36m2.3032\u001b[0m  13.4390\n",
            "0.1\n",
            "---Query no:  3 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4984\u001b[0m  14.2530\n",
            "      2        \u001b[36m2.3031\u001b[0m  14.5695\n",
            "      3        2.3033  13.6930\n",
            "      4        2.3031  13.6124\n",
            "      5        2.3032  13.5997\n",
            "      6        2.3032  13.5812\n",
            "      7        2.3032  13.5887\n",
            "      8        2.3032  13.5971\n",
            "      9        2.3032  13.8883\n",
            "     10        2.3032  14.1086\n",
            "0.1\n",
            "---Query no:  4 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3653\u001b[0m  13.6758\n",
            "      2        \u001b[36m2.1028\u001b[0m  14.2530\n",
            "      3        \u001b[36m1.9151\u001b[0m  14.0438\n",
            "      4        \u001b[36m1.8220\u001b[0m  13.7478\n",
            "      5        \u001b[36m1.7250\u001b[0m  13.7457\n",
            "      6        \u001b[36m1.6988\u001b[0m  13.7908\n",
            "      7        \u001b[36m1.6564\u001b[0m  13.7169\n",
            "      8        \u001b[36m1.6248\u001b[0m  13.7827\n",
            "      9        \u001b[36m1.5449\u001b[0m  13.6765\n",
            "     10        \u001b[36m1.5334\u001b[0m  14.4307\n",
            "0.3778\n",
            "---Query no:  5 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4446\u001b[0m  13.8260\n",
            "      2        \u001b[36m2.3033\u001b[0m  14.0039\n",
            "      3        \u001b[36m2.3032\u001b[0m  14.2680\n",
            "      4        2.3035  13.7148\n",
            "      5        2.3033  13.6755\n",
            "      6        2.3032  13.7627\n",
            "      7        2.3032  13.6851\n",
            "      8        2.3032  13.7392\n",
            "      9        2.3032  13.7296\n",
            "     10        2.3032  15.5174\n",
            "0.1\n",
            "---Query no:  6 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5444\u001b[0m  13.8292\n",
            "      2        \u001b[36m2.3031\u001b[0m  14.2318\n",
            "      3        2.3031  14.3014\n",
            "      4        2.3032  13.9670\n",
            "      5        \u001b[36m2.3030\u001b[0m  14.0388\n",
            "      6        2.3031  13.8622\n",
            "      7        2.3032  13.8780\n",
            "      8        2.3032  13.8147\n",
            "      9        \u001b[36m2.3029\u001b[0m  14.3726\n",
            "     10        2.3035  14.1358\n",
            "0.1\n",
            "---Query no:  7 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.6378\u001b[0m  14.2149\n",
            "      2        \u001b[36m2.3033\u001b[0m  14.5139\n",
            "      3        \u001b[36m2.3030\u001b[0m  14.0172\n",
            "      4        2.3034  13.8868\n",
            "      5        2.3032  13.9137\n",
            "      6        2.3032  13.8502\n",
            "      7        2.3031  13.8801\n",
            "      8        2.3031  14.1016\n",
            "      9        2.3031  14.5315\n",
            "     10        2.3031  13.8387\n",
            "0.1\n",
            "---Query no:  8 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3001\u001b[0m  14.7605\n",
            "      2        \u001b[36m2.0164\u001b[0m  13.9780\n",
            "      3        \u001b[36m1.8771\u001b[0m  13.8888\n",
            "      4        \u001b[36m1.8021\u001b[0m  13.9562\n",
            "      5        \u001b[36m1.7221\u001b[0m  14.9008\n",
            "      6        \u001b[36m1.6723\u001b[0m  13.9040\n",
            "      7        \u001b[36m1.5967\u001b[0m  13.9529\n",
            "      8        \u001b[36m1.5368\u001b[0m  14.5597\n",
            "      9        \u001b[36m1.5166\u001b[0m  14.1316\n",
            "     10        \u001b[36m1.4364\u001b[0m  13.8895\n",
            "0.423\n",
            "---Query no:  9 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4468\u001b[0m  14.5222\n",
            "      2        \u001b[36m1.9719\u001b[0m  14.0882\n",
            "      3        \u001b[36m1.8039\u001b[0m  14.0320\n",
            "      4        1.8046  14.0353\n",
            "      5        \u001b[36m1.7134\u001b[0m  13.9988\n",
            "      6        \u001b[36m1.6679\u001b[0m  14.1868\n",
            "      7        \u001b[36m1.6059\u001b[0m  14.7893\n",
            "      8        \u001b[36m1.5407\u001b[0m  14.0935\n",
            "      9        \u001b[36m1.5358\u001b[0m  14.0400\n",
            "     10        \u001b[36m1.4859\u001b[0m  14.0312\n",
            "0.4312\n",
            "---Query no:  10 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4821\u001b[0m  14.1582\n",
            "      2        \u001b[36m2.3033\u001b[0m  14.1171\n",
            "      3        2.3034  14.1207\n",
            "      4        \u001b[36m2.3033\u001b[0m  14.1221\n",
            "      5        \u001b[36m2.3032\u001b[0m  14.9433\n",
            "      6        \u001b[36m2.3031\u001b[0m  14.1338\n",
            "      7        2.3031  14.1248\n",
            "      8        2.3031  14.1470\n",
            "      9        2.3031  14.1456\n",
            "     10        2.3031  14.1513\n",
            "0.1\n",
            "---Query no:  11 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.7521\u001b[0m  14.3462\n",
            "      2        \u001b[36m2.1998\u001b[0m  14.3914\n",
            "      3        \u001b[36m2.1086\u001b[0m  14.9279\n",
            "      4        \u001b[36m2.0390\u001b[0m  14.2008\n",
            "      5        \u001b[36m2.0126\u001b[0m  14.2730\n",
            "      6        \u001b[36m1.9148\u001b[0m  14.2856\n",
            "      7        \u001b[36m1.8390\u001b[0m  14.3381\n",
            "      8        1.8555  14.7688\n",
            "      9        \u001b[36m1.7693\u001b[0m  14.5962\n",
            "     10        \u001b[36m1.7573\u001b[0m  14.3051\n",
            "0.37\n",
            "---Query no:  12 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5688\u001b[0m  14.8174\n",
            "      2        \u001b[36m2.3030\u001b[0m  14.3697\n",
            "      3        2.3033  14.3914\n",
            "      4        2.3034  14.3918\n",
            "      5        2.3032  14.4395\n",
            "      6        2.3033  15.1966\n",
            "      7        2.3032  14.3444\n",
            "      8        2.3032  14.3802\n",
            "      9        2.3031  14.3745\n",
            "     10        2.3031  14.4124\n",
            "0.1\n",
            "---Query no:  13 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4589\u001b[0m  14.5689\n",
            "      2        \u001b[36m2.3054\u001b[0m  14.4855\n",
            "      4        \u001b[36m2.3033\u001b[0m  14.4562\n",
            "      5        \u001b[36m2.3033\u001b[0m  14.5133\n",
            "      6        2.3035  14.4569\n",
            "      7        2.3034  15.4759\n",
            "      8        \u001b[36m2.3032\u001b[0m  15.0736\n",
            "      9        2.3033  14.3309\n",
            "     10        2.3032  14.3837\n",
            "0.1\n",
            "---Query no:  14 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5743\u001b[0m  14.5564\n",
            "      2        \u001b[36m2.1304\u001b[0m  14.4766\n",
            "      3        \u001b[36m1.9652\u001b[0m  14.6957\n",
            "      4        \u001b[36m1.8431\u001b[0m  14.6285\n",
            "      5        \u001b[36m1.8358\u001b[0m  15.2939\n",
            "      6        \u001b[36m1.7645\u001b[0m  14.4336\n",
            "      7        \u001b[36m1.6976\u001b[0m  14.4611\n",
            "      8        \u001b[36m1.6772\u001b[0m  14.5334\n",
            "      9        \u001b[36m1.6131\u001b[0m  14.5421\n",
            "     10        \u001b[36m1.5788\u001b[0m  15.3138\n",
            "0.4278\n",
            "---Query no:  15 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4992\u001b[0m  14.8731\n",
            "      2        \u001b[36m2.2240\u001b[0m  14.9147\n",
            "      3        \u001b[36m2.1360\u001b[0m  14.4605\n",
            "      4        \u001b[36m2.0657\u001b[0m  14.4996\n",
            "      5        \u001b[36m2.0294\u001b[0m  14.5308\n",
            "      6        \u001b[36m2.0135\u001b[0m  14.7110\n",
            "      7        \u001b[36m1.9875\u001b[0m  15.0783\n",
            "      8        \u001b[36m1.9707\u001b[0m  14.4575\n",
            "      9        \u001b[36m1.9607\u001b[0m  14.4881\n",
            "     10        \u001b[36m1.9542\u001b[0m  14.5990\n",
            "0.305\n",
            "---Query no:  16 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3958\u001b[0m  14.6526\n",
            "      2        \u001b[36m2.1985\u001b[0m  15.5523\n",
            "      3        \u001b[36m2.1068\u001b[0m  15.4832\n",
            "      4        2.1198  14.5977\n",
            "      5        \u001b[36m2.0732\u001b[0m  14.5591\n",
            "      6        \u001b[36m2.0037\u001b[0m  14.6312\n",
            "      7        \u001b[36m2.0002\u001b[0m  14.6669\n",
            "      8        \u001b[36m1.9667\u001b[0m  15.4383\n",
            "      9        \u001b[36m1.9635\u001b[0m  14.5661\n",
            "     10        \u001b[36m1.9580\u001b[0m  14.6536\n",
            "0.3146\n",
            "---Query no:  17 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.7301\u001b[0m  14.7212\n",
            "      2        \u001b[36m2.2768\u001b[0m  14.6880\n",
            "      3        \u001b[36m2.1728\u001b[0m  14.7766\n",
            "      4        \u001b[36m2.0962\u001b[0m  15.4524\n",
            "      5        \u001b[36m2.0864\u001b[0m  15.1887\n",
            "      6        \u001b[36m2.0657\u001b[0m  14.9745\n",
            "      7        \u001b[36m1.9742\u001b[0m  14.9994\n",
            "      8        \u001b[36m1.9093\u001b[0m  14.7881\n",
            "      9        1.9201  15.3269\n",
            "     10        \u001b[36m1.8613\u001b[0m  14.6872\n",
            "0.3564\n",
            "---Query no:  18 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3915\u001b[0m  15.1562\n",
            "      2        \u001b[36m2.0677\u001b[0m  14.7705\n",
            "      3        \u001b[36m1.9560\u001b[0m  14.8120\n",
            "      4        \u001b[36m1.8880\u001b[0m  14.7602\n",
            "      5        \u001b[36m1.7913\u001b[0m  15.5704\n",
            "      6        \u001b[36m1.6784\u001b[0m  14.7897\n",
            "      7        \u001b[36m1.6141\u001b[0m  14.7815\n",
            "      8        \u001b[36m1.5818\u001b[0m  14.8135\n",
            "      9        \u001b[36m1.5501\u001b[0m  16.4643\n",
            "     10        \u001b[36m1.5230\u001b[0m  14.8936\n",
            "0.4304\n",
            "---Query no:  19 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5318\u001b[0m  15.6173\n",
            "      2        \u001b[36m2.1511\u001b[0m  14.8567\n",
            "      3        \u001b[36m2.0123\u001b[0m  14.8858\n",
            "      4        \u001b[36m1.9181\u001b[0m  14.8555\n",
            "      5        \u001b[36m1.8637\u001b[0m  15.6806\n",
            "      6        \u001b[36m1.7738\u001b[0m  14.8427\n",
            "      7        \u001b[36m1.6986\u001b[0m  14.8441\n",
            "      8        \u001b[36m1.6630\u001b[0m  14.8450\n",
            "      9        \u001b[36m1.6129\u001b[0m  15.3620\n",
            "     10        \u001b[36m1.6091\u001b[0m  15.1416\n",
            "0.4204\n",
            "---Query no:  20 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.6208\u001b[0m  15.7561\n",
            "      2        \u001b[36m2.1131\u001b[0m  14.9394\n",
            "      3        \u001b[36m1.9346\u001b[0m  14.9124\n",
            "      4        \u001b[36m1.8573\u001b[0m  14.8577\n",
            "      5        \u001b[36m1.8215\u001b[0m  15.6083\n",
            "      6        \u001b[36m1.7687\u001b[0m  15.1476\n",
            "      7        \u001b[36m1.7533\u001b[0m  14.8621\n",
            "      8        \u001b[36m1.7179\u001b[0m  14.9028\n",
            "      9        \u001b[36m1.6889\u001b[0m  15.1144\n",
            "     10        \u001b[36m1.6785\u001b[0m  15.5171\n",
            "0.3372\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[103  13  38  12  49   6  44  26 152  57]\n",
            " [  1 137   5   7   8   8  83  35  28 188]\n",
            " [  6   1  44  22 177  27 157  40  12  14]\n",
            " [  0   3  13  85  95  38 231  16   3  16]\n",
            " [  5   0  13  20 215  12 180  30  10  15]\n",
            " [  1   2  19  97 116  55 170  27   2  11]\n",
            " [  0   1   8  22  90   3 362   9   1   4]\n",
            " [  2   1  15  14  90  15 137 194   3  29]\n",
            " [ 31  22  11  23  33  17  41  17 214  91]\n",
            " [  5  29   8  14  10  12  98  16  31 277]]\n",
            "Accuracy:  0.3372\n",
            "Macro F1-score:  0.3206418782786121\n",
            "Micro F1-score:  0.3372\n",
            "Weighted F1-score:  0.3206418782786121\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "AL_Retrain(5000, 20,  30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzLvra96iNrO",
        "outputId": "49494ae8-f849-4223-9f3f-51f279c8a1df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3057\u001b[0m  26.8425\n",
            "      2        \u001b[36m1.8534\u001b[0m  26.8089\n",
            "      3        \u001b[36m1.7350\u001b[0m  27.6792\n",
            "      4        \u001b[36m1.6930\u001b[0m  27.4294\n",
            "      5        \u001b[36m1.6416\u001b[0m  27.2543\n",
            "      6        \u001b[36m1.6131\u001b[0m  26.8727\n",
            "      7        \u001b[36m1.5726\u001b[0m  26.8667\n",
            "      8        \u001b[36m1.5449\u001b[0m  26.8242\n",
            "      9        \u001b[36m1.5095\u001b[0m  28.4753\n",
            "     10        1.5105  29.0073\n",
            "No of initial data:  10000\n",
            "0.4558\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[280  23  18   9   5   7   4   8 115  31]\n",
            " [ 22 295   1  15   1   3   7   4  53  99]\n",
            " [ 56  12  98  46  79  78  45  36  30  20]\n",
            " [ 16  11  31 120  34 144  38  48  24  34]\n",
            " [ 38   1  50  43 151  66  38  71  22  20]\n",
            " [ 10  18  30  85  32 221  18  50  11  25]\n",
            " [  5  18  24  63  58  25 220  44   9  34]\n",
            " [ 23  13  11  29  16  56  12 275   9  56]\n",
            " [103  35   5   5   0   6   1   2 315  28]\n",
            " [ 20  79   4   7   0  10   8  10  58 304]]\n",
            "Accuracy:  0.4558\n",
            "Macro F1-score:  0.4460572649230509\n",
            "Micro F1-score:  0.4558\n",
            "Weighted F1-score:  0.44605726492305087\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[8, 4, 4, 5, 6, 5, 7, 7, 7, 1, 7, 3, 1, 0, 2, 5, 5, 3, 4, 6, 4, 6, 4, 3, 5, 0, 6, 7, 3, 3, 0, 4, 7, 2, 2, 2, 6, 7, 3, 3, 5, 4, 5, 4, 4, 1, 5, 6, 6, 2, 3, 7, 7, 0, 7, 5, 5, 6, 3, 4, 6, 3, 6, 4, 4, 6, 2, 6, 8, 9, 5, 1, 3, 5, 3, 0, 3, 5, 6, 5, 4, 0, 3, 2, 4, 2, 9, 4, 0, 4, 0, 2, 3, 6, 7, 4, 5, 2, 4, 2, 6, 3, 7, 0, 2, 2, 9, 5, 4, 7, 2, 3, 2, 2, 4, 6, 7, 6, 2, 7, 7, 3, 4, 6, 3, 2, 4, 6, 2, 2, 7, 3, 2, 0, 4, 4, 6, 2, 3, 5, 3, 1, 3, 3, 6, 2, 3, 9, 4, 3, 5, 3, 6, 2, 5, 6, 2, 5, 3, 3, 3, 4, 2, 4, 9, 7, 7, 3, 5, 2, 6, 9, 4, 8, 3, 6, 6, 3, 4, 5, 4, 5, 1, 5, 0, 2, 2, 3, 4, 4, 2, 7, 6, 5, 2, 4, 1, 2, 6, 8, 7, 3, 5, 7, 6, 5, 7, 7, 3, 2, 7, 3, 4, 2, 3, 2, 2, 8, 9, 6, 3, 4, 6, 7, 4, 4, 9, 7, 4, 2, 4, 5, 9, 4, 3, 3, 0, 2, 4, 3, 3, 3, 5, 2, 6, 6, 6, 4, 3, 2, 7, 5, 3, 4, 5, 3, 6, 6, 0, 2, 7, 3, 5, 5, 7, 4, 8, 7, 5, 2, 3, 7, 4, 3, 4, 9, 6, 5, 9, 4, 6, 9, 4, 3, 6, 3, 6, 2, 7, 4, 0, 3, 0, 9, 9, 6, 7, 7, 3, 5, 4, 5, 3, 7, 2, 3, 6, 4, 3, 3, 5, 2, 3, 2, 2, 7, 4, 1, 2, 3, 4, 7, 4, 5, 8, 2, 4, 5, 7, 2, 2, 3, 5, 5, 0, 2, 2, 5, 6, 4, 2, 7, 6, 4, 2, 6, 6, 2, 6, 4, 7, 6, 1, 2, 5, 4, 2, 3, 2, 8, 5, 3, 9, 5, 0, 4, 7, 4, 2, 2, 8, 5, 5, 6, 2, 4, 8, 7, 6, 5, 6, 1, 6, 0, 2, 4, 4, 8, 5, 6, 8, 6, 4, 6, 4, 2, 8, 4, 5, 3, 5, 9, 6, 3, 3, 6, 7, 6, 6, 6, 5, 4, 3, 6, 7, 9, 5, 2, 1, 2, 4, 6, 9, 6, 4, 2, 4, 7, 6, 5, 7, 3, 4, 4, 2, 6, 7, 2, 2, 2, 7, 4, 2, 7, 2, 2, 0, 5, 6, 4, 6, 3, 1, 1, 6, 9, 5, 7, 7, 2, 6, 6, 2, 7, 7, 4, 1, 6, 3, 4, 5, 8, 1, 6, 5, 6, 7, 9, 3, 5, 6, 3, 0, 1, 6, 5, 0, 7, 2, 9, 6, 6, 2, 9, 3, 4, 6, 4, 6, 3, 6, 3, 5, 6, 6, 6, 5, 5, 3, 2, 6, 5, 0, 6, 7, 4, 2, 4, 8, 6, 5, 8, 7, 6, 4, 9, 7, 5, 6, 1, 5, 8, 6, 6, 7, 5, 3, 7, 7, 9, 3, 5, 6, 3, 5, 7, 2, 5, 7, 7, 7, 3, 6, 0, 5, 5, 3, 3, 6, 2, 3, 6, 8, 6, 6, 9, 7, 5, 4, 8, 3, 2, 4, 5, 6, 4, 3, 4, 8, 2, 6, 3, 7, 5, 0, 2, 2, 6, 7, 5, 2, 3, 6, 3, 5, 5, 3, 5, 6, 2, 4, 6, 5, 1, 4, 3, 7, 8, 5, 9, 7, 3, 3, 6, 3, 3, 4, 5, 6, 5, 6, 5, 3, 3, 7, 6, 5, 1, 3, 3, 3, 3, 2, 1, 1, 6, 2, 3, 5, 1, 0, 5, 6, 5, 9, 6, 7, 5, 9, 2, 2, 7, 4, 6, 5, 4, 1, 5, 8, 1, 6, 3, 6, 3, 2, 2, 4, 7, 4, 4, 5, 3, 6, 2, 8, 7, 6, 3, 2, 3, 9, 5, 6, 2, 4, 5, 4, 3, 3, 7, 0, 6, 3, 5, 5, 3, 2, 2, 5, 5, 3, 5, 2, 7, 3, 2, 7, 6, 2, 6, 3, 2, 1, 3, 5, 5, 6, 4, 7, 3, 5, 4, 9, 3, 5, 4, 3, 1, 4, 5, 3, 7, 3, 4, 0, 9, 5, 4, 5, 6, 4, 4, 5, 7, 4, 3, 5, 7, 6, 5, 6, 2, 3, 9, 9, 5, 1, 2, 3, 9, 0, 1, 7, 7, 8, 2, 1, 5, 7, 5, 8, 3, 5, 7, 7, 0, 8, 6, 3, 6, 7, 2, 2, 2, 4, 7, 3, 8, 4, 2, 6, 6, 3, 5, 5, 7, 1, 3, 2, 4, 6, 2, 3, 2, 2, 5, 6, 3, 1, 5, 3, 1, 7, 3, 6, 7, 5, 5, 3, 8, 1, 1, 3, 9, 7, 2, 4, 5, 2, 2, 3, 3, 7, 7, 6, 5, 2, 0, 1, 1, 5, 2, 2, 6, 3, 6, 3, 6, 2, 2, 2, 5, 2, 7, 4, 7, 0, 5, 2, 5, 5, 5, 7, 6, 7, 3, 3, 2, 5, 6, 4, 3, 4, 5, 8, 5, 4, 4, 6, 4, 7, 5, 2, 5, 6, 8, 6, 2, 2, 2, 6, 7, 2, 1, 5, 6, 3, 5, 8, 2, 6, 7, 6, 3, 5, 5, 6, 4, 5, 5, 2, 2, 8, 8, 4, 7, 2, 4, 7, 6, 4, 2, 4, 0, 5, 7, 7, 5, 4, 3, 9, 2, 2, 3, 5, 0, 5, 5, 3, 2, 6, 1, 7, 4, 1, 5, 3, 5, 5, 6, 3, 2, 4, 4, 4, 6, 2, 6, 7, 4, 8, 6, 4, 5, 2, 3, 4, 4, 4, 7, 6, 0, 2, 6, 4, 7, 1, 0, 2, 0, 7, 6, 2, 2, 4, 9, 0, 2, 3, 7, 4, 9, 5, 8, 3, 7, 4, 5, 6, 5, 5, 2, 4, 2, 7, 6, 3, 3, 6, 4, 2, 5, 3, 5, 6, 4, 6, 3, 3, 5, 5, 5, 4, 3, 1, 7, 4, 9, 6, 4, 3, 5, 7, 5, 3, 4, 6, 0, 4, 6, 3, 3, 3, 4, 2, 4, 9, 6, 8, 6, 3, 2, 9, 7, 4, 5, 2, 2, 4, 6, 2, 1, 0, 5, 8, 2, 6, 1, 4, 2, 6, 3, 6, 4, 2, 2, 5, 5, 5, 5, 0, 0, 2, 4, 6, 1, 7, 2, 5, 6, 8, 6, 7, 5, 4, 5, 6, 4, 3, 4, 2, 1, 4, 3, 3, 6, 2, 3, 6, 7, 4, 5, 6, 3, 4, 6, 4, 4, 4, 5, 4, 0, 5, 4, 6, 6, 2, 4, 6, 5, 6, 2, 2, 8, 5, 1, 4, 2, 6, 6, 4, 6, 2, 0, 3, 1, 2, 4, 4, 5, 4, 4, 3, 2, 5, 9, 5, 1, 3, 1, 3, 4, 2, 0, 5, 3, 5, 3, 5, 7, 4, 2, 2, 2, 3, 1, 8, 6, 8, 4, 5, 7, 2, 0, 3, 9, 4, 9, 2, 2, 7, 5, 3, 4, 0, 5, 8, 4, 5, 3, 7, 0, 6, 2, 4, 6, 2, 4, 8, 8, 9, 6, 3, 7, 2, 7, 3, 2, 6, 6, 3, 5, 5, 0, 0, 0, 5, 2, 5, 6, 5, 3, 7, 0, 4, 2, 5, 7, 6, 3, 5, 3, 4, 6, 7, 0, 4, 5, 9, 6, 8, 3, 5, 0, 1, 3, 3, 4, 4, 5, 1, 3, 5, 5, 4, 3, 3, 4, 2, 5, 3, 4, 6, 2, 9, 2, 7, 5, 4, 4, 7, 4, 0, 6, 2, 3, 4, 3, 6, 7, 5, 6, 3, 5, 6, 2, 2, 1, 4, 5, 3, 7, 7, 3, 3, 3, 3, 3, 1, 6, 5, 7, 8, 7, 3, 2, 6, 4, 9, 2, 5, 5, 7, 1, 6, 0, 4, 5, 6, 7, 6, 4, 6, 6, 4, 4, 5, 3, 9, 0, 1, 5, 8, 7, 3, 3, 3, 4, 5, 3, 9, 7, 3, 5, 4, 4, 7, 4, 3, 2, 6, 6, 5, 6, 0, 2, 2, 3, 6, 6, 5, 2, 8, 3, 9, 5, 2, 1, 1, 2, 5, 4, 2, 1, 4, 0, 4, 7, 4, 3, 0, 3, 3, 7, 6, 0, 5, 2, 3, 6, 4, 6, 3, 7, 3, 1, 5, 9, 6, 2, 6, 2, 4, 3, 6, 5, 0, 3, 5, 6, 2, 6, 2, 2, 8, 9, 4, 3, 6, 6, 6, 5, 4, 4, 3, 5, 8, 6, 4, 9, 2, 9, 7, 4, 4, 3, 5, 0, 4, 4, 7, 4, 2, 2, 3, 0, 6, 7, 4, 2, 6, 6, 7, 2, 4, 5, 6, 7, 9, 4, 8, 0, 9, 6, 9, 4, 7, 8, 4, 3, 9, 2, 5, 1, 7, 4, 6, 3, 2, 5, 3, 3, 5, 2, 7, 3, 2, 2, 4, 7, 3, 6, 2, 0, 2, 6, 4, 6, 3, 5, 7, 0, 6, 5, 1, 3, 2, 0, 2, 9, 7, 2, 6, 6, 7, 3, 9, 9, 2, 7, 0, 5, 4, 2, 0, 0, 5, 3, 2, 5, 9, 8, 7, 0, 8, 0, 7, 3, 7, 3, 1, 9, 5, 2, 6, 7, 5, 5, 6, 2, 3, 3, 1, 4, 5, 6, 2, 5, 5, 7, 6, 7, 5, 7, 3, 5, 2, 4, 0, 3, 3, 2, 7, 3, 3, 7, 3, 6, 7, 2, 5, 4, 1, 4, 6, 6, 7, 6, 4, 2, 2, 6, 6, 7, 2, 4, 2, 3, 6, 6, 2, 4, 6, 3, 3, 0, 6, 3, 4, 5, 5, 1, 9, 4, 4, 6, 2, 0, 7, 3, 6, 3, 0, 6, 1, 2, 5, 3, 4, 5, 2, 5, 4, 4, 7, 4, 6, 5, 9, 2, 2, 2, 6, 5, 5, 2, 4, 2, 4, 7, 3, 7, 6, 3, 3, 4, 9, 8, 3, 4, 7, 6, 6, 4, 7, 2, 1, 6, 3, 3, 4, 4, 3, 8, 4, 3, 5, 7, 6, 6, 2, 2, 9, 5, 4, 7, 5, 4, 3, 5, 0, 5, 8, 2, 6, 6, 4, 1, 6, 8, 6, 9, 0, 9, 4, 2, 3, 2, 4, 6, 6, 6, 6, 9, 0, 6, 4, 3, 5, 5, 4, 2, 7, 5, 6, 3, 2, 5, 6, 6, 2, 6, 4, 8, 4, 2, 6, 6, 6, 2, 1, 5, 9, 4, 1, 7, 2, 0, 2, 8, 7, 6, 7, 3, 5, 4, 8, 6, 3, 5, 6, 3, 3, 9, 5, 7, 2, 3, 7, 9, 9, 4, 7, 4, 4, 9, 9, 5, 7, 2, 7, 3, 5, 3, 3, 7, 5, 3, 3, 2, 3, 3, 3, 4, 6, 2, 6, 3, 5, 1, 3, 5, 6, 2, 5, 4, 2, 6, 2, 4, 4, 2, 2, 4, 3, 4, 7, 6, 6, 5, 9, 5, 3, 2, 3, 9, 3, 4, 2, 2, 2, 6, 8, 5, 3, 2, 5, 6, 3, 3, 0, 6, 0, 5, 3, 0, 2, 5, 2, 4, 1, 6, 3, 5, 2, 4, 6, 3, 1, 2, 9, 3, 4, 2, 0, 3, 4, 4, 3, 2, 5, 1, 3, 3, 2, 9, 9, 3, 7, 5, 5, 9, 5, 3, 2, 2, 5, 2, 3, 5, 8, 5, 2, 0, 9, 3, 5, 3, 0, 0, 4, 3, 3, 5, 2, 9, 2, 7, 7, 2, 4, 7, 2, 1, 2, 4, 0, 6, 7, 2, 7, 7, 3, 5, 3, 6, 7, 2, 5, 2, 7, 3, 6, 3, 5, 2, 3, 8, 2, 0, 4, 8, 3, 3, 3, 3, 5, 6, 6, 3, 5, 6, 8, 2, 6, 3, 7, 3, 5, 3, 2, 4, 7, 3, 4, 6, 6, 7, 4, 7, 3, 5, 2, 4, 1, 7, 4, 3, 2, 0, 8, 3, 3, 6, 7, 4, 4, 6, 3, 6, 7, 3, 7, 3, 4, 5, 4, 3, 4, 4, 4, 5, 8, 6, 3, 9, 8, 4, 3, 2, 5, 2, 2, 8, 4, 2, 0, 5, 3, 7, 5, 7, 7, 4, 2, 6, 2, 6, 6, 5, 7, 2, 7, 7, 3, 2, 5, 7, 5, 3, 3, 5, 2, 3, 4, 7, 6, 0, 2, 3, 2, 4, 5, 3, 9, 7, 4, 2, 8, 2, 9, 1, 8, 2, 7, 4, 2, 5, 5, 2, 0, 4, 5, 9, 7, 6, 2, 4, 3, 6, 1, 3, 5, 3, 7, 4, 5, 4, 6, 2, 6, 3, 8, 6, 6, 6, 6, 2, 6, 3, 4, 3, 2, 3, 4, 6, 6, 1, 7, 4, 7, 7, 7, 8, 4, 6, 2, 3, 6, 6, 3, 4, 5, 0, 2, 3, 8, 3, 0, 5, 6, 2, 0, 3, 4, 7, 7, 4, 6, 2, 0, 1, 7, 2, 0, 2, 4, 5, 8, 8, 0, 3, 4, 4, 0, 7, 7, 7, 3, 4, 3, 2, 4, 6, 6, 9, 4, 1, 5, 9, 1, 4, 2, 6, 4, 4, 2, 3, 5, 6, 6, 4, 9, 4, 7, 3, 6, 0, 4, 4, 2, 7, 1, 4, 5, 4, 4, 0, 7, 3, 6, 3, 7, 3, 2, 4, 5, 2, 7, 4, 7, 3, 1, 6, 9, 5, 7, 5, 6, 7, 3, 5, 3, 4, 0, 1, 0, 5, 5, 5, 2, 2, 6, 1, 3, 2, 2, 7, 2, 0, 7, 3, 4, 6, 0, 7, 3, 6, 2, 7, 5, 7, 6, 8, 5, 8, 0, 4, 3, 5, 3, 5, 3, 9, 3, 7, 4, 4, 2, 4, 3, 6, 7, 2, 2, 3, 4, 2, 7, 5, 4, 5, 8, 2, 6, 2, 8, 1, 5, 6, 7, 7, 0, 4, 4, 2, 6, 5, 7, 7, 6, 3, 5, 4, 4, 3, 7, 4, 4, 8, 4, 6, 8, 3, 6, 4, 6, 1, 5, 2, 7, 4, 3, 5, 4, 4, 4, 6, 5, 6, 4, 5, 7, 4, 8, 3, 7, 8, 3, 3, 5, 6, 6, 6, 3, 7, 3, 4, 5, 3, 4, 1, 4, 2, 6, 0, 6, 4, 7, 3, 7, 7, 3, 2, 6, 1, 2, 4, 9, 3, 3, 0, 3, 9, 7, 6, 6, 2, 5, 6, 0, 4, 8, 6, 7, 6, 7, 6, 9, 4, 6, 6, 7, 6, 3, 1, 7, 6, 4, 9, 4, 6, 3, 3, 9, 4, 3, 3, 3, 3, 1, 7, 2, 5, 2, 6, 0, 7, 6, 9, 4, 6, 6, 6, 2, 4, 2, 5, 9, 5, 3, 4, 3, 6, 4, 7, 2, 3, 1, 2, 3, 4, 3, 4, 3, 4, 6, 5, 8, 2, 7, 9, 5, 5, 8, 3, 1, 3, 4, 5, 3, 9, 3, 2, 3, 8, 2, 5, 7, 5, 6, 2, 3, 3, 3, 8, 3, 0, 3, 7, 9, 9, 6, 3, 4, 4, 5, 9, 3, 4, 4, 0, 5, 3, 8, 4, 6, 6, 3, 3, 4, 2, 5, 4, 2, 9, 2, 2, 2, 5, 5, 8, 2, 2, 3, 3, 5, 8, 4, 6, 3, 0, 1, 6, 0, 5, 5, 7, 2, 4, 8, 2, 3, 4, 5, 5, 2, 3, 4, 6, 0, 3, 5, 2, 2, 0, 2, 2, 6, 3, 0, 6, 3, 5, 3, 6, 2, 4, 2, 7, 0, 4, 3, 6, 7, 3, 2, 6, 2, 1, 4, 0, 3, 5, 2, 4, 4, 0, 4, 6, 3, 6, 5, 3, 3, 5, 3, 2, 2, 5, 6, 9, 1, 6, 6, 4, 3, 4, 2, 2, 3, 6, 3, 6, 2, 2, 3, 7, 6, 3, 4, 5, 4, 1, 7, 9, 6, 5, 5, 8, 6, 3, 1, 6, 8, 0, 6, 3, 3, 7, 2, 7, 3, 7, 4, 9, 7, 5, 4, 7, 3, 5, 2, 3, 4, 4, 3, 5, 4, 2, 6, 4, 1, 6, 6, 2, 7, 4, 3, 4, 2, 0, 3, 5, 3, 2, 8, 7, 0, 2, 7, 0, 4, 6, 3, 5, 8, 7, 3, 5, 2, 7, 3, 1, 6, 0, 4, 5, 6, 2, 6, 3, 3, 8, 3, 2, 1, 6, 2, 5, 1, 7, 3, 5, 3, 6, 3, 4, 3, 2, 2, 4, 7, 5, 5, 0, 7, 6, 2, 2, 0, 5, 2, 5, 8, 2, 3, 4, 4, 4, 1, 5, 2, 4, 5, 8, 5, 2, 6, 6, 0, 5, 3, 0, 0, 6, 2, 8, 9, 2, 5, 5, 2, 5, 2, 5, 2, 7, 4, 0, 5, 2, 0, 2, 7, 5, 6, 1, 6, 6, 2, 6, 2, 3, 2, 7, 5, 6, 2, 2, 3, 5, 3, 0, 3, 0, 4, 4, 3, 6, 4, 6, 4, 1, 3, 7, 5, 6, 6, 6, 2, 5, 0, 4, 7, 4, 9, 6, 2, 4, 4, 7, 2, 2, 6, 1, 4, 2, 2, 0, 3, 3, 7, 5, 3, 2, 4, 2, 4, 9, 5, 5, 1, 6, 4, 7, 3, 4, 9, 6, 7, 5, 5, 2, 5, 6, 7, 9, 5, 6, 5, 5, 3, 5, 7, 2, 3, 6, 4, 2, 2, 5, 6, 6, 5, 6, 1, 6, 3, 5, 4, 3, 0, 4, 0, 4, 5, 5, 3, 4, 2, 5, 4, 5, 2, 4, 5, 6, 3, 8, 6, 4, 5, 2, 4, 9, 7, 0, 7, 1, 7, 0, 9, 2, 6, 2, 3, 9, 2, 7, 9, 6, 3, 0, 1, 7, 5, 0, 4, 9, 0, 6, 3, 6, 3, 7, 5, 6, 3, 2, 5, 6, 3, 3, 2, 7, 6, 2, 3, 2, 5, 4, 1, 7, 3, 5, 4, 2, 6, 3, 5, 7, 7, 1, 2, 2, 3, 6, 7, 4, 3, 6, 0, 4, 2, 4, 7, 4, 2, 6, 2, 7, 5, 3, 5, 2, 5, 2, 5, 5, 2, 3, 3, 2, 6, 2, 3, 4, 0, 6, 1, 5, 4, 3, 6, 6, 3, 2, 4, 3, 6, 5, 3, 2, 4, 2, 3, 3, 9, 2, 2, 4, 6, 0, 9, 4, 6, 3, 3, 7, 5, 3, 5, 0, 2, 9, 7, 5, 1, 8, 2, 6, 4, 3, 6, 5, 5, 2, 6, 6, 3, 8, 3, 5, 5, 2, 3, 3, 5, 5, 8, 3, 4, 2, 7, 9, 6, 3, 6, 7, 4, 3, 2, 6, 7, 5, 0, 5, 8, 9, 9, 5, 9, 2, 3, 0, 5, 7, 3, 7, 4, 2, 6, 5, 2, 7, 8, 1, 4, 7, 3, 6, 2, 3, 3, 7, 3, 5, 2, 6, 4, 1, 2, 9, 7, 3, 1, 4, 8, 1, 7, 6, 2, 5, 2, 3, 2, 9, 8, 6, 7, 2, 5, 4, 5, 3, 2, 1, 7, 5, 2, 4, 3, 3, 3, 6, 9, 4, 7, 2, 4, 4, 7, 6, 4, 6, 2, 6, 3, 9, 6, 3, 3, 5, 5, 6, 4, 5, 7, 6, 1, 2, 6, 7, 3, 7, 7, 3, 5, 3, 4, 2, 5, 5, 0, 4, 7, 7, 7, 1, 6, 4, 5, 6, 4, 2, 7, 7, 3, 2, 8, 4, 5, 0, 6, 4, 2, 3, 1, 7, 2, 5, 9, 4, 3, 7, 3, 5, 3, 7, 5, 5, 4, 3, 0, 7, 3, 2, 5, 6, 2, 3, 4, 7, 6, 4, 6, 5, 0, 5, 6, 2, 3, 3, 9, 7, 5, 0, 7, 6, 5, 4, 6, 3, 5, 2, 6, 7, 4, 3, 3, 8, 3, 0, 6, 2, 6, 6, 9, 2, 3, 4, 6, 6, 0, 5, 0, 5, 6, 5, 3, 6, 4, 2, 5, 6, 6, 3, 7, 8, 8, 5, 5, 9, 2, 7, 2, 3, 7, 3, 6, 2, 5, 6, 5, 5, 6, 4, 4, 2, 7, 2, 3, 3, 5, 4, 2, 4, 3, 4, 3, 3, 2, 2, 2, 2, 2, 7, 8, 5, 3, 1, 7, 4, 8, 6, 6, 4, 3, 0, 6, 4, 7, 5, 8, 9, 8, 5, 3, 1, 5, 2, 3, 4, 3, 7, 1, 4, 6, 3, 6, 3, 0, 5, 7, 6, 4, 3, 4, 6, 3, 7, 7, 6, 2, 9, 6, 3, 1, 6, 5, 9, 9, 7, 2, 6, 6, 6, 5, 2, 2, 5, 3, 4, 5, 2, 4, 8, 2, 7, 6, 5, 3, 3, 4, 5, 7, 9, 5, 9, 2, 3, 5, 2, 6, 4, 6, 4, 3, 2, 6, 7, 6, 8, 7, 4, 1, 3, 9, 3, 6, 3, 3, 6, 3, 4, 5, 2, 7, 5, 6, 0, 6, 9, 3, 7, 9, 1, 4, 2, 5, 2, 8, 1, 3, 6, 2, 3, 9, 5, 2, 3, 6, 7, 4, 1, 3, 2, 7, 9, 1, 4, 9, 1, 6, 9, 4, 5, 5, 7, 4, 3, 6, 4, 1, 5, 5, 2, 0, 2, 7, 2, 2, 2, 5, 9, 6, 6, 5, 6, 3, 0, 6, 7, 2, 3, 2, 7, 3, 4, 2, 2, 2, 7, 7, 7, 4, 5, 1, 2, 2, 4, 4, 6, 0, 4, 5, 7, 3, 2, 1, 5, 4, 2, 7, 0, 2, 0, 6, 2, 7, 5, 5, 4, 0, 1, 6, 8, 3, 8, 1, 6, 2, 2, 9, 2, 4, 2, 2, 3, 3, 6, 0, 3, 5, 0, 5, 2, 3, 7, 5, 3, 6, 5, 5, 6, 3, 2, 6, 2, 0, 3, 3, 5, 5, 5, 3, 2, 4, 6, 3, 6, 5, 4, 4, 6, 6, 0, 7, 0, 8, 9, 2, 3, 2, 6, 2, 1, 2, 5, 4, 6, 6, 1, 0, 6, 4, 3, 6, 6, 7, 6, 3, 4, 2, 3, 4, 5, 5, 4, 5, 3, 3, 4, 4, 6, 3, 5, 4, 3, 8, 5, 8, 4, 6, 5, 7, 9, 2, 2, 6, 5, 5, 2, 5, 4, 0, 7, 5, 4, 5, 3, 9, 5, 5, 3, 6, 4, 7, 2, 9, 8, 6, 4, 7, 0, 8, 6, 2, 3, 5, 6, 2, 0, 3, 5, 6, 4, 5, 4, 6, 7, 6, 5, 3, 2, 5, 5, 5, 5, 2, 4, 3, 3, 1, 4, 6, 3, 9, 5, 6, 6, 3, 3, 0, 5, 4, 7, 9, 2, 3, 7, 6, 4, 4, 6, 7, 4, 4, 3, 6, 7, 3, 3, 1, 3, 7, 6, 9, 4, 0, 5, 1, 7, 2, 4, 5, 1, 2, 4, 4, 4, 4, 6, 2, 3, 4, 2, 6, 3, 2, 1, 4, 4, 0, 6, 2, 3, 3, 6, 4, 6, 2, 5, 4, 4, 9, 3, 3, 2, 2, 7, 9, 2, 7, 8, 6, 0, 6, 6, 7, 2, 5, 3, 4, 5, 3, 2, 4, 7, 6, 7, 7, 6, 5, 0, 9, 1, 2, 0, 4, 6, 6, 5, 4, 3, 7, 2, 9, 1, 2, 4, 1, 5, 6, 4, 3, 6, 0, 8, 6, 2, 6, 7, 5, 5, 0, 4, 4, 5, 3, 1, 6, 2, 1, 9, 3, 7, 5, 7, 3, 7, 4, 3, 4, 7, 5, 6, 2, 5, 6, 5, 5, 5, 2, 6, 7, 7, 4, 2, 5, 1, 0, 5, 3, 5, 5, 2, 2, 6, 5, 6, 4, 6, 5, 7, 5, 7, 1, 6, 9, 3, 2, 2, 4, 0, 6, 4, 1, 4, 1, 4, 6, 6, 4, 2, 5, 7, 7, 9, 4, 2, 6, 6, 6, 6, 2, 5, 6, 9, 2, 7, 4, 1, 6, 2, 4, 6, 0, 6, 5, 2, 0, 3, 4, 6, 2, 5, 3, 2, 7, 4, 5, 5, 1, 4, 3, 2, 4, 4, 2, 6, 8, 3, 4, 5, 6, 7, 2, 3, 5, 4, 8, 3, 0, 2, 0, 6, 5, 7, 0, 3, 0, 5, 3, 7, 4, 4, 1, 2, 4, 0, 4, 2, 4, 3, 7, 6, 7, 2, 2, 3, 2, 0, 4, 2, 6, 2, 3, 5, 4, 7, 5, 3, 2, 7, 4, 3, 1, 3, 7, 3, 7, 4, 2, 5, 4, 6, 3, 4, 6, 5, 0, 6, 6, 5, 2, 3, 7, 3, 5, 3, 7, 1, 9, 3, 6, 4, 5, 5, 8, 3, 4, 4, 6, 3, 6, 2, 1, 4, 5, 4, 6, 3, 4, 5, 5, 7, 9, 6, 3, 4, 2, 7, 1, 4, 6, 3, 5, 4, 5, 6, 0, 4, 7, 5, 5, 7, 2, 5, 2, 8, 3, 6, 2, 4, 8, 4, 0, 2, 8, 9, 3, 6, 7, 5, 4, 6, 6, 5, 2, 2, 7, 9, 5, 7, 0, 5, 3, 2, 7, 7, 4, 2, 0, 6, 3, 3, 3, 3, 1, 6, 3, 4, 0, 8, 2, 7, 9, 6, 2, 6, 3, 5, 4, 3, 6, 4, 2, 3, 3, 5, 0, 7, 3, 7, 2, 5, 2, 5, 7, 9, 4, 2, 9, 4, 6, 6, 4, 2, 2, 3, 4, 7, 5, 6, 6, 0, 0, 6, 3, 4, 9, 0, 7, 2, 3, 7, 3, 4, 1, 3, 9, 1, 9, 1, 2, 4, 2, 2, 5, 6, 4, 3, 0, 3, 1, 3, 2, 8, 4, 3, 1, 7, 9, 5, 6, 3, 2, 7, 9, 2, 2, 5, 2, 5, 8, 6, 3, 1, 3, 3, 5, 4, 3, 5, 3, 7, 2, 0, 9, 5, 4, 7, 6, 8, 4, 5, 1, 8, 0, 3, 6, 7, 4, 6, 8, 1, 7, 9, 0, 5, 3, 4, 8, 4, 5, 3, 3, 7, 6, 7, 9, 6, 3, 2, 6, 7, 2, 3, 2, 3, 6, 7, 7, 4, 8, 5, 3, 6, 7, 6, 6, 5, 4, 7, 9, 6, 3, 6, 4, 7, 7, 7, 2, 8, 5, 9, 4, 8, 4, 9, 7, 3, 2, 4, 7, 0, 3, 5, 3, 4, 6, 3, 4, 7, 6, 4, 7, 6, 7, 6, 6, 8, 0, 5, 9, 5, 6, 2, 2, 8, 7, 2, 6, 6, 2, 0, 4, 2, 3, 7, 7, 9, 5, 2, 4, 6, 7, 3, 3, 7, 7, 9, 3, 9, 9, 5, 7, 2, 3, 4, 3, 2, 5, 5, 1, 3, 4, 5, 3, 9, 4, 2, 0, 0, 3, 2, 4, 5, 5, 3, 4, 5, 3, 6, 4, 3, 4, 2, 6, 7, 5, 4, 0, 2, 2, 4, 3, 2, 6, 3, 6, 8, 3, 4, 3, 6, 3, 9, 6, 2, 6, 3, 4, 8, 8, 2, 6, 5, 7, 3, 6, 6, 2, 3, 7, 6, 4, 0, 2, 3, 6, 3, 6, 7, 2, 6, 6, 4, 6, 6, 5, 0, 2, 2, 3, 5, 2, 1, 9, 6, 2, 6, 6, 9, 5, 4, 5, 5, 2, 7, 5, 7, 0, 2, 2, 6, 5, 5, 3, 7, 7, 5, 6, 6, 6, 3, 6, 3, 5, 2, 0, 4, 5, 2, 9, 2, 5, 9, 3, 7, 7, 1, 7, 4, 3, 0, 2, 2, 3, 5, 6, 3, 9, 5, 4, 6, 4, 6, 3, 5, 3, 3, 2, 3, 5, 4, 0, 4, 1, 6, 5, 2, 8, 5, 5, 6, 3, 2, 3, 6, 4, 6, 3, 3, 0, 6, 4, 5, 3, 5, 5, 6, 6, 4, 2, 3, 3, 3, 6, 1, 4, 8, 4, 2, 8, 3, 4, 4, 4, 7, 5, 3, 5, 7, 8, 2, 7, 2, 7, 7, 6, 5, 1, 5, 3, 4, 4, 5, 4, 2, 4, 3, 9, 2, 9, 2, 3, 6, 7, 2, 4, 7, 2, 2, 3, 6, 3, 5, 7, 0, 4, 9, 6, 0, 9, 5, 0, 5, 7, 3, 6, 6, 9, 7, 5, 4, 8, 2, 1, 3, 4, 7, 4, 6, 3, 4, 3, 5, 6, 5, 3, 6, 5, 3, 7, 1, 1, 4, 5, 3, 8, 3, 4, 4, 8, 5, 2, 6, 5, 0, 6, 4, 3, 8, 7, 6, 5, 3, 4, 6, 4, 3, 8, 2, 3, 4, 3, 3, 2, 7, 3, 4, 6, 2, 0, 7, 1, 5, 9, 4, 3, 0, 7, 8, 2, 4, 4, 2, 9, 7, 5, 2, 8, 5, 4, 5, 6, 5, 4, 2, 2, 7, 4, 2, 6, 9, 3, 1, 2, 6, 6, 0, 4, 3, 2, 5, 3, 7, 6, 3, 5, 5, 5, 7, 3, 6, 6, 5, 8, 4, 6, 5, 5, 2, 2, 2, 7, 3, 2, 4, 7, 3, 7, 3, 3, 2, 4, 2, 3, 2, 4, 4, 6, 3, 5, 3, 8, 0, 3, 9, 7, 3, 2, 9, 2, 3, 4, 5, 5, 6, 6, 2, 4, 3, 5, 4, 6, 3, 2, 9, 1, 2, 7, 6, 1, 8, 6, 2, 2, 7, 7, 2, 3, 4, 1, 6, 6, 1, 6, 4, 2, 4, 5, 1, 4, 5, 6, 3, 5, 4, 1, 2, 6, 9, 5, 2, 6, 3, 2, 3, 3, 3, 2, 2, 6, 7, 6, 3, 4, 0, 2, 4, 4, 2, 4, 4, 3, 2, 6, 0, 6, 1, 4, 6, 2, 3, 3, 5, 6, 5, 6, 2, 3, 5, 2, 4, 7, 4, 0, 4, 0, 5, 5, 1, 7, 7, 1, 7, 3, 7, 5, 5, 0, 7, 6, 4, 7, 4, 3, 2, 2, 4, 1, 3, 6, 4, 4, 7, 9, 2, 6, 2, 3, 3, 2, 0, 4, 1, 4, 2, 4, 1, 6, 9, 2, 4, 6, 3, 3, 7, 2, 3, 5, 1, 2, 2, 6, 3, 0, 4, 5, 9, 5, 3, 2, 2, 6, 5, 9, 7, 5, 7, 5, 6, 1, 5, 5, 0, 4, 1, 4, 7, 6, 4, 4, 7, 3, 7, 6, 2, 5, 5, 5, 7, 5, 2, 9, 2, 7, 2, 4, 6, 2, 4, 7, 5, 8, 2, 2, 6, 4, 8, 1, 7, 4, 4, 3, 6, 6, 7, 2, 7, 3, 4, 7, 7, 4, 6, 4, 3, 4, 5, 6, 4, 7, 4, 2, 6, 2, 6, 7, 7, 5, 7, 4, 5, 3, 6, 3, 8, 2, 2, 9, 2, 2, 0, 2, 5, 4, 8, 6, 7, 3, 5, 4, 3, 4, 4, 5, 1, 5, 6, 0, 4, 3, 2, 7, 6, 3, 3, 5, 4, 4, 5, 3, 6, 4, 3, 0, 7, 2, 4, 5, 6, 4, 6, 4, 2, 2, 6, 9, 5, 5, 6, 2, 3, 3, 0, 5, 2, 3, 5, 2, 5, 5, 4, 3, 2, 4, 3, 6, 7, 4, 5, 6, 1, 4, 5, 3, 5, 2, 4, 7, 4, 4, 4, 4, 6, 1, 5, 3, 8, 3, 3, 3, 3, 6, 8, 2, 5, 2, 3, 1, 7, 7, 5, 4, 9, 7, 3, 5, 4, 3, 5, 4, 7, 2, 2, 2, 3, 3, 6, 4, 7, 3, 7, 5, 5, 5, 7, 2, 1, 3, 7, 6, 8, 6, 9, 7, 7, 9, 4, 4, 7, 6, 2, 0, 0, 8, 2, 2, 3, 4, 8, 4, 4, 0, 5, 2, 2, 5, 6, 2, 9, 5, 4, 6, 9, 7, 6, 4, 2, 0, 6, 6, 3, 2, 6, 2, 5, 6, 3, 6, 3, 3, 5, 7, 6, 2, 6, 3, 6, 4, 3, 4, 7, 4, 7, 6, 7, 0, 3, 5, 5, 4, 1, 5, 3, 5, 5, 6, 9, 5, 3, 3, 5, 2, 9, 6, 7, 3, 6, 6, 5, 4, 6, 6, 4, 4, 7, 2, 8, 4, 2, 6, 5, 3, 5, 4, 3, 5, 4, 3, 3, 6, 5, 2, 4, 5, 2, 9, 9, 2, 5, 2, 4, 7, 9, 3, 3, 2, 7, 0, 7, 1, 5, 4, 3, 2, 8, 4, 4, 3, 4, 4, 1, 3, 2, 6, 6, 7, 2, 2, 0, 8, 6, 6, 5, 9, 5, 9, 0, 4, 6, 0, 1, 6, 2, 3, 5, 8, 4, 3, 3, 9, 4, 5, 2, 6, 6, 3, 3, 2, 1, 2, 5, 8, 5, 6, 0, 0, 5, 3, 4, 6, 6, 7, 4, 2, 2, 4, 2, 9, 6, 3, 2, 2, 3, 5, 3, 9, 6, 3, 6, 2, 4, 8, 4, 3, 1, 6, 8, 3, 6, 3, 5, 7, 4, 2, 2, 2, 2, 0, 6, 6, 6, 5, 6, 1, 0, 6, 9, 5, 8, 2, 2, 5, 3, 3, 2, 5, 5, 6, 3, 4, 6, 2, 0, 0, 5, 5, 2, 6, 7, 6, 5, 4, 6, 5, 5, 7, 5, 2, 6, 8, 3, 2, 4, 4, 4, 6, 6, 3, 6, 5, 6, 2, 6, 0, 2, 6, 7, 9, 4, 4, 4, 4, 8, 2, 4, 4, 4, 5, 5, 0, 2, 2, 4, 2, 5, 6, 6, 8, 4, 4, 4, 7, 4, 3, 6, 4, 9, 4, 2, 6, 4, 4, 5, 2, 5, 0, 6, 4, 7, 4, 1, 6, 5, 5, 1, 5, 8, 3, 2, 6, 1, 7, 4, 9, 0, 6, 6, 5, 7, 4, 2, 4, 6, 4, 3, 2, 4, 7, 2, 4, 9, 3, 3, 5, 3, 3, 2, 6, 1, 3, 5, 7, 4, 6, 2, 9, 7, 2, 5, 6, 4, 7, 5, 3, 2, 7, 4, 6, 7, 6, 7, 9, 3, 0, 7, 4, 0, 0, 4, 7, 3, 5, 4, 5, 6, 8, 4, 0, 2, 6, 4, 3, 3, 3, 5, 2, 6, 1, 2, 3, 0, 4, 3, 7, 6, 5, 6, 9, 5, 0, 6, 5, 3, 6, 4, 6, 6, 3, 2, 3, 2, 5, 9, 5, 1, 6, 6, 6, 5, 6, 6, 1, 7, 3, 5, 3, 0, 5, 2, 5, 5, 5, 7, 8, 5, 2, 5, 5, 6, 5, 5, 6, 6, 4, 3, 7, 0, 3, 2, 7, 3, 1, 2, 2, 6, 9, 7, 3, 3, 4, 9, 6, 6, 5, 3, 8, 2, 3, 5, 4, 8, 8, 6, 0, 3, 5, 5, 2, 6, 6, 6, 3, 3, 7, 3, 2, 5, 3, 3, 5, 2, 3, 5, 8, 5, 5, 6, 7, 0, 5, 5, 4, 3, 8, 7, 6, 5, 6, 1, 6, 4, 5, 5, 9, 2, 2, 3, 7, 4, 5, 8, 4, 4, 4, 4, 2, 6, 4, 2, 7, 7, 5, 3, 6, 7, 3, 5, 6, 3, 3, 6, 3, 7, 7, 0, 3, 2, 4, 3, 3, 2, 3, 7, 3, 2, 0, 7, 2, 3, 5, 5, 4, 3, 9, 2, 6, 4, 9, 3, 4, 0, 2, 2, 5, 7, 3, 7, 5, 7, 8, 2, 3, 1, 2, 6, 2, 2, 6, 5, 6, 9, 7, 0, 5, 3, 7, 3, 7, 8, 3, 4, 6, 4, 5, 5, 4, 5, 0, 1, 9, 9, 7, 9, 6, 6, 4, 5, 7, 3, 7, 6, 4, 3, 5, 9, 3, 3, 6, 5, 0, 1, 3, 6, 7, 3, 6, 4, 4, 3, 6, 4, 2, 7, 5, 7, 4, 7, 2, 2, 2, 3, 5, 6, 4, 4, 5, 9, 5, 3, 2, 7, 6, 4, 4, 0, 0, 6, 8, 6, 0, 7, 4, 2, 6, 5, 0, 4, 7, 4, 2, 3, 9, 2, 4, 6, 2, 4, 4, 6, 2, 2, 2, 3, 9, 5, 2, 7, 5, 2, 7, 3, 7, 4, 5, 2, 5, 4, 1, 6, 5, 2, 4, 3, 6, 8, 2, 2, 4, 8, 0, 2, 3, 2, 4, 5, 4, 3, 2, 3, 5, 4, 6, 2, 3, 9, 5, 6, 2, 2, 2, 1, 3, 7, 6, 5, 6, 3, 5, 2, 4, 7, 7, 2, 4, 7, 6, 5, 3, 5, 6, 0, 2, 2, 9, 5, 5, 6, 6, 1, 4, 1, 7, 4, 3, 6, 3, 2, 8, 7, 2, 3, 1, 5, 4, 5, 4, 3, 3, 2, 4, 7, 4, 5, 0, 3, 9, 2, 7, 5, 7, 7, 7, 0, 1, 3, 4, 7, 1, 0, 5, 5, 3, 3, 2, 4, 6, 3, 5, 7, 7, 3, 6, 3, 5, 4, 4, 2, 3, 4, 6, 7, 2, 6, 8, 5, 2, 4, 6, 2, 4, 4, 7, 3, 5, 5, 2, 6, 9, 7, 9, 6, 7, 6, 7, 2, 6, 7, 3, 1, 0, 3, 5, 3, 2, 3, 5, 6, 3, 5, 6, 6, 3, 4, 0, 6, 3, 2, 4, 4, 0, 9, 3, 4, 7, 2, 6, 6, 5, 7, 4, 4, 6, 2, 6, 2, 7, 4, 3, 4, 9, 3, 3, 0, 7, 2, 8, 5, 7, 1, 3, 7, 1, 0, 2, 3, 0, 6, 8, 5, 2, 9, 4, 9, 3, 6, 2, 5, 0, 4, 6, 1, 7, 2, 5, 9, 3, 7, 5, 3, 5, 3, 2, 5, 6, 4, 7, 3, 5, 7, 3, 3, 5, 2, 2, 6, 2, 3, 5, 5, 3, 9, 5, 3, 7, 6, 1, 6, 8, 2, 7, 5, 2, 0, 2, 0, 7, 3, 7, 2, 3, 7, 3, 3, 3, 9, 2, 3, 6, 0, 6, 4, 3, 6, 3, 3, 3, 5, 7, 3, 4, 6, 1, 5, 9, 3, 5, 6, 6, 3, 3, 2, 9, 6, 3, 5, 3, 6, 6, 4, 3, 9, 6, 7, 6, 2, 3, 5, 6, 8, 5, 4, 6, 6, 6, 4, 2, 3, 4, 3, 8, 6, 4, 0, 4, 2, 7, 6, 6, 2, 4, 8, 7, 9, 3, 1, 2, 9, 6, 5, 0, 5, 2, 7, 6, 4, 7, 6, 2, 5, 2, 7, 5, 1, 6, 5, 3, 1, 4, 5, 7, 3, 3, 5, 9, 5, 4, 5, 4, 0, 1, 5, 7, 9, 3, 2, 2, 8, 4, 2, 3, 3, 4, 4, 2, 3, 1, 1, 7, 8, 5, 3, 6, 7, 6, 6, 9, 3, 4, 9, 3, 7, 5, 6, 7, 5, 0, 7, 2, 6, 0, 2, 1, 2, 5, 1, 4, 4, 4, 9, 9, 4, 6, 2, 5, 6, 9, 5, 6, 9, 0, 7, 2, 2, 5, 5, 6, 7, 2, 4, 7, 0, 2, 6, 2, 7, 5, 2, 5, 5, 0, 6, 7, 2, 5, 5, 5, 8, 8, 2, 0, 9, 5, 5, 5, 9, 2, 6, 1, 7, 7, 8, 4, 6, 5, 6, 6, 1, 4, 5, 4, 5, 5, 9, 6, 4, 4, 1, 2, 8, 0, 6, 6, 4, 4, 2, 6, 4, 5, 4, 2, 2, 2, 2, 6, 8, 4, 2, 5, 5, 4, 2, 6, 5, 7, 8, 5, 2, 7, 5, 6, 5, 4, 4, 5, 7, 2, 0, 6, 5, 4, 4, 6, 2, 2, 6, 6, 5, 2, 8, 9, 7, 6, 2, 8, 1, 6, 2, 4, 5, 6, 4, 7, 2, 7, 5, 5, 5, 6, 6, 4, 9, 7, 2, 4, 6, 6, 4, 6, 7, 7, 7, 4, 2, 9, 6, 5, 2, 5, 7, 4, 7, 5, 5, 4, 7, 4, 5, 2, 6, 9, 4, 0, 9, 7, 2, 2, 1, 1, 7, 7, 5, 6, 7, 2, 0, 7, 5, 4, 7, 4, 9, 9, 7, 5, 4, 0, 0, 7, 4, 2, 6, 2, 6, 6, 5, 6, 2, 4, 7, 2, 4, 4, 5, 8, 6, 7, 7, 0, 5, 4, 5, 5, 7, 4, 2, 6, 5, 1, 2, 1, 6, 5, 9, 8, 4, 8, 4, 5, 4, 1, 5, 2, 9, 7, 6, 2, 4, 4, 7, 2, 2, 8, 0, 2, 8, 2, 5, 4, 0, 7, 2, 2, 4, 5, 2, 4, 6, 4, 8, 2, 8, 9, 7, 6, 6, 2, 6, 4, 2, 5, 4, 4, 6, 1, 5, 9, 6, 2, 6, 4, 6, 1, 8, 2, 5, 4, 2, 2, 2, 6, 9, 5, 0, 2, 7, 5, 7, 0, 8, 9, 2, 4, 4, 7, 2, 2, 5, 0, 0, 4, 6, 7, 5, 2, 2, 2, 2, 7, 1, 4, 7, 9, 4, 4, 1, 5, 4, 2, 7, 5, 5, 9, 4, 6, 2, 2, 5, 5, 8, 7, 4, 7, 6, 7, 6, 8, 6, 4, 7, 5, 6, 7, 0, 6, 7, 6, 2, 4, 5, 4, 4, 6, 5, 4, 5, 4, 5, 6, 8, 4, 7, 4, 6, 9, 2, 2, 2, 6, 2, 2, 2, 8, 5, 5, 7, 4, 1, 4, 2, 6, 9, 4, 4, 4, 6, 6, 5, 2, 7, 5, 2, 9, 0, 2, 4, 1, 5, 7, 7, 4, 4, 5, 5, 7, 4, 2, 1, 5, 1, 4, 2, 7, 4, 5, 5, 0, 5, 2, 5, 5, 9, 5, 4, 5, 7, 2, 4, 2, 4, 2, 8, 9, 4, 9, 4, 5, 4, 2, 5, 4, 4, 2, 1, 4, 5, 5, 4, 4, 4, 1, 4, 5, 0, 7, 7, 5, 4, 9, 9, 8, 5, 4, 9, 4, 9, 0, 5, 5, 9, 9, 0, 5, 7, 5, 5, 4, 1, 5, 5, 7, 4, 4, 7, 5, 1, 5, 0, 4, 7, 7, 4, 1, 7, 4, 5, 9, 4, 7, 5, 5, 7, 4, 1, 5, 7, 9, 7, 5, 0, 1, 0, 5, 0, 5, 7, 5, 1, 1, 8, 0, 5, 5, 9, 5, 9, 5, 5, 5, 7, 5, 1, 7, 5, 7, 7, 7, 7, 8, 0, 8, 9, 9, 7, 7, 9, 0, 0, 7, 7, 9, 7, 9, 7, 7, 9, 9, 0, 7, 9, 1, 7, 7, 8, 0, 1, 1, 7, 7, 7, 1, 7, 8, 0, 0, 8, 7, 0, 0, 8, 7, 8, 7, 0, 7, 9, 1, 1, 7, 0, 1, 7, 1, 0, 7, 0, 7, 7, 1, 1, 1, 8, 0, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 0, 1, 8, 0, 0, 1, 1, 7, 8, 1, 7, 9, 0, 7, 7, 7, 9, 9, 7, 1, 9, 7, 7, 8, 7, 0, 7, 7, 1, 7, 7, 7, 9, 7, 8, 7, 9, 1, 9, 7, 9, 0, 0, 8, 7, 0, 7, 0, 9, 7, 7, 8, 1, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 8, 7, 8, 7, 9, 8, 8, 0, 7, 0, 8, 1, 7, 7, 9, 7, 7, 7, 0, 8, 1, 7, 1, 7, 1, 7, 7, 1, 9, 0, 1, 0, 9, 7, 7, 7, 1, 7, 7, 7, 1, 1, 7, 1, 9, 0, 7, 1, 1, 7, 0, 8, 7, 7, 7, 9, 7, 7, 7, 7, 8, 9, 8, 0, 8, 7, 8, 7, 7, 0, 1, 0, 7, 9, 9, 7, 0, 1, 9, 7, 8, 7, 9, 9, 8, 1, 1, 1, 1, 7, 1, 7, 1, 1, 7, 0, 0, 9, 1, 7, 8, 7, 1, 9, 8, 9, 7, 8, 9, 7, 0, 1, 1, 7, 7, 1, 7, 9, 9, 7, 1, 9, 7, 1, 9, 0, 9, 1, 0, 7, 7, 7, 7, 8, 7, 9, 9, 7, 9, 7, 7, 7, 0, 8, 9, 0, 7, 7, 0, 7, 9, 9, 9, 7, 0, 8, 9, 9, 9, 8, 7, 9, 7, 7, 7, 0, 7, 7, 8, 9, 1, 7, 1, 9, 7, 1, 7, 8, 9, 7, 7, 7, 7, 7, 8, 1, 8, 7, 7, 9, 9, 1, 7, 0, 1, 7, 8, 7, 0, 7, 8, 7, 9, 0, 7, 7, 8, 0, 7, 7, 9, 9, 9, 1, 9, 7, 7, 0, 7, 0, 7, 0, 8, 8, 0, 1, 9, 1, 9, 1, 8, 8, 0, 7, 0, 7, 0, 8, 1, 0, 8, 9, 7, 7, 7, 7, 7, 7, 0, 7, 9, 9, 7, 7, 9, 7, 0, 8, 7, 8, 7, 0, 1, 0, 9, 0, 7, 7, 8, 7, 7, 0, 8, 8, 9, 0, 0, 1, 0, 0, 1, 7, 0, 8, 8, 8, 0, 1, 7, 9, 8, 0, 7, 1, 7, 9, 0, 7, 8, 9, 1, 9, 8, 0, 0, 8, 0, 1, 7, 7, 1, 0, 7, 0, 7, 0, 0, 8, 9, 0, 8, 7, 0, 8, 7, 0, 9, 9, 0, 7, 7, 1, 7, 7, 9, 7, 1, 1, 7, 1, 7, 7, 9, 1, 9, 7, 7, 7, 0, 7, 0, 8, 1, 1, 7, 1, 8, 7, 7, 7, 7, 0, 7, 8, 0, 1, 9, 9, 7, 7, 1, 7, 9, 7, 7, 8, 1, 7, 7, 9, 7, 7, 7, 0, 9, 7, 8, 9, 0, 1, 7, 7, 0, 7, 9, 0, 7, 7, 0, 0, 7, 9, 7, 8, 1, 7, 7, 9, 9, 1, 9, 7, 1, 7, 0, 1, 8, 0, 7, 1, 9, 7, 7, 0, 0, 7, 7, 9, 7, 7, 7, 1, 7, 7, 7, 7, 7, 8, 0, 8, 9, 0, 0, 9, 0, 0, 0, 1, 9, 7, 9, 7, 1, 0, 8, 1, 8, 7, 0, 1, 8, 7, 1, 9, 9, 0, 0, 9, 0, 0, 7, 1, 7, 0, 1, 1, 1, 9, 7, 1, 7, 1, 9, 8, 0, 7, 1, 7, 9, 0, 9, 7, 9, 8, 0, 7, 7, 7, 8, 7, 9, 0, 8, 1, 9, 1, 1, 0, 9, 7, 8, 1, 7, 8, 7, 7, 9, 7, 9, 8, 7, 9, 7, 1, 7, 7, 7, 1, 7, 8, 7, 0, 7, 8, 9, 1, 7, 7, 7, 7, 7, 9, 9, 8, 0, 0, 0, 1, 7, 7, 7, 7, 0, 1, 1, 9, 0, 9, 0, 0, 0, 8, 0, 0, 1, 1, 1, 8, 1, 0, 8, 8, 9, 9, 8, 1, 1, 8, 8, 1, 9, 1, 1, 0, 1, 8, 0, 8, 8, 1, 0, 8, 9, 0, 9, 1, 9, 0, 9, 0, 0, 1, 0, 0, 8, 8, 1, 0, 9, 0, 1, 9, 9, 0, 0, 1, 9, 0, 9, 9, 9, 8, 0, 0, 8, 1, 1, 9, 1, 9, 9, 9, 0, 0, 9, 1, 9, 8, 9, 8, 1, 9, 8, 8, 9, 9, 1, 1, 0, 0, 0, 9, 9, 9, 1, 0, 0, 0, 0, 8, 8, 1, 0, 8, 0, 9, 9, 8, 9, 8, 0, 9, 1, 1, 0, 1, 9, 0, 1, 1, 1, 8, 9, 8, 8, 1, 0, 0, 8, 0, 9, 9, 9, 8, 8, 0, 8, 1, 1, 0, 8, 8, 1, 0, 9, 8, 9, 1, 0, 0, 9, 9, 0, 0, 9, 0, 0, 0, 9, 9, 0, 8, 1, 8, 0, 9, 8, 1, 9, 9, 8, 0, 0, 1, 9, 9, 8, 0, 1, 0, 9, 8, 0, 1, 8, 0, 1, 1, 0, 9, 9, 1, 0, 0, 0, 8, 9, 9, 0, 9, 0, 0, 8, 0, 0, 8, 8, 9, 1, 8, 0, 1, 0, 9, 8, 8, 0, 1, 0, 0, 8, 0, 0, 8, 9, 0, 9, 9, 9, 1, 9, 1, 1, 8, 9, 0, 0, 0, 9, 9, 8, 8, 9, 1, 8, 8, 8, 0, 1, 1, 0, 9, 1, 0, 9, 9, 1, 0, 0, 9, 1, 8, 9, 0, 1, 1, 0, 0, 1, 9, 8, 1, 0, 0, 0, 8, 9, 0, 9, 9, 8, 0, 9, 1, 9, 0, 9, 1, 9, 8, 9, 9, 8, 1, 8, 0, 9, 1, 0, 9, 8, 9, 9, 9, 8, 0, 9, 8, 8, 1, 9, 0, 0, 1, 0, 8, 8, 1, 1, 8, 8, 9, 1, 9, 0, 1, 1, 9, 0, 8, 1, 9, 1, 0, 8, 0, 8, 0, 0, 1, 0, 8, 9, 1, 9, 8, 0, 9, 8, 9, 8, 9, 1, 9, 8, 9, 0, 8, 9, 9, 9, 9, 9, 9, 9, 1, 1, 0, 0, 8, 8, 9, 0, 0, 8, 0, 8, 0, 1, 9, 0, 9, 0, 9, 0, 0, 0, 9, 1, 0, 0, 0, 9, 8, 8, 8, 9, 8, 9, 1, 0, 1, 1, 1, 9, 0, 8, 1, 1, 9, 8, 8, 8, 0, 8, 8, 9, 9, 9, 1, 0, 0, 0, 0, 0, 8, 9, 9, 0, 1, 1, 8, 8, 0, 1, 0, 8, 8, 1, 8, 9, 1, 1, 8, 8, 1, 0, 0, 9, 0, 9, 1, 9, 0, 1, 9, 9, 8, 0, 9, 9, 9, 8, 1, 8, 9, 9, 0, 1, 9, 0, 0, 0, 9, 0, 1, 9, 9, 0, 9, 9, 1, 8, 1, 8, 9, 8, 9, 8, 8, 9, 0, 1, 8, 1, 9, 0, 8, 0, 9, 0, 0, 9, 9, 1, 8, 0, 8, 9, 0, 8, 1, 0, 0, 0, 1, 0, 9, 8, 0, 1, 8, 1, 0, 9, 8, 8, 9, 0, 1, 8, 9, 1, 0, 8, 1, 1, 8, 9, 8, 1, 8, 9, 8, 0, 8, 0, 0, 9, 1, 1, 9, 0, 8, 9, 8, 8, 9, 9, 0, 0, 9, 9, 8, 9, 8, 8, 1, 8, 8, 8, 1, 1, 0, 8, 8, 8, 8, 8, 8, 1, 8, 8, 0, 0, 0, 0, 1, 1, 0, 8, 0, 8, 9, 8, 0, 8, 1, 0, 9, 9, 1, 8, 8, 8, 9, 1, 9, 8, 0, 0, 0, 0, 9, 9, 1, 9, 0, 1, 1, 0, 9, 9, 9, 0, 0, 0, 1, 1, 0, 0, 9, 8, 9, 0, 1, 8, 9, 8, 8, 0, 8, 8, 0, 1, 9, 1, 1, 0, 0, 1, 8, 0, 0, 9, 0, 0, 9, 1, 0, 8, 9, 0, 8, 9, 0, 1, 1, 9, 1, 8, 0, 0, 8, 1, 8, 1, 9, 8, 8, 0, 9, 1, 0, 9, 8, 8, 8, 1, 0, 9, 8, 8, 8, 8, 8, 1, 8, 9, 1, 1, 1, 9, 0, 9, 8, 9, 9, 9, 0, 8, 8, 8, 8, 8, 1, 1, 8, 8, 9, 9, 1, 9, 1, 0, 1, 1, 0, 1, 8, 8, 8, 0, 8, 0, 0, 9, 8, 0, 9, 0, 1, 9, 0, 9, 1, 8, 8, 9, 8, 8, 1, 1, 9, 9, 0, 9, 9, 9, 8, 9, 8, 1, 0, 8, 1, 8, 8, 8, 9, 8, 0, 0, 8, 9, 1, 8, 9, 0, 0, 0, 1, 9, 0, 1, 1, 8, 1, 1, 1, 9, 9, 8, 0, 1, 0, 8, 8, 8, 9, 9, 8, 1, 8, 1, 9, 9, 0, 9, 1, 0, 1, 9, 8, 9, 9, 8, 0, 1, 9, 8, 1, 1, 0, 9, 8, 0, 1, 1, 0, 8, 1, 8, 9, 9, 0, 9, 9, 8, 8, 9, 1, 0, 9, 0, 1, 9, 1, 9, 9, 9, 8, 0, 0, 8, 0, 9, 0, 0, 8, 1, 9, 9, 9, 0, 1, 8, 8, 0, 9, 1, 1, 8, 9, 9, 9, 8, 1, 0, 9, 0, 0, 9, 9, 9, 1, 9, 8, 8, 1, 0, 8, 1, 9, 0, 9, 8, 1, 0, 0, 1, 8, 9, 9, 0, 9, 8, 9, 9, 8, 1, 9, 8, 9, 1, 8, 9, 1, 8, 8, 1, 9, 8, 1, 9, 8, 9, 9, 8, 1, 1, 8, 1, 0, 0, 9, 0, 1, 0, 9, 0, 0, 0, 8, 1, 1, 8, 8, 0, 0, 8, 0, 9, 1, 8, 0, 9, 8, 8, 9, 1, 0, 1, 9, 0, 9, 9, 1, 0, 1, 1, 0, 8, 1, 0, 0, 9, 0, 1, 8, 0, 1, 0, 8, 0, 8, 0, 8, 9, 1, 0, 1, 0, 9, 9, 0, 1, 1, 9, 0, 0, 9, 8, 8, 1, 1, 0, 0, 8, 1, 0, 0, 1, 0, 0, 8, 9, 9, 9, 8, 0, 1, 8, 0, 8, 9, 0, 1, 8, 1, 0, 8, 1, 0, 8, 0, 0, 8, 1, 8, 0, 1, 0, 9, 1, 9, 0, 9, 1, 8, 9, 8, 1, 9, 0, 1, 8, 8, 8, 1, 9, 8, 9, 8, 9, 9, 1, 1, 8, 9, 1, 8, 8, 1, 9, 8, 0, 1, 8, 0, 9, 0, 9, 1, 0, 0, 8, 1, 0, 1, 8, 9, 0, 0, 1, 9, 1, 0, 8, 8, 9, 9, 1, 1, 8, 9, 1, 0, 1, 8, 8, 8, 1, 1, 1, 0, 0, 8, 9, 0, 8, 1, 9, 1, 8, 8, 8, 9, 8, 0, 0, 0, 8, 0, 9, 0, 9, 1, 8, 9, 9, 8, 1, 1, 1, 9, 8, 9, 1, 0, 9, 0, 0, 9, 9, 0, 9, 0, 1, 0, 1, 0, 9, 8, 8, 1, 8, 1, 1, 8, 9, 1, 0, 0, 9, 8, 1, 8, 0, 0, 9, 0, 8, 8, 9, 1, 0, 9, 8, 1, 0, 8, 0, 1, 1, 1, 1, 0, 0, 9, 9, 1, 9, 8, 9, 0, 9, 1, 0, 0, 0, 9, 9, 9, 1, 9, 9, 8, 8, 8, 0, 8, 0, 8, 9, 1, 1, 0, 9, 9, 1, 9, 1, 1, 9, 8, 0, 1, 9, 9, 0, 8, 8, 8, 8, 1, 9, 8, 0, 8, 0, 9, 0, 9, 9, 1, 0, 1, 1, 9, 1, 1, 0, 9, 0, 0, 1, 0, 0, 9, 9, 0, 1, 8, 0, 1, 8, 8, 8, 8, 1, 0, 0, 9, 1, 9, 0, 1, 0, 8, 9, 0, 8, 9, 9, 8, 1, 9, 1, 9, 9, 1, 9, 9, 8, 9, 8, 1, 8, 0, 9, 1, 0, 0, 1, 0, 8, 1, 1, 8, 8, 9, 0, 0, 1, 9, 9, 9, 8, 9, 1, 0, 8, 9, 8, 1, 9, 1, 0, 0, 0, 9, 9, 0, 1, 8, 8, 9, 9, 9, 9, 0, 9, 0, 0, 9, 9, 1, 9, 1, 9, 9, 8, 1, 8, 8, 8, 9, 0, 0, 9, 0, 0, 9, 0, 9, 9, 1, 0, 0, 0, 0, 8, 8, 1, 0, 0, 0, 8, 1, 9, 1, 0, 0, 0, 9, 8, 0, 1, 9, 1, 8, 0, 1, 1, 9, 1, 9, 1, 9, 8, 9, 0, 8, 1, 8, 9, 8, 1, 0, 9, 0, 9, 1, 9, 8, 8, 8, 8, 9, 1, 9, 0, 0, 9, 9, 9, 9, 0, 8, 1, 1, 8, 9, 0, 0, 8, 1, 0, 8, 1, 1, 1, 1, 9, 9, 9, 0, 1, 8, 8, 9, 9, 1, 0, 9, 8, 0, 0, 8, 1, 9, 0, 0, 8, 9, 9, 0, 8, 0, 0, 9, 9, 8, 0, 1, 0, 8, 9, 9, 9, 9, 1, 0, 1, 9, 8, 9, 8, 9, 0, 8, 0, 9, 8, 1, 9, 9, 9, 9, 0, 1, 1, 9, 1, 0, 1, 9, 1, 8, 8, 0, 0, 0, 8, 9, 9, 8, 8, 0, 0, 8, 1, 1, 0, 9, 9, 1, 1, 8, 8, 9, 9, 9, 8, 0, 0, 0, 9, 1, 8, 1, 1, 9, 9, 9, 0, 9, 8, 1, 0, 1, 0, 8, 9, 1, 1, 0, 9, 8, 1, 8, 8, 8, 1, 0, 0, 1, 0, 8, 8, 0, 1, 0, 1, 9, 9, 9, 1, 0, 8, 1, 1, 1, 1, 9, 8, 9, 1, 1, 9, 1, 9, 0, 9, 0, 9, 0, 9, 0, 1, 0, 1, 1, 8, 1, 9, 9, 1, 9, 0, 1, 1, 9, 0, 1, 9, 8, 0, 8, 9, 8, 1, 0, 9, 8, 1, 1, 1, 1, 1, 8, 8, 1, 0, 9, 1, 9, 0, 8, 1, 9, 0, 8, 8, 9, 0, 8, 1, 8, 8, 0, 1, 8, 8, 1, 1, 9, 9, 8, 9, 0, 1, 8, 0, 1, 1, 1, 1, 1, 1, 0, 0, 9, 8, 9, 8, 9, 8, 1, 1, 0, 1, 9, 8, 1, 1, 8, 8, 1, 8, 0, 8, 0, 8, 8, 1, 0, 0, 0, 9, 9, 9, 0, 9, 1, 1, 8, 1, 1, 1, 8, 9, 0, 0, 1, 8, 0, 0, 8, 1, 0, 1, 0, 9, 1, 0, 9, 1, 9, 9, 9, 9, 8, 0, 9, 1, 1, 9, 8, 0, 8, 8, 1, 8, 1, 8, 9, 8, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 8, 0, 8, 1, 8, 1, 8, 0, 8, 0, 1, 0, 9, 9, 0, 0, 9, 8, 0, 8, 1, 8, 9, 9, 0, 8, 0, 1, 8, 0, 8, 0, 9, 8, 8, 0, 0, 9, 0, 0, 9, 0, 8, 9, 1, 0, 1, 8, 1, 8, 8, 9, 8, 8, 1, 8, 1, 9, 9, 0, 1, 0, 8, 0, 0, 9, 8, 8, 9, 1, 0, 9, 0, 9, 9, 8, 1, 0, 1, 1, 9, 8, 8, 9, 1, 9, 1, 0, 9, 9, 9, 8, 8, 8, 8, 9, 0, 0, 0, 0, 0, 9, 0, 0, 8, 1, 0, 1, 8, 8, 0, 8, 0, 9, 9, 9, 8, 8, 9, 9, 1, 8, 1, 1, 9, 0, 9, 0, 0, 1, 1, 8, 8, 9, 8, 9, 1, 1, 8, 9, 0, 0, 1, 0, 9, 0, 9, 8, 0, 1, 8, 1, 8, 9, 8, 0, 8, 9, 9, 0, 1, 1, 0, 1, 8, 9, 8, 0, 1, 9, 8, 9, 8, 8, 9, 8, 1, 8, 1, 1, 8, 8, 9, 9, 1, 9, 8, 8, 8, 1, 0, 9, 9, 1, 1, 1, 8, 9, 1, 9, 1, 8, 9, 8, 0, 9, 8, 0, 1, 0, 9, 1, 9, 9, 8, 9, 9, 0, 1, 8, 1, 1, 1, 9, 8, 1, 1, 9, 8, 1, 8, 8, 8, 8, 0, 1, 9, 0, 0, 1, 9, 1, 8, 8, 8, 8, 9, 1, 9, 9, 0, 1, 0, 9, 1, 0, 1, 0, 8, 0, 9, 0, 1, 0, 1, 9, 8, 8, 8, 1, 8, 9, 8, 9, 8, 9, 1, 8, 1, 9, 1, 8, 0, 0, 0, 9, 0, 8, 0, 8, 8, 1, 9, 0, 9, 8, 9, 9, 8, 8, 0, 8, 0, 9, 9, 0, 1, 9, 0, 1, 0, 1, 1, 9, 8, 9, 1, 9, 0, 0, 8, 8, 0, 8, 9, 8, 0, 0, 1, 9, 0, 9, 9, 1, 8, 9, 0, 1, 8, 1, 0, 8, 0, 1, 1, 8, 9, 8, 0, 1, 1, 8, 0, 0, 1, 9, 1, 1, 8, 9, 0, 0, 9, 1, 8, 0, 1, 9, 8, 1, 8, 8, 9, 1, 8, 8, 9, 1, 9, 8, 9, 1, 1, 8, 9, 1, 9, 8, 8, 8, 1, 9, 8, 8, 9, 8, 8, 8, 1, 1, 1, 8, 1, 8, 1, 1, 8, 8, 1, 1, 8, 1, 8, 8, 8, 1, 8, 8, 1, 8, 8, 8, 1, 8, 1, 8, 8, 1, 8, 1, 8, 8, 1, 8, 8, 8, 1, 1, 8, 1, 1, 1, 1, 1, 1, 8, 8, 1, 1, 1, 1, 1, 8, 1, 8, 1, 1, 1, 8, 1, 1, 1, 8, 1, 8, 1, 1, 8, 1, 1, 1, 8, 8, 1, 1, 1, 1, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 8, 8, 8, 1, 8, 1, 8, 1, 1, 1, 1, 1, 1, 8, 1, 1, 8, 1, 8, 8, 1, 8, 8, 8, 8, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 8, 8, 1, 8, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 8, 8, 1, 8, 1, 1, 1, 1, 8, 1, 1, 8, 1, 8, 8, 1, 8, 1, 8, 1, 1, 1, 1, 1, 1, 8, 1, 8, 1, 1, 1, 8, 1, 8, 8, 8, 1, 8, 8, 8, 8, 8, 8, 1, 8, 1, 1, 1, 8, 1, 8, 8, 1, 8, 8, 1, 8, 8, 8, 1, 8, 8, 1, 1, 1, 8, 1, 8, 1, 8, 1, 1, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
            "Counter({8: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 1: 1000, 3: 1000, 0: 1000, 2: 1000, 9: 1000})\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2614\u001b[0m  26.9467\n",
            "      2        2.4531  26.7878\n",
            "      3        2.3441  26.7491\n",
            "      4        2.3389  26.6259\n",
            "      5        2.3373  27.6095\n",
            "      6        2.3366  26.7492\n",
            "      7        2.2908  26.8445\n",
            "      8        2.3519  26.7588\n",
            "      9        2.3505  27.5319\n",
            "     10        2.3413  30.8937\n",
            "0.1002\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[  0   1   0   0   0   0   0   0 499   0]\n",
            " [  0   1   0   0   0   0   0   0 499   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]]\n",
            "Accuracy:  0.1002\n",
            "Macro F1-score:  0.018586838531650045\n",
            "Micro F1-score:  0.1002\n",
            "Weighted F1-score:  0.01858683853165004\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "---Query no:  1 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2924\u001b[0m  27.5497\n",
            "      2        \u001b[36m1.8860\u001b[0m  26.7830\n",
            "      3        \u001b[36m1.7832\u001b[0m  26.9118\n",
            "      4        \u001b[36m1.7344\u001b[0m  26.8536\n",
            "      5        \u001b[36m1.7031\u001b[0m  27.3919\n",
            "      6        \u001b[36m1.6610\u001b[0m  27.6475\n",
            "      7        \u001b[36m1.6338\u001b[0m  26.9749\n",
            "      8        \u001b[36m1.6302\u001b[0m  26.8789\n",
            "      9        \u001b[36m1.6246\u001b[0m  27.7276\n",
            "     10        \u001b[36m1.5949\u001b[0m  30.0004\n",
            "0.4074\n",
            "---Query no:  2 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3727\u001b[0m  27.0755\n",
            "      2        \u001b[36m2.3036\u001b[0m  27.7147\n",
            "      3        \u001b[36m2.3035\u001b[0m  26.9427\n",
            "      4        \u001b[36m2.3035\u001b[0m  26.9745\n",
            "      5        \u001b[36m2.3035\u001b[0m  28.0402\n",
            "      6        2.3035  27.4192\n",
            "      7        2.3035  27.2246\n",
            "      8        2.3035  26.9122\n",
            "      9        2.3035  27.8391\n",
            "     10        2.3035  29.9866\n",
            "0.1\n",
            "---Query no:  3 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2763\u001b[0m  26.9557\n",
            "      2        \u001b[36m2.0550\u001b[0m  26.9614\n",
            "      3        \u001b[36m2.0075\u001b[0m  27.5939\n",
            "      4        \u001b[36m1.8814\u001b[0m  27.0808\n",
            "      5        \u001b[36m1.7911\u001b[0m  26.9218\n",
            "      6        \u001b[36m1.7410\u001b[0m  27.1130\n",
            "      7        \u001b[36m1.6989\u001b[0m  26.8641\n",
            "      8        \u001b[36m1.6246\u001b[0m  27.7272\n",
            "      9        \u001b[36m1.6181\u001b[0m  27.6568\n",
            "     10        \u001b[36m1.6032\u001b[0m  29.1019\n",
            "0.4078\n",
            "---Query no:  4 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5805\u001b[0m  28.0118\n",
            "      2        \u001b[36m1.9782\u001b[0m  26.9088\n",
            "      3        \u001b[36m1.8357\u001b[0m  27.0151\n",
            "      4        \u001b[36m1.7600\u001b[0m  27.4698\n",
            "      5        \u001b[36m1.7170\u001b[0m  27.4440\n",
            "      6        \u001b[36m1.6860\u001b[0m  27.0320\n",
            "      7        \u001b[36m1.6657\u001b[0m  26.9800\n",
            "      8        \u001b[36m1.6131\u001b[0m  27.0315\n",
            "      9        \u001b[36m1.5838\u001b[0m  28.5121\n",
            "     10        \u001b[36m1.5606\u001b[0m  29.1865\n",
            "0.4354\n",
            "---Query no:  5 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3356\u001b[0m  27.9569\n",
            "      2        \u001b[36m1.9408\u001b[0m  27.0320\n",
            "      3        \u001b[36m1.8055\u001b[0m  27.0468\n",
            "      4        \u001b[36m1.7316\u001b[0m  27.0534\n",
            "      5        \u001b[36m1.6660\u001b[0m  27.3009\n",
            "      6        \u001b[36m1.6183\u001b[0m  27.7323\n",
            "      7        \u001b[36m1.6029\u001b[0m  27.0190\n",
            "      8        1.6395  27.9891\n",
            "      9        \u001b[36m1.5918\u001b[0m  28.0055\n",
            "     10        \u001b[36m1.5763\u001b[0m  30.1148\n",
            "0.4302\n",
            "---Query no:  6 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2910\u001b[0m  27.4852\n",
            "      2        \u001b[36m2.0877\u001b[0m  28.0741\n",
            "      3        \u001b[36m2.0305\u001b[0m  27.1207\n",
            "      4        \u001b[36m1.9831\u001b[0m  27.0757\n",
            "      5        1.9853  27.0278\n",
            "      6        \u001b[36m1.9678\u001b[0m  27.5388\n",
            "      7        \u001b[36m1.9662\u001b[0m  27.6020\n",
            "      8        \u001b[36m1.9476\u001b[0m  27.1268\n",
            "      9        \u001b[36m1.9383\u001b[0m  28.2030\n",
            "     10        1.9479  30.2759\n",
            "0.3132\n",
            "---Query no:  7 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3543\u001b[0m  27.3038\n",
            "      2        \u001b[36m2.1032\u001b[0m  27.2066\n",
            "      3        \u001b[36m2.0185\u001b[0m  29.0486\n",
            "      4        \u001b[36m1.9128\u001b[0m  27.1441\n",
            "      5        \u001b[36m1.8243\u001b[0m  27.0991\n",
            "      6        \u001b[36m1.7712\u001b[0m  27.1399\n",
            "      7        \u001b[36m1.7544\u001b[0m  27.7146\n",
            "      8        \u001b[36m1.6997\u001b[0m  27.5378\n",
            "      9        \u001b[36m1.6726\u001b[0m  28.1640\n",
            "     10        \u001b[36m1.6517\u001b[0m  30.0429\n",
            "0.4006\n",
            "---Query no:  8 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2081\u001b[0m  27.3200\n",
            "      2        \u001b[36m1.8062\u001b[0m  27.1857\n",
            "      3        \u001b[36m1.7057\u001b[0m  27.5697\n",
            "      4        \u001b[36m1.6543\u001b[0m  27.6363\n",
            "      5        \u001b[36m1.5834\u001b[0m  27.2035\n",
            "      6        \u001b[36m1.5275\u001b[0m  27.2396\n",
            "      7        \u001b[36m1.4945\u001b[0m  27.1686\n",
            "      8        \u001b[36m1.4555\u001b[0m  27.9463\n",
            "      9        \u001b[36m1.4273\u001b[0m  28.2055\n",
            "     10        \u001b[36m1.4070\u001b[0m  29.5776\n",
            "0.4606\n",
            "---Query no:  9 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4669\u001b[0m  27.2051\n",
            "      2        \u001b[36m1.9911\u001b[0m  27.3915\n",
            "      3        \u001b[36m1.8702\u001b[0m  27.7069\n",
            "      4        \u001b[36m1.8116\u001b[0m  27.5225\n",
            "      5        \u001b[36m1.7736\u001b[0m  27.1984\n",
            "      6        \u001b[36m1.7321\u001b[0m  27.2196\n",
            "      7        \u001b[36m1.7234\u001b[0m  27.4497\n",
            "      8        \u001b[36m1.6978\u001b[0m  27.8912\n",
            "      9        1.7038  28.3990\n",
            "     10        \u001b[36m1.6938\u001b[0m  30.1261\n",
            "0.3938\n",
            "---Query no:  10 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.1752\u001b[0m  27.4294\n",
            "      2        \u001b[36m1.8043\u001b[0m  27.3292\n",
            "      3        \u001b[36m1.6996\u001b[0m  27.6706\n",
            "      4        \u001b[36m1.6396\u001b[0m  27.8280\n",
            "      5        \u001b[36m1.5875\u001b[0m  27.3931\n",
            "      6        \u001b[36m1.5405\u001b[0m  27.4751\n",
            "      7        \u001b[36m1.5170\u001b[0m  29.2004\n",
            "      8        \u001b[36m1.4562\u001b[0m  27.4485\n",
            "      9        \u001b[36m1.4255\u001b[0m  28.5839\n",
            "     10        \u001b[36m1.4223\u001b[0m  30.6063\n",
            "0.472\n",
            "---Query no:  11 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5668\u001b[0m  27.5299\n",
            "      2        \u001b[36m2.1075\u001b[0m  27.5838\n",
            "      3        \u001b[36m2.0443\u001b[0m  28.3025\n",
            "      4        \u001b[36m1.9903\u001b[0m  27.6671\n",
            "      5        \u001b[36m1.9692\u001b[0m  27.7149\n",
            "      6        \u001b[36m1.9260\u001b[0m  28.0440\n",
            "      7        \u001b[36m1.8163\u001b[0m  27.8583\n",
            "      8        \u001b[36m1.7739\u001b[0m  27.4002\n",
            "      9        \u001b[36m1.7323\u001b[0m  28.4369\n",
            "     10        \u001b[36m1.6945\u001b[0m  30.6493\n",
            "0.3848\n",
            "---Query no:  12 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2758\u001b[0m  27.4162\n",
            "      2        \u001b[36m1.9383\u001b[0m  28.2097\n",
            "      3        \u001b[36m1.8623\u001b[0m  28.3805\n",
            "      4        \u001b[36m1.7933\u001b[0m  27.4015\n",
            "      5        \u001b[36m1.7653\u001b[0m  27.3155\n",
            "      6        \u001b[36m1.7388\u001b[0m  28.1105\n",
            "      7        \u001b[36m1.6975\u001b[0m  27.3739\n",
            "      8        \u001b[36m1.6692\u001b[0m  27.3604\n",
            "      9        \u001b[36m1.6192\u001b[0m  28.8005\n",
            "     10        \u001b[36m1.5794\u001b[0m  30.0915\n",
            "0.4248\n",
            "---Query no:  13 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.1887\u001b[0m  28.1544\n",
            "      2        \u001b[36m1.7755\u001b[0m  27.7901\n",
            "      3        \u001b[36m1.6913\u001b[0m  27.5051\n",
            "      4        \u001b[36m1.6464\u001b[0m  27.5175\n",
            "      5        \u001b[36m1.5843\u001b[0m  28.3041\n",
            "      6        \u001b[36m1.5336\u001b[0m  27.4708\n",
            "      7        \u001b[36m1.5286\u001b[0m  27.4412\n",
            "      8        \u001b[36m1.4974\u001b[0m  27.5960\n",
            "      9        \u001b[36m1.4471\u001b[0m  29.4978\n",
            "     10        1.4492  30.8367\n",
            "0.4458\n",
            "---Query no:  14 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2857\u001b[0m  27.6302\n",
            "      2        \u001b[36m1.8901\u001b[0m  27.5118\n",
            "      3        \u001b[36m1.8236\u001b[0m  27.4913\n",
            "      4        \u001b[36m1.7558\u001b[0m  28.3190\n",
            "      5        \u001b[36m1.7297\u001b[0m  27.5061\n",
            "      6        \u001b[36m1.6824\u001b[0m  27.6026\n",
            "      7        \u001b[36m1.6459\u001b[0m  27.5462\n",
            "      8        1.6505  28.2711\n",
            "      9        \u001b[36m1.6234\u001b[0m  28.9145\n",
            "     10        \u001b[36m1.6007\u001b[0m  30.7416\n",
            "0.4586\n",
            "---Query no:  15 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3615\u001b[0m  27.7241\n",
            "      2        \u001b[36m1.9037\u001b[0m  27.5974\n",
            "      3        \u001b[36m1.8180\u001b[0m  28.4683\n",
            "      4        \u001b[36m1.7714\u001b[0m  27.5326\n",
            "      5        \u001b[36m1.7302\u001b[0m  27.5675\n",
            "      6        \u001b[36m1.6999\u001b[0m  28.9126\n",
            "      7        \u001b[36m1.6606\u001b[0m  28.0004\n",
            "      8        \u001b[36m1.6453\u001b[0m  27.5636\n",
            "      9        \u001b[36m1.5952\u001b[0m  28.7311\n",
            "     10        1.6055  30.6958\n",
            "0.3996\n",
            "---Query no:  16 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5147\u001b[0m  27.6425\n",
            "      2        \u001b[36m2.3033\u001b[0m  28.4541\n",
            "      3        2.3034  27.5820\n",
            "      4        2.3035  27.6311\n",
            "      5        2.3035  28.0577\n",
            "      6        2.3035  27.9360\n",
            "      7        2.3035  27.6312\n",
            "      8        2.3035  27.7776\n",
            "      9        2.3035  29.7423\n",
            "     10        2.3035  30.0515\n",
            "0.1\n",
            "---Query no:  17 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4045\u001b[0m  28.4662\n",
            "      2        \u001b[36m1.9055\u001b[0m  28.6296\n",
            "      3        \u001b[36m1.8355\u001b[0m  27.5847\n",
            "      4        \u001b[36m1.7739\u001b[0m  28.4256\n",
            "      5        \u001b[36m1.7462\u001b[0m  28.1153\n",
            "      6        \u001b[36m1.7054\u001b[0m  27.7797\n",
            "      7        \u001b[36m1.6844\u001b[0m  28.3301\n",
            "      8        \u001b[36m1.6593\u001b[0m  27.7945\n",
            "      9        \u001b[36m1.6572\u001b[0m  28.8573\n",
            "     10        \u001b[36m1.6219\u001b[0m  30.8708\n",
            "0.445\n",
            "---Query no:  18 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2789\u001b[0m  27.7066\n",
            "      2        \u001b[36m1.9326\u001b[0m  28.1132\n",
            "      3        \u001b[36m1.8289\u001b[0m  28.1926\n",
            "      4        \u001b[36m1.7556\u001b[0m  27.5967\n",
            "      5        \u001b[36m1.7131\u001b[0m  27.6049\n",
            "      6        \u001b[36m1.6616\u001b[0m  28.5508\n",
            "      7        \u001b[36m1.6295\u001b[0m  27.7212\n",
            "      8        \u001b[36m1.5793\u001b[0m  27.7271\n",
            "      9        \u001b[36m1.5618\u001b[0m  30.7269\n",
            "     10        \u001b[36m1.5583\u001b[0m  30.3461\n",
            "0.4232\n",
            "---Query no:  19 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3553\u001b[0m  28.6045\n",
            "      2        \u001b[36m1.8963\u001b[0m  27.6976\n",
            "      3        \u001b[36m1.7123\u001b[0m  27.7290\n",
            "      4        \u001b[36m1.6490\u001b[0m  28.0958\n",
            "      5        \u001b[36m1.5910\u001b[0m  28.2579\n",
            "      6        \u001b[36m1.5371\u001b[0m  27.7328\n",
            "      7        \u001b[36m1.4725\u001b[0m  27.7437\n",
            "      8        \u001b[36m1.4289\u001b[0m  28.6361\n",
            "      9        \u001b[36m1.4230\u001b[0m  29.0365\n",
            "     10        \u001b[36m1.4005\u001b[0m  30.5432\n",
            "0.4376\n",
            "---Query no:  20 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4752\u001b[0m  27.7698\n",
            "      2        \u001b[36m2.0589\u001b[0m  27.7478\n",
            "      3        \u001b[36m2.0264\u001b[0m  28.5224\n",
            "      4        \u001b[36m1.9917\u001b[0m  27.7999\n",
            "      5        2.0047  28.9075\n",
            "      6        \u001b[36m1.9502\u001b[0m  28.5687\n",
            "      7        1.9514  27.8342\n",
            "      8        \u001b[36m1.9386\u001b[0m  27.9059\n",
            "      9        \u001b[36m1.9047\u001b[0m  29.8923\n",
            "     10        \u001b[36m1.8806\u001b[0m  30.2956\n",
            "0.3426\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[263  55   7  10   9   9   4  13  82  48]\n",
            " [ 40 257   5  21   0  11   7  13  85  61]\n",
            " [ 58  31  26  84 104  43  48  61  29  16]\n",
            " [ 27  29  29 197  30  43  53  34  31  27]\n",
            " [ 33  18  12  71 166  23  60  64  34  19]\n",
            " [ 17  36  24 147  29 101  39  38  45  24]\n",
            " [  2  19  13 138 109  26 135  35  13  10]\n",
            " [ 29  41  24  44  33  24  18 204  29  54]\n",
            " [193  54   4  19   0  10   1   6 168  45]\n",
            " [ 48  96   5  29   3  13   4  13  93 196]]\n",
            "Accuracy:  0.3426\n",
            "Macro F1-score:  0.32908752323229573\n",
            "Micro F1-score:  0.3426\n",
            "Weighted F1-score:  0.32908752323229573\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "AL_Retrain(10000, 20, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jTBCnTveiTIs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4b7c6f4-237e-4f26-fcd6-1b6ec1674566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2946\u001b[0m  24.1496\n",
            "      2        \u001b[36m1.9393\u001b[0m  17.8882\n",
            "      3        \u001b[36m1.8359\u001b[0m  17.6566\n",
            "      4        \u001b[36m1.7776\u001b[0m  17.8736\n",
            "      5        \u001b[36m1.7190\u001b[0m  17.8636\n",
            "      6        \u001b[36m1.6822\u001b[0m  17.5761\n",
            "      7        \u001b[36m1.6275\u001b[0m  18.1591\n",
            "      8        \u001b[36m1.6148\u001b[0m  17.5270\n",
            "      9        \u001b[36m1.5610\u001b[0m  17.8811\n",
            "     10        \u001b[36m1.5387\u001b[0m  17.9679\n",
            "No of initial data:  10000\n",
            "0.408\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[295   7  25  10  30   9   6  27  62  29]\n",
            " [ 35 198  13  10  16  17  23  27  32 129]\n",
            " [ 27   5 103  31 193  62  38  36   4   1]\n",
            " [ 20   4  40  96 100  88  91  44   8   9]\n",
            " [ 22   1  37  26 281  37  47  39   7   3]\n",
            " [  9   8  55  59  80 193  62  27   4   3]\n",
            " [  3   6  29  35 180  25 205  12   1   4]\n",
            " [ 15   3  39  23 157  43  11 202   2   5]\n",
            " [140  11  17  16  21   6   5  12 243  29]\n",
            " [ 43  42   9  12  23   8  24  71  44 224]]\n",
            "Accuracy:  0.408\n",
            "Macro F1-score:  0.4079767528316472\n",
            "Micro F1-score:  0.408\n",
            "Weighted F1-score:  0.4079767528316472\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[9, 4, 0, 9, 7, 2, 6, 2, 7, 9, 7, 6, 5, 3, 7, 0, 1, 2, 5, 3, 1, 4, 6, 4, 0, 3, 3, 7, 3, 9, 1, 2, 4, 5, 9, 0, 7, 7, 0, 2, 3, 2, 7, 9, 7, 1, 3, 3, 9, 4, 3, 5, 6, 2, 1, 3, 8, 7, 4, 3, 9, 5, 1, 7, 6, 5, 0, 6, 9, 3, 5, 1, 3, 4, 3, 1, 4, 0, 9, 6, 3, 2, 6, 4, 9, 1, 7, 9, 3, 0, 6, 2, 5, 1, 6, 2, 4, 6, 4, 3, 9, 0, 2, 2, 8, 5, 4, 9, 9, 0, 2, 4, 4, 3, 3, 1, 8, 6, 2, 5, 4, 3, 4, 2, 9, 3, 0, 6, 4, 1, 9, 3, 3, 9, 9, 4, 5, 2, 7, 9, 3, 4, 1, 1, 4, 2, 3, 7, 9, 0, 3, 4, 3, 1, 1, 0, 6, 1, 0, 2, 2, 9, 5, 1, 0, 5, 7, 2, 2, 6, 1, 0, 4, 2, 2, 7, 7, 3, 1, 5, 7, 5, 2, 9, 9, 2, 8, 2, 1, 0, 1, 7, 1, 9, 8, 1, 3, 4, 3, 8, 3, 1, 3, 0, 8, 6, 3, 6, 9, 1, 5, 8, 6, 4, 9, 2, 9, 4, 5, 8, 3, 4, 3, 3, 9, 3, 3, 7, 7, 7, 6, 5, 2, 3, 5, 6, 1, 7, 0, 3, 7, 3, 4, 2, 2, 2, 9, 2, 2, 5, 6, 2, 2, 1, 5, 6, 2, 6, 0, 7, 1, 3, 2, 4, 0, 2, 8, 7, 4, 4, 3, 0, 2, 8, 2, 2, 4, 5, 5, 4, 6, 8, 2, 7, 4, 3, 4, 2, 4, 7, 8, 3, 3, 7, 2, 8, 3, 6, 9, 1, 4, 4, 6, 2, 6, 2, 8, 3, 6, 5, 5, 7, 5, 0, 2, 7, 1, 9, 5, 2, 9, 5, 8, 7, 2, 2, 8, 9, 7, 7, 1, 3, 6, 8, 1, 7, 4, 7, 9, 9, 9, 1, 7, 9, 7, 3, 3, 9, 5, 0, 5, 2, 9, 9, 5, 4, 3, 9, 3, 8, 6, 3, 5, 3, 3, 6, 4, 0, 4, 2, 1, 4, 5, 1, 6, 3, 4, 8, 0, 8, 2, 5, 6, 3, 5, 5, 4, 2, 7, 1, 0, 7, 4, 9, 2, 4, 6, 6, 4, 2, 5, 0, 8, 7, 1, 4, 8, 0, 9, 2, 3, 8, 4, 3, 1, 3, 7, 3, 4, 8, 4, 2, 5, 9, 7, 7, 9, 9, 5, 5, 9, 3, 8, 4, 8, 5, 9, 7, 4, 1, 4, 4, 3, 5, 2, 7, 5, 1, 6, 4, 2, 7, 6, 1, 6, 9, 3, 9, 2, 5, 9, 6, 3, 2, 0, 1, 2, 6, 2, 6, 3, 3, 0, 8, 5, 7, 0, 8, 8, 9, 6, 7, 9, 2, 3, 1, 8, 5, 2, 5, 4, 5, 5, 5, 5, 9, 3, 2, 3, 1, 7, 4, 5, 2, 6, 2, 4, 5, 2, 7, 6, 6, 4, 6, 5, 1, 3, 7, 7, 0, 2, 2, 5, 6, 7, 2, 2, 9, 7, 7, 0, 8, 3, 9, 0, 3, 8, 5, 8, 8, 6, 3, 5, 9, 1, 9, 4, 4, 7, 3, 7, 0, 6, 0, 1, 5, 1, 3, 6, 5, 7, 9, 0, 8, 9, 6, 3, 4, 5, 0, 4, 2, 9, 7, 5, 4, 1, 6, 3, 3, 3, 6, 2, 5, 6, 2, 2, 3, 3, 2, 2, 5, 1, 7, 2, 0, 4, 9, 3, 5, 1, 4, 9, 1, 8, 0, 9, 6, 9, 3, 2, 5, 7, 5, 3, 3, 4, 5, 5, 9, 7, 5, 5, 7, 0, 5, 8, 1, 7, 5, 1, 3, 7, 3, 3, 6, 9, 9, 5, 8, 9, 3, 5, 5, 1, 2, 8, 8, 8, 6, 4, 7, 3, 4, 5, 0, 6, 1, 7, 3, 6, 8, 2, 1, 8, 9, 8, 6, 1, 5, 3, 6, 5, 3, 2, 1, 0, 2, 1, 5, 9, 9, 5, 1, 3, 8, 4, 3, 9, 2, 7, 6, 2, 3, 4, 1, 2, 4, 6, 2, 3, 9, 9, 3, 5, 0, 9, 7, 3, 7, 7, 3, 1, 6, 3, 5, 5, 7, 2, 3, 3, 9, 7, 1, 6, 2, 9, 4, 3, 0, 3, 3, 4, 3, 1, 5, 1, 4, 2, 6, 0, 4, 5, 1, 3, 2, 5, 5, 2, 2, 6, 8, 0, 1, 0, 7, 5, 7, 9, 3, 4, 1, 4, 4, 1, 3, 3, 6, 2, 5, 8, 7, 5, 3, 1, 4, 5, 2, 6, 6, 0, 9, 6, 4, 7, 9, 3, 4, 4, 3, 5, 1, 9, 1, 1, 7, 3, 3, 4, 5, 0, 2, 2, 9, 7, 0, 5, 7, 9, 3, 3, 9, 2, 6, 7, 2, 5, 2, 4, 4, 3, 3, 9, 2, 3, 2, 4, 3, 2, 5, 5, 3, 7, 3, 5, 3, 5, 5, 6, 9, 2, 9, 6, 4, 9, 0, 3, 0, 9, 7, 9, 9, 3, 7, 5, 6, 5, 4, 2, 5, 7, 5, 7, 8, 8, 5, 3, 9, 5, 6, 1, 5, 1, 5, 5, 5, 3, 5, 1, 9, 7, 6, 1, 5, 1, 4, 7, 2, 1, 8, 2, 5, 8, 5, 8, 9, 3, 5, 3, 7, 3, 5, 6, 3, 4, 2, 6, 6, 5, 6, 2, 2, 1, 7, 7, 8, 6, 3, 1, 1, 3, 8, 5, 7, 9, 1, 9, 7, 5, 3, 6, 5, 8, 9, 0, 1, 2, 5, 1, 9, 5, 3, 1, 4, 9, 7, 6, 5, 2, 7, 1, 9, 7, 5, 1, 5, 7, 3, 6, 4, 2, 1, 2, 0, 8, 5, 4, 5, 5, 7, 2, 9, 7, 1, 5, 7, 8, 2, 5, 9, 0, 9, 7, 2, 9, 2, 5, 9, 3, 7, 4, 9, 9, 5, 3, 1, 9, 5, 1, 2, 7, 2, 4, 4, 0, 5, 7, 1, 2, 4, 6, 5, 8, 6, 3, 5, 5, 3, 3, 3, 3, 9, 5, 5, 1, 6, 3, 7, 5, 6, 3, 9, 4, 5, 9, 6, 4, 8, 2, 2, 7, 0, 2, 3, 0, 1, 7, 1, 0, 2, 6, 9, 8, 5, 3, 1, 7, 3, 1, 3, 5, 6, 2, 6, 0, 2, 6, 3, 9, 9, 3, 6, 1, 5, 3, 1, 5, 4, 8, 5, 4, 3, 3, 8, 2, 7, 2, 1, 2, 3, 2, 4, 9, 6, 4, 3, 6, 1, 9, 7, 2, 1, 6, 2, 5, 8, 2, 1, 5, 2, 6, 5, 2, 6, 2, 5, 6, 6, 2, 5, 7, 4, 0, 2, 1, 7, 2, 3, 1, 1, 1, 6, 7, 4, 3, 3, 3, 2, 2, 2, 2, 8, 1, 4, 5, 1, 7, 4, 3, 3, 3, 4, 6, 6, 6, 4, 5, 5, 4, 1, 6, 1, 5, 7, 6, 8, 6, 9, 9, 4, 4, 7, 6, 9, 9, 3, 3, 1, 9, 1, 9, 2, 8, 1, 1, 8, 4, 2, 1, 5, 3, 7, 3, 1, 1, 5, 3, 4, 6, 3, 7, 3, 5, 3, 7, 8, 7, 7, 3, 8, 7, 3, 3, 4, 6, 5, 9, 5, 5, 5, 9, 2, 7, 4, 1, 2, 8, 5, 6, 2, 8, 4, 0, 4, 4, 0, 1, 5, 1, 7, 5, 3, 4, 2, 0, 9, 4, 5, 3, 6, 3, 7, 5, 1, 1, 0, 0, 0, 5, 5, 1, 3, 3, 5, 8, 3, 4, 6, 8, 5, 3, 2, 9, 2, 0, 9, 8, 4, 4, 3, 9, 8, 5, 2, 3, 6, 7, 3, 1, 4, 3, 0, 5, 5, 5, 3, 9, 1, 6, 5, 9, 9, 0, 3, 5, 0, 8, 7, 1, 2, 7, 3, 8, 4, 2, 3, 5, 1, 9, 2, 9, 7, 9, 3, 1, 3, 7, 3, 6, 1, 4, 3, 5, 6, 3, 3, 1, 7, 5, 6, 1, 6, 1, 7, 4, 5, 3, 4, 3, 3, 9, 5, 0, 1, 7, 1, 3, 5, 5, 6, 8, 7, 0, 9, 0, 1, 2, 3, 5, 5, 8, 8, 5, 7, 8, 5, 1, 1, 3, 2, 6, 9, 5, 3, 3, 0, 6, 3, 9, 1, 7, 8, 5, 4, 9, 7, 6, 2, 4, 9, 2, 7, 3, 9, 8, 1, 3, 9, 4, 9, 0, 8, 6, 4, 9, 3, 5, 3, 3, 1, 1, 3, 3, 7, 7, 6, 3, 7, 8, 4, 7, 2, 2, 4, 0, 3, 8, 0, 7, 0, 4, 0, 5, 4, 8, 1, 3, 1, 5, 2, 6, 8, 8, 1, 2, 3, 6, 7, 9, 7, 5, 6, 5, 2, 2, 0, 6, 1, 3, 7, 1, 4, 2, 7, 6, 4, 1, 0, 2, 1, 4, 6, 4, 5, 7, 1, 7, 0, 9, 1, 4, 8, 1, 2, 1, 5, 2, 8, 3, 3, 9, 4, 7, 7, 0, 5, 9, 7, 0, 5, 1, 9, 6, 6, 3, 2, 1, 3, 2, 9, 0, 2, 3, 9, 9, 1, 9, 2, 7, 4, 1, 5, 1, 1, 9, 8, 3, 2, 0, 0, 5, 3, 0, 0, 7, 0, 8, 3, 5, 6, 3, 7, 5, 7, 9, 7, 3, 4, 3, 2, 8, 1, 1, 6, 5, 5, 3, 5, 4, 4, 6, 0, 6, 7, 3, 2, 2, 5, 4, 6, 3, 1, 7, 3, 7, 4, 1, 5, 9, 4, 0, 6, 1, 6, 4, 8, 9, 2, 9, 2, 3, 2, 2, 3, 4, 1, 7, 1, 3, 5, 8, 7, 2, 9, 4, 5, 5, 3, 6, 5, 3, 8, 4, 0, 4, 0, 5, 7, 0, 3, 3, 9, 4, 7, 1, 0, 4, 3, 4, 1, 0, 2, 2, 9, 6, 0, 5, 7, 8, 2, 6, 3, 8, 4, 3, 9, 9, 1, 3, 7, 4, 5, 0, 2, 8, 4, 7, 6, 6, 1, 6, 2, 8, 5, 9, 9, 0, 8, 1, 1, 3, 5, 3, 5, 5, 3, 7, 5, 6, 5, 4, 3, 1, 6, 8, 4, 9, 4, 8, 6, 4, 6, 5, 0, 7, 2, 1, 1, 6, 5, 3, 1, 1, 4, 4, 9, 3, 0, 2, 4, 9, 5, 7, 5, 5, 5, 1, 5, 9, 6, 4, 1, 7, 1, 0, 0, 3, 1, 9, 8, 5, 2, 9, 8, 4, 5, 2, 8, 0, 9, 9, 7, 5, 2, 1, 7, 2, 3, 2, 1, 6, 7, 7, 6, 6, 6, 5, 5, 3, 5, 7, 5, 1, 2, 5, 6, 2, 3, 9, 9, 9, 4, 2, 0, 1, 6, 1, 2, 6, 3, 5, 5, 6, 7, 2, 9, 5, 0, 7, 3, 3, 3, 0, 4, 7, 8, 7, 1, 5, 1, 7, 2, 6, 8, 7, 9, 6, 1, 6, 4, 7, 8, 3, 3, 0, 4, 3, 4, 6, 8, 9, 5, 1, 9, 3, 7, 7, 7, 2, 9, 2, 2, 3, 8, 1, 9, 5, 3, 3, 3, 9, 0, 8, 5, 5, 3, 9, 6, 8, 9, 0, 0, 5, 6, 4, 2, 8, 4, 9, 2, 9, 1, 9, 5, 7, 3, 2, 3, 3, 4, 6, 2, 2, 2, 5, 5, 3, 3, 7, 5, 3, 3, 3, 4, 9, 2, 3, 5, 2, 0, 1, 4, 2, 7, 8, 3, 5, 3, 9, 5, 4, 4, 3, 0, 5, 0, 0, 1, 9, 6, 4, 7, 9, 9, 2, 4, 0, 6, 7, 3, 2, 7, 4, 7, 6, 1, 4, 3, 5, 4, 3, 5, 7, 1, 3, 1, 2, 7, 6, 2, 9, 1, 9, 3, 9, 3, 9, 9, 1, 6, 8, 6, 5, 2, 0, 1, 7, 2, 2, 8, 0, 4, 7, 3, 7, 2, 8, 6, 5, 2, 3, 3, 3, 4, 0, 7, 6, 3, 1, 0, 8, 9, 7, 3, 4, 4, 4, 5, 5, 6, 8, 3, 9, 5, 3, 4, 1, 8, 3, 3, 2, 7, 9, 4, 3, 7, 3, 1, 3, 4, 8, 9, 5, 4, 4, 7, 9, 9, 9, 7, 1, 1, 9, 4, 3, 3, 6, 2, 9, 2, 0, 4, 3, 6, 3, 3, 0, 6, 5, 7, 3, 1, 4, 3, 5, 5, 4, 1, 3, 7, 5, 3, 9, 9, 4, 7, 8, 1, 3, 2, 7, 3, 1, 8, 4, 4, 4, 4, 2, 9, 7, 4, 7, 9, 4, 9, 7, 0, 3, 4, 9, 7, 3, 5, 6, 4, 0, 4, 0, 0, 4, 1, 8, 8, 8, 6, 6, 2, 9, 9, 8, 4, 2, 2, 0, 0, 5, 7, 9, 4, 5, 7, 5, 8, 5, 6, 6, 7, 5, 6, 7, 3, 8, 7, 9, 7, 4, 3, 0, 7, 7, 0, 2, 3, 8, 4, 6, 4, 2, 3, 8, 1, 7, 5, 5, 4, 0, 3, 8, 2, 1, 7, 4, 5, 1, 7, 1, 5, 4, 7, 3, 9, 5, 8, 8, 5, 5, 6, 1, 3, 3, 3, 1, 3, 6, 1, 5, 4, 3, 6, 6, 3, 5, 3, 4, 3, 6, 3, 6, 4, 9, 7, 4, 4, 9, 4, 1, 3, 9, 3, 1, 4, 5, 2, 9, 9, 4, 2, 5, 0, 3, 0, 4, 2, 5, 5, 5, 5, 2, 4, 7, 2, 3, 4, 4, 9, 1, 5, 1, 1, 5, 3, 9, 9, 7, 3, 0, 0, 5, 7, 3, 0, 7, 7, 4, 9, 6, 6, 1, 9, 6, 9, 4, 5, 1, 1, 0, 4, 2, 6, 6, 1, 4, 7, 3, 7, 7, 8, 8, 4, 7, 3, 9, 4, 9, 7, 9, 8, 9, 5, 7, 5, 7, 6, 5, 9, 2, 1, 9, 2, 0, 6, 5, 3, 2, 3, 7, 6, 7, 3, 7, 5, 5, 5, 8, 5, 3, 4, 4, 6, 4, 6, 1, 3, 5, 3, 6, 0, 0, 5, 8, 3, 3, 3, 5, 7, 5, 6, 5, 5, 1, 3, 5, 4, 9, 5, 4, 5, 2, 6, 3, 0, 9, 4, 2, 8, 6, 9, 5, 3, 4, 7, 2, 1, 5, 5, 3, 4, 3, 8, 9, 4, 4, 2, 4, 8, 7, 9, 9, 2, 8, 0, 3, 2, 4, 0, 6, 0, 1, 5, 9, 4, 5, 6, 8, 9, 0, 5, 7, 1, 5, 4, 1, 2, 4, 6, 7, 9, 3, 6, 9, 3, 4, 0, 3, 4, 5, 2, 7, 1, 3, 7, 8, 6, 7, 7, 5, 3, 4, 7, 1, 3, 4, 3, 8, 4, 6, 5, 8, 8, 5, 6, 6, 0, 9, 3, 7, 5, 1, 9, 3, 0, 1, 1, 8, 4, 9, 2, 0, 2, 9, 0, 7, 5, 1, 3, 3, 3, 8, 7, 9, 3, 1, 4, 9, 9, 2, 5, 3, 5, 9, 1, 4, 9, 3, 5, 9, 6, 1, 5, 6, 7, 6, 7, 5, 5, 7, 0, 6, 9, 3, 8, 0, 3, 4, 6, 1, 1, 3, 6, 5, 7, 1, 6, 4, 5, 9, 6, 1, 7, 4, 8, 6, 2, 6, 3, 4, 1, 6, 1, 3, 7, 7, 4, 7, 0, 2, 5, 2, 3, 7, 1, 3, 3, 7, 6, 2, 4, 6, 7, 5, 3, 4, 3, 7, 9, 7, 0, 2, 7, 5, 8, 2, 9, 3, 5, 5, 3, 2, 3, 8, 9, 9, 2, 1, 3, 8, 1, 1, 8, 5, 6, 7, 5, 5, 5, 4, 5, 1, 8, 5, 1, 9, 3, 3, 8, 7, 8, 2, 1, 3, 5, 1, 3, 8, 5, 3, 0, 3, 9, 3, 5, 3, 2, 6, 9, 1, 6, 4, 0, 4, 7, 1, 3, 7, 7, 3, 9, 9, 5, 6, 7, 7, 6, 1, 3, 7, 3, 3, 5, 9, 2, 5, 6, 1, 1, 7, 3, 8, 3, 2, 0, 2, 7, 0, 1, 0, 3, 1, 6, 8, 4, 5, 8, 3, 9, 6, 2, 0, 4, 8, 3, 2, 4, 3, 3, 9, 7, 4, 3, 7, 4, 5, 4, 0, 5, 2, 2, 0, 5, 3, 5, 4, 1, 9, 2, 4, 5, 7, 2, 9, 3, 2, 1, 4, 0, 2, 4, 6, 5, 1, 6, 5, 1, 3, 3, 1, 2, 6, 2, 2, 8, 5, 1, 9, 1, 7, 9, 0, 1, 6, 8, 0, 8, 6, 3, 8, 4, 7, 4, 1, 0, 7, 5, 6, 3, 1, 2, 1, 9, 6, 6, 9, 3, 1, 4, 2, 0, 9, 7, 5, 5, 3, 3, 9, 9, 8, 7, 3, 0, 4, 4, 3, 2, 1, 5, 9, 5, 8, 6, 6, 6, 7, 4, 3, 4, 6, 6, 0, 5, 9, 5, 3, 5, 2, 9, 4, 2, 0, 6, 6, 9, 7, 0, 3, 7, 2, 6, 3, 8, 7, 5, 2, 9, 4, 0, 3, 3, 9, 5, 2, 2, 6, 2, 0, 0, 4, 2, 0, 0, 7, 3, 0, 5, 8, 7, 3, 0, 2, 2, 1, 4, 1, 0, 3, 5, 3, 5, 9, 2, 7, 5, 2, 3, 1, 9, 2, 0, 4, 2, 2, 2, 3, 6, 7, 3, 5, 1, 2, 3, 4, 0, 0, 5, 5, 9, 3, 6, 3, 1, 4, 8, 1, 3, 2, 3, 9, 0, 3, 7, 7, 6, 3, 1, 5, 7, 1, 6, 5, 9, 6, 0, 5, 1, 9, 5, 9, 1, 0, 1, 5, 5, 9, 4, 5, 9, 8, 5, 8, 6, 5, 1, 9, 8, 1, 4, 5, 0, 1, 7, 4, 6, 3, 9, 5, 8, 9, 7, 3, 1, 3, 5, 6, 3, 5, 0, 9, 1, 4, 7, 3, 6, 7, 5, 1, 1, 4, 6, 6, 3, 3, 9, 9, 1, 8, 8, 8, 4, 5, 2, 3, 2, 5, 4, 2, 4, 3, 7, 4, 3, 1, 5, 2, 5, 1, 2, 5, 0, 3, 8, 3, 7, 3, 9, 5, 7, 1, 5, 4, 5, 3, 3, 5, 1, 6, 8, 6, 9, 2, 4, 4, 5, 4, 0, 8, 3, 2, 3, 7, 0, 8, 3, 0, 1, 7, 5, 2, 6, 3, 7, 8, 6, 6, 2, 2, 7, 1, 5, 3, 2, 5, 6, 8, 9, 0, 1, 7, 4, 5, 9, 6, 9, 7, 2, 7, 9, 2, 3, 1, 5, 0, 5, 5, 7, 9, 9, 5, 2, 7, 7, 9, 6, 6, 0, 0, 8, 7, 3, 6, 4, 6, 9, 1, 8, 3, 3, 7, 2, 3, 6, 5, 2, 3, 6, 0, 1, 2, 3, 5, 1, 3, 0, 4, 8, 8, 7, 4, 3, 5, 2, 1, 5, 7, 1, 5, 5, 3, 1, 1, 6, 4, 2, 2, 5, 8, 3, 3, 2, 3, 3, 5, 2, 2, 7, 5, 1, 3, 2, 2, 8, 0, 5, 5, 5, 9, 9, 6, 8, 4, 8, 1, 4, 6, 3, 2, 6, 5, 3, 9, 7, 5, 4, 3, 3, 3, 2, 7, 1, 7, 1, 2, 2, 2, 2, 6, 2, 7, 1, 6, 7, 1, 2, 1, 5, 7, 8, 8, 0, 9, 0, 2, 4, 0, 8, 7, 2, 1, 9, 1, 3, 6, 3, 4, 3, 9, 4, 3, 3, 3, 0, 3, 7, 2, 5, 9, 7, 9, 5, 3, 2, 2, 5, 5, 7, 0, 2, 2, 0, 5, 5, 5, 5, 6, 2, 2, 8, 1, 4, 3, 1, 9, 5, 5, 3, 1, 1, 1, 3, 7, 0, 3, 9, 2, 4, 3, 2, 6, 7, 9, 3, 2, 2, 3, 6, 2, 3, 6, 1, 9, 1, 7, 4, 3, 5, 2, 3, 9, 8, 6, 4, 9, 1, 7, 9, 5, 1, 2, 3, 3, 1, 3, 8, 2, 5, 3, 7, 2, 3, 2, 1, 1, 4, 3, 2, 3, 3, 0, 3, 5, 3, 7, 9, 1, 8, 5, 2, 2, 4, 4, 9, 4, 7, 2, 6, 9, 4, 9, 2, 8, 5, 6, 3, 3, 4, 4, 5, 6, 6, 5, 6, 7, 3, 4, 3, 9, 9, 3, 2, 3, 9, 0, 2, 4, 5, 2, 4, 7, 3, 9, 4, 6, 9, 2, 2, 3, 5, 5, 6, 1, 1, 7, 2, 4, 0, 9, 0, 1, 8, 2, 1, 5, 3, 9, 3, 3, 8, 1, 5, 6, 3, 7, 6, 6, 2, 2, 7, 1, 5, 3, 2, 4, 7, 4, 8, 1, 5, 9, 5, 1, 8, 1, 3, 8, 1, 4, 9, 0, 9, 3, 1, 2, 3, 2, 2, 3, 1, 2, 0, 7, 3, 8, 7, 4, 5, 2, 3, 5, 2, 7, 5, 2, 8, 6, 6, 3, 9, 3, 5, 3, 2, 6, 7, 5, 2, 5, 5, 2, 3, 7, 8, 2, 1, 2, 0, 8, 1, 3, 2, 8, 6, 1, 7, 1, 7, 9, 5, 4, 6, 0, 5, 2, 5, 5, 8, 3, 5, 3, 6, 3, 8, 4, 7, 2, 3, 0, 2, 6, 1, 1, 3, 3, 8, 2, 5, 1, 3, 1, 6, 6, 3, 2, 8, 2, 7, 9, 2, 1, 5, 8, 2, 3, 9, 4, 3, 1, 0, 6, 5, 3, 2, 7, 5, 4, 3, 3, 4, 5, 3, 5, 1, 6, 5, 0, 5, 2, 2, 4, 9, 9, 9, 2, 3, 6, 9, 4, 1, 5, 0, 4, 9, 3, 4, 2, 6, 5, 7, 1, 5, 1, 9, 0, 6, 2, 1, 3, 3, 4, 2, 9, 3, 0, 3, 3, 9, 5, 7, 3, 3, 7, 3, 9, 1, 2, 4, 5, 8, 9, 9, 6, 0, 9, 7, 3, 4, 5, 1, 5, 9, 4, 0, 2, 1, 4, 8, 6, 1, 3, 9, 1, 3, 9, 3, 0, 2, 1, 3, 4, 6, 0, 7, 9, 1, 5, 9, 6, 3, 3, 5, 1, 3, 4, 7, 8, 4, 3, 6, 5, 5, 5, 3, 1, 8, 4, 2, 4, 7, 0, 5, 5, 4, 2, 2, 2, 9, 3, 3, 1, 7, 5, 2, 5, 7, 3, 2, 6, 3, 3, 2, 0, 4, 3, 0, 8, 2, 2, 5, 4, 3, 6, 7, 1, 1, 4, 6, 2, 2, 0, 3, 1, 1, 1, 9, 4, 3, 9, 8, 2, 3, 4, 5, 7, 9, 3, 3, 5, 1, 9, 4, 9, 6, 3, 6, 4, 7, 9, 5, 2, 1, 4, 4, 6, 5, 6, 7, 4, 1, 3, 6, 1, 9, 1, 7, 7, 7, 3, 3, 9, 1, 9, 4, 9, 9, 1, 2, 6, 5, 3, 5, 7, 3, 5, 9, 4, 4, 7, 3, 6, 8, 3, 9, 7, 5, 5, 5, 3, 2, 3, 7, 9, 2, 3, 3, 7, 5, 5, 2, 6, 5, 6, 6, 7, 2, 2, 0, 0, 3, 3, 8, 2, 6, 0, 0, 3, 7, 4, 4, 7, 9, 0, 5, 7, 2, 4, 0, 4, 5, 4, 1, 4, 7, 8, 5, 5, 3, 6, 8, 9, 4, 5, 8, 7, 0, 8, 9, 9, 5, 0, 4, 6, 7, 1, 4, 2, 4, 6, 5, 4, 4, 3, 7, 9, 7, 5, 6, 4, 6, 6, 4, 1, 0, 6, 7, 5, 2, 4, 3, 9, 7, 6, 1, 6, 5, 3, 5, 3, 5, 3, 0, 6, 9, 2, 7, 7, 1, 1, 6, 3, 9, 1, 6, 6, 1, 0, 1, 4, 1, 3, 6, 6, 6, 7, 7, 1, 5, 6, 1, 4, 1, 2, 5, 5, 7, 4, 1, 3, 4, 7, 5, 8, 9, 2, 7, 6, 3, 1, 3, 5, 2, 6, 1, 3, 3, 4, 7, 1, 7, 2, 5, 1, 9, 9, 0, 5, 7, 0, 1, 2, 5, 9, 1, 9, 8, 0, 1, 7, 5, 3, 4, 0, 0, 9, 3, 5, 9, 7, 2, 1, 1, 3, 9, 4, 2, 7, 5, 2, 3, 1, 9, 5, 4, 5, 1, 9, 5, 2, 8, 5, 5, 1, 7, 0, 3, 2, 5, 3, 8, 2, 2, 3, 1, 5, 2, 5, 5, 4, 6, 1, 5, 1, 1, 2, 0, 4, 5, 7, 3, 4, 3, 7, 1, 6, 3, 9, 6, 5, 1, 1, 2, 0, 3, 2, 1, 1, 9, 8, 0, 6, 9, 6, 3, 5, 5, 3, 5, 2, 0, 4, 4, 4, 3, 5, 2, 6, 3, 4, 3, 7, 2, 1, 5, 2, 8, 5, 7, 1, 5, 1, 6, 5, 9, 8, 7, 5, 4, 9, 5, 3, 5, 9, 5, 2, 2, 1, 1, 8, 5, 5, 5, 7, 9, 9, 2, 3, 0, 0, 0, 1, 2, 7, 2, 9, 6, 3, 4, 1, 8, 7, 5, 9, 2, 4, 2, 6, 2, 1, 1, 3, 3, 3, 3, 1, 6, 3, 9, 0, 6, 5, 2, 6, 6, 2, 6, 1, 7, 6, 3, 5, 1, 0, 3, 2, 2, 3, 7, 3, 7, 7, 7, 1, 5, 9, 3, 4, 5, 4, 6, 1, 7, 8, 2, 4, 3, 5, 2, 7, 1, 4, 5, 2, 4, 3, 1, 7, 0, 7, 5, 3, 3, 4, 4, 7, 1, 8, 1, 8, 4, 6, 8, 7, 2, 6, 6, 3, 1, 0, 3, 3, 6, 5, 3, 4, 5, 1, 2, 7, 3, 2, 1, 0, 8, 1, 3, 3, 5, 2, 9, 5, 4, 3, 4, 7, 1, 4, 0, 3, 9, 7, 9, 2, 3, 9, 7, 7, 4, 3, 9, 3, 2, 1, 2, 3, 3, 8, 7, 4, 3, 0, 0, 9, 7, 0, 5, 6, 7, 3, 5, 9, 3, 5, 7, 4, 7, 0, 1, 1, 6, 9, 3, 2, 3, 7, 3, 5, 3, 3, 4, 9, 4, 3, 3, 3, 1, 0, 2, 2, 4, 6, 6, 1, 3, 3, 0, 4, 5, 0, 9, 9, 3, 0, 8, 5, 5, 2, 2, 6, 2, 1, 5, 3, 5, 7, 2, 1, 4, 1, 7, 0, 5, 3, 2, 6, 7, 7, 5, 6, 0, 2, 5, 1, 7, 8, 8, 9, 5, 9, 9, 2, 2, 1, 5, 5, 5, 7, 9, 3, 9, 4, 5, 3, 3, 5, 7, 6, 9, 6, 5, 5, 5, 7, 0, 0, 4, 2, 2, 1, 9, 3, 3, 7, 3, 1, 5, 6, 2, 6, 4, 6, 2, 1, 8, 6, 2, 5, 5, 3, 9, 4, 0, 4, 0, 2, 1, 5, 2, 4, 7, 2, 7, 5, 3, 2, 6, 3, 9, 3, 6, 1, 6, 6, 4, 0, 5, 7, 5, 3, 8, 8, 3, 4, 9, 7, 4, 0, 6, 3, 2, 7, 8, 9, 7, 3, 1, 6, 1, 3, 7, 5, 2, 3, 2, 9, 9, 2, 6, 9, 1, 7, 2, 2, 1, 6, 6, 6, 7, 5, 8, 6, 1, 6, 6, 3, 5, 5, 4, 3, 9, 5, 1, 9, 5, 7, 7, 7, 1, 7, 9, 8, 3, 6, 1, 7, 4, 7, 6, 2, 9, 6, 0, 1, 4, 3, 2, 6, 7, 5, 0, 3, 8, 2, 1, 3, 7, 9, 1, 2, 5, 8, 1, 3, 3, 7, 6, 0, 3, 4, 4, 3, 5, 2, 3, 1, 5, 7, 3, 3, 0, 8, 2, 8, 8, 3, 5, 0, 7, 3, 5, 1, 2, 2, 2, 0, 3, 7, 6, 3, 4, 6, 5, 4, 4, 3, 9, 6, 8, 8, 7, 5, 2, 0, 1, 8, 2, 2, 1, 3, 7, 2, 9, 5, 9, 5, 7, 3, 7, 7, 6, 1, 2, 4, 9, 4, 2, 1, 3, 8, 7, 6, 2, 1, 5, 5, 4, 3, 6, 3, 0, 0, 7, 6, 2, 4, 4, 8, 9, 1, 6, 6, 5, 3, 9, 8, 3, 5, 4, 1, 7, 5, 2, 2, 8, 7, 5, 3, 9, 3, 9, 1, 4, 3, 5, 0, 5, 5, 6, 8, 5, 5, 5, 4, 4, 5, 4, 5, 3, 4, 2, 1, 9, 4, 2, 5, 3, 4, 5, 7, 9, 2, 4, 2, 7, 0, 6, 9, 2, 4, 3, 5, 3, 1, 6, 9, 4, 8, 2, 3, 3, 1, 6, 4, 5, 7, 7, 3, 6, 1, 7, 8, 9, 3, 0, 0, 5, 5, 2, 3, 4, 9, 6, 8, 7, 5, 5, 1, 5, 1, 8, 0, 2, 3, 1, 4, 9, 3, 5, 3, 9, 5, 6, 6, 7, 1, 8, 4, 9, 7, 7, 8, 6, 6, 5, 2, 6, 8, 8, 7, 3, 0, 4, 7, 8, 8, 5, 2, 1, 2, 3, 2, 6, 8, 9, 6, 7, 7, 4, 0, 6, 1, 5, 4, 6, 5, 0, 5, 0, 5, 8, 2, 8, 9, 4, 6, 2, 4, 2, 7, 1, 5, 7, 6, 3, 3, 1, 1, 5, 1, 3, 1, 7, 8, 3, 5, 7, 6, 2, 3, 3, 1, 6, 6, 1, 6, 0, 6, 3, 6, 9, 7, 3, 3, 1, 6, 3, 0, 6, 6, 1, 8, 4, 2, 7, 9, 3, 3, 7, 0, 4, 6, 1, 9, 0, 7, 9, 9, 2, 9, 8, 2, 6, 0, 2, 2, 7, 3, 2, 8, 8, 3, 6, 8, 5, 7, 5, 0, 2, 3, 5, 9, 2, 2, 8, 1, 5, 3, 5, 9, 0, 9, 4, 0, 1, 4, 9, 3, 4, 1, 8, 6, 7, 7, 3, 7, 5, 9, 2, 3, 8, 1, 4, 7, 5, 1, 6, 3, 5, 8, 1, 2, 5, 5, 9, 4, 6, 3, 1, 9, 4, 9, 2, 2, 3, 2, 7, 7, 5, 5, 4, 3, 2, 4, 8, 7, 9, 7, 1, 9, 8, 5, 2, 4, 6, 5, 7, 3, 1, 1, 9, 2, 9, 9, 3, 7, 1, 3, 9, 8, 9, 2, 1, 6, 6, 5, 2, 5, 5, 1, 7, 1, 1, 9, 4, 3, 2, 1, 2, 1, 5, 7, 2, 9, 5, 6, 7, 1, 9, 7, 0, 2, 8, 0, 5, 6, 6, 5, 2, 7, 2, 0, 9, 4, 3, 4, 2, 2, 5, 9, 0, 9, 4, 1, 4, 2, 4, 0, 3, 8, 1, 5, 1, 1, 2, 0, 7, 6, 2, 9, 7, 5, 3, 2, 8, 1, 7, 4, 4, 1, 0, 6, 2, 9, 9, 0, 1, 5, 7, 7, 4, 3, 5, 8, 3, 3, 6, 3, 4, 9, 4, 7, 0, 3, 3, 3, 1, 0, 5, 6, 4, 5, 0, 5, 4, 6, 9, 8, 9, 1, 7, 1, 8, 6, 7, 7, 4, 9, 5, 9, 8, 7, 4, 3, 6, 2, 5, 4, 5, 5, 3, 3, 1, 9, 3, 1, 6, 5, 2, 7, 3, 3, 4, 6, 1, 7, 5, 1, 8, 7, 3, 7, 3, 7, 5, 3, 0, 5, 5, 4, 9, 9, 3, 6, 2, 7, 0, 5, 4, 1, 2, 3, 4, 1, 8, 4, 0, 2, 6, 5, 7, 0, 8, 3, 6, 4, 7, 3, 1, 3, 7, 3, 4, 3, 1, 7, 4, 2, 8, 3, 6, 7, 2, 6, 4, 3, 3, 5, 3, 6, 7, 5, 5, 3, 5, 5, 9, 0, 4, 7, 9, 0, 6, 4, 7, 7, 7, 5, 4, 2, 9, 7, 1, 2, 7, 3, 1, 8, 9, 6, 7, 5, 1, 3, 1, 4, 4, 2, 9, 4, 5, 4, 1, 3, 6, 2, 7, 6, 1, 4, 0, 5, 9, 6, 3, 6, 1, 4, 1, 4, 3, 1, 5, 3, 3, 6, 7, 2, 2, 6, 1, 3, 6, 6, 2, 2, 4, 8, 3, 9, 7, 3, 5, 4, 5, 4, 3, 9, 4, 9, 5, 9, 5, 2, 0, 3, 8, 2, 3, 7, 3, 9, 2, 9, 8, 4, 1, 1, 7, 0, 3, 9, 8, 2, 3, 5, 9, 4, 1, 9, 9, 1, 1, 3, 2, 7, 1, 3, 3, 9, 1, 2, 6, 3, 5, 7, 7, 8, 9, 5, 6, 1, 1, 3, 9, 1, 8, 6, 7, 5, 5, 9, 2, 7, 3, 5, 8, 8, 3, 6, 4, 2, 9, 0, 4, 1, 9, 3, 7, 7, 2, 2, 5, 6, 0, 2, 2, 4, 2, 9, 2, 8, 4, 8, 5, 3, 3, 3, 8, 7, 6, 3, 5, 6, 1, 5, 2, 7, 4, 3, 5, 3, 6, 3, 5, 4, 9, 3, 4, 7, 2, 7, 6, 3, 6, 8, 4, 7, 4, 3, 3, 4, 6, 4, 6, 1, 0, 5, 0, 6, 7, 5, 7, 3, 6, 0, 5, 2, 2, 6, 4, 6, 2, 1, 6, 3, 5, 7, 9, 5, 2, 1, 4, 5, 4, 8, 7, 9, 9, 7, 8, 9, 6, 3, 0, 1, 3, 3, 5, 4, 2, 1, 3, 5, 0, 5, 6, 6, 4, 5, 9, 2, 6, 2, 4, 5, 0, 5, 6, 7, 8, 2, 4, 7, 5, 8, 4, 5, 3, 4, 5, 4, 3, 7, 4, 8, 5, 2, 3, 2, 3, 7, 8, 6, 6, 6, 9, 5, 0, 6, 4, 1, 8, 0, 2, 9, 0, 1, 7, 4, 0, 1, 6, 3, 9, 4, 5, 1, 5, 3, 3, 1, 7, 3, 0, 5, 0, 4, 4, 6, 1, 2, 9, 8, 4, 5, 6, 1, 3, 6, 7, 8, 2, 9, 9, 9, 1, 2, 3, 4, 4, 6, 0, 9, 3, 9, 3, 4, 8, 1, 6, 7, 4, 3, 5, 5, 7, 1, 9, 6, 9, 6, 8, 3, 2, 9, 5, 7, 6, 6, 4, 3, 6, 8, 1, 7, 1, 6, 2, 5, 8, 6, 5, 8, 1, 3, 2, 5, 0, 6, 9, 1, 3, 7, 9, 3, 7, 6, 7, 4, 8, 8, 4, 4, 5, 8, 5, 1, 3, 9, 3, 8, 1, 2, 7, 6, 5, 8, 0, 5, 9, 8, 3, 2, 4, 3, 9, 7, 6, 3, 6, 5, 4, 2, 1, 5, 2, 2, 2, 7, 6, 5, 2, 8, 4, 5, 1, 7, 2, 3, 5, 0, 9, 4, 5, 3, 3, 7, 5, 7, 7, 6, 8, 6, 8, 7, 3, 4, 4, 6, 6, 7, 1, 7, 7, 9, 9, 2, 7, 7, 0, 7, 6, 4, 2, 3, 8, 7, 9, 8, 5, 8, 9, 4, 2, 2, 6, 7, 3, 6, 6, 1, 5, 8, 2, 4, 4, 2, 1, 6, 2, 6, 2, 3, 3, 5, 5, 3, 7, 8, 3, 3, 7, 2, 7, 1, 5, 6, 5, 4, 6, 8, 3, 9, 0, 7, 2, 9, 2, 5, 5, 6, 0, 0, 3, 2, 6, 0, 2, 5, 5, 5, 0, 3, 1, 1, 2, 6, 7, 3, 0, 4, 3, 3, 2, 7, 6, 2, 8, 6, 5, 9, 1, 0, 5, 2, 8, 5, 1, 6, 2, 2, 9, 7, 5, 9, 7, 2, 8, 0, 9, 7, 3, 4, 6, 7, 6, 4, 4, 3, 5, 0, 6, 0, 7, 7, 0, 8, 3, 3, 5, 3, 2, 0, 3, 5, 3, 1, 4, 2, 5, 8, 0, 2, 2, 6, 0, 4, 2, 2, 3, 2, 3, 6, 5, 8, 4, 5, 2, 6, 9, 2, 9, 7, 8, 4, 4, 3, 8, 7, 7, 5, 2, 4, 4, 3, 4, 5, 2, 4, 4, 9, 5, 1, 9, 7, 3, 6, 0, 1, 5, 9, 8, 4, 6, 4, 2, 6, 3, 4, 9, 2, 3, 2, 4, 2, 0, 3, 7, 4, 2, 6, 0, 9, 2, 2, 9, 4, 3, 6, 0, 7, 4, 4, 3, 2, 6, 3, 1, 7, 8, 1, 3, 1, 5, 3, 6, 5, 7, 5, 2, 2, 5, 3, 3, 3, 1, 2, 1, 2, 6, 5, 9, 4, 5, 7, 1, 3, 1, 3, 3, 0, 3, 3, 4, 7, 1, 8, 9, 4, 5, 9, 9, 3, 7, 0, 5, 4, 4, 0, 6, 2, 3, 4, 4, 4, 0, 1, 3, 5, 5, 6, 7, 3, 2, 1, 3, 2, 6, 1, 6, 7, 8, 1, 1, 9, 8, 6, 8, 3, 4, 1, 4, 1, 7, 4, 7, 9, 4, 1, 8, 3, 5, 6, 9, 9, 6, 3, 9, 4, 8, 2, 1, 5, 6, 5, 5, 2, 5, 1, 5, 5, 4, 8, 2, 3, 5, 6, 2, 8, 4, 9, 6, 3, 3, 7, 2, 1, 9, 3, 7, 2, 3, 9, 5, 5, 9, 3, 2, 7, 7, 5, 4, 3, 7, 9, 6, 6, 2, 0, 4, 4, 7, 3, 2, 6, 9, 4, 5, 5, 4, 7, 8, 7, 0, 3, 3, 2, 5, 6, 7, 0, 5, 7, 2, 5, 2, 4, 6, 5, 3, 3, 6, 1, 3, 1, 5, 1, 7, 5, 4, 5, 4, 4, 7, 3, 2, 6, 2, 3, 3, 5, 2, 7, 3, 5, 5, 3, 9, 5, 6, 2, 3, 0, 5, 5, 4, 5, 4, 1, 0, 9, 8, 4, 0, 5, 3, 0, 7, 7, 7, 7, 6, 1, 3, 5, 1, 3, 4, 6, 1, 8, 5, 2, 5, 3, 2, 7, 1, 9, 2, 3, 1, 3, 3, 4, 0, 6, 9, 6, 9, 9, 4, 1, 5, 6, 8, 3, 7, 3, 4, 4, 6, 2, 5, 4, 4, 7, 9, 6, 7, 8, 6, 2, 3, 2, 5, 0, 2, 5, 1, 5, 9, 9, 9, 6, 1, 3, 5, 1, 7, 5, 1, 6, 6, 5, 4, 4, 4, 5, 9, 9, 2, 4, 2, 5, 5, 4, 2, 7, 3, 5, 3, 3, 5, 3, 3, 8, 9, 7, 9, 5, 7, 2, 1, 2, 2, 1, 1, 9, 8, 6, 7, 6, 4, 5, 7, 6, 2, 2, 0, 6, 4, 7, 3, 2, 1, 3, 9, 2, 5, 2, 8, 9, 9, 1, 7, 1, 7, 0, 9, 1, 2, 1, 5, 5, 0, 9, 5, 6, 1, 3, 2, 1, 9, 5, 7, 3, 5, 4, 5, 3, 3, 5, 5, 1, 6, 6, 4, 7, 1, 8, 0, 9, 3, 2, 7, 1, 2, 3, 6, 5, 8, 0, 7, 0, 7, 5, 9, 7, 2, 6, 5, 0, 7, 5, 3, 0, 1, 6, 2, 8, 8, 8, 0, 9, 0, 2, 7, 8, 2, 8, 0, 7, 6, 6, 3, 5, 9, 9, 3, 1, 2, 5, 6, 9, 7, 8, 5, 2, 5, 4, 3, 2, 3, 9, 3, 8, 3, 3, 3, 5, 7, 6, 5, 9, 0, 4, 7, 9, 9, 5, 7, 5, 1, 3, 5, 0, 3, 2, 3, 8, 7, 0, 6, 3, 3, 4, 7, 1, 2, 2, 0, 9, 5, 2, 9, 2, 3, 2, 7, 4, 5, 0, 1, 2, 2, 5, 1, 9, 4, 8, 7, 4, 0, 5, 7, 8, 3, 4, 9, 3, 4, 2, 2, 2, 7, 1, 4, 5, 0, 9, 7, 3, 5, 5, 8, 9, 6, 7, 3, 1, 2, 6, 4, 4, 7, 3, 7, 6, 5, 5, 6, 1, 7, 5, 8, 6, 9, 3, 1, 8, 3, 9, 4, 3, 4, 5, 4, 5, 5, 2, 7, 3, 4, 6, 5, 2, 3, 6, 1, 8, 7, 0, 8, 8, 3, 1, 6, 2, 7, 1, 6, 5, 6, 9, 3, 6, 6, 6, 2, 6, 5, 0, 2, 3, 3, 9, 2, 3, 8, 9, 5, 0, 3, 7, 1, 8, 5, 6, 4, 5, 3, 9, 2, 6, 4, 5, 5, 0, 4, 0, 6, 4, 7, 5, 7, 7, 5, 9, 3, 8, 1, 3, 2, 5, 8, 4, 7, 5, 3, 6, 8, 3, 3, 7, 1, 3, 3, 5, 5, 5, 4, 5, 7, 3, 1, 0, 2, 6, 7, 2, 3, 9, 0, 5, 1, 2, 4, 9, 3, 6, 5, 0, 5, 5, 7, 2, 2, 4, 5, 7, 9, 2, 1, 2, 4, 3, 3, 1, 5, 9, 0, 2, 9, 4, 4, 3, 0, 6, 1, 9, 3, 5, 9, 1, 7, 6, 9, 2, 4, 3, 0, 5, 3, 0, 5, 5, 3, 3, 5, 1, 6, 9, 4, 3, 2, 1, 5, 9, 6, 3, 6, 1, 9, 2, 4, 3, 4, 4, 1, 3, 9, 1, 2, 7, 9, 7, 3, 0, 9, 0, 5, 3, 3, 6, 1, 8, 4, 2, 1, 9, 4, 9, 2, 3, 1, 3, 5, 1, 3, 5, 3, 7, 5, 9, 5, 8, 9, 8, 4, 2, 5, 7, 5, 5, 2, 6, 8, 6, 8, 5, 7, 6, 6, 1, 9, 5, 5, 2, 3, 9, 5, 9, 9, 1, 1, 2, 4, 2, 4, 5, 8, 5, 9, 6, 1, 1, 7, 5, 2, 1, 5, 7, 5, 8, 0, 6, 4, 2, 8, 5, 0, 8, 7, 5, 1, 4, 4, 9, 2, 9, 5, 1, 2, 9, 5, 2, 6, 2, 7, 2, 6, 5, 2, 0, 7, 7, 5, 4, 5, 4, 1, 4, 5, 6, 8, 6, 1, 2, 5, 5, 6, 7, 5, 6, 9, 4, 1, 9, 4, 6, 8, 5, 4, 2, 2, 5, 6, 1, 6, 5, 1, 4, 4, 9, 9, 2, 9, 7, 6, 5, 5, 6, 9, 8, 9, 8, 2, 2, 4, 1, 1, 5, 6, 5, 4, 6, 5, 6, 9, 0, 4, 8, 0, 4, 4, 0, 9, 7, 2, 4, 7, 6, 2, 1, 4, 0, 7, 7, 6, 6, 6, 9, 6, 2, 1, 5, 0, 4, 4, 7, 4, 8, 5, 6, 7, 6, 7, 5, 4, 2, 9, 1, 6, 5, 2, 9, 2, 2, 5, 2, 0, 6, 2, 9, 4, 5, 7, 9, 9, 2, 9, 5, 5, 9, 6, 4, 6, 2, 4, 5, 1, 7, 9, 5, 1, 4, 8, 1, 6, 7, 1, 4, 7, 4, 7, 2, 5, 2, 8, 7, 4, 2, 9, 8, 7, 2, 2, 2, 5, 7, 7, 5, 6, 6, 1, 4, 1, 9, 2, 9, 9, 0, 4, 0, 8, 5, 1, 0, 7, 4, 9, 0, 1, 5, 0, 2, 8, 1, 7, 1, 7, 9, 1, 7, 5, 6, 1, 4, 1, 7, 9, 9, 4, 5, 8, 9, 4, 9, 7, 2, 5, 2, 4, 1, 6, 9, 7, 1, 9, 5, 7, 8, 5, 2, 6, 1, 8, 2, 1, 4, 7, 2, 4, 4, 9, 9, 6, 6, 8, 6, 8, 7, 1, 9, 4, 4, 6, 7, 0, 0, 9, 2, 9, 5, 5, 7, 4, 7, 5, 8, 5, 2, 9, 8, 8, 6, 7, 2, 5, 5, 6, 4, 8, 5, 5, 4, 5, 5, 5, 9, 1, 2, 7, 8, 1, 1, 8, 6, 9, 2, 9, 7, 4, 8, 0, 0, 0, 5, 6, 9, 2, 4, 4, 1, 6, 9, 4, 0, 1, 7, 9, 0, 1, 5, 8, 1, 5, 5, 0, 6, 1, 8, 7, 7, 9, 7, 1, 5, 5, 1, 0, 0, 2, 6, 1, 9, 5, 6, 4, 6, 7, 9, 0, 6, 7, 9, 4, 2, 1, 2, 6, 2, 7, 7, 2, 7, 2, 7, 1, 9, 6, 0, 2, 2, 2, 5, 4, 4, 1, 5, 5, 0, 5, 1, 4, 4, 5, 9, 2, 1, 0, 6, 5, 0, 4, 7, 9, 8, 5, 0, 0, 4, 7, 4, 9, 5, 5, 2, 7, 6, 9, 5, 2, 5, 9, 6, 7, 6, 6, 8, 7, 6, 6, 5, 4, 2, 7, 1, 0, 1, 6, 7, 7, 2, 9, 2, 6, 9, 1, 9, 8, 8, 6, 2, 9, 1, 4, 5, 6, 6, 5, 4, 7, 1, 4, 1, 9, 6, 6, 0, 4, 2, 4, 4, 6, 7, 9, 9, 9, 1, 1, 2, 0, 2, 0, 8, 6, 4, 5, 9, 8, 6, 6, 2, 5, 8, 4, 1, 2, 5, 5, 2, 2, 1, 9, 4, 9, 5, 9, 1, 4, 1, 4, 0, 8, 0, 2, 4, 7, 7, 1, 7, 5, 1, 1, 8, 0, 9, 9, 6, 7, 7, 9, 6, 6, 4, 1, 0, 5, 2, 1, 7, 8, 2, 6, 1, 9, 1, 2, 0, 2, 7, 4, 5, 0, 8, 2, 2, 0, 1, 7, 5, 7, 5, 2, 9, 6, 2, 5, 8, 6, 4, 0, 8, 8, 5, 5, 5, 9, 4, 9, 5, 7, 5, 7, 7, 1, 9, 8, 7, 2, 9, 0, 5, 5, 5, 8, 9, 7, 4, 5, 2, 5, 2, 2, 5, 0, 8, 6, 7, 1, 1, 4, 9, 4, 7, 9, 2, 5, 7, 6, 6, 2, 6, 1, 6, 0, 7, 6, 1, 6, 7, 1, 4, 2, 9, 2, 2, 1, 9, 7, 0, 8, 8, 9, 7, 7, 2, 8, 5, 9, 2, 7, 9, 1, 2, 7, 2, 5, 4, 4, 4, 2, 9, 7, 4, 7, 5, 4, 0, 1, 1, 1, 7, 8, 9, 5, 5, 9, 6, 5, 4, 0, 9, 4, 5, 7, 4, 7, 7, 1, 4, 6, 4, 4, 7, 9, 0, 4, 8, 9, 2, 2, 9, 2, 0, 4, 1, 1, 9, 1, 0, 4, 1, 1, 2, 6, 2, 4, 9, 7, 9, 4, 6, 6, 1, 8, 7, 7, 4, 1, 2, 1, 2, 6, 8, 8, 2, 0, 2, 4, 7, 4, 9, 4, 6, 8, 0, 8, 4, 0, 0, 1, 4, 9, 6, 1, 2, 1, 1, 4, 1, 9, 2, 9, 6, 1, 7, 7, 0, 0, 6, 7, 4, 7, 4, 6, 7, 6, 8, 7, 7, 4, 9, 7, 0, 8, 1, 4, 4, 6, 1, 4, 6, 6, 0, 0, 0, 1, 6, 7, 1, 2, 7, 1, 2, 4, 2, 7, 2, 2, 6, 1, 9, 2, 0, 2, 2, 9, 1, 0, 6, 7, 1, 6, 6, 2, 0, 2, 9, 2, 0, 4, 4, 2, 1, 4, 4, 2, 8, 0, 4, 7, 0, 1, 1, 7, 1, 0, 4, 2, 1, 4, 2, 6, 9, 2, 8, 8, 6, 0, 6, 0, 0, 6, 2, 1, 2, 8, 7, 2, 0, 6, 9, 1, 7, 6, 9, 2, 2, 9, 0, 9, 6, 0, 9, 4, 2, 0, 9, 7, 4, 8, 2, 7, 0, 2, 8, 4, 8, 4, 1, 7, 7, 1, 8, 0, 1, 2, 8, 9, 0, 8, 9, 6, 2, 2, 6, 1, 1, 7, 0, 8, 6, 7, 4, 2, 8, 2, 1, 1, 8, 6, 2, 1, 6, 9, 4, 9, 4, 9, 9, 7, 4, 4, 2, 1, 1, 0, 1, 6, 1, 2, 6, 7, 6, 7, 6, 0, 6, 1, 9, 1, 6, 2, 4, 6, 9, 0, 8, 6, 4, 7, 0, 8, 0, 1, 2, 2, 9, 4, 0, 1, 8, 9, 4, 7, 6, 6, 7, 7, 6, 7, 4, 4, 6, 4, 7, 4, 7, 0, 6, 8, 7, 0, 0, 9, 2, 0, 4, 1, 2, 2, 2, 0, 8, 7, 8, 6, 8, 1, 4, 2, 2, 1, 0, 9, 0, 7, 2, 1, 9, 9, 6, 2, 1, 2, 1, 2, 1, 8, 9, 1, 9, 1, 4, 0, 2, 6, 9, 9, 4, 6, 9, 2, 1, 7, 4, 4, 7, 8, 4, 4, 9, 2, 9, 9, 6, 8, 6, 6, 4, 4, 7, 6, 1, 7, 2, 7, 7, 6, 4, 2, 2, 2, 6, 1, 2, 4, 2, 7, 1, 9, 0, 0, 2, 1, 4, 9, 7, 6, 0, 2, 1, 8, 7, 1, 6, 1, 6, 9, 4, 6, 9, 8, 9, 4, 1, 8, 1, 4, 2, 6, 6, 2, 8, 1, 7, 9, 6, 4, 1, 1, 7, 4, 7, 2, 4, 1, 4, 8, 1, 4, 2, 2, 8, 2, 6, 9, 1, 8, 9, 0, 4, 0, 4, 8, 2, 2, 7, 4, 0, 7, 8, 7, 1, 0, 6, 4, 9, 8, 7, 8, 8, 7, 9, 8, 7, 7, 7, 8, 1, 0, 4, 4, 7, 7, 6, 4, 1, 2, 6, 8, 1, 2, 7, 6, 1, 2, 7, 4, 7, 2, 9, 7, 4, 1, 7, 6, 2, 4, 2, 0, 9, 1, 2, 7, 4, 4, 0, 2, 1, 9, 7, 7, 4, 9, 4, 7, 2, 6, 4, 4, 0, 6, 8, 9, 8, 2, 4, 9, 2, 1, 6, 0, 7, 8, 9, 2, 2, 9, 7, 2, 7, 7, 2, 1, 4, 7, 9, 7, 0, 0, 4, 7, 8, 7, 4, 6, 7, 1, 7, 4, 7, 4, 2, 1, 7, 2, 7, 8, 4, 6, 2, 9, 8, 8, 4, 6, 7, 7, 4, 6, 2, 8, 9, 8, 2, 6, 8, 2, 6, 2, 9, 0, 2, 2, 1, 2, 2, 7, 7, 1, 9, 1, 6, 7, 9, 6, 9, 7, 1, 4, 7, 1, 4, 0, 2, 9, 0, 2, 7, 4, 1, 2, 9, 1, 2, 2, 1, 1, 2, 9, 1, 4, 2, 7, 7, 8, 2, 2, 0, 1, 4, 1, 7, 1, 7, 4, 6, 0, 2, 6, 8, 8, 8, 1, 7, 2, 8, 4, 9, 1, 4, 8, 4, 7, 1, 6, 9, 2, 7, 6, 4, 1, 2, 6, 7, 0, 1, 6, 2, 9, 4, 9, 2, 7, 8, 4, 1, 8, 7, 9, 1, 2, 2, 6, 7, 2, 8, 7, 9, 4, 8, 6, 7, 2, 1, 4, 8, 1, 8, 6, 1, 7, 2, 2, 8, 1, 1, 8, 2, 7, 9, 6, 4, 7, 7, 4, 4, 7, 2, 6, 2, 9, 6, 4, 2, 1, 9, 2, 6, 9, 6, 1, 0, 9, 6, 7, 6, 7, 6, 6, 7, 0, 9, 0, 4, 4, 1, 0, 1, 4, 8, 0, 7, 6, 9, 0, 4, 6, 0, 6, 0, 1, 8, 0, 7, 1, 2, 8, 6, 6, 6, 7, 2, 9, 4, 9, 7, 8, 9, 8, 8, 4, 7, 9, 2, 6, 9, 1, 4, 4, 4, 2, 4, 1, 2, 9, 8, 0, 4, 7, 2, 4, 2, 2, 0, 7, 2, 9, 2, 4, 7, 0, 2, 6, 0, 4, 4, 1, 6, 0, 7, 1, 2, 9, 7, 6, 2, 9, 4, 9, 8, 9, 8, 1, 1, 0, 4, 1, 6, 1, 6, 9, 2, 1, 4, 6, 9, 1, 1, 9, 7, 8, 6, 9, 7, 2, 7, 8, 9, 8, 8, 4, 1, 9, 2, 9, 0, 9, 2, 7, 4, 2, 6, 9, 2, 0, 4, 2, 4, 8, 4, 1, 7, 4, 8, 2, 4, 9, 7, 7, 0, 0, 6, 4, 7, 2, 4, 1, 9, 0, 9, 1, 7, 2, 9, 6, 9, 4, 4, 2, 4, 6, 8, 9, 6, 2, 6, 9, 7, 4, 6, 1, 4, 4, 2, 1, 0, 8, 2, 9, 9, 0, 7, 0, 6, 9, 8, 8, 1, 6, 9, 0, 0, 2, 6, 7, 0, 9, 6, 9, 2, 7, 6, 9, 2, 7, 4, 8, 0, 8, 8, 1, 2, 2, 7, 9, 0, 9, 6, 6, 2, 6, 8, 8, 0, 6, 7, 4, 2, 2, 9, 6, 8, 4, 6, 4, 7, 9, 8, 7, 8, 1, 6, 7, 8, 9, 2, 9, 7, 9, 8, 6, 9, 9, 8, 6, 7, 4, 9, 7, 9, 4, 6, 4, 7, 0, 6, 0, 9, 1, 6, 2, 4, 1, 7, 7, 1, 4, 9, 0, 2, 4, 4, 1, 0, 9, 6, 1, 7, 8, 2, 8, 6, 6, 4, 4, 9, 1, 9, 7, 7, 4, 4, 9, 9, 8, 9, 0, 4, 1, 8, 7, 1, 8, 0, 1, 6, 9, 4, 0, 6, 4, 6, 1, 1, 7, 7, 9, 1, 8, 0, 1, 7, 6, 0, 0, 8, 7, 4, 7, 1, 9, 6, 7, 6, 8, 7, 6, 1, 6, 7, 7, 7, 6, 7, 7, 6, 4, 0, 7, 1, 6, 1, 1, 6, 7, 6, 0, 9, 0, 6, 9, 6, 8, 6, 0, 6, 8, 8, 9, 4, 1, 4, 6, 1, 7, 4, 9, 0, 1, 7, 7, 4, 7, 7, 6, 4, 9, 4, 9, 6, 7, 6, 6, 9, 6, 0, 9, 4, 6, 6, 4, 6, 6, 0, 7, 9, 9, 1, 4, 1, 9, 9, 1, 1, 4, 7, 7, 4, 6, 4, 8, 9, 6, 7, 4, 9, 8, 0, 0, 8, 1, 9, 9, 4, 4, 1, 4, 8, 9, 9, 4, 1, 9, 4, 7, 7, 1, 1, 8, 9, 7, 0, 6, 8, 4, 4, 0, 9, 1, 1, 9, 4, 9, 6, 0, 0, 4, 7, 7, 9, 1, 4, 4, 6, 4, 0, 1, 9, 6, 7, 1, 9, 4, 1, 4, 7, 7, 4, 9, 4, 4, 1, 6, 6, 4, 6, 6, 9, 4, 0, 9, 6, 6, 9, 1, 4, 1, 1, 6, 9, 7, 8, 8, 4, 0, 7, 0, 6, 9, 9, 8, 4, 7, 7, 4, 4, 8, 1, 0, 1, 1, 6, 6, 1, 6, 4, 1, 0, 7, 4, 9, 1, 9, 6, 8, 6, 6, 8, 6, 4, 9, 8, 0, 8, 4, 7, 0, 8, 4, 9, 4, 9, 7, 9, 7, 0, 6, 4, 9, 9, 1, 7, 1, 0, 4, 6, 7, 6, 8, 4, 0, 1, 1, 4, 8, 8, 6, 9, 7, 6, 4, 4, 7, 8, 0, 8, 0, 4, 1, 4, 1, 1, 4, 7, 6, 0, 6, 0, 1, 7, 7, 8, 0, 4, 6, 9, 1, 9, 6, 0, 0, 6, 8, 0, 7, 9, 1, 4, 6, 1, 7, 4, 8, 4, 4, 0, 9, 1, 0, 4, 1, 7, 0, 6, 6, 9, 1, 0, 4, 4, 0, 9, 7, 1, 0, 7, 0, 0, 7, 4, 1, 9, 4, 9, 1, 4, 6, 1, 9, 7, 4, 4, 9, 1, 7, 9, 9, 1, 0, 0, 7, 9, 6, 0, 7, 0, 6, 6, 7, 1, 7, 7, 9, 4, 1, 4, 6, 8, 4, 9, 4, 8, 0, 1, 7, 1, 7, 7, 1, 4, 7, 1, 9, 1, 6, 9, 8, 0, 7, 9, 6, 9, 7, 7, 9, 1, 1, 7, 6, 8, 7, 8, 1, 6, 4, 6, 9, 4, 6, 8, 9, 6, 9, 1, 7, 1, 9, 1, 4, 7, 4, 6, 9, 9, 9, 4, 1, 0, 9, 7, 1, 8, 1, 1, 8, 0, 9, 0, 9, 9, 6, 9, 8, 1, 9, 9, 4, 6, 6, 4, 6, 0, 4, 0, 0, 4, 4, 8, 6, 0, 0, 4, 4, 1, 1, 6, 1, 0, 6, 0, 1, 1, 6, 9, 8, 6, 6, 9, 6, 1, 9, 6, 9, 1, 9, 9, 6, 9, 6, 1, 0, 8, 1, 1, 6, 1, 1, 9, 8, 9, 6, 9, 6, 8, 6, 8, 0, 9, 9, 0, 8, 0, 9, 6, 8, 8, 1, 6, 0, 8, 1, 1, 1, 1, 8, 9, 9, 6, 6, 1, 1, 6, 1, 8, 9, 6, 9, 6, 6, 0, 1, 1, 1, 6, 9, 9, 1, 1, 6, 9, 1, 9, 0, 6, 6, 8, 8, 8, 9, 6, 1, 6, 1, 1, 6, 9, 0, 9, 6, 9, 9, 9, 0, 0, 0, 9, 0, 8, 1, 0, 0, 8, 0, 9, 0, 9, 0, 0, 0, 1, 9, 9, 8, 9, 6, 6, 0, 9, 6, 9, 8, 0, 6, 6, 6, 6, 6, 0, 0, 6, 6, 6, 8, 0, 6, 0, 6, 6, 0, 6, 9, 6, 9, 8, 6, 8, 6, 0, 9, 0, 6, 6, 6, 6, 0, 9, 8, 9, 0, 6, 0, 8, 6, 8, 9, 0, 9, 0, 9, 0, 0, 6, 9, 9, 6, 9, 8, 8, 9, 9, 8, 9, 8, 0, 8, 6, 0, 9, 9, 9, 6, 8, 6, 6, 9, 9, 8, 6, 6, 8, 9, 0, 6, 0, 0, 8, 9, 8, 6, 8, 0, 8, 0, 0, 6, 0, 8, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 8, 8, 8, 6, 0, 6, 8, 6, 6, 0, 0, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 8, 8, 0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 8, 0, 8, 0, 0, 0, 8, 8, 8, 8, 8, 0, 8, 0, 0, 0, 8, 0, 8, 0, 8, 0, 8, 0, 0, 8, 8, 8, 0, 8, 8, 8, 8, 8, 0, 8, 8, 8, 0, 0, 8, 8, 8, 0, 0, 8, 0, 8, 8, 8, 8, 0, 0, 8, 0, 8, 0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 8, 8, 0, 0, 8, 8, 0, 8, 0, 0, 0, 8, 0, 8, 0, 0, 8, 0, 0, 0, 0, 8, 8, 0, 8, 0, 8, 8, 0, 0, 8, 0, 0, 0, 0, 0, 8, 0, 0, 8, 8, 0, 0, 8, 8, 0, 8, 0, 0, 0, 8, 8, 0, 0, 0, 8, 8, 0, 8, 8, 8, 8, 8, 0, 0, 8, 8, 8, 0, 8, 8, 0, 8, 8, 8, 0, 8, 8, 0, 8, 8, 0, 8, 0, 8, 0, 0, 0, 0, 8, 8, 0, 8, 0, 0, 8, 0, 0, 0, 0, 0, 0, 8, 8, 0, 0, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0, 8, 8, 8, 8, 8, 0, 0, 8, 8, 8, 0, 8, 8, 0, 0, 8, 8, 8, 8, 0, 0, 0, 0, 0, 8, 8, 0, 0, 8, 0, 0, 8, 8, 8, 0, 0, 0, 8, 8, 0, 8, 0, 0, 0, 0, 8, 8, 0, 0, 0, 8, 8, 8, 0, 8, 0, 8, 0, 8, 8, 8, 8, 0, 8, 0, 0, 0, 0, 0, 8, 0, 0, 8, 8, 0, 8, 0, 0, 0, 0, 8, 8, 8, 0, 0, 0, 0, 8, 0, 8, 8, 0, 8, 8, 0, 0, 8, 0, 0, 0, 8, 8, 0, 8, 8, 8, 0, 8, 8, 8, 0, 0, 0, 8, 0, 8, 0, 8, 8, 8, 0, 0, 0, 8, 0, 0, 8, 0, 8, 0, 0, 8, 0, 8, 8, 8, 0, 0, 0, 8, 0, 0, 8, 0, 0, 0, 8, 0, 0, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 0, 8, 8, 8, 0, 0, 0, 0, 0, 0, 8, 8, 0, 0, 8, 0, 8, 8, 0, 8, 0, 8, 8, 8, 0, 0, 0, 0, 0, 8, 8, 0, 8, 8, 0, 8, 8, 8, 8, 0, 8, 0, 0, 0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 8, 0, 8, 8, 0, 8, 0, 8, 8, 0, 0, 0, 0, 8, 8, 8, 0, 8, 0, 8, 0, 8, 0, 8, 8, 8, 0, 8, 8, 0, 0, 8, 8, 0, 8, 0, 8, 8, 0, 8, 0, 0, 8, 0, 0, 8, 8, 8, 0, 8, 0, 0, 8, 0, 8, 8, 8, 0, 8, 8, 8, 0, 8, 0, 8, 8, 8, 8, 8, 8, 0, 8, 0, 8, 0, 8, 0, 8, 0, 8, 0, 0, 8, 0, 8, 0, 8, 8, 0, 0, 8, 8, 8, 8, 8, 0, 0, 0, 8, 8, 8, 0, 0, 0, 0, 0, 0, 8, 8, 8, 0, 0, 0, 8, 0, 0, 0, 0, 0, 8, 0, 0, 8, 8, 0, 8, 0, 0, 8, 8, 8, 8, 8, 0, 8, 8, 0, 8, 0, 0, 0, 8, 8, 8, 8, 0, 0, 8, 8, 0, 0, 8, 8, 0, 0, 8, 0, 0, 8, 8, 0, 8, 8, 8, 8, 8, 0, 0, 8, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 8, 8, 0, 8, 8, 0, 0, 0, 0, 0, 8, 0, 0, 8, 8, 0, 8, 8, 0, 0, 8, 0, 0, 8, 0, 8, 0, 8, 8, 0, 8, 8, 0, 0, 8, 0, 0, 0, 8, 0, 0, 8, 8, 0, 8, 0, 8, 8, 0, 8, 0, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
            "Counter({9: 1000, 4: 1000, 0: 1000, 7: 1000, 2: 1000, 6: 1000, 5: 1000, 3: 1000, 1: 1000, 8: 1000})\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3336\u001b[0m  18.7438\n",
            "      2        2.3873  17.5283\n",
            "      3        \u001b[36m2.3186\u001b[0m  17.9098\n",
            "      4        \u001b[36m2.3177\u001b[0m  17.6628\n",
            "      5        \u001b[36m2.3175\u001b[0m  17.7721\n",
            "      6        \u001b[36m2.3175\u001b[0m  17.8946\n",
            "      7        \u001b[36m2.3175\u001b[0m  17.9995\n",
            "      8        \u001b[36m2.3175\u001b[0m  17.9777\n",
            "      9        \u001b[36m2.3175\u001b[0m  17.9321\n",
            "     10        \u001b[36m2.3174\u001b[0m  17.5287\n",
            "0.1\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]\n",
            " [  0   0   0   0   0   0   0   0 500   0]]\n",
            "Accuracy:  0.1\n",
            "Macro F1-score:  0.01818181818181818\n",
            "Micro F1-score:  0.10000000000000002\n",
            "Weighted F1-score:  0.01818181818181818\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "---Query no:  1 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5389\u001b[0m  17.7420\n",
            "      2        \u001b[36m2.0347\u001b[0m  17.9587\n",
            "      3        \u001b[36m1.9959\u001b[0m  17.8227\n",
            "      4        \u001b[36m1.9887\u001b[0m  17.5507\n",
            "      5        \u001b[36m1.9598\u001b[0m  17.8027\n",
            "      6        1.9617  17.5903\n",
            "      7        \u001b[36m1.9363\u001b[0m  17.7938\n",
            "      8        1.9386  17.8737\n",
            "      9        \u001b[36m1.9248\u001b[0m  17.5348\n",
            "     10        1.9288  17.7599\n",
            "0.3088\n",
            "---Query no:  2 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3737\u001b[0m  18.0624\n",
            "      2        \u001b[36m2.0226\u001b[0m  17.7826\n",
            "      3        \u001b[36m1.9883\u001b[0m  17.8417\n",
            "      4        \u001b[36m1.9548\u001b[0m  17.9592\n",
            "      5        \u001b[36m1.9466\u001b[0m  17.6139\n",
            "      6        \u001b[36m1.9389\u001b[0m  17.9216\n",
            "      7        \u001b[36m1.9210\u001b[0m  17.9180\n",
            "      8        \u001b[36m1.9128\u001b[0m  17.6925\n",
            "      9        1.9143  17.9492\n",
            "     10        \u001b[36m1.8995\u001b[0m  17.8716\n",
            "0.3216\n",
            "---Query no:  3 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2651\u001b[0m  20.3939\n",
            "      2        \u001b[36m1.9608\u001b[0m  17.8304\n",
            "      3        \u001b[36m1.8392\u001b[0m  18.1096\n",
            "      4        \u001b[36m1.8043\u001b[0m  18.0868\n",
            "      5        \u001b[36m1.7461\u001b[0m  18.0841\n",
            "      6        \u001b[36m1.7158\u001b[0m  18.0331\n",
            "      7        \u001b[36m1.6938\u001b[0m  17.8767\n",
            "      8        1.8923  17.8795\n",
            "      9        1.7157  17.9320\n",
            "     10        \u001b[36m1.6480\u001b[0m  17.6788\n",
            "0.4352\n",
            "---Query no:  4 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3922\u001b[0m  17.6953\n",
            "      2        \u001b[36m2.3036\u001b[0m  17.9898\n",
            "      3        \u001b[36m2.3036\u001b[0m  17.9023\n",
            "      4        2.3036  17.6023\n",
            "      5        2.3036  17.9153\n",
            "      6        2.3036  17.5808\n",
            "      7        2.3036  17.9761\n",
            "      8        2.3036  17.9641\n",
            "      9        2.3036  17.6096\n",
            "     10        2.3036  17.7858\n",
            "0.1\n",
            "---Query no:  5 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2863\u001b[0m  18.0956\n",
            "      2        \u001b[36m2.0079\u001b[0m  17.7457\n",
            "      3        \u001b[36m1.9181\u001b[0m  17.9741\n",
            "      4        \u001b[36m1.8478\u001b[0m  17.9835\n",
            "      5        \u001b[36m1.8377\u001b[0m  17.7016\n",
            "      6        \u001b[36m1.7891\u001b[0m  17.9175\n",
            "      7        \u001b[36m1.7832\u001b[0m  17.9947\n",
            "      8        \u001b[36m1.7404\u001b[0m  17.6546\n",
            "      9        \u001b[36m1.7360\u001b[0m  17.9485\n",
            "     10        \u001b[36m1.7116\u001b[0m  17.7371\n",
            "0.386\n",
            "---Query no:  6 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2139\u001b[0m  17.7471\n",
            "      2        \u001b[36m1.8796\u001b[0m  17.9860\n",
            "      3        \u001b[36m1.8039\u001b[0m  18.3318\n",
            "      4        \u001b[36m1.7657\u001b[0m  17.7835\n",
            "      5        \u001b[36m1.6920\u001b[0m  17.9757\n",
            "      6        \u001b[36m1.6559\u001b[0m  18.1013\n",
            "      7        \u001b[36m1.6347\u001b[0m  17.6984\n",
            "      8        \u001b[36m1.5998\u001b[0m  19.9951\n",
            "      9        \u001b[36m1.5766\u001b[0m  17.9550\n",
            "     10        \u001b[36m1.5638\u001b[0m  17.7314\n",
            "0.4398\n",
            "---Query no:  7 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4240\u001b[0m  17.8331\n",
            "      2        \u001b[36m2.3038\u001b[0m  18.0584\n",
            "      3        \u001b[36m2.3036\u001b[0m  17.7405\n",
            "      4        2.3036  18.0648\n",
            "      5        \u001b[36m2.3035\u001b[0m  18.0281\n",
            "      6        2.3035  17.7365\n",
            "      7        2.3035  18.0797\n",
            "      8        2.3035  18.1300\n",
            "      9        2.3036  17.7240\n",
            "     10        2.3036  18.0666\n",
            "0.1\n",
            "---Query no:  8 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2537\u001b[0m  18.1609\n",
            "      2        \u001b[36m1.7914\u001b[0m  18.0866\n",
            "      3        \u001b[36m1.6998\u001b[0m  17.8248\n",
            "      4        \u001b[36m1.6198\u001b[0m  18.1306\n",
            "      5        \u001b[36m1.5724\u001b[0m  18.1434\n",
            "      6        \u001b[36m1.5196\u001b[0m  17.8578\n",
            "      7        \u001b[36m1.4897\u001b[0m  18.1028\n",
            "      8        1.5080  18.0101\n",
            "      9        \u001b[36m1.4287\u001b[0m  17.9205\n",
            "     10        \u001b[36m1.3922\u001b[0m  18.1372\n",
            "0.4648\n",
            "---Query no:  9 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.2020\u001b[0m  18.4735\n",
            "      2        \u001b[36m1.8412\u001b[0m  17.8820\n",
            "      3        \u001b[36m1.7445\u001b[0m  18.1376\n",
            "      4        \u001b[36m1.6994\u001b[0m  18.1298\n",
            "      5        \u001b[36m1.6224\u001b[0m  17.9758\n",
            "      6        \u001b[36m1.5915\u001b[0m  18.1118\n",
            "      7        1.6096  18.1169\n",
            "      8        \u001b[36m1.5474\u001b[0m  17.8475\n",
            "      9        1.5540  18.1710\n",
            "     10        \u001b[36m1.5135\u001b[0m  18.1959\n",
            "0.462\n",
            "---Query no:  10 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5112\u001b[0m  18.2581\n",
            "      2        \u001b[36m2.3036\u001b[0m  17.9439\n",
            "      3        \u001b[36m2.3035\u001b[0m  18.2247\n",
            "      4        \u001b[36m2.3035\u001b[0m  17.9958\n",
            "      5        \u001b[36m2.3035\u001b[0m  18.2021\n",
            "      6        2.3035  18.2423\n",
            "      7        2.3035  17.9970\n",
            "      8        2.3047  18.2087\n",
            "      9        2.3037  18.1881\n",
            "     10        2.3036  17.9423\n",
            "0.1\n",
            "---Query no:  11 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3793\u001b[0m  19.2884\n",
            "      2        \u001b[36m2.3002\u001b[0m  18.8809\n",
            "      3        \u001b[36m2.2289\u001b[0m  18.8662\n",
            "      4        \u001b[36m2.0902\u001b[0m  18.9858\n",
            "      5        \u001b[36m2.0251\u001b[0m  18.7159\n",
            "      6        2.0313  18.8280\n",
            "      7        \u001b[36m1.9147\u001b[0m  18.8044\n",
            "      8        \u001b[36m1.9045\u001b[0m  18.8307\n",
            "      9        \u001b[36m1.8705\u001b[0m  19.1482\n",
            "     10        \u001b[36m1.8240\u001b[0m  19.4558\n",
            "0.3134\n",
            "---Query no:  12 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3703\u001b[0m  18.8190\n",
            "      2        \u001b[36m2.0232\u001b[0m  19.0141\n",
            "      3        \u001b[36m1.9604\u001b[0m  19.0397\n",
            "      4        \u001b[36m1.9244\u001b[0m  19.5323\n",
            "      5        \u001b[36m1.8872\u001b[0m  19.1825\n",
            "      6        \u001b[36m1.8693\u001b[0m  18.7813\n",
            "      7        2.0647  19.4311\n",
            "      8        1.9688  18.2809\n",
            "      9        1.9035  18.0553\n",
            "     10        \u001b[36m1.8628\u001b[0m  18.1279\n",
            "0.36\n",
            "---Query no:  13 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3606\u001b[0m  18.1498\n",
            "      2        \u001b[36m1.9614\u001b[0m  18.3517\n",
            "      3        \u001b[36m1.8448\u001b[0m  18.3919\n",
            "      4        \u001b[36m1.7721\u001b[0m  18.1672\n",
            "      5        \u001b[36m1.7218\u001b[0m  18.4113\n",
            "      6        \u001b[36m1.7075\u001b[0m  18.4389\n",
            "      7        \u001b[36m1.6560\u001b[0m  18.0595\n",
            "      8        \u001b[36m1.6384\u001b[0m  18.5658\n",
            "      9        1.6491  18.4821\n",
            "     10        \u001b[36m1.5936\u001b[0m  18.0968\n",
            "0.4058\n",
            "---Query no:  14 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3117\u001b[0m  18.3046\n",
            "      2        \u001b[36m1.8733\u001b[0m  18.6013\n",
            "      3        \u001b[36m1.7349\u001b[0m  18.4854\n",
            "      4        \u001b[36m1.6649\u001b[0m  18.1838\n",
            "      5        \u001b[36m1.6039\u001b[0m  18.5507\n",
            "      6        \u001b[36m1.5546\u001b[0m  18.5533\n",
            "      7        \u001b[36m1.5221\u001b[0m  18.5030\n",
            "      8        \u001b[36m1.5044\u001b[0m  18.5704\n",
            "      9        \u001b[36m1.4734\u001b[0m  18.5555\n",
            "     10        \u001b[36m1.4292\u001b[0m  18.2049\n",
            "0.4664\n",
            "---Query no:  15 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3093\u001b[0m  18.3138\n",
            "      2        \u001b[36m2.0621\u001b[0m  18.5076\n",
            "      3        \u001b[36m2.0262\u001b[0m  18.5277\n",
            "      4        \u001b[36m1.9692\u001b[0m  18.1556\n",
            "      5        \u001b[36m1.8937\u001b[0m  18.4586\n",
            "      6        \u001b[36m1.8391\u001b[0m  18.5978\n",
            "      7        \u001b[36m1.8112\u001b[0m  18.2286\n",
            "      8        \u001b[36m1.7750\u001b[0m  18.4867\n",
            "      9        \u001b[36m1.7521\u001b[0m  18.5394\n",
            "     10        1.7628  18.4305\n",
            "0.3946\n",
            "---Query no:  16 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3940\u001b[0m  18.6607\n",
            "      2        \u001b[36m2.1298\u001b[0m  18.2710\n",
            "      3        \u001b[36m2.1244\u001b[0m  18.6096\n",
            "      4        \u001b[36m2.0659\u001b[0m  18.5318\n",
            "      5        \u001b[36m2.0000\u001b[0m  18.3103\n",
            "      6        \u001b[36m1.9674\u001b[0m  18.6469\n",
            "      7        \u001b[36m1.9577\u001b[0m  18.5174\n",
            "      8        \u001b[36m1.9126\u001b[0m  18.4725\n",
            "      9        \u001b[36m1.9072\u001b[0m  18.4526\n",
            "     10        \u001b[36m1.8919\u001b[0m  18.5316\n",
            "0.3364\n",
            "---Query no:  17 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.4686\u001b[0m  18.7306\n",
            "      2        \u001b[36m1.9030\u001b[0m  18.4038\n",
            "      3        \u001b[36m1.8132\u001b[0m  18.3890\n",
            "      4        \u001b[36m1.7611\u001b[0m  18.5537\n",
            "      5        \u001b[36m1.7025\u001b[0m  18.8519\n",
            "      6        \u001b[36m1.6843\u001b[0m  18.2114\n",
            "      7        \u001b[36m1.6643\u001b[0m  18.5470\n",
            "      8        \u001b[36m1.6187\u001b[0m  18.5390\n",
            "      9        1.6295  18.2792\n",
            "     10        \u001b[36m1.5867\u001b[0m  18.5653\n",
            "0.4232\n",
            "---Query no:  18 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3145\u001b[0m  18.7761\n",
            "      2        \u001b[36m2.0539\u001b[0m  18.7087\n",
            "      3        \u001b[36m1.9245\u001b[0m  18.4480\n",
            "      4        \u001b[36m1.8759\u001b[0m  18.7225\n",
            "      5        \u001b[36m1.8612\u001b[0m  18.6943\n",
            "      6        \u001b[36m1.7772\u001b[0m  18.4190\n",
            "      7        \u001b[36m1.7456\u001b[0m  18.7517\n",
            "      8        \u001b[36m1.7287\u001b[0m  18.7176\n",
            "      9        \u001b[36m1.7218\u001b[0m  18.7424\n",
            "     10        \u001b[36m1.7106\u001b[0m  18.4075\n",
            "0.3812\n",
            "---Query no:  19 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.5124\u001b[0m  18.4698\n",
            "      2        \u001b[36m2.3035\u001b[0m  18.6389\n",
            "      3        \u001b[36m2.3034\u001b[0m  18.6866\n",
            "      4        2.3034  18.3890\n",
            "      5        2.3035  18.6858\n",
            "      6        2.3035  18.7038\n",
            "      7        2.3035  18.3984\n",
            "      8        2.3035  18.7130\n",
            "      9        2.3035  18.7240\n",
            "     10        2.3035  18.4829\n",
            "0.1\n",
            "---Query no:  20 ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss      dur\n",
            "-------  ------------  -------\n",
            "      1        \u001b[36m2.3237\u001b[0m  18.6158\n",
            "      2        \u001b[36m1.9525\u001b[0m  19.1110\n",
            "      3        \u001b[36m1.8550\u001b[0m  18.7567\n",
            "      4        \u001b[36m1.8171\u001b[0m  18.8064\n",
            "      5        \u001b[36m1.7867\u001b[0m  18.4590\n",
            "      6        \u001b[36m1.7486\u001b[0m  18.7682\n",
            "      7        \u001b[36m1.7310\u001b[0m  18.6751\n",
            "      8        \u001b[36m1.7062\u001b[0m  18.4494\n",
            "      9        \u001b[36m1.6680\u001b[0m  18.9590\n",
            "     10        \u001b[36m1.6566\u001b[0m  18.8059\n",
            "0.4082\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[162  24  47  21  24   6  12  22 134  48]\n",
            " [ 14 260   0  34   2   3  19  14  25 129]\n",
            " [ 15   2  68  91 139  65  52  35  18  15]\n",
            " [  8   3  24 187  60  90  72  23   7  26]\n",
            " [  8   1  18  63 197  79  69  50   7   8]\n",
            " [  3   4  26 155  52 168  57  20   2  13]\n",
            " [  0   1   5  79 112  36 237  13   0  17]\n",
            " [  6   1  16  78  57  69  39 205   2  27]\n",
            " [ 48  38  15  47  12   4  11   3 249  73]\n",
            " [  9  52   3  26   3   5  42  24  28 308]]\n",
            "Accuracy:  0.4082\n",
            "Macro F1-score:  0.4074052797384914\n",
            "Micro F1-score:  0.4082\n",
            "Weighted F1-score:  0.4074052797384914\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "AL_Retrain(10000, 20, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v64WwYjniUAJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPa+284hGMLphG+sm9OdL2w",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}