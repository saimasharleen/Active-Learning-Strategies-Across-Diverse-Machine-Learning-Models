{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuInwkqwJqgddT3MTB3lzk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saimasharleen/Active-Learning-Strategies-Across-Diverse-Machine-Learning-Models/blob/main/MNIST_logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX-FYh9ragNg",
        "outputId": "fd65d18f-1ded-4feb-a4e6-8fa5ef79fe67"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/modAL-python/modAL.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPxaS5Inxu3Y",
        "outputId": "34c68377-0ee4-4788-b960-5a1db5fc4a7e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/modAL-python/modAL.git\n",
            "  Cloning https://github.com/modAL-python/modAL.git to /tmp/pip-req-build-agcfiaki\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/modAL-python/modAL.git /tmp/pip-req-build-agcfiaki\n",
            "  Resolved https://github.com/modAL-python/modAL.git to commit bba6f6fd00dbb862b1e09259b78caf6cffa2e755\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.11.4)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.5.3)\n",
            "Collecting skorch==0.9.0 (from modAL-python==0.4.2)\n",
            "  Downloading skorch-0.9.0-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.8/125.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch==0.9.0->modAL-python==0.4.2) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.10/dist-packages (from skorch==0.9.0->modAL-python==0.4.2) (4.66.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->modAL-python==0.4.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->modAL-python==0.4.2) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->modAL-python==0.4.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->modAL-python==0.4.2) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.0->modAL-python==0.4.2) (1.16.0)\n",
            "Building wheels for collected packages: modAL-python\n",
            "  Building wheel for modAL-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for modAL-python: filename=modAL_python-0.4.2-py3-none-any.whl size=32650 sha256=749234b72352fe4279fb3e2093a72ac5c8a3332c71e34726e1cf4b261a06bdae\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8io89ily/wheels/d9/fb/59/7deb61b460c1c36394cd093758986ff7d36f71352dcb2e02c5\n",
            "Successfully built modAL-python\n",
            "Installing collected packages: skorch, modAL-python\n",
            "Successfully installed modAL-python-0.4.2 skorch-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import modAL"
      ],
      "metadata": {
        "id": "c58FtgdOxz27"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import MNIST\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "import collections\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.uncertainty import uncertainty_sampling\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score"
      ],
      "metadata": {
        "id": "GRV17iwdyarb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_data = MNIST('.', download= True, transform = ToTensor())\n",
        "dataloader = DataLoader(mnist_data, shuffle=True, batch_size = 60000 )\n",
        "x, y = next(iter(dataloader))\n",
        "\n",
        "x = x.detach().cpu().numpy()\n",
        "y = y.detach().cpu().numpy()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=10000, random_state=0, stratify=y)\n",
        "x_test=x_test.reshape(len(x_test), 1, 28, 28)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBGl4JkIymnn",
        "outputId": "cbf9cf62-62a2-4e48-cfce-33151ea22367"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 82100049.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 31196418.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 26549342.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3164014.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#build the logistic regression model\n",
        "from torch import nn\n",
        "from skorch import NeuralNetClassifier\n",
        "import torch\n",
        "class Regression_Model(nn.Module):\n",
        "    def __init__( self):\n",
        "        super( Regression_Model , self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28*28, 10))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.sigmoid(self.fc(x))\n",
        "        return out"
      ],
      "metadata": {
        "id": "mN2Te1FIysBs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap with Skorch for compatiblity with sklearn\n",
        "\n",
        "classifier = NeuralNetClassifier(Regression_Model,\n",
        "    criterion = nn.CrossEntropyLoss,\n",
        "    optimizer = torch.optim.Adam,\n",
        "    train_split = None,\n",
        "    verbose = 1,\n",
        "    lr=0.01,\n",
        "    device = device,\n",
        "    )"
      ],
      "metadata": {
        "id": "2TIxZRzeyx0g"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the base model\n",
        "import joblib\n",
        "filename = \"regression_version1.joblib\"\n",
        "joblib.dump(classifier, filename)\n",
        "#loaded_model = joblib.load(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPUH3jW9zNX_",
        "outputId": "5f9a8461-67a1-4cf5-f764-b769eef2863c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['regression_version1.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def CF_Print(y_test, y_pred):\n",
        "    accuracy = accuracy_score(y_pred, y_test)\n",
        "    CF = confusion_matrix(y_test, y_pred)\n",
        "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "    micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
        "    weighted_f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    print('Confusion Matrix:')\n",
        "    print(CF)\n",
        "    print('Accuracy: ', accuracy)\n",
        "    print('Macro F1-score: ', macro_f1)\n",
        "    print('Micro F1-score: ', micro_f1)\n",
        "    print('Weighted F1-score: ', weighted_f1)\n",
        "    print(\"---------------------------------\")"
      ],
      "metadata": {
        "id": "sW1YTMgOzRJq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AL_Retrain(n_initial, n_queries, instances):\n",
        "    x_initial, x_pool, y_initial,  y_pool = train_test_split(x_train,y_train, train_size=n_initial, random_state=0, stratify=y_train)\n",
        "    x_initial = x_initial.reshape(len(x_initial), 1, 28, 28)\n",
        "    x_pool = x_pool.reshape(len(x_pool), 1, 28, 28)\n",
        "    filename = \"regression_version1.joblib\"\n",
        "    classifier = joblib.load(filename)\n",
        "    learner = ActiveLearner(\n",
        "        estimator = classifier,\n",
        "        query_strategy = uncertainty_sampling,\n",
        "        X_training = x_initial, y_training = y_initial, epochs=10,\n",
        "    )\n",
        "    print(\"No of initial data: \", n_initial)\n",
        "    print(learner.score(x_test, y_test))\n",
        "    y_pred = learner.predict(x_test)\n",
        "    print('Confusion Matrix After trainig with initial data')\n",
        "    CF_Print(y_test, y_pred)\n",
        "    print(\"---- Train From Scratch with first model-----\")\n",
        "    AL_Train_Scratch(n_initial, learner)\n",
        "    print(\"---- Teach/Retrain with new data-------\")\n",
        "    for idx in range(n_queries):\n",
        "        print('--- Query no:  ', idx+1, ' ----')\n",
        "        query_idx, query_instance = learner.query(x_pool, n_instances=instances)\n",
        "        learner.teach(\n",
        "            X=x_pool[query_idx],\n",
        "            y=y_pool[query_idx],\n",
        "        )\n",
        "        print('Instance', y_pool[query_idx] )\n",
        "        print(learner.score(x_test, y_test))\n",
        "        x_pool = np.delete(x_pool, query_idx, axis=0)\n",
        "        y_pool = np.delete(y_pool, query_idx, axis=0)\n",
        "    y_pred = learner.predict(x_test)\n",
        "    print('Confusion Matrix After RE-TRAINGING')\n",
        "    CF_Print(y_test, y_pred)"
      ],
      "metadata": {
        "id": "8uHEAMrNzT2E"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model from scratch based on the dataset selected by active learning method ensuring the uniform distribution of the data\n",
        "def AL_Train_Scratch(n_initial, trained_learner):\n",
        "    global x_train\n",
        "    x_train_reshaped=x_train.reshape(len(x_train), 1, 28, 28)\n",
        "    query_idx, query_instance = trained_learner.query(x_train_reshaped, n_instances=(n_initial*3))\n",
        "    distribution=[0]*10\n",
        "    flag=0\n",
        "    data_per_class= int(n_initial/10)\n",
        "    x_initial=[]\n",
        "    y_initial=[]\n",
        "    x_temp= x_train_reshaped[query_idx]\n",
        "    y_temp=y_train[query_idx]\n",
        "    for data, label in zip(x_temp, y_temp):\n",
        "        if distribution[label]<data_per_class:\n",
        "            x_initial.append(data)\n",
        "            y_initial.append(label)\n",
        "            distribution[label]+=1\n",
        "            if distribution[label]==data_per_class:\n",
        "                flag+=1\n",
        "        if flag==10:\n",
        "            break\n",
        "    del x_temp, y_temp\n",
        "    print(y_initial)\n",
        "    counter = collections.Counter(y_initial)\n",
        "    print(counter)\n",
        "    filename = \"regression_version1.joblib\"\n",
        "    classifier = joblib.load(filename)\n",
        "    x_initial= np.array(x_initial)\n",
        "    y_initial = np.array(y_initial)\n",
        "    x_initial = x_initial.reshape(len(x_initial), 1, 28, 28)\n",
        "    new_learner = ActiveLearner(\n",
        "        estimator = classifier,\n",
        "        query_strategy = uncertainty_sampling,\n",
        "        X_training = x_initial, y_training = y_initial, epochs=10,\n",
        "    )\n",
        "    print(new_learner.score(x_test, y_test))\n",
        "    y_pred = new_learner.predict(x_test)\n",
        "    print(\"Confusion Matrix after training the model with most important dataset\")\n",
        "    CF_Print(y_test, y_pred)"
      ],
      "metadata": {
        "id": "CTSh_chlzWT5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AL_Retrain(30, 10, 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmGPwc5lzc72",
        "outputId": "f3163cf3-bd9e-46c3-953d-f605e804b6f2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2944\u001b[0m  0.0657\n",
            "      2        \u001b[36m2.1376\u001b[0m  0.0043\n",
            "      3        \u001b[36m2.0110\u001b[0m  0.0066\n",
            "      4        \u001b[36m1.9103\u001b[0m  0.0129\n",
            "      5        \u001b[36m1.8272\u001b[0m  0.0029\n",
            "      6        \u001b[36m1.7592\u001b[0m  0.0027\n",
            "      7        \u001b[36m1.7049\u001b[0m  0.0104\n",
            "      8        \u001b[36m1.6624\u001b[0m  0.0028\n",
            "      9        \u001b[36m1.6292\u001b[0m  0.0028\n",
            "     10        \u001b[36m1.6026\u001b[0m  0.0029\n",
            "No of initial data:  30\n",
            "0.5236\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[784   2  14   5   9  52  97   0  23   1]\n",
            " [  0 905  21  99   5  20  25  46   3   0]\n",
            " [117 110 290  54  58 162 141  24  33   4]\n",
            " [ 34  36  11 381   4 397  34  31  76  18]\n",
            " [ 20  15  11  63 534   0  32  35  18 246]\n",
            " [164  17   7 107  33 253  93   5 140  84]\n",
            " [ 79  18  86   0  40   9 749   0   5   0]\n",
            " [ 28  31   1  30 204  12   1 482   3 252]\n",
            " [ 47 145  12 169  86  40  83  27 310  56]\n",
            " [ 10  10   8  70 207   5   7 110  17 548]]\n",
            "Accuracy:  0.5236\n",
            "Macro F1-score:  0.507511296443625\n",
            "Micro F1-score:  0.5236\n",
            "Weighted F1-score:  0.5125886556187137\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[5, 8, 0, 8, 8, 2, 0, 2, 5, 2, 3, 7, 5, 0, 7, 9, 3, 3, 9, 6, 9, 7]\n",
            "Counter({5: 3, 8: 3, 0: 3, 2: 3, 3: 3, 7: 3, 9: 3, 6: 1})\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3191\u001b[0m  0.0019\n",
            "      2        \u001b[36m2.0647\u001b[0m  0.0024\n",
            "      3        \u001b[36m1.9754\u001b[0m  0.0026\n",
            "      4        \u001b[36m1.8867\u001b[0m  0.0034\n",
            "      5        \u001b[36m1.7931\u001b[0m  0.0036\n",
            "      6        \u001b[36m1.7215\u001b[0m  0.0035\n",
            "      7        \u001b[36m1.6821\u001b[0m  0.0022\n",
            "      8        \u001b[36m1.6574\u001b[0m  0.0023\n",
            "      9        \u001b[36m1.6259\u001b[0m  0.0024\n",
            "     10        \u001b[36m1.5949\u001b[0m  0.0025\n",
            "0.3031\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[ 616    0  104   94    0    2   18    1   31  121]\n",
            " [   0    0   51 1072    0    0    0    1    0    0]\n",
            " [  12    0  763  162    0    3   18    8   25    2]\n",
            " [   9    0  190  503    0  148    9   17  140    6]\n",
            " [  13    0   33  536    0   28   37  137   65  125]\n",
            " [  38    0   39  555    0  200    8    5   39   19]\n",
            " [  33    0  113  530    0    4  286    0    6   14]\n",
            " [   7    0   87  496    0    0    2  376   43   33]\n",
            " [  10    0  110  610    0   36    1    9  192    7]\n",
            " [  10    0   41  506    0    7    5  287   41   95]]\n",
            "Accuracy:  0.3031\n",
            "Macro F1-score:  0.29779616102800066\n",
            "Micro F1-score:  0.3031\n",
            "Weighted F1-score:  0.2943451236074698\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "--- Query no:   1  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2956\u001b[0m  0.0022\n",
            "      2        \u001b[36m2.1095\u001b[0m  0.0035\n",
            "      3        \u001b[36m2.0401\u001b[0m  0.0034\n",
            "      4        \u001b[36m1.9912\u001b[0m  0.0040\n",
            "      5        \u001b[36m1.9443\u001b[0m  0.0028\n",
            "      6        \u001b[36m1.8947\u001b[0m  0.0026\n",
            "      7        \u001b[36m1.8422\u001b[0m  0.0026\n",
            "      8        \u001b[36m1.7946\u001b[0m  0.0027\n",
            "      9        \u001b[36m1.7622\u001b[0m  0.0028\n",
            "     10        \u001b[36m1.7409\u001b[0m  0.0029\n",
            "Instance [0 5 8 2 8 3 0 0 0 8 8 8 8 8 8 2 5 3 0 8]\n",
            "0.1575\n",
            "--- Query no:   2  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3110\u001b[0m  0.0022\n",
            "      2        \u001b[36m2.1470\u001b[0m  0.0030\n",
            "      3        \u001b[36m2.0728\u001b[0m  0.0024\n",
            "      4        \u001b[36m2.0183\u001b[0m  0.0044\n",
            "      5        \u001b[36m1.9688\u001b[0m  0.0043\n",
            "      6        \u001b[36m1.9207\u001b[0m  0.0049\n",
            "      7        \u001b[36m1.8730\u001b[0m  0.0046\n",
            "      8        \u001b[36m1.8287\u001b[0m  0.0027\n",
            "      9        \u001b[36m1.7925\u001b[0m  0.0041\n",
            "     10        \u001b[36m1.7621\u001b[0m  0.0041\n",
            "Instance [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "0.2053\n",
            "--- Query no:   3  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3048\u001b[0m  0.0027\n",
            "      2        \u001b[36m2.1687\u001b[0m  0.0032\n",
            "      3        \u001b[36m2.0930\u001b[0m  0.0028\n",
            "      4        \u001b[36m2.0318\u001b[0m  0.0032\n",
            "      5        \u001b[36m1.9756\u001b[0m  0.0038\n",
            "      6        \u001b[36m1.9241\u001b[0m  0.0035\n",
            "      7        \u001b[36m1.8794\u001b[0m  0.0027\n",
            "      8        \u001b[36m1.8426\u001b[0m  0.0030\n",
            "      9        \u001b[36m1.8106\u001b[0m  0.0045\n",
            "     10        \u001b[36m1.7803\u001b[0m  0.0052\n",
            "Instance [2 6 1 5 7 6 1 7 2 6 5 7 1 6 1 1 7 6 6 7]\n",
            "0.3821\n",
            "--- Query no:   4  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3049\u001b[0m  0.0045\n",
            "      2        \u001b[36m2.1824\u001b[0m  0.0036\n",
            "      3        \u001b[36m2.1150\u001b[0m  0.0049\n",
            "      4        \u001b[36m2.0602\u001b[0m  0.0043\n",
            "      5        \u001b[36m2.0073\u001b[0m  0.0046\n",
            "      6        \u001b[36m1.9558\u001b[0m  0.0044\n",
            "      7        \u001b[36m1.9091\u001b[0m  0.0048\n",
            "      8        \u001b[36m1.8690\u001b[0m  0.0048\n",
            "      9        \u001b[36m1.8340\u001b[0m  0.0047\n",
            "     10        \u001b[36m1.8015\u001b[0m  0.0045\n",
            "Instance [9 2 5 7 6 4 4 6 6 2 2 2 2 3 5 5 2 2 2 2]\n",
            "0.5419\n",
            "--- Query no:   5  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3049\u001b[0m  0.0038\n",
            "      2        \u001b[36m2.1468\u001b[0m  0.0059\n",
            "      3        \u001b[36m2.0895\u001b[0m  0.0070\n",
            "      4        \u001b[36m2.0518\u001b[0m  0.0045\n",
            "      5        \u001b[36m2.0124\u001b[0m  0.0061\n",
            "      6        \u001b[36m1.9701\u001b[0m  0.0057\n",
            "      7        \u001b[36m1.9300\u001b[0m  0.0059\n",
            "      8        \u001b[36m1.8946\u001b[0m  0.0058\n",
            "      9        \u001b[36m1.8635\u001b[0m  0.0057\n",
            "     10        \u001b[36m1.8366\u001b[0m  0.0057\n",
            "Instance [4 5 7 4 2 4 9 4 4 4 4 9 4 4 4 4 4 5 6 4]\n",
            "0.4951\n",
            "--- Query no:   6  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3258\u001b[0m  0.0043\n",
            "      2        \u001b[36m2.1461\u001b[0m  0.0063\n",
            "      3        \u001b[36m2.0782\u001b[0m  0.0047\n",
            "      4        \u001b[36m2.0543\u001b[0m  0.0051\n",
            "      5        \u001b[36m2.0208\u001b[0m  0.0044\n",
            "      6        \u001b[36m1.9752\u001b[0m  0.0059\n",
            "      7        \u001b[36m1.9233\u001b[0m  0.0060\n",
            "      8        \u001b[36m1.8717\u001b[0m  0.0061\n",
            "      9        \u001b[36m1.8274\u001b[0m  0.0061\n",
            "     10        \u001b[36m1.7967\u001b[0m  0.0060\n",
            "Instance [7 3 9 7 7 3 3 3 3 3 9 3 7 3 3 9 7 3 7 9]\n",
            "0.6045\n",
            "--- Query no:   7  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3060\u001b[0m  0.0041\n",
            "      2        \u001b[36m2.1332\u001b[0m  0.0057\n",
            "      3        \u001b[36m2.0430\u001b[0m  0.0054\n",
            "      4        \u001b[36m1.9852\u001b[0m  0.0047\n",
            "      5        \u001b[36m1.9279\u001b[0m  0.0044\n",
            "      6        \u001b[36m1.8728\u001b[0m  0.0062\n",
            "      7        \u001b[36m1.8272\u001b[0m  0.0061\n",
            "      8        \u001b[36m1.7914\u001b[0m  0.0050\n",
            "      9        \u001b[36m1.7622\u001b[0m  0.0060\n",
            "     10        \u001b[36m1.7366\u001b[0m  0.0059\n",
            "Instance [2 2 0 2 2 2 0 4 0 5 2 5 2 2 5 2 7 8 4 9]\n",
            "0.6774\n",
            "--- Query no:   8  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2949\u001b[0m  0.0044\n",
            "      2        \u001b[36m2.1284\u001b[0m  0.0057\n",
            "      3        \u001b[36m2.0457\u001b[0m  0.0055\n",
            "      4        \u001b[36m1.9801\u001b[0m  0.0060\n",
            "      5        \u001b[36m1.9269\u001b[0m  0.0048\n",
            "      6        \u001b[36m1.8736\u001b[0m  0.0056\n",
            "      7        \u001b[36m1.8222\u001b[0m  0.0048\n",
            "      8        \u001b[36m1.7801\u001b[0m  0.0063\n",
            "      9        \u001b[36m1.7497\u001b[0m  0.0054\n",
            "     10        \u001b[36m1.7260\u001b[0m  0.0053\n",
            "Instance [4 8 8 4 4 4 5 8 4 4 4 8 4 0 4 4 4 4 4 4]\n",
            "0.6766\n",
            "--- Query no:   9  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2824\u001b[0m  0.0068\n",
            "      2        \u001b[36m2.1410\u001b[0m  0.0093\n",
            "      3        \u001b[36m2.0511\u001b[0m  0.0074\n",
            "      4        \u001b[36m1.9760\u001b[0m  0.0070\n",
            "      5        \u001b[36m1.9181\u001b[0m  0.0072\n",
            "      6        \u001b[36m1.8619\u001b[0m  0.0073\n",
            "      7        \u001b[36m1.8159\u001b[0m  0.0072\n",
            "      8        \u001b[36m1.7830\u001b[0m  0.0070\n",
            "      9        \u001b[36m1.7529\u001b[0m  0.0074\n",
            "     10        \u001b[36m1.7258\u001b[0m  0.0059\n",
            "Instance [0 2 0 9 6 6 9 8 8 6 5 0 4 0 7 9 6 8 0 5]\n",
            "0.7043\n",
            "--- Query no:   10  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2879\u001b[0m  0.0103\n",
            "      2        \u001b[36m2.1494\u001b[0m  0.0078\n",
            "      3        \u001b[36m2.0690\u001b[0m  0.0067\n",
            "      4        \u001b[36m1.9888\u001b[0m  0.0067\n",
            "      5        \u001b[36m1.9255\u001b[0m  0.0089\n",
            "      6        \u001b[36m1.8760\u001b[0m  0.0066\n",
            "      7        \u001b[36m1.8359\u001b[0m  0.0064\n",
            "      8        \u001b[36m1.7998\u001b[0m  0.0065\n",
            "      9        \u001b[36m1.7689\u001b[0m  0.0068\n",
            "     10        \u001b[36m1.7436\u001b[0m  0.0068\n",
            "Instance [4 4 0 9 7 0 2 2 2 3 0 2 3 5 5 2 5 8 8 5]\n",
            "0.7037\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[858   0   7   8   4  29  11   0  69   1]\n",
            " [  0 878 127   6   1   3   2   0 107   0]\n",
            " [ 35   8 817  38  15   2  12  11  55   0]\n",
            " [ 34  11  51 758   4  17  10  17 115   5]\n",
            " [  2   4  31   0 903   1   4   9  15   5]\n",
            " [ 25   4  13 185  47 304  17   0 299   9]\n",
            " [ 41   3 155   1   8   5 756   0  17   0]\n",
            " [  2  11  26   2  93  10   0 828  22  50]\n",
            " [  9  36  25  58  23  10   6   7 793   8]\n",
            " [  6   6  26  15 681   1   0  74  41 142]]\n",
            "Accuracy:  0.7037\n",
            "Macro F1-score:  0.681062291274566\n",
            "Micro F1-score:  0.7037\n",
            "Weighted F1-score:  0.6859040511178867\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AL_Retrain(30, 10, 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBLdaLYmzjw1",
        "outputId": "41041af5-e757-4edc-efb4-e69ca9f71bb0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2996\u001b[0m  0.0030\n",
            "      2        \u001b[36m2.1434\u001b[0m  0.0024\n",
            "      3        \u001b[36m2.0174\u001b[0m  0.0031\n",
            "      4        \u001b[36m1.9161\u001b[0m  0.0030\n",
            "      5        \u001b[36m1.8320\u001b[0m  0.0032\n",
            "      6        \u001b[36m1.7630\u001b[0m  0.0027\n",
            "      7        \u001b[36m1.7078\u001b[0m  0.0053\n",
            "      8        \u001b[36m1.6647\u001b[0m  0.0044\n",
            "      9        \u001b[36m1.6308\u001b[0m  0.0024\n",
            "     10        \u001b[36m1.6037\u001b[0m  0.0023\n",
            "No of initial data:  30\n",
            "0.531\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[794   2  17   6   5  59  87   0  16   1]\n",
            " [  0 910  26 112   7  17  24  24   4   0]\n",
            " [112 104 309  54  52 175 130  23  32   2]\n",
            " [ 31  32  10 406   2 388  36  26  72  19]\n",
            " [ 22  11  10  49 587   0  29  26  19 221]\n",
            " [151  15  10 116  31 266  88   8 143  75]\n",
            " [ 80  14  92   0  51  13 733   0   3   0]\n",
            " [ 26  30   0  23 205  14   1 486   3 256]\n",
            " [ 38 126  12 180 100  46  65  26 314  68]\n",
            " [ 11  10  15  73 238   4   5 107  24 505]]\n",
            "Accuracy:  0.531\n",
            "Macro F1-score:  0.516939981152115\n",
            "Micro F1-score:  0.531\n",
            "Weighted F1-score:  0.5221268695836478\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[0, 6, 2, 8, 5, 2, 2, 8, 0, 8, 0, 3, 3, 7, 5, 5, 9, 3, 7, 9, 6]\n",
            "Counter({0: 3, 2: 3, 8: 3, 5: 3, 3: 3, 6: 2, 7: 2, 9: 2})\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3083\u001b[0m  0.0017\n",
            "      2        \u001b[36m2.0462\u001b[0m  0.0025\n",
            "      3        \u001b[36m1.9275\u001b[0m  0.0021\n",
            "      4        \u001b[36m1.8242\u001b[0m  0.0025\n",
            "      5        \u001b[36m1.7275\u001b[0m  0.0031\n",
            "      6        \u001b[36m1.6686\u001b[0m  0.0029\n",
            "      7        \u001b[36m1.6404\u001b[0m  0.0027\n",
            "      8        \u001b[36m1.6153\u001b[0m  0.0034\n",
            "      9        \u001b[36m1.5883\u001b[0m  0.0021\n",
            "     10        \u001b[36m1.5645\u001b[0m  0.0016\n",
            "0.3517\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[ 685    0   81   49    0   67   26    1   78    0]\n",
            " [   1    0    3 1081    0    0    1    9   29    0]\n",
            " [  97    0  509  272    0    1   26   10   72    6]\n",
            " [  43    0   77  758    0   56    6   28   28   26]\n",
            " [  49    0   44  376    0    1   25  102  269  108]\n",
            " [  43    0   65  213    0  258    8    7  284   25]\n",
            " [  35    0   84  356    0    2  347    0  162    0]\n",
            " [   3    0    6  377    0    0    5  392  254    7]\n",
            " [  25    0    7  365    0    7    2   10  543   16]\n",
            " [  20    0    5  409    0    7   11  201  314   25]]\n",
            "Accuracy:  0.3517\n",
            "Macro F1-score:  0.32339645279330204\n",
            "Micro F1-score:  0.3517\n",
            "Weighted F1-score:  0.3192110753416384\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "--- Query no:   1  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3129\u001b[0m  0.0022\n",
            "      2        \u001b[36m2.1141\u001b[0m  0.0061\n",
            "      3        \u001b[36m2.0543\u001b[0m  0.0035\n",
            "      4        \u001b[36m2.0101\u001b[0m  0.0028\n",
            "      5        \u001b[36m1.9638\u001b[0m  0.0028\n",
            "      6        \u001b[36m1.9187\u001b[0m  0.0024\n",
            "      7        \u001b[36m1.8741\u001b[0m  0.0027\n",
            "      8        \u001b[36m1.8312\u001b[0m  0.0034\n",
            "      9        \u001b[36m1.7986\u001b[0m  0.0038\n",
            "     10        \u001b[36m1.7728\u001b[0m  0.0023\n",
            "Instance [0 8 8 8 8 8 3 2 0 0 8 8 8 8 2 5 0 8 8 5 0 7 6 5 8 2 5 2 2 0]\n",
            "0.1258\n",
            "--- Query no:   2  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2981\u001b[0m  0.0024\n",
            "      2        \u001b[36m2.1442\u001b[0m  0.0039\n",
            "      3        \u001b[36m2.0774\u001b[0m  0.0032\n",
            "      4        \u001b[36m2.0226\u001b[0m  0.0041\n",
            "      5        \u001b[36m1.9700\u001b[0m  0.0040\n",
            "      6        \u001b[36m1.9234\u001b[0m  0.0027\n",
            "      7        \u001b[36m1.8827\u001b[0m  0.0038\n",
            "      8        \u001b[36m1.8479\u001b[0m  0.0041\n",
            "      9        \u001b[36m1.8184\u001b[0m  0.0041\n",
            "     10        \u001b[36m1.7930\u001b[0m  0.0041\n",
            "Instance [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "0.259\n",
            "--- Query no:   3  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3119\u001b[0m  0.0028\n",
            "      2        \u001b[36m2.1804\u001b[0m  0.0055\n",
            "      3        \u001b[36m2.1139\u001b[0m  0.0040\n",
            "      4        \u001b[36m2.0563\u001b[0m  0.0038\n",
            "      5        \u001b[36m1.9994\u001b[0m  0.0040\n",
            "      6        \u001b[36m1.9513\u001b[0m  0.0037\n",
            "      7        \u001b[36m1.9142\u001b[0m  0.0037\n",
            "      8        \u001b[36m1.8801\u001b[0m  0.0035\n",
            "      9        \u001b[36m1.8463\u001b[0m  0.0035\n",
            "     10        \u001b[36m1.8147\u001b[0m  0.0036\n",
            "Instance [6 1 7 3 1 3 7 2 6 6 4 9 7 7 6 5 2 2 5 3 3 6 9 2 2 5 5 1 5 7]\n",
            "0.458\n",
            "--- Query no:   4  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3037\u001b[0m  0.0040\n",
            "      2        \u001b[36m2.1330\u001b[0m  0.0064\n",
            "      3        \u001b[36m2.0755\u001b[0m  0.0047\n",
            "      4        \u001b[36m2.0343\u001b[0m  0.0048\n",
            "      5        \u001b[36m1.9942\u001b[0m  0.0060\n",
            "      6        \u001b[36m1.9519\u001b[0m  0.0060\n",
            "      7        \u001b[36m1.9108\u001b[0m  0.0046\n",
            "      8        \u001b[36m1.8722\u001b[0m  0.0076\n",
            "      9        \u001b[36m1.8366\u001b[0m  0.0042\n",
            "     10        \u001b[36m1.8045\u001b[0m  0.0048\n",
            "Instance [4 4 4 4 4 3 4 3 4 2 2 5 5 2 4 2 5 4 4 5 2 4 4 5 2 4 4 4 4 4]\n",
            "0.4368\n",
            "--- Query no:   5  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2770\u001b[0m  0.0041\n",
            "      2        \u001b[36m2.0999\u001b[0m  0.0065\n",
            "      3        \u001b[36m2.0254\u001b[0m  0.0051\n",
            "      4        \u001b[36m1.9739\u001b[0m  0.0050\n",
            "      5        \u001b[36m1.9311\u001b[0m  0.0049\n",
            "      6        \u001b[36m1.8917\u001b[0m  0.0048\n",
            "      7        \u001b[36m1.8559\u001b[0m  0.0057\n",
            "      8        \u001b[36m1.8245\u001b[0m  0.0051\n",
            "      9        \u001b[36m1.7965\u001b[0m  0.0062\n",
            "     10        \u001b[36m1.7692\u001b[0m  0.0064\n",
            "Instance [2 6 2 2 9 6 5 7 6 2 6 6 4 2 6 6 2 8 2 6 6 2 2 2 6 2 2 6 6 2]\n",
            "0.4951\n",
            "--- Query no:   6  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2992\u001b[0m  0.0045\n",
            "      2        \u001b[36m2.1237\u001b[0m  0.0073\n",
            "      3        \u001b[36m2.0300\u001b[0m  0.0054\n",
            "      4        \u001b[36m1.9619\u001b[0m  0.0052\n",
            "      5        \u001b[36m1.9067\u001b[0m  0.0051\n",
            "      6        \u001b[36m1.8570\u001b[0m  0.0054\n",
            "      7        \u001b[36m1.8118\u001b[0m  0.0060\n",
            "      8        \u001b[36m1.7759\u001b[0m  0.0060\n",
            "      9        \u001b[36m1.7491\u001b[0m  0.0067\n",
            "     10        \u001b[36m1.7251\u001b[0m  0.0059\n",
            "Instance [4 5 9 4 9 9 9 9 1 4 9 5 9 9 5 9 9 9 9 9 9 9 3 9 5 9 9 7 9 9]\n",
            "0.5623\n",
            "--- Query no:   7  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3100\u001b[0m  0.0047\n",
            "      2        \u001b[36m2.1333\u001b[0m  0.0063\n",
            "      3        \u001b[36m2.0353\u001b[0m  0.0079\n",
            "      4        \u001b[36m1.9614\u001b[0m  0.0063\n",
            "      5        \u001b[36m1.9042\u001b[0m  0.0064\n",
            "      6        \u001b[36m1.8612\u001b[0m  0.0058\n",
            "      7        \u001b[36m1.8206\u001b[0m  0.0054\n",
            "      8        \u001b[36m1.7844\u001b[0m  0.0060\n",
            "      9        \u001b[36m1.7573\u001b[0m  0.0058\n",
            "     10        \u001b[36m1.7357\u001b[0m  0.0057\n",
            "Instance [6 9 6 6 8 6 6 0 6 6 0 6 6 6 1 6 6 8 6 6 6 6 6 6 6 0 6 6 6 6]\n",
            "0.5567\n",
            "--- Query no:   8  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2950\u001b[0m  0.0058\n",
            "      2        \u001b[36m2.1185\u001b[0m  0.0084\n",
            "      3        \u001b[36m2.0304\u001b[0m  0.0080\n",
            "      4        \u001b[36m1.9646\u001b[0m  0.0079\n",
            "      5        \u001b[36m1.8991\u001b[0m  0.0082\n",
            "      6        \u001b[36m1.8426\u001b[0m  0.0078\n",
            "      7        \u001b[36m1.8043\u001b[0m  0.0077\n",
            "      8        \u001b[36m1.7769\u001b[0m  0.0077\n",
            "      9        \u001b[36m1.7528\u001b[0m  0.0070\n",
            "     10        \u001b[36m1.7324\u001b[0m  0.0079\n",
            "Instance [3 3 5 3 2 8 3 0 0 8 3 3 3 0 4 3 5 5 3 0 8 8 8 3 8 9 3 3 5 8]\n",
            "0.5982\n",
            "--- Query no:   9  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2951\u001b[0m  0.0100\n",
            "      2        \u001b[36m2.1099\u001b[0m  0.0119\n",
            "      3        \u001b[36m2.0157\u001b[0m  0.0095\n",
            "      4        \u001b[36m1.9348\u001b[0m  0.0097\n",
            "      5        \u001b[36m1.8654\u001b[0m  0.0094\n",
            "      6        \u001b[36m1.8209\u001b[0m  0.0099\n",
            "      7        \u001b[36m1.7863\u001b[0m  0.0089\n",
            "      8        \u001b[36m1.7573\u001b[0m  0.0089\n",
            "      9        \u001b[36m1.7333\u001b[0m  0.0086\n",
            "     10        \u001b[36m1.7123\u001b[0m  0.0087\n",
            "Instance [7 4 4 8 6 4 4 3 1 3 4 5 8 3 3 4 8 8 5 7 4 4 8 2 5 7 7 3 3 4]\n",
            "0.6249\n",
            "--- Query no:   10  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2905\u001b[0m  0.0065\n",
            "      2        \u001b[36m2.1094\u001b[0m  0.0092\n",
            "      3        \u001b[36m2.0188\u001b[0m  0.0091\n",
            "      4        \u001b[36m1.9465\u001b[0m  0.0074\n",
            "      5        \u001b[36m1.8836\u001b[0m  0.0073\n",
            "      6        \u001b[36m1.8346\u001b[0m  0.0073\n",
            "      7        \u001b[36m1.7965\u001b[0m  0.0073\n",
            "      8        \u001b[36m1.7693\u001b[0m  0.0078\n",
            "      9        \u001b[36m1.7463\u001b[0m  0.0117\n",
            "     10        \u001b[36m1.7243\u001b[0m  0.0114\n",
            "Instance [9 2 8 9 3 8 2 3 9 9 8 4 1 2 2 2 8 3 3 3 2 8 3 4 2 3 4 3 9 5]\n",
            "0.6352\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[396   0  11  13   4 482  39   2  36   4]\n",
            " [  0 842  74  20   1   0   2   0 184   1]\n",
            " [  1  14 760  91  25   6  14   3  76   3]\n",
            " [  0  14  21 807   3  40   3   5 104  25]\n",
            " [  0   7  51   0 815  12   4   9  12  64]\n",
            " [  7   6  11 204  26 344  25   0 258  22]\n",
            " [  1   3 180   1  10  21 742   0  28   0]\n",
            " [  0  16  57  17  38  70   0 409  14 423]\n",
            " [  5  21  11  36   9  20   8   3 792  70]\n",
            " [  1   4  56  10 383  11   0  64  18 445]]\n",
            "Accuracy:  0.6352\n",
            "Macro F1-score:  0.6284519168879099\n",
            "Micro F1-score:  0.6352\n",
            "Weighted F1-score:  0.6329346306426119\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AL_Retrain(50, 10, 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZp4nt_hznAo",
        "outputId": "ccc0cbd5-dc66-4b58-c8aa-1b29da765ee1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2898\u001b[0m  0.0022\n",
            "      2        \u001b[36m2.1418\u001b[0m  0.0025\n",
            "      3        \u001b[36m2.0251\u001b[0m  0.0024\n",
            "      4        \u001b[36m1.9295\u001b[0m  0.0026\n",
            "      5        \u001b[36m1.8501\u001b[0m  0.0028\n",
            "      6        \u001b[36m1.7864\u001b[0m  0.0028\n",
            "      7        \u001b[36m1.7369\u001b[0m  0.0027\n",
            "      8        \u001b[36m1.6977\u001b[0m  0.0025\n",
            "      9        \u001b[36m1.6653\u001b[0m  0.0038\n",
            "     10        \u001b[36m1.6378\u001b[0m  0.0025\n",
            "No of initial data:  50\n",
            "0.5966\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[820   4  17   7   3  25  80   0  13  18]\n",
            " [  0 927  24 149   1   3   5   4  11   0]\n",
            " [148  97 359  56  43  23 113  19 123  12]\n",
            " [ 23  28  14 437   4 348  23  16 107  22]\n",
            " [  9  20   6  24 634   0  10  52  16 203]\n",
            " [124  25  11 137  35 229  62   6 203  71]\n",
            " [ 52  46  61   1  18  16 780   1  10   1]\n",
            " [  7  51   3  21  90   4   1 687   2 178]\n",
            " [ 47  80  13 102  25  15  42  16 579  56]\n",
            " [  6  17   3  39 202   3   0 201   7 514]]\n",
            "Accuracy:  0.5966\n",
            "Macro F1-score:  0.5813533250032935\n",
            "Micro F1-score:  0.5966\n",
            "Weighted F1-score:  0.586174332628545\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[2, 8, 5, 5, 2, 8, 8, 2, 2, 2, 8, 8, 0, 0, 5, 5, 0, 3, 0, 3, 3, 0, 5, 3, 7, 3, 9, 9, 4]\n",
            "Counter({2: 5, 8: 5, 5: 5, 0: 5, 3: 5, 9: 2, 7: 1, 4: 1})\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3059\u001b[0m  0.0018\n",
            "      2        \u001b[36m2.0350\u001b[0m  0.0023\n",
            "      3        \u001b[36m1.9701\u001b[0m  0.0025\n",
            "      4        \u001b[36m1.9284\u001b[0m  0.0023\n",
            "      5        \u001b[36m1.8852\u001b[0m  0.0037\n",
            "      6        \u001b[36m1.8416\u001b[0m  0.0029\n",
            "      7        \u001b[36m1.7976\u001b[0m  0.0027\n",
            "      8        \u001b[36m1.7531\u001b[0m  0.0047\n",
            "      9        \u001b[36m1.7189\u001b[0m  0.0023\n",
            "     10        \u001b[36m1.6997\u001b[0m  0.0021\n",
            "0.2306\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[120   0 107   0   0  21   0   0 635 104]\n",
            " [  0   0 228  21 375   0   0   0 500   0]\n",
            " [  4   0 669  17   9   0   0   0 288   6]\n",
            " [ 11   0 182 509   0  24   0   0 294   2]\n",
            " [  1   0  35   2  20   2   0   0 908   6]\n",
            " [  9   0 110  49   1 125   0   0 608   1]\n",
            " [ 32   0 122   0   0   0   0   0 816  16]\n",
            " [ 75   0  24   2   3   2   0   0 933   5]\n",
            " [  0   0  96  17   0   7   0   0 855   0]\n",
            " [  2   0   1   4  14   1   0   0 962   8]]\n",
            "Accuracy:  0.2306\n",
            "Macro F1-score:  0.18272888421213823\n",
            "Micro F1-score:  0.2306\n",
            "Weighted F1-score:  0.1806050689682749\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "--- Query no:   1  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2849\u001b[0m  0.0022\n",
            "      2        \u001b[36m2.1340\u001b[0m  0.0033\n",
            "      3        \u001b[36m2.0597\u001b[0m  0.0032\n",
            "      4        \u001b[36m1.9936\u001b[0m  0.0044\n",
            "      5        \u001b[36m1.9261\u001b[0m  0.0031\n",
            "      6        \u001b[36m1.8609\u001b[0m  0.0046\n",
            "      7        \u001b[36m1.8063\u001b[0m  0.0042\n",
            "      8        \u001b[36m1.7676\u001b[0m  0.0042\n",
            "      9        \u001b[36m1.7419\u001b[0m  0.0042\n",
            "     10        \u001b[36m1.7199\u001b[0m  0.0041\n",
            "Instance [0 2 2 5 8 8 2 5 8 8 0 2 2 3 5 2 0 3 0 0]\n",
            "0.6544\n",
            "--- Query no:   2  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3029\u001b[0m  0.0023\n",
            "      2        \u001b[36m2.1577\u001b[0m  0.0050\n",
            "      3        \u001b[36m2.0912\u001b[0m  0.0037\n",
            "      4        \u001b[36m2.0350\u001b[0m  0.0031\n",
            "      5        \u001b[36m1.9739\u001b[0m  0.0031\n",
            "      6        \u001b[36m1.9116\u001b[0m  0.0044\n",
            "      7        \u001b[36m1.8592\u001b[0m  0.0043\n",
            "      8        \u001b[36m1.8207\u001b[0m  0.0046\n",
            "      9        \u001b[36m1.7857\u001b[0m  0.0029\n",
            "     10        \u001b[36m1.7526\u001b[0m  0.0032\n",
            "Instance [8 5 1 8 5 5 5 5 5 7 3 8 5 5 5 9 9 5 5 5]\n",
            "0.6343\n",
            "--- Query no:   3  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3151\u001b[0m  0.0025\n",
            "      2        \u001b[36m2.1828\u001b[0m  0.0048\n",
            "      3        \u001b[36m2.1161\u001b[0m  0.0043\n",
            "      4        \u001b[36m2.0609\u001b[0m  0.0045\n",
            "      5        \u001b[36m2.0040\u001b[0m  0.0040\n",
            "      6        \u001b[36m1.9476\u001b[0m  0.0044\n",
            "      7        \u001b[36m1.8968\u001b[0m  0.0039\n",
            "      8        \u001b[36m1.8524\u001b[0m  0.0048\n",
            "      9        \u001b[36m1.8132\u001b[0m  0.0031\n",
            "     10        \u001b[36m1.7814\u001b[0m  0.0038\n",
            "Instance [2 2 4 2 2 4 9 2 6 8 7 2 4 9 4 3 5 6 5 4]\n",
            "0.6657\n",
            "--- Query no:   4  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3048\u001b[0m  0.0038\n",
            "      2        \u001b[36m2.1409\u001b[0m  0.0063\n",
            "      3        \u001b[36m2.0925\u001b[0m  0.0053\n",
            "      4        \u001b[36m2.0588\u001b[0m  0.0055\n",
            "      5        \u001b[36m2.0249\u001b[0m  0.0058\n",
            "      6        \u001b[36m1.9893\u001b[0m  0.0056\n",
            "      7        \u001b[36m1.9543\u001b[0m  0.0073\n",
            "      8        \u001b[36m1.9217\u001b[0m  0.0058\n",
            "      9        \u001b[36m1.8927\u001b[0m  0.0043\n",
            "     10        \u001b[36m1.8655\u001b[0m  0.0050\n",
            "Instance [9 9 1 5 2 2 7 8 8 8 4 8 2 2 2 1 9 2 2 2]\n",
            "0.1839\n",
            "--- Query no:   5  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2977\u001b[0m  0.0039\n",
            "      2        \u001b[36m2.1342\u001b[0m  0.0054\n",
            "      3        \u001b[36m2.0741\u001b[0m  0.0049\n",
            "      4        \u001b[36m2.0290\u001b[0m  0.0054\n",
            "      5        \u001b[36m1.9907\u001b[0m  0.0058\n",
            "      6        \u001b[36m1.9526\u001b[0m  0.0059\n",
            "      7        \u001b[36m1.9173\u001b[0m  0.0058\n",
            "      8        \u001b[36m1.8815\u001b[0m  0.0051\n",
            "      9        \u001b[36m1.8425\u001b[0m  0.0056\n",
            "     10        \u001b[36m1.8092\u001b[0m  0.0057\n",
            "Instance [4 7 4 9 5 7 5 5 5 5 3 9 4 4 5 4 5 9 4 1]\n",
            "0.597\n",
            "--- Query no:   6  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3103\u001b[0m  0.0040\n",
            "      2        \u001b[36m2.1411\u001b[0m  0.0060\n",
            "      3        \u001b[36m2.0748\u001b[0m  0.0059\n",
            "      4        \u001b[36m2.0245\u001b[0m  0.0055\n",
            "      5        \u001b[36m1.9749\u001b[0m  0.0059\n",
            "      6        \u001b[36m1.9295\u001b[0m  0.0060\n",
            "      7        \u001b[36m1.8846\u001b[0m  0.0057\n",
            "      8        \u001b[36m1.8365\u001b[0m  0.0051\n",
            "      9        \u001b[36m1.7996\u001b[0m  0.0048\n",
            "     10        \u001b[36m1.7727\u001b[0m  0.0050\n",
            "Instance [4 5 2 9 9 4 7 8 3 9 5 9 3 6 9 9 5 8 0 5]\n",
            "0.6459\n",
            "--- Query no:   7  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3004\u001b[0m  0.0043\n",
            "      2        \u001b[36m2.1419\u001b[0m  0.0073\n",
            "      3        \u001b[36m2.0600\u001b[0m  0.0057\n",
            "      4        \u001b[36m1.9948\u001b[0m  0.0053\n",
            "      5        \u001b[36m1.9344\u001b[0m  0.0062\n",
            "      6        \u001b[36m1.8910\u001b[0m  0.0065\n",
            "      7        \u001b[36m1.8506\u001b[0m  0.0053\n",
            "      8        \u001b[36m1.8100\u001b[0m  0.0052\n",
            "      9        \u001b[36m1.7743\u001b[0m  0.0059\n",
            "     10        \u001b[36m1.7483\u001b[0m  0.0060\n",
            "Instance [8 4 7 7 2 0 6 7 3 2 7 0 7 0 7 8 3 7 7 8]\n",
            "0.7003\n",
            "--- Query no:   8  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2920\u001b[0m  0.0068\n",
            "      2        \u001b[36m2.1501\u001b[0m  0.0076\n",
            "      3        \u001b[36m2.0726\u001b[0m  0.0071\n",
            "      4        \u001b[36m2.0050\u001b[0m  0.0068\n",
            "      5        \u001b[36m1.9389\u001b[0m  0.0070\n",
            "      6        \u001b[36m1.8879\u001b[0m  0.0069\n",
            "      7        \u001b[36m1.8448\u001b[0m  0.0063\n",
            "      8        \u001b[36m1.8065\u001b[0m  0.0062\n",
            "      9        \u001b[36m1.7796\u001b[0m  0.0076\n",
            "     10        \u001b[36m1.7562\u001b[0m  0.0069\n",
            "Instance [5 3 8 1 6 1 3 4 3 8 8 2 8 1 1 7 3 3 7 1]\n",
            "0.7535\n",
            "--- Query no:   9  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2996\u001b[0m  0.0081\n",
            "      2        \u001b[36m2.1653\u001b[0m  0.0089\n",
            "      3        \u001b[36m2.0828\u001b[0m  0.0104\n",
            "      4        \u001b[36m2.0146\u001b[0m  0.0119\n",
            "      5        \u001b[36m1.9549\u001b[0m  0.0089\n",
            "      6        \u001b[36m1.9104\u001b[0m  0.0070\n",
            "      7        \u001b[36m1.8682\u001b[0m  0.0074\n",
            "      8        \u001b[36m1.8277\u001b[0m  0.0061\n",
            "      9        \u001b[36m1.7938\u001b[0m  0.0065\n",
            "     10        \u001b[36m1.7684\u001b[0m  0.0103\n",
            "Instance [7 7 1 7 2 7 3 7 7 0 7 9 7 0 5 9 8 9 7 4]\n",
            "0.7485\n",
            "--- Query no:   10  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3112\u001b[0m  0.0050\n",
            "      2        \u001b[36m2.1783\u001b[0m  0.0095\n",
            "      3        \u001b[36m2.0955\u001b[0m  0.0056\n",
            "      4        \u001b[36m2.0297\u001b[0m  0.0061\n",
            "      5        \u001b[36m1.9716\u001b[0m  0.0057\n",
            "      6        \u001b[36m1.9258\u001b[0m  0.0051\n",
            "      7        \u001b[36m1.8821\u001b[0m  0.0065\n",
            "      8        \u001b[36m1.8405\u001b[0m  0.0058\n",
            "      9        \u001b[36m1.8084\u001b[0m  0.0069\n",
            "     10        \u001b[36m1.7845\u001b[0m  0.0070\n",
            "Instance [8 0 7 8 5 4 4 5 7 5 3 9 4 5 6 6 7 7 7 4]\n",
            "0.753\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[800   0  17   9   2 111  12   1  35   0]\n",
            " [  0 952 116   1   2  21   3   0  29   0]\n",
            " [ 10  11 825  23  26   6  25   7  56   4]\n",
            " [ 30  15  83 728   1  56  16  18  64  11]\n",
            " [  6   3   9   0 746  10   0   2  12 186]\n",
            " [ 42   6  15 131   8 493  32   1 156  19]\n",
            " [ 41   3 153   0  38  22 725   1   3   0]\n",
            " [ 16   9  33  19  12  17   0 736   9 193]\n",
            " [  7  31  42  18   5  89  19   3 712  49]\n",
            " [  4   4   8  17  45  19   0  71  11 813]]\n",
            "Accuracy:  0.753\n",
            "Macro F1-score:  0.7518585709503876\n",
            "Micro F1-score:  0.753\n",
            "Weighted F1-score:  0.7553122644335046\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AL_Retrain(50, 10, 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TAieaAAzwqn",
        "outputId": "b8c3ba03-fed2-4a93-d180-6eed6a332aae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3050\u001b[0m  0.0022\n",
            "      2        \u001b[36m2.1519\u001b[0m  0.0034\n",
            "      3        \u001b[36m2.0298\u001b[0m  0.0030\n",
            "      4        \u001b[36m1.9324\u001b[0m  0.0034\n",
            "      5        \u001b[36m1.8529\u001b[0m  0.0033\n",
            "      6        \u001b[36m1.7889\u001b[0m  0.0023\n",
            "      7        \u001b[36m1.7384\u001b[0m  0.0023\n",
            "      8        \u001b[36m1.6985\u001b[0m  0.0033\n",
            "      9        \u001b[36m1.6659\u001b[0m  0.0033\n",
            "     10        \u001b[36m1.6385\u001b[0m  0.0021\n",
            "No of initial data:  50\n",
            "0.5926\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[803   4  27   7   3  31  80   1  14  17]\n",
            " [  0 933  19 147   0   2   7   3  13   0]\n",
            " [121 104 365  46  47  39 121  18 122  10]\n",
            " [ 19  32   8 428   5 340  23  20 124  23]\n",
            " [  6  22   6  21 616   0  17  70  14 202]\n",
            " [113  33  14 135  37 206  58  13 225  69]\n",
            " [ 54  50  63   0  13  11 785   0  10   0]\n",
            " [  8  55   4  25  90   1   1 705   3 152]\n",
            " [ 35  93  16  81  29  17  50  17 584  53]\n",
            " [  4  18   2  39 206   4   0 210   8 501]]\n",
            "Accuracy:  0.5926\n",
            "Macro F1-score:  0.576153371470215\n",
            "Micro F1-score:  0.5926\n",
            "Weighted F1-score:  0.581155800484345\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[2, 8, 2, 5, 2, 0, 5, 0, 8, 5, 0, 8, 8, 3, 8, 2, 2, 0, 0, 3, 3, 5, 3, 5, 3, 4, 9, 6, 7, 6]\n",
            "Counter({2: 5, 8: 5, 5: 5, 0: 5, 3: 5, 6: 2, 4: 1, 9: 1, 7: 1})\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3158\u001b[0m  0.0019\n",
            "      2        \u001b[36m2.0483\u001b[0m  0.0023\n",
            "      3        \u001b[36m1.9907\u001b[0m  0.0024\n",
            "      4        \u001b[36m1.9457\u001b[0m  0.0027\n",
            "      5        \u001b[36m1.8913\u001b[0m  0.0022\n",
            "      6        \u001b[36m1.8353\u001b[0m  0.0022\n",
            "      7        \u001b[36m1.7825\u001b[0m  0.0022\n",
            "      8        \u001b[36m1.7343\u001b[0m  0.0026\n",
            "      9        \u001b[36m1.6966\u001b[0m  0.0025\n",
            "     10        \u001b[36m1.6617\u001b[0m  0.0021\n",
            "0.3094\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[754   0 170   1   0  51   9   1   1   0]\n",
            " [  7   0  88 717 191   4   0  48  69   0]\n",
            " [ 55   0 773  93   0   1   0   4  67   0]\n",
            " [ 52   0 219 676   0  57   0   6  12   0]\n",
            " [136   0 316 199   5  23  34  26 235   0]\n",
            " [120   0 171 176   0 358   1  48  29   0]\n",
            " [149   0 623  22   0   3 179   0  10   0]\n",
            " [321   0  29 336   0   3   1 184 170   0]\n",
            " [ 31   0 254 409   0  35   0  81 165   0]\n",
            " [143   0  64 422   0  18   1  35 309   0]]\n",
            "Accuracy:  0.3094\n",
            "Macro F1-score:  0.2503836976616378\n",
            "Micro F1-score:  0.3094\n",
            "Weighted F1-score:  0.245596015319231\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "--- Query no:   1  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3033\u001b[0m  0.0023\n",
            "      2        \u001b[36m2.1301\u001b[0m  0.0049\n",
            "      3        \u001b[36m2.0671\u001b[0m  0.0029\n",
            "      4        \u001b[36m2.0213\u001b[0m  0.0026\n",
            "      5        \u001b[36m1.9742\u001b[0m  0.0029\n",
            "      6        \u001b[36m1.9239\u001b[0m  0.0040\n",
            "      7        \u001b[36m1.8720\u001b[0m  0.0028\n",
            "      8        \u001b[36m1.8228\u001b[0m  0.0039\n",
            "      9        \u001b[36m1.7833\u001b[0m  0.0029\n",
            "     10        \u001b[36m1.7585\u001b[0m  0.0035\n",
            "Instance [8 2 2 2 0 0 8 2 0 8 0 2 2 2 8 8 0 0 8 5 5 0 2 3 5 3 8 8 0 2]\n",
            "0.5455\n",
            "--- Query no:   2  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3054\u001b[0m  0.0026\n",
            "      2        \u001b[36m2.1543\u001b[0m  0.0034\n",
            "      3        \u001b[36m2.0844\u001b[0m  0.0047\n",
            "      4        \u001b[36m2.0321\u001b[0m  0.0054\n",
            "      5        \u001b[36m1.9810\u001b[0m  0.0037\n",
            "      6        \u001b[36m1.9272\u001b[0m  0.0034\n",
            "      7        \u001b[36m1.8713\u001b[0m  0.0048\n",
            "      8        \u001b[36m1.8185\u001b[0m  0.0036\n",
            "      9        \u001b[36m1.7770\u001b[0m  0.0053\n",
            "     10        \u001b[36m1.7486\u001b[0m  0.0035\n",
            "Instance [1 3 3 1 1 1 3 1 1 1 1 1 1 1 3 1 5 1 1 9 1 3 1 1 1 1 1 6 1 1]\n",
            "0.6372\n",
            "--- Query no:   3  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2919\u001b[0m  0.0041\n",
            "      2        \u001b[36m2.0967\u001b[0m  0.0072\n",
            "      3        \u001b[36m2.0244\u001b[0m  0.0064\n",
            "      4        \u001b[36m1.9665\u001b[0m  0.0060\n",
            "      5        \u001b[36m1.9226\u001b[0m  0.0051\n",
            "      6        \u001b[36m1.8887\u001b[0m  0.0059\n",
            "      7        \u001b[36m1.8578\u001b[0m  0.0048\n",
            "      8        \u001b[36m1.8310\u001b[0m  0.0060\n",
            "      9        \u001b[36m1.8087\u001b[0m  0.0047\n",
            "     10        \u001b[36m1.7893\u001b[0m  0.0047\n",
            "Instance [5 5 5 2 6 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5 5 5 5 0 2 5 5 5 5 6]\n",
            "0.3648\n",
            "--- Query no:   4  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3200\u001b[0m  0.0041\n",
            "      2        \u001b[36m2.0990\u001b[0m  0.0066\n",
            "      3        \u001b[36m1.9796\u001b[0m  0.0059\n",
            "      4        \u001b[36m1.9052\u001b[0m  0.0059\n",
            "      5        \u001b[36m1.8549\u001b[0m  0.0058\n",
            "      6        \u001b[36m1.8108\u001b[0m  0.0047\n",
            "      7        \u001b[36m1.7706\u001b[0m  0.0047\n",
            "      8        \u001b[36m1.7346\u001b[0m  0.0056\n",
            "      9        \u001b[36m1.7079\u001b[0m  0.0047\n",
            "     10        \u001b[36m1.6898\u001b[0m  0.0048\n",
            "Instance [7 7 7 7 9 7 7 7 7 7 7 7 7 7 7 7 7 7 9 7 7 7 7 7 7 7 7 7 7 7]\n",
            "0.6231\n",
            "--- Query no:   5  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2736\u001b[0m  0.0045\n",
            "      2        \u001b[36m2.0854\u001b[0m  0.0087\n",
            "      3        \u001b[36m1.9798\u001b[0m  0.0076\n",
            "      4        \u001b[36m1.9128\u001b[0m  0.0061\n",
            "      5        \u001b[36m1.8657\u001b[0m  0.0060\n",
            "      6        \u001b[36m1.8178\u001b[0m  0.0060\n",
            "      7        \u001b[36m1.7753\u001b[0m  0.0061\n",
            "      8        \u001b[36m1.7462\u001b[0m  0.0062\n",
            "      9        \u001b[36m1.7264\u001b[0m  0.0060\n",
            "     10        \u001b[36m1.7050\u001b[0m  0.0055\n",
            "Instance [8 8 8 0 3 8 8 8 8 8 0 2 0 3 3 8 3 8 8 2 8 8 8 8 0 8 3 8 8 8]\n",
            "0.5893\n",
            "--- Query no:   6  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3068\u001b[0m  0.0047\n",
            "      2        \u001b[36m2.1187\u001b[0m  0.0062\n",
            "      3        \u001b[36m2.0046\u001b[0m  0.0069\n",
            "      4        \u001b[36m1.9322\u001b[0m  0.0067\n",
            "      5        \u001b[36m1.8769\u001b[0m  0.0055\n",
            "      6        \u001b[36m1.8210\u001b[0m  0.0056\n",
            "      7        \u001b[36m1.7790\u001b[0m  0.0057\n",
            "      8        \u001b[36m1.7497\u001b[0m  0.0055\n",
            "      9        \u001b[36m1.7177\u001b[0m  0.0055\n",
            "     10        \u001b[36m1.6890\u001b[0m  0.0061\n",
            "Instance [7 3 7 4 5 4 4 4 9 4 4 9 7 8 4 4 8 7 9 4 7 4 3 4 4 4 8 4 9 9]\n",
            "0.6408\n",
            "--- Query no:   7  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3214\u001b[0m  0.0062\n",
            "      2        \u001b[36m2.1028\u001b[0m  0.0078\n",
            "      3        \u001b[36m2.0014\u001b[0m  0.0078\n",
            "      4        \u001b[36m1.9478\u001b[0m  0.0065\n",
            "      5        \u001b[36m1.8976\u001b[0m  0.0067\n",
            "      6        \u001b[36m1.8435\u001b[0m  0.0080\n",
            "      7        \u001b[36m1.8029\u001b[0m  0.0089\n",
            "      8        \u001b[36m1.7747\u001b[0m  0.0078\n",
            "      9        \u001b[36m1.7498\u001b[0m  0.0079\n",
            "     10        \u001b[36m1.7292\u001b[0m  0.0078\n",
            "Instance [6 8 6 8 5 9 4 4 3 2 2 4 6 0 2 6 2 3 6 6 4 6 6 6 5 6 4 4 6 3]\n",
            "0.619\n",
            "--- Query no:   8  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2960\u001b[0m  0.0091\n",
            "      2        \u001b[36m2.0919\u001b[0m  0.0120\n",
            "      3        \u001b[36m1.9931\u001b[0m  0.0083\n",
            "      4        \u001b[36m1.9170\u001b[0m  0.0111\n",
            "      5        \u001b[36m1.8531\u001b[0m  0.0084\n",
            "      6        \u001b[36m1.7962\u001b[0m  0.0089\n",
            "      7        \u001b[36m1.7575\u001b[0m  0.0107\n",
            "      8        \u001b[36m1.7335\u001b[0m  0.0087\n",
            "      9        \u001b[36m1.7102\u001b[0m  0.0101\n",
            "     10        \u001b[36m1.6901\u001b[0m  0.0124\n",
            "Instance [4 1 4 3 2 0 7 6 2 6 8 4 3 5 9 3 8 2 2 2 6 3 2 6 2 2 6 6 6 2]\n",
            "0.6909\n",
            "--- Query no:   9  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3080\u001b[0m  0.0064\n",
            "      2        \u001b[36m2.1108\u001b[0m  0.0097\n",
            "      3        \u001b[36m1.9961\u001b[0m  0.0089\n",
            "      4        \u001b[36m1.9134\u001b[0m  0.0080\n",
            "      5        \u001b[36m1.8534\u001b[0m  0.0079\n",
            "      6        \u001b[36m1.8040\u001b[0m  0.0080\n",
            "      7        \u001b[36m1.7647\u001b[0m  0.0073\n",
            "      8        \u001b[36m1.7368\u001b[0m  0.0082\n",
            "      9        \u001b[36m1.7139\u001b[0m  0.0085\n",
            "     10        \u001b[36m1.6950\u001b[0m  0.0083\n",
            "Instance [4 5 6 0 6 9 4 7 8 4 9 6 2 5 0 4 9 2 9 4 9 8 2 9 7 0 5 7 9 5]\n",
            "0.6959\n",
            "--- Query no:   10  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2991\u001b[0m  0.0069\n",
            "      2        \u001b[36m2.1149\u001b[0m  0.0111\n",
            "      3        \u001b[36m2.0018\u001b[0m  0.0095\n",
            "      4        \u001b[36m1.9237\u001b[0m  0.0087\n",
            "      5        \u001b[36m1.8686\u001b[0m  0.0091\n",
            "      6        \u001b[36m1.8207\u001b[0m  0.0086\n",
            "      7        \u001b[36m1.7821\u001b[0m  0.0088\n",
            "      8        \u001b[36m1.7545\u001b[0m  0.0079\n",
            "      9        \u001b[36m1.7306\u001b[0m  0.0089\n",
            "     10        \u001b[36m1.7107\u001b[0m  0.0082\n",
            "Instance [6 5 4 4 5 7 5 3 5 5 1 9 8 5 5 9 8 5 4 3 6 5 0 9 5 3 7 8 8 4]\n",
            "0.7034\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[712   0  38   1   3 176  18   1  38   0]\n",
            " [  0 725  43  23   2   4   2   1 324   0]\n",
            " [  4   8 722  47  17   7  42   9 135   2]\n",
            " [ 18   9  45 767   6  48   9  23  91   6]\n",
            " [  0   2  18   6 818  11  20  31  40  28]\n",
            " [ 17   1   7 209   8 429  29   4 184  15]\n",
            " [  6   2  91   6   0  21 853   0   7   0]\n",
            " [  4   6  18   4  18  12   0 855  70  57]\n",
            " [  5  15  14  80   7  33  10   9 799   3]\n",
            " [  6   4  21  30 359   7   0 176  35 354]]\n",
            "Accuracy:  0.7034\n",
            "Macro F1-score:  0.6989765864059516\n",
            "Micro F1-score:  0.7034\n",
            "Weighted F1-score:  0.7018901774662528\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AL_Retrain(100, 10, 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7fEXHvvz0L2",
        "outputId": "90fc7f11-8a12-40ec-d4a3-d4329e2e154c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2977\u001b[0m  0.0027\n",
            "      2        \u001b[36m2.1675\u001b[0m  0.0033\n",
            "      3        \u001b[36m2.0622\u001b[0m  0.0034\n",
            "      4        \u001b[36m1.9773\u001b[0m  0.0033\n",
            "      5        \u001b[36m1.9064\u001b[0m  0.0037\n",
            "      6        \u001b[36m1.8480\u001b[0m  0.0030\n",
            "      7        \u001b[36m1.8012\u001b[0m  0.0034\n",
            "      8        \u001b[36m1.7637\u001b[0m  0.0036\n",
            "      9        \u001b[36m1.7326\u001b[0m  0.0029\n",
            "     10        \u001b[36m1.7059\u001b[0m  0.0029\n",
            "No of initial data:  100\n",
            "0.6967\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[832   2  19   2   1  65  54   0   8   4]\n",
            " [  0 996  12  17   1  15   3   1  79   0]\n",
            " [ 58  25 705  11  16  28  35   7 105   3]\n",
            " [ 31  28  58 442   5 275  22  11 142   8]\n",
            " [  9  13  16   3 829   7   7   7  32  51]\n",
            " [ 67   7  22 100  28 448  32   1 159  39]\n",
            " [ 26  24  63   0   4  78 791   0   0   0]\n",
            " [ 18  19   5  40 125   5   3 691  46  92]\n",
            " [ 30  47  42  26  22  33  18   5 735  17]\n",
            " [ 17  10  16  35 315   7   0  63  31 498]]\n",
            "Accuracy:  0.6967\n",
            "Macro F1-score:  0.689493989480441\n",
            "Micro F1-score:  0.6967\n",
            "Weighted F1-score:  0.6934635382481932\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[2, 8, 9, 8, 5, 3, 8, 8, 5, 0, 8, 8, 3, 8, 8, 5, 5, 4, 8, 8, 5, 5, 4, 5, 9, 3, 5, 0, 3, 9, 5, 7, 5, 3, 9, 0, 3, 4, 9, 4, 0, 2, 3, 3, 3, 3, 7, 9, 1, 9, 0, 0, 2, 7, 4, 0, 7, 4, 7, 1, 2, 7, 2, 9, 4, 9, 4, 9, 4, 2, 4, 0, 2, 7, 7, 2, 2, 7, 0, 7, 2, 0, 6, 1]\n",
            "Counter({2: 10, 8: 10, 9: 10, 5: 10, 3: 10, 0: 10, 4: 10, 7: 10, 1: 3, 6: 1})\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3052\u001b[0m  0.0022\n",
            "      2        \u001b[36m2.1478\u001b[0m  0.0050\n",
            "      3        \u001b[36m2.0623\u001b[0m  0.0030\n",
            "      4        \u001b[36m1.9962\u001b[0m  0.0030\n",
            "      5        \u001b[36m1.9299\u001b[0m  0.0039\n",
            "      6        \u001b[36m1.8700\u001b[0m  0.0039\n",
            "      7        \u001b[36m1.8313\u001b[0m  0.0040\n",
            "      8        \u001b[36m1.8050\u001b[0m  0.0039\n",
            "      9        \u001b[36m1.7755\u001b[0m  0.0040\n",
            "     10        \u001b[36m1.7446\u001b[0m  0.0033\n",
            "0.3869\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[666   0   7   4   0 196   0   5  12  97]\n",
            " [ 26   0  95 369 469   0   0   7 146  12]\n",
            " [271   0 342 184  43  10   0  92  49   2]\n",
            " [ 53   0  14 802   8  12   0  24  43  66]\n",
            " [111   0  29   6 198  27   0 183 266 154]\n",
            " [112   0   8 134  14 298   0   8 176 153]\n",
            " [399   0 126   1 131  63   0  72 122  72]\n",
            " [ 33   0  58  40  20   2   0 664   7 220]\n",
            " [146   0 144 167  16  51   0  13 278 160]\n",
            " [ 43   0  39  38  90   0   0  90  71 621]]\n",
            "Accuracy:  0.3869\n",
            "Macro F1-score:  0.3349122859447978\n",
            "Micro F1-score:  0.3869000000000001\n",
            "Weighted F1-score:  0.33271138318414933\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "--- Query no:   1  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3099\u001b[0m  0.0026\n",
            "      2        \u001b[36m2.1711\u001b[0m  0.0039\n",
            "      3        \u001b[36m2.0825\u001b[0m  0.0046\n",
            "      4        \u001b[36m2.0102\u001b[0m  0.0047\n",
            "      5        \u001b[36m1.9471\u001b[0m  0.0037\n",
            "      6        \u001b[36m1.8969\u001b[0m  0.0043\n",
            "      7        \u001b[36m1.8592\u001b[0m  0.0043\n",
            "      8        \u001b[36m1.8290\u001b[0m  0.0044\n",
            "      9        \u001b[36m1.8022\u001b[0m  0.0046\n",
            "     10        \u001b[36m1.7776\u001b[0m  0.0040\n",
            "Instance [8 8 5 0 8 0 8 8 5 3 8 8 8 8 8 0 3 8 3 3]\n",
            "0.4282\n",
            "--- Query no:   2  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3047\u001b[0m  0.0039\n",
            "      2        \u001b[36m2.1188\u001b[0m  0.0070\n",
            "      3        \u001b[36m2.0376\u001b[0m  0.0047\n",
            "      4        \u001b[36m1.9792\u001b[0m  0.0044\n",
            "      5        \u001b[36m1.9253\u001b[0m  0.0048\n",
            "      6        \u001b[36m1.8778\u001b[0m  0.0048\n",
            "      7        \u001b[36m1.8365\u001b[0m  0.0047\n",
            "      8        \u001b[36m1.8024\u001b[0m  0.0047\n",
            "      9        \u001b[36m1.7764\u001b[0m  0.0052\n",
            "     10        \u001b[36m1.7564\u001b[0m  0.0058\n",
            "Instance [1 9 7 3 1 9 4 2 6 6 2 4 2 4 7 2 2 2 6 2]\n",
            "0.6351\n",
            "--- Query no:   3  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3063\u001b[0m  0.0043\n",
            "      2        \u001b[36m2.1112\u001b[0m  0.0045\n",
            "      3        \u001b[36m2.0206\u001b[0m  0.0053\n",
            "      4        \u001b[36m1.9518\u001b[0m  0.0049\n",
            "      5        \u001b[36m1.8911\u001b[0m  0.0050\n",
            "      6        \u001b[36m1.8399\u001b[0m  0.0048\n",
            "      7        \u001b[36m1.8014\u001b[0m  0.0056\n",
            "      8        \u001b[36m1.7727\u001b[0m  0.0060\n",
            "      9        \u001b[36m1.7501\u001b[0m  0.0066\n",
            "     10        \u001b[36m1.7312\u001b[0m  0.0051\n",
            "Instance [9 9 9 7 9 9 4 6 9 7 7 6 9 4 0 9 5 2 5 4]\n",
            "0.6163\n",
            "--- Query no:   4  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3046\u001b[0m  0.0046\n",
            "      2        \u001b[36m2.1194\u001b[0m  0.0067\n",
            "      3        \u001b[36m2.0212\u001b[0m  0.0051\n",
            "      4        \u001b[36m1.9452\u001b[0m  0.0056\n",
            "      5        \u001b[36m1.8817\u001b[0m  0.0050\n",
            "      6        \u001b[36m1.8292\u001b[0m  0.0046\n",
            "      7        \u001b[36m1.7899\u001b[0m  0.0070\n",
            "      8        \u001b[36m1.7593\u001b[0m  0.0068\n",
            "      9        \u001b[36m1.7340\u001b[0m  0.0064\n",
            "     10        \u001b[36m1.7125\u001b[0m  0.0054\n",
            "Instance [8 5 9 0 3 2 8 0 4 9 4 2 9 3 0 3 7 7 2 5]\n",
            "0.6907\n",
            "--- Query no:   5  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3049\u001b[0m  0.0045\n",
            "      2        \u001b[36m2.1323\u001b[0m  0.0056\n",
            "      3        \u001b[36m2.0420\u001b[0m  0.0065\n",
            "      4        \u001b[36m1.9688\u001b[0m  0.0066\n",
            "      5        \u001b[36m1.9056\u001b[0m  0.0055\n",
            "      6        \u001b[36m1.8525\u001b[0m  0.0056\n",
            "      7        \u001b[36m1.8084\u001b[0m  0.0053\n",
            "      8        \u001b[36m1.7737\u001b[0m  0.0060\n",
            "      9        \u001b[36m1.7459\u001b[0m  0.0065\n",
            "     10        \u001b[36m1.7230\u001b[0m  0.0064\n",
            "Instance [7 4 7 7 2 4 2 4 9 7 7 7 9 4 9 9 9 7 7 5]\n",
            "0.7028\n",
            "--- Query no:   6  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2963\u001b[0m  0.0047\n",
            "      2        \u001b[36m2.1325\u001b[0m  0.0074\n",
            "      3        \u001b[36m2.0380\u001b[0m  0.0058\n",
            "      4        \u001b[36m1.9646\u001b[0m  0.0070\n",
            "      5        \u001b[36m1.9045\u001b[0m  0.0057\n",
            "      6        \u001b[36m1.8566\u001b[0m  0.0069\n",
            "      7        \u001b[36m1.8161\u001b[0m  0.0068\n",
            "      8        \u001b[36m1.7812\u001b[0m  0.0065\n",
            "      9        \u001b[36m1.7538\u001b[0m  0.0064\n",
            "     10        \u001b[36m1.7321\u001b[0m  0.0062\n",
            "Instance [2 3 3 4 3 3 0 0 4 0 5 3 4 3 5 6 5 5 4 5]\n",
            "0.7108\n",
            "--- Query no:   7  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3012\u001b[0m  0.0068\n",
            "      2        \u001b[36m2.1446\u001b[0m  0.0103\n",
            "      3        \u001b[36m2.0495\u001b[0m  0.0065\n",
            "      4        \u001b[36m1.9748\u001b[0m  0.0103\n",
            "      5        \u001b[36m1.9118\u001b[0m  0.0088\n",
            "      6        \u001b[36m1.8647\u001b[0m  0.0091\n",
            "      7        \u001b[36m1.8268\u001b[0m  0.0079\n",
            "      8        \u001b[36m1.7926\u001b[0m  0.0063\n",
            "      9        \u001b[36m1.7646\u001b[0m  0.0065\n",
            "     10        \u001b[36m1.7427\u001b[0m  0.0063\n",
            "Instance [8 3 1 6 3 8 3 8 5 5 4 6 8 8 7 2 6 5 1 6]\n",
            "0.7318\n",
            "--- Query no:   8  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3006\u001b[0m  0.0061\n",
            "      2        \u001b[36m2.1289\u001b[0m  0.0101\n",
            "      3        \u001b[36m2.0520\u001b[0m  0.0130\n",
            "      4        \u001b[36m1.9864\u001b[0m  0.0115\n",
            "      5        \u001b[36m1.9293\u001b[0m  0.0116\n",
            "      6        \u001b[36m1.8841\u001b[0m  0.0085\n",
            "      7        \u001b[36m1.8437\u001b[0m  0.0087\n",
            "      8        \u001b[36m1.8090\u001b[0m  0.0082\n",
            "      9        \u001b[36m1.7811\u001b[0m  0.0069\n",
            "     10        \u001b[36m1.7579\u001b[0m  0.0068\n",
            "Instance [9 2 0 7 2 5 5 6 7 2 2 1 0 3 6 9 4 9 9 2]\n",
            "0.7168\n",
            "--- Query no:   9  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2945\u001b[0m  0.0074\n",
            "      2        \u001b[36m2.1315\u001b[0m  0.0102\n",
            "      3        \u001b[36m2.0343\u001b[0m  0.0093\n",
            "      4        \u001b[36m1.9587\u001b[0m  0.0079\n",
            "      5        \u001b[36m1.9029\u001b[0m  0.0080\n",
            "      6        \u001b[36m1.8580\u001b[0m  0.0070\n",
            "      7        \u001b[36m1.8216\u001b[0m  0.0067\n",
            "      8        \u001b[36m1.7909\u001b[0m  0.0075\n",
            "      9        \u001b[36m1.7663\u001b[0m  0.0066\n",
            "     10        \u001b[36m1.7454\u001b[0m  0.0068\n",
            "Instance [5 0 0 3 4 0 4 3 3 1 1 3 8 4 4 4 9 4 5 8]\n",
            "0.7138\n",
            "--- Query no:   10  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2922\u001b[0m  0.0066\n",
            "      2        \u001b[36m2.1268\u001b[0m  0.0082\n",
            "      3        \u001b[36m2.0208\u001b[0m  0.0076\n",
            "      4        \u001b[36m1.9425\u001b[0m  0.0077\n",
            "      5        \u001b[36m1.8865\u001b[0m  0.0094\n",
            "      6        \u001b[36m1.8439\u001b[0m  0.0087\n",
            "      7        \u001b[36m1.8081\u001b[0m  0.0071\n",
            "      8        \u001b[36m1.7788\u001b[0m  0.0069\n",
            "      9        \u001b[36m1.7539\u001b[0m  0.0068\n",
            "     10        \u001b[36m1.7337\u001b[0m  0.0069\n",
            "Instance [6 4 1 8 0 9 7 2 2 6 0 6 5 5 9 3 3 9 2 8]\n",
            "0.7299\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[908   0   3   7   0  33   7   1  26   2]\n",
            " [  0 891   5  74   3   0   3   1 147   0]\n",
            " [ 43  20 700  62  10   2  18   8 123   7]\n",
            " [ 33   3  15 864   0   4   4  16  64  19]\n",
            " [  5   1  14   6 734   6   3   6  30 169]\n",
            " [ 49   4   8 291   7 317   7   0 185  35]\n",
            " [ 53   0 138   1  32  77 675   0  10   0]\n",
            " [  4   3   6  11  20   4   0 605  16 375]\n",
            " [ 18   9   7  91   5  15   4   2 801  23]\n",
            " [  7   3   3  16 120   4   0  10  25 804]]\n",
            "Accuracy:  0.7299\n",
            "Macro F1-score:  0.7244889325010309\n",
            "Micro F1-score:  0.7299\n",
            "Weighted F1-score:  0.7284733536056878\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AL_Retrain(100, 10, 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fNbWxNnz5gB",
        "outputId": "8677d50b-1149-4ffc-f1b0-332f750fcec5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3156\u001b[0m  0.0026\n",
            "      2        \u001b[36m2.1860\u001b[0m  0.0038\n",
            "      3        \u001b[36m2.0810\u001b[0m  0.0041\n",
            "      4        \u001b[36m1.9942\u001b[0m  0.0038\n",
            "      5        \u001b[36m1.9203\u001b[0m  0.0034\n",
            "      6        \u001b[36m1.8592\u001b[0m  0.0033\n",
            "      7        \u001b[36m1.8108\u001b[0m  0.0034\n",
            "      8        \u001b[36m1.7724\u001b[0m  0.0036\n",
            "      9        \u001b[36m1.7404\u001b[0m  0.0031\n",
            "     10        \u001b[36m1.7127\u001b[0m  0.0031\n",
            "No of initial data:  100\n",
            "0.6956\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[838   3  18   3   1  66  49   0   6   3]\n",
            " [  0 988   7  16   0  26   2   1  83   1]\n",
            " [ 59  26 685   9  15  34  44   3 115   3]\n",
            " [ 32  36  50 462   6 250  19  10 148   9]\n",
            " [  9  13  15   2 821   8   5   7  34  60]\n",
            " [ 56   9  14 111  30 437  30   2 181  33]\n",
            " [ 28  26  63   0   6  80 783   0   0   0]\n",
            " [ 17  23   5  41 118   6   3 680  43 108]\n",
            " [ 23  55  41  40  26  31  14   4 726  15]\n",
            " [ 17  15  13  28 294   6   1  51  31 536]]\n",
            "Accuracy:  0.6956\n",
            "Macro F1-score:  0.689869071501459\n",
            "Micro F1-score:  0.6956\n",
            "Weighted F1-score:  0.6937511899526922\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[0, 8, 8, 8, 5, 7, 5, 2, 5, 8, 8, 8, 3, 0, 8, 0, 8, 8, 5, 5, 4, 3, 3, 9, 9, 9, 4, 2, 3, 8, 9, 7, 2, 5, 9, 2, 7, 3, 5, 5, 9, 3, 5, 3, 5, 3, 3, 0, 0, 7, 4, 2, 2, 3, 4, 4, 7, 4, 7, 4, 2, 2, 2, 2, 0, 9, 7, 4, 4, 7, 0, 7, 0, 9, 7, 0, 0, 4, 9, 9, 1, 6, 1, 6, 6]\n",
            "Counter({0: 10, 8: 10, 5: 10, 7: 10, 2: 10, 3: 10, 4: 10, 9: 10, 6: 3, 1: 2})\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2988\u001b[0m  0.0023\n",
            "      2        \u001b[36m2.1412\u001b[0m  0.0043\n",
            "      3        \u001b[36m2.0534\u001b[0m  0.0034\n",
            "      4        \u001b[36m1.9815\u001b[0m  0.0033\n",
            "      5        \u001b[36m1.9137\u001b[0m  0.0038\n",
            "      6        \u001b[36m1.8626\u001b[0m  0.0034\n",
            "      7        \u001b[36m1.8293\u001b[0m  0.0031\n",
            "      8        \u001b[36m1.8004\u001b[0m  0.0034\n",
            "      9        \u001b[36m1.7701\u001b[0m  0.0029\n",
            "     10        \u001b[36m1.7403\u001b[0m  0.0025\n",
            "0.3603\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[413   0 122  37   0 207   4   8  21 175]\n",
            " [ 23   0 179 135 499   0   0   0 259  29]\n",
            " [ 59   0 551 173  64   1   0  45  71  29]\n",
            " [ 29   0 197 711   6  15   0  12  30  22]\n",
            " [ 81   0  48  28 215   4   0 219 112 267]\n",
            " [172   0 108 227  32 195   0   3 140  26]\n",
            " [416   0  35  44  92   4   5 101 212  77]\n",
            " [ 47   0 130  18  37   0   0 666  31 115]\n",
            " [119   0 269 141   9  17   0   8 363  49]\n",
            " [105   0  75  41 126   3   0  63  95 484]]\n",
            "Accuracy:  0.3603\n",
            "Macro F1-score:  0.3160306135113881\n",
            "Micro F1-score:  0.36029999999999995\n",
            "Weighted F1-score:  0.31473295947733915\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "--- Query no:   1  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3012\u001b[0m  0.0054\n",
            "      2        \u001b[36m2.1370\u001b[0m  0.0053\n",
            "      3        \u001b[36m2.1068\u001b[0m  0.0046\n",
            "      4        \u001b[36m2.0841\u001b[0m  0.0050\n",
            "      5        \u001b[36m2.0455\u001b[0m  0.0049\n",
            "      6        \u001b[36m1.9898\u001b[0m  0.0048\n",
            "      7        \u001b[36m1.9270\u001b[0m  0.0053\n",
            "      8        \u001b[36m1.8690\u001b[0m  0.0045\n",
            "      9        \u001b[36m1.8271\u001b[0m  0.0044\n",
            "     10        \u001b[36m1.8018\u001b[0m  0.0048\n",
            "Instance [8 8 0 2 8 8 0 5 8 3 8 5 5 0 7 8 5 8 4 4 8 3 5 3 0 8 2 8 2 3]\n",
            "0.6651\n",
            "--- Query no:   2  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3017\u001b[0m  0.0040\n",
            "      2        \u001b[36m2.1235\u001b[0m  0.0060\n",
            "      3        \u001b[36m2.0430\u001b[0m  0.0045\n",
            "      4        \u001b[36m1.9685\u001b[0m  0.0051\n",
            "      5        \u001b[36m1.9131\u001b[0m  0.0045\n",
            "      6        \u001b[36m1.8663\u001b[0m  0.0046\n",
            "      7        \u001b[36m1.8173\u001b[0m  0.0044\n",
            "      8        \u001b[36m1.7781\u001b[0m  0.0057\n",
            "      9        \u001b[36m1.7516\u001b[0m  0.0060\n",
            "     10        \u001b[36m1.7305\u001b[0m  0.0060\n",
            "Instance [9 5 6 8 2 6 6 5 6 2 0 6 2 6 6 6 0 3 4 2 9 6 6 0 6 6 0 0 6 5]\n",
            "0.6923\n",
            "--- Query no:   3  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3015\u001b[0m  0.0043\n",
            "      2        \u001b[36m2.1298\u001b[0m  0.0069\n",
            "      3        \u001b[36m2.0378\u001b[0m  0.0060\n",
            "      4        \u001b[36m1.9627\u001b[0m  0.0055\n",
            "      5        \u001b[36m1.9049\u001b[0m  0.0059\n",
            "      6        \u001b[36m1.8544\u001b[0m  0.0073\n",
            "      7        \u001b[36m1.8055\u001b[0m  0.0060\n",
            "      8        \u001b[36m1.7682\u001b[0m  0.0060\n",
            "      9        \u001b[36m1.7427\u001b[0m  0.0063\n",
            "     10        \u001b[36m1.7204\u001b[0m  0.0061\n",
            "Instance [7 6 9 9 9 2 9 6 7 7 5 4 7 9 2 7 8 5 6 8 2 6 6 2 9 4 2 9 9 9]\n",
            "0.7373\n",
            "--- Query no:   4  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2980\u001b[0m  0.0046\n",
            "      2        \u001b[36m2.1387\u001b[0m  0.0068\n",
            "      3        \u001b[36m2.0470\u001b[0m  0.0069\n",
            "      4        \u001b[36m1.9714\u001b[0m  0.0067\n",
            "      5        \u001b[36m1.9079\u001b[0m  0.0055\n",
            "      6        \u001b[36m1.8581\u001b[0m  0.0070\n",
            "      7        \u001b[36m1.8158\u001b[0m  0.0075\n",
            "      8        \u001b[36m1.7800\u001b[0m  0.0073\n",
            "      9        \u001b[36m1.7519\u001b[0m  0.0068\n",
            "     10        \u001b[36m1.7293\u001b[0m  0.0065\n",
            "Instance [5 9 4 9 5 8 4 5 3 5 6 3 0 3 5 1 0 5 4 5 5 4 5 5 5 5 4 5 4 1]\n",
            "0.7526\n",
            "--- Query no:   5  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2971\u001b[0m  0.0047\n",
            "      2        \u001b[36m2.1498\u001b[0m  0.0076\n",
            "      3        \u001b[36m2.0636\u001b[0m  0.0057\n",
            "      4        \u001b[36m1.9889\u001b[0m  0.0063\n",
            "      5        \u001b[36m1.9277\u001b[0m  0.0092\n",
            "      6        \u001b[36m1.8808\u001b[0m  0.0065\n",
            "      7        \u001b[36m1.8416\u001b[0m  0.0066\n",
            "      8        \u001b[36m1.8069\u001b[0m  0.0056\n",
            "      9        \u001b[36m1.7777\u001b[0m  0.0053\n",
            "     10        \u001b[36m1.7543\u001b[0m  0.0054\n",
            "Instance [7 5 5 3 1 3 7 4 8 5 3 4 5 0 8 0 7 5 2 0 2 2 2 4 5 5 3 2 0 5]\n",
            "0.7547\n",
            "--- Query no:   6  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2921\u001b[0m  0.0092\n",
            "      2        \u001b[36m2.1205\u001b[0m  0.0105\n",
            "      3        \u001b[36m2.0285\u001b[0m  0.0092\n",
            "      4        \u001b[36m1.9697\u001b[0m  0.0090\n",
            "      5        \u001b[36m1.9107\u001b[0m  0.0089\n",
            "      6        \u001b[36m1.8602\u001b[0m  0.0089\n",
            "      7        \u001b[36m1.8240\u001b[0m  0.0088\n",
            "      8        \u001b[36m1.7955\u001b[0m  0.0087\n",
            "      9        \u001b[36m1.7717\u001b[0m  0.0086\n",
            "     10        \u001b[36m1.7523\u001b[0m  0.0089\n",
            "Instance [9 7 9 9 8 9 9 6 3 2 9 0 7 9 4 2 8 1 9 4 7 9 6 4 7 7 7 7 5 9]\n",
            "0.7217\n",
            "--- Query no:   7  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2845\u001b[0m  0.0064\n",
            "      2        \u001b[36m2.1222\u001b[0m  0.0082\n",
            "      3        \u001b[36m2.0247\u001b[0m  0.0084\n",
            "      4        \u001b[36m1.9500\u001b[0m  0.0083\n",
            "      5        \u001b[36m1.8854\u001b[0m  0.0090\n",
            "      6        \u001b[36m1.8459\u001b[0m  0.0085\n",
            "      7        \u001b[36m1.8110\u001b[0m  0.0087\n",
            "      8        \u001b[36m1.7814\u001b[0m  0.0086\n",
            "      9        \u001b[36m1.7585\u001b[0m  0.0083\n",
            "     10        \u001b[36m1.7371\u001b[0m  0.0083\n",
            "Instance [8 3 6 8 5 4 8 8 1 8 6 0 5 8 1 3 1 8 7 5 8 8 0 3 1 2 1 8 1 8]\n",
            "0.7384\n",
            "--- Query no:   8  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2837\u001b[0m  0.0064\n",
            "      2        \u001b[36m2.1239\u001b[0m  0.0093\n",
            "      3        \u001b[36m2.0356\u001b[0m  0.0085\n",
            "      4        \u001b[36m1.9628\u001b[0m  0.0075\n",
            "      5        \u001b[36m1.8998\u001b[0m  0.0085\n",
            "      6        \u001b[36m1.8567\u001b[0m  0.0079\n",
            "      7        \u001b[36m1.8204\u001b[0m  0.0073\n",
            "      8        \u001b[36m1.7923\u001b[0m  0.0082\n",
            "      9        \u001b[36m1.7693\u001b[0m  0.0076\n",
            "     10        \u001b[36m1.7477\u001b[0m  0.0083\n",
            "Instance [3 9 7 5 3 9 7 7 6 8 7 8 6 6 5 4 5 5 9 5 9 3 6 8 8 7 1 3 7 6]\n",
            "0.7487\n",
            "--- Query no:   9  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2907\u001b[0m  0.0068\n",
            "      2        \u001b[36m2.1311\u001b[0m  0.0096\n",
            "      3        \u001b[36m2.0452\u001b[0m  0.0081\n",
            "      4        \u001b[36m1.9734\u001b[0m  0.0084\n",
            "      5        \u001b[36m1.9138\u001b[0m  0.0089\n",
            "      6        \u001b[36m1.8716\u001b[0m  0.0083\n",
            "      7        \u001b[36m1.8345\u001b[0m  0.0080\n",
            "      8        \u001b[36m1.8064\u001b[0m  0.0077\n",
            "      9        \u001b[36m1.7837\u001b[0m  0.0080\n",
            "     10        \u001b[36m1.7622\u001b[0m  0.0082\n",
            "Instance [7 8 9 8 4 9 4 4 1 9 3 7 8 4 1 4 0 8 4 4 3 5 2 0 8 1 1 1 3 7]\n",
            "0.7571\n",
            "--- Query no:   10  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2896\u001b[0m  0.0078\n",
            "      2        \u001b[36m2.1237\u001b[0m  0.0126\n",
            "      3        \u001b[36m2.0507\u001b[0m  0.0099\n",
            "      4        \u001b[36m1.9809\u001b[0m  0.0120\n",
            "      5        \u001b[36m1.9210\u001b[0m  0.0105\n",
            "      6        \u001b[36m1.8788\u001b[0m  0.0103\n",
            "      7        \u001b[36m1.8475\u001b[0m  0.0100\n",
            "      8        \u001b[36m1.8217\u001b[0m  0.0086\n",
            "      9        \u001b[36m1.7995\u001b[0m  0.0089\n",
            "     10        \u001b[36m1.7796\u001b[0m  0.0086\n",
            "Instance [9 5 6 5 2 7 4 5 3 4 8 1 8 2 6 4 9 9 4 4 4 0 2 2 4 7 4 6 9 9]\n",
            "0.7302\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[694   0   5   0   3 229  23   1  31   1]\n",
            " [  0 996  21   7   6   6   3   1  81   3]\n",
            " [  5  12 688  28  20  16  44  14 163   3]\n",
            " [ 20   7  18 740   6  38  28  15 107  43]\n",
            " [  1   1  18   0 795  12   8   2   8 129]\n",
            " [ 30   3   4  38  13 507  31   0 225  52]\n",
            " [  7   3  82   0  18  18 846   0  12   0]\n",
            " [  5   3   8   1  45   4   2 592   8 376]\n",
            " [  7  11   6  20  16  52   8   0 797  58]\n",
            " [  4   1   2   9 302   3   0   8  16 647]]\n",
            "Accuracy:  0.7302\n",
            "Macro F1-score:  0.7320789979211311\n",
            "Micro F1-score:  0.7302\n",
            "Weighted F1-score:  0.7361415824539272\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AL_Retrain(300, 10, 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMmXuF4Bz-fO",
        "outputId": "55194851-0f2e-49db-e690-34acca8c12b8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2494\u001b[0m  0.0067\n",
            "      2        \u001b[36m1.9828\u001b[0m  0.0072\n",
            "      3        \u001b[36m1.8457\u001b[0m  0.0079\n",
            "      4        \u001b[36m1.7722\u001b[0m  0.0082\n",
            "      5        \u001b[36m1.7267\u001b[0m  0.0076\n",
            "      6        \u001b[36m1.6954\u001b[0m  0.0076\n",
            "      7        \u001b[36m1.6720\u001b[0m  0.0075\n",
            "      8        \u001b[36m1.6536\u001b[0m  0.0105\n",
            "      9        \u001b[36m1.6386\u001b[0m  0.0094\n",
            "     10        \u001b[36m1.6261\u001b[0m  0.0095\n",
            "No of initial data:  300\n",
            "0.7852\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[ 894    2    6    5    0   11   42    0   25    2]\n",
            " [   0 1054   18   10    1   12    2    3   24    0]\n",
            " [  29   19  782   21    6    0   44   14   66   12]\n",
            " [  13   38   56  756    0   53   18   20   47   21]\n",
            " [   8   10   14    1  615    1   26    8   26  265]\n",
            " [  39   27   16   99   17  541   29    5   96   34]\n",
            " [  21   19   56    0    0   22  858    0   10    0]\n",
            " [  21   22    8   11   10    0    1  848   22  101]\n",
            " [  26   63   19   69    5   26   13    4  721   29]\n",
            " [  13   11    9   14   41    5    1   85   30  783]]\n",
            "Accuracy:  0.7852\n",
            "Macro F1-score:  0.781277330927407\n",
            "Micro F1-score:  0.7852\n",
            "Weighted F1-score:  0.7837642008020332\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[3, 0, 8, 8, 8, 8, 8, 0, 8, 0, 5, 2, 8, 5, 8, 8, 0, 3, 6, 8, 5, 3, 3, 4, 8, 2, 7, 0, 8, 3, 3, 3, 8, 4, 8, 8, 0, 8, 5, 3, 3, 7, 2, 2, 8, 8, 8, 8, 3, 8, 7, 0, 5, 0, 3, 5, 5, 2, 8, 2, 4, 3, 8, 9, 8, 5, 9, 8, 5, 7, 1, 8, 5, 8, 5, 4, 7, 3, 8, 3, 8, 8, 9, 2, 5, 5, 5, 3, 3, 3, 3, 3, 2, 9, 5, 0, 3, 0, 7, 3, 1, 0, 0, 5, 2, 3, 4, 3, 5, 0, 5, 5, 5, 3, 7, 4, 5, 3, 0, 5, 3, 7, 4, 7, 5, 1, 0, 5, 5, 3, 4, 2, 3, 5, 0, 9, 3, 5, 2, 3, 0, 9, 7, 2, 4, 5, 0, 0, 4, 7, 0, 5, 7, 5, 0, 0, 9, 0, 4, 1, 0, 0, 0, 0, 1, 0, 4, 0, 4, 7, 0, 4, 2, 2, 2, 4, 4, 2, 2, 2, 4, 4, 2, 2, 9, 7, 4, 4, 2, 7, 9, 6, 9, 7, 7, 1, 4, 4, 4, 2, 7, 1, 6, 2, 9, 4, 4, 4, 2, 4, 4, 6, 7, 7, 2, 9, 9, 2, 2, 2, 7, 2, 2, 7, 4, 9, 6, 4, 7, 9, 7, 7, 1, 9, 6, 7, 7, 9, 1, 1, 9, 1, 1, 9, 7, 9, 7, 1, 7, 9, 9, 1, 9, 1, 6, 9, 6]\n",
            "Counter({3: 30, 0: 30, 8: 30, 5: 30, 2: 30, 4: 30, 7: 30, 9: 24, 1: 15, 6: 8})\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3522\u001b[0m  0.0095\n",
            "      2        \u001b[36m2.1542\u001b[0m  0.0081\n",
            "      3        \u001b[36m2.0463\u001b[0m  0.0071\n",
            "      4        \u001b[36m1.9931\u001b[0m  0.0068\n",
            "      5        \u001b[36m1.9477\u001b[0m  0.0082\n",
            "      6        \u001b[36m1.8957\u001b[0m  0.0067\n",
            "      7        \u001b[36m1.8525\u001b[0m  0.0087\n",
            "      8        \u001b[36m1.8223\u001b[0m  0.0075\n",
            "      9        \u001b[36m1.7990\u001b[0m  0.0081\n",
            "     10        \u001b[36m1.7781\u001b[0m  0.0072\n",
            "0.4313\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[119   1 344  78  11 144 146   0 144   0]\n",
            " [  8 638   1  69 132   1   0  74  72 129]\n",
            " [ 10  52 482 215  47  26  64  36  48  13]\n",
            " [  2  96  27 672   4 110   5  65  31  10]\n",
            " [  5  35  72   2 432 121  62 115  81  49]\n",
            " [ 23  61  23 214  64 278  62   3 152  23]\n",
            " [109 109 294  95 135  28 181  21  14   0]\n",
            " [  2  13  42   1  17  47   1 717  23 181]\n",
            " [  4 104  26 123  29  89  30  13 442 115]\n",
            " [  1  78  68   5 147  53   3 214  71 352]]\n",
            "Accuracy:  0.4313\n",
            "Macro F1-score:  0.40933102630293206\n",
            "Micro F1-score:  0.4313\n",
            "Weighted F1-score:  0.41374337149236307\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "--- Query no:   1  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2428\u001b[0m  0.0067\n",
            "      2        \u001b[36m1.9918\u001b[0m  0.0090\n",
            "      3        \u001b[36m1.8850\u001b[0m  0.0084\n",
            "      4        \u001b[36m1.8098\u001b[0m  0.0084\n",
            "      5        \u001b[36m1.7583\u001b[0m  0.0080\n",
            "      6        \u001b[36m1.7233\u001b[0m  0.0079\n",
            "      7        \u001b[36m1.6982\u001b[0m  0.0077\n",
            "      8        \u001b[36m1.6809\u001b[0m  0.0074\n",
            "      9        \u001b[36m1.6677\u001b[0m  0.0079\n",
            "     10        \u001b[36m1.6538\u001b[0m  0.0100\n",
            "Instance [8 3 0 8 8 8 0 8 8 0 5 0 0 8 8 2 5 8 8 2]\n",
            "0.7785\n",
            "--- Query no:   2  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2414\u001b[0m  0.0067\n",
            "      2        \u001b[36m1.9978\u001b[0m  0.0071\n",
            "      3        \u001b[36m1.8881\u001b[0m  0.0081\n",
            "      4        \u001b[36m1.8160\u001b[0m  0.0076\n",
            "      5        \u001b[36m1.7675\u001b[0m  0.0082\n",
            "      6        \u001b[36m1.7327\u001b[0m  0.0086\n",
            "      7        \u001b[36m1.7056\u001b[0m  0.0078\n",
            "      8        \u001b[36m1.6875\u001b[0m  0.0080\n",
            "      9        \u001b[36m1.6723\u001b[0m  0.0074\n",
            "     10        \u001b[36m1.6574\u001b[0m  0.0076\n",
            "Instance [3 6 5 4 4 2 8 2 7 5 4 9 2 7 8 3 4 3 7 6]\n",
            "0.7885\n",
            "--- Query no:   3  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2513\u001b[0m  0.0067\n",
            "      2        \u001b[36m2.0149\u001b[0m  0.0085\n",
            "      3        \u001b[36m1.9091\u001b[0m  0.0088\n",
            "      4        \u001b[36m1.8384\u001b[0m  0.0087\n",
            "      5        \u001b[36m1.7907\u001b[0m  0.0087\n",
            "      6        \u001b[36m1.7556\u001b[0m  0.0105\n",
            "      7        \u001b[36m1.7275\u001b[0m  0.0097\n",
            "      8        \u001b[36m1.7087\u001b[0m  0.0080\n",
            "      9        \u001b[36m1.6932\u001b[0m  0.0084\n",
            "     10        \u001b[36m1.6784\u001b[0m  0.0074\n",
            "Instance [5 1 5 1 7 5 2 5 7 3 3 4 8 7 3 8 3 5 8 3]\n",
            "0.7948\n",
            "--- Query no:   4  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2431\u001b[0m  0.0092\n",
            "      2        \u001b[36m2.0186\u001b[0m  0.0093\n",
            "      3        \u001b[36m1.9165\u001b[0m  0.0088\n",
            "      4        \u001b[36m1.8493\u001b[0m  0.0085\n",
            "      5        \u001b[36m1.8039\u001b[0m  0.0078\n",
            "      6        \u001b[36m1.7694\u001b[0m  0.0078\n",
            "      7        \u001b[36m1.7416\u001b[0m  0.0083\n",
            "      8        \u001b[36m1.7220\u001b[0m  0.0116\n",
            "      9        \u001b[36m1.7056\u001b[0m  0.0090\n",
            "     10        \u001b[36m1.6908\u001b[0m  0.0080\n",
            "Instance [9 8 7 4 2 6 7 8 3 5 4 2 4 3 6 0 9 7 6 5]\n",
            "0.8027\n",
            "--- Query no:   5  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2498\u001b[0m  0.0118\n",
            "      2        \u001b[36m2.0221\u001b[0m  0.0149\n",
            "      3        \u001b[36m1.9291\u001b[0m  0.0137\n",
            "      4        \u001b[36m1.8638\u001b[0m  0.0115\n",
            "      5        \u001b[36m1.8166\u001b[0m  0.0121\n",
            "      6        \u001b[36m1.7832\u001b[0m  0.0119\n",
            "      7        \u001b[36m1.7598\u001b[0m  0.0119\n",
            "      8        \u001b[36m1.7407\u001b[0m  0.0120\n",
            "      9        \u001b[36m1.7245\u001b[0m  0.0117\n",
            "     10        \u001b[36m1.7096\u001b[0m  0.0116\n",
            "Instance [3 9 0 2 9 0 4 0 4 6 0 8 4 0 2 7 0 1 2 6]\n",
            "0.7904\n",
            "--- Query no:   6  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2461\u001b[0m  0.0086\n",
            "      2        \u001b[36m2.0194\u001b[0m  0.0112\n",
            "      3        \u001b[36m1.9256\u001b[0m  0.0108\n",
            "      4        \u001b[36m1.8570\u001b[0m  0.0103\n",
            "      5        \u001b[36m1.8110\u001b[0m  0.0124\n",
            "      6        \u001b[36m1.7785\u001b[0m  0.0097\n",
            "      7        \u001b[36m1.7510\u001b[0m  0.0098\n",
            "      8        \u001b[36m1.7303\u001b[0m  0.0098\n",
            "      9        \u001b[36m1.7130\u001b[0m  0.0101\n",
            "     10        \u001b[36m1.6977\u001b[0m  0.0106\n",
            "Instance [2 8 8 3 8 1 1 3 3 8 8 8 3 8 1 3 8 5 4 3]\n",
            "0.7985\n",
            "--- Query no:   7  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2470\u001b[0m  0.0085\n",
            "      2        \u001b[36m2.0212\u001b[0m  0.0132\n",
            "      3        \u001b[36m1.9295\u001b[0m  0.0110\n",
            "      4        \u001b[36m1.8614\u001b[0m  0.0102\n",
            "      5        \u001b[36m1.8156\u001b[0m  0.0103\n",
            "      6        \u001b[36m1.7801\u001b[0m  0.0101\n",
            "      7        \u001b[36m1.7545\u001b[0m  0.0191\n",
            "      8        \u001b[36m1.7356\u001b[0m  0.0140\n",
            "      9        \u001b[36m1.7168\u001b[0m  0.0102\n",
            "     10        \u001b[36m1.7007\u001b[0m  0.0106\n",
            "Instance [3 5 2 4 5 8 4 8 6 5 5 3 7 8 4 4 6 2 6 2]\n",
            "0.8006\n",
            "--- Query no:   8  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2424\u001b[0m  0.0162\n",
            "      2        \u001b[36m2.0241\u001b[0m  0.0190\n",
            "      3        \u001b[36m1.9269\u001b[0m  0.0137\n",
            "      4        \u001b[36m1.8619\u001b[0m  0.0208\n",
            "      5        \u001b[36m1.8173\u001b[0m  0.0153\n",
            "      6        \u001b[36m1.7816\u001b[0m  0.0110\n",
            "      7        \u001b[36m1.7581\u001b[0m  0.0108\n",
            "      8        \u001b[36m1.7371\u001b[0m  0.0112\n",
            "      9        \u001b[36m1.7191\u001b[0m  0.0111\n",
            "     10        \u001b[36m1.7029\u001b[0m  0.0108\n",
            "Instance [0 7 5 9 6 6 9 4 0 9 8 0 0 0 7 3 2 9 3 9]\n",
            "0.7988\n",
            "--- Query no:   9  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2455\u001b[0m  0.0153\n",
            "      2        \u001b[36m2.0278\u001b[0m  0.0119\n",
            "      3        \u001b[36m1.9298\u001b[0m  0.0104\n",
            "      4        \u001b[36m1.8686\u001b[0m  0.0125\n",
            "      5        \u001b[36m1.8236\u001b[0m  0.0115\n",
            "      6        \u001b[36m1.7896\u001b[0m  0.0112\n",
            "      7        \u001b[36m1.7657\u001b[0m  0.0116\n",
            "      8        \u001b[36m1.7449\u001b[0m  0.0111\n",
            "      9        \u001b[36m1.7265\u001b[0m  0.0121\n",
            "     10        \u001b[36m1.7106\u001b[0m  0.0102\n",
            "Instance [7 6 5 3 4 4 9 4 0 4 6 9 9 4 0 7 4 3 9 3]\n",
            "0.8069\n",
            "--- Query no:   10  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2456\u001b[0m  0.0089\n",
            "      2        \u001b[36m2.0348\u001b[0m  0.0118\n",
            "      3        \u001b[36m1.9402\u001b[0m  0.0109\n",
            "      4        \u001b[36m1.8798\u001b[0m  0.0111\n",
            "      5        \u001b[36m1.8358\u001b[0m  0.0108\n",
            "      6        \u001b[36m1.8004\u001b[0m  0.0098\n",
            "      7        \u001b[36m1.7762\u001b[0m  0.0096\n",
            "      8        \u001b[36m1.7549\u001b[0m  0.0104\n",
            "      9        \u001b[36m1.7365\u001b[0m  0.0104\n",
            "     10        \u001b[36m1.7201\u001b[0m  0.0105\n",
            "Instance [4 4 3 9 1 9 4 1 9 2 8 6 2 5 8 9 7 4 0 8]\n",
            "0.8104\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[ 921    0    4    8    2   23   16    0   12    1]\n",
            " [   0 1015   42    5    1    4    1    0   56    0]\n",
            " [  15   32  730   41   17    3   31    8  112    4]\n",
            " [   8    9   38  831    1    4    5   21   85   20]\n",
            " [   4    3    7    0  843    0   13    4   31   69]\n",
            " [  30    2    6  154   15  465   16    1  180   34]\n",
            " [  18   11   31    7    4   31  872    0   12    0]\n",
            " [   3    9   19    5   14    2    0  847   34  111]\n",
            " [  10   24   13   27    3   17    7    0  852   22]\n",
            " [   7    4    4   17  141    2    0   50   39  728]]\n",
            "Accuracy:  0.8104\n",
            "Macro F1-score:  0.8065847729412102\n",
            "Micro F1-score:  0.8104\n",
            "Weighted F1-score:  0.8096158435330524\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "AL_Retrain(300, 10, 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jHW_XfU0HXc",
        "outputId": "b0d04983-c288-425d-bfaf-30bc6c7f79e6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2482\u001b[0m  0.0072\n",
            "      2        \u001b[36m1.9808\u001b[0m  0.0089\n",
            "      3        \u001b[36m1.8464\u001b[0m  0.0109\n",
            "      4        \u001b[36m1.7720\u001b[0m  0.0096\n",
            "      5        \u001b[36m1.7273\u001b[0m  0.0072\n",
            "      6        \u001b[36m1.6958\u001b[0m  0.0073\n",
            "      7        \u001b[36m1.6723\u001b[0m  0.0079\n",
            "      8        \u001b[36m1.6543\u001b[0m  0.0086\n",
            "      9        \u001b[36m1.6394\u001b[0m  0.0083\n",
            "     10        \u001b[36m1.6270\u001b[0m  0.0082\n",
            "No of initial data:  300\n",
            "0.7847\n",
            "Confusion Matrix After trainig with initial data\n",
            "Confusion Matrix:\n",
            "[[ 895    3    8    6    0    9   41    0   24    1]\n",
            " [   0 1056   17   10    1   11    2    2   25    0]\n",
            " [  29   20  784   20    7    0   44   15   64   10]\n",
            " [  13   39   58  755    0   53   17   20   47   20]\n",
            " [   9   10   12    2  607    0   28    8   25  273]\n",
            " [  39   31   16  102   15  548   27    5   87   33]\n",
            " [  22   22   53    0    0   22  857    0   10    0]\n",
            " [  22   23    8   11    8    0    2  832   25  113]\n",
            " [  28   64   22   69    5   22   13    2  720   30]\n",
            " [  10   10    9   15   31    5    1   86   32  793]]\n",
            "Accuracy:  0.7847\n",
            "Macro F1-score:  0.7810319696783756\n",
            "Micro F1-score:  0.7847\n",
            "Weighted F1-score:  0.7833410470370814\n",
            "---------------------------------\n",
            "---- Train From Scratch with first model-----\n",
            "[3, 8, 8, 8, 5, 3, 0, 4, 9, 0, 7, 4, 8, 7, 3, 5, 5, 5, 5, 8, 8, 3, 8, 7, 3, 5, 2, 5, 2, 2, 8, 5, 8, 5, 3, 5, 7, 8, 6, 3, 5, 8, 3, 2, 5, 8, 3, 5, 3, 3, 0, 5, 8, 5, 7, 5, 8, 5, 3, 8, 3, 1, 3, 8, 1, 8, 0, 3, 3, 5, 9, 8, 5, 8, 8, 0, 2, 4, 5, 3, 5, 5, 4, 8, 3, 8, 5, 3, 8, 5, 3, 8, 4, 8, 8, 1, 8, 5, 8, 9, 8, 5, 5, 8, 5, 2, 4, 3, 3, 4, 3, 0, 4, 0, 0, 4, 4, 3, 3, 3, 0, 0, 7, 7, 5, 2, 9, 3, 2, 5, 3, 3, 3, 4, 1, 4, 0, 7, 7, 4, 0, 0, 7, 0, 0, 2, 0, 9, 9, 2, 0, 2, 9, 9, 4, 2, 0, 0, 4, 0, 0, 7, 0, 2, 0, 6, 1, 0, 0, 0, 0, 7, 2, 0, 0, 9, 4, 0, 4, 4, 2, 4, 7, 9, 4, 2, 7, 2, 2, 7, 7, 9, 4, 4, 6, 2, 2, 2, 2, 2, 4, 4, 2, 7, 4, 9, 2, 1, 9, 7, 7, 4, 2, 4, 4, 7, 7, 9, 7, 4, 7, 6, 1, 4, 2, 2, 6, 7, 2, 6, 7, 2, 7, 7, 9, 9, 7, 7, 7, 9, 6, 6, 9, 1, 6, 9, 1, 1, 6, 1, 9, 9, 9, 9, 9, 9, 1, 6, 9, 9, 9]\n",
            "Counter({3: 30, 8: 30, 5: 30, 0: 30, 4: 30, 7: 30, 2: 30, 9: 28, 1: 12, 6: 11})\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3611\u001b[0m  0.0059\n",
            "      2        \u001b[36m2.1453\u001b[0m  0.0089\n",
            "      3        \u001b[36m2.0496\u001b[0m  0.0078\n",
            "      4        \u001b[36m2.0179\u001b[0m  0.0060\n",
            "      5        \u001b[36m1.9875\u001b[0m  0.0078\n",
            "      6        \u001b[36m1.9482\u001b[0m  0.0065\n",
            "      7        \u001b[36m1.9036\u001b[0m  0.0080\n",
            "      8        \u001b[36m1.8605\u001b[0m  0.0067\n",
            "      9        \u001b[36m1.8261\u001b[0m  0.0068\n",
            "     10        \u001b[36m1.8011\u001b[0m  0.0080\n",
            "0.4552\n",
            "Confusion Matrix after training the model with most important dataset\n",
            "Confusion Matrix:\n",
            "[[375   0 300  23   7 118  41   0  29  94]\n",
            " [  8 570  17  43   5   1  48  82  65 285]\n",
            " [ 42  30 600  95  69  40  18  30  53  16]\n",
            " [ 47  59  16 639   3 107   2  70  31  48]\n",
            " [ 12  18  29   1 440  61  21 138  37 217]\n",
            " [ 57  24  19 223  12 123 144   2 187 112]\n",
            " [217  41 350   1 145  37 136   5  25  29]\n",
            " [  8   5  27   2  17   5   0 595   3 382]\n",
            " [ 67  45  43  65   9  67   6  12 402 259]\n",
            " [  3  27  16   7  50   8   0 197  12 672]]\n",
            "Accuracy:  0.4552\n",
            "Macro F1-score:  0.43901731861185267\n",
            "Micro F1-score:  0.45519999999999994\n",
            "Weighted F1-score:  0.4444744149931439\n",
            "---------------------------------\n",
            "---- Teach/Retrain with new data-------\n",
            "--- Query no:   1  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2392\u001b[0m  0.0068\n",
            "      2        \u001b[36m1.9887\u001b[0m  0.0098\n",
            "      3        \u001b[36m1.8851\u001b[0m  0.0089\n",
            "      4        \u001b[36m1.8170\u001b[0m  0.0085\n",
            "      5        \u001b[36m1.7668\u001b[0m  0.0097\n",
            "      6        \u001b[36m1.7330\u001b[0m  0.0091\n",
            "      7        \u001b[36m1.7061\u001b[0m  0.0099\n",
            "      8        \u001b[36m1.6846\u001b[0m  0.0095\n",
            "      9        \u001b[36m1.6707\u001b[0m  0.0083\n",
            "     10        \u001b[36m1.6584\u001b[0m  0.0099\n",
            "Instance [8 3 0 0 8 8 8 8 0 8 8 8 2 8 0 5 8 7 5 0 8 8 9 5 8 7 3 8 3 3]\n",
            "0.7801\n",
            "--- Query no:   2  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2497\u001b[0m  0.0070\n",
            "      2        \u001b[36m2.0085\u001b[0m  0.0106\n",
            "      3        \u001b[36m1.9040\u001b[0m  0.0093\n",
            "      4        \u001b[36m1.8340\u001b[0m  0.0077\n",
            "      5        \u001b[36m1.7861\u001b[0m  0.0087\n",
            "      6        \u001b[36m1.7506\u001b[0m  0.0078\n",
            "      7        \u001b[36m1.7216\u001b[0m  0.0076\n",
            "      8        \u001b[36m1.7017\u001b[0m  0.0074\n",
            "      9        \u001b[36m1.6859\u001b[0m  0.0078\n",
            "     10        \u001b[36m1.6706\u001b[0m  0.0084\n",
            "Instance [9 2 6 1 2 5 5 8 4 5 2 6 2 2 5 5 8 3 5 5 7 5 3 6 3 3 4 6 3 4]\n",
            "0.7939\n",
            "--- Query no:   3  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2472\u001b[0m  0.0113\n",
            "      2        \u001b[36m2.0076\u001b[0m  0.0159\n",
            "      3        \u001b[36m1.9226\u001b[0m  0.0120\n",
            "      4        \u001b[36m1.8573\u001b[0m  0.0115\n",
            "      5        \u001b[36m1.8179\u001b[0m  0.0112\n",
            "      6        \u001b[36m1.7888\u001b[0m  0.0115\n",
            "      7        \u001b[36m1.7638\u001b[0m  0.0113\n",
            "      8        \u001b[36m1.7451\u001b[0m  0.0158\n",
            "      9        \u001b[36m1.7283\u001b[0m  0.0152\n",
            "     10        \u001b[36m1.7134\u001b[0m  0.0106\n",
            "Instance [9 0 4 8 4 4 4 2 3 3 3 4 7 4 5 7 1 8 5 5 7 0 4 6 8 9 4 7 7 4]\n",
            "0.7647\n",
            "--- Query no:   4  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2425\u001b[0m  0.0132\n",
            "      2        \u001b[36m2.0082\u001b[0m  0.0149\n",
            "      3        \u001b[36m1.9108\u001b[0m  0.0142\n",
            "      4        \u001b[36m1.8411\u001b[0m  0.0122\n",
            "      5        \u001b[36m1.7935\u001b[0m  0.0119\n",
            "      6        \u001b[36m1.7606\u001b[0m  0.0118\n",
            "      7        \u001b[36m1.7391\u001b[0m  0.0122\n",
            "      8        \u001b[36m1.7198\u001b[0m  0.0119\n",
            "      9        \u001b[36m1.7026\u001b[0m  0.0144\n",
            "     10        \u001b[36m1.6877\u001b[0m  0.0129\n",
            "Instance [7 0 4 3 5 0 7 4 8 7 8 4 5 0 4 4 9 8 2 5 8 5 3 7 7 0 1 2 3 3]\n",
            "0.7686\n",
            "--- Query no:   5  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2452\u001b[0m  0.0083\n",
            "      2        \u001b[36m2.0081\u001b[0m  0.0107\n",
            "      3        \u001b[36m1.9037\u001b[0m  0.0104\n",
            "      4        \u001b[36m1.8389\u001b[0m  0.0114\n",
            "      5        \u001b[36m1.7915\u001b[0m  0.0104\n",
            "      6        \u001b[36m1.7614\u001b[0m  0.0100\n",
            "      7        \u001b[36m1.7387\u001b[0m  0.0098\n",
            "      8        \u001b[36m1.7185\u001b[0m  0.0095\n",
            "      9        \u001b[36m1.7010\u001b[0m  0.0092\n",
            "     10        \u001b[36m1.6873\u001b[0m  0.0110\n",
            "Instance [7 5 9 7 3 2 7 6 6 6 5 2 8 0 6 5 6 6 3 6 3 2 0 5 0 3 0 6 8 2]\n",
            "0.7824\n",
            "--- Query no:   6  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2458\u001b[0m  0.0086\n",
            "      2        \u001b[36m2.0222\u001b[0m  0.0102\n",
            "      3        \u001b[36m1.9181\u001b[0m  0.0106\n",
            "      4        \u001b[36m1.8542\u001b[0m  0.0123\n",
            "      5        \u001b[36m1.8071\u001b[0m  0.0122\n",
            "      6        \u001b[36m1.7740\u001b[0m  0.0125\n",
            "      7        \u001b[36m1.7513\u001b[0m  0.0124\n",
            "      8        \u001b[36m1.7309\u001b[0m  0.0120\n",
            "      9        \u001b[36m1.7130\u001b[0m  0.0141\n",
            "     10        \u001b[36m1.6981\u001b[0m  0.0109\n",
            "Instance [9 8 2 4 8 4 7 2 9 6 7 9 4 9 6 4 4 7 8 6 3 3 2 2 4 2 6 8 5 5]\n",
            "0.7922\n",
            "--- Query no:   7  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2470\u001b[0m  0.0088\n",
            "      2        \u001b[36m2.0306\u001b[0m  0.0132\n",
            "      3        \u001b[36m1.9332\u001b[0m  0.0100\n",
            "      4        \u001b[36m1.8730\u001b[0m  0.0099\n",
            "      5        \u001b[36m1.8271\u001b[0m  0.0095\n",
            "      6        \u001b[36m1.7935\u001b[0m  0.0095\n",
            "      7        \u001b[36m1.7703\u001b[0m  0.0101\n",
            "      8        \u001b[36m1.7499\u001b[0m  0.0096\n",
            "      9        \u001b[36m1.7318\u001b[0m  0.0104\n",
            "     10        \u001b[36m1.7161\u001b[0m  0.0140\n",
            "Instance [4 2 0 5 5 3 8 5 2 9 4 0 4 5 6 9 9 9 4 4 3 8 4 3 1 4 0 8 8 4]\n",
            "0.8008\n",
            "--- Query no:   8  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2504\u001b[0m  0.0101\n",
            "      2        \u001b[36m2.0210\u001b[0m  0.0139\n",
            "      3        \u001b[36m1.9243\u001b[0m  0.0122\n",
            "      4        \u001b[36m1.8644\u001b[0m  0.0119\n",
            "      5        \u001b[36m1.8209\u001b[0m  0.0118\n",
            "      6        \u001b[36m1.7918\u001b[0m  0.0118\n",
            "      7        \u001b[36m1.7696\u001b[0m  0.0120\n",
            "      8        \u001b[36m1.7507\u001b[0m  0.0124\n",
            "      9        \u001b[36m1.7337\u001b[0m  0.0121\n",
            "     10        \u001b[36m1.7199\u001b[0m  0.0119\n",
            "Instance [9 2 2 1 3 1 9 7 2 0 6 4 1 2 1 1 5 9 9 9 5 2 0 4 2 2 4 9 5 3]\n",
            "0.787\n",
            "--- Query no:   9  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2460\u001b[0m  0.0107\n",
            "      2        \u001b[36m2.0239\u001b[0m  0.0132\n",
            "      3        \u001b[36m1.9273\u001b[0m  0.0134\n",
            "      4        \u001b[36m1.8682\u001b[0m  0.0140\n",
            "      5        \u001b[36m1.8237\u001b[0m  0.0116\n",
            "      6        \u001b[36m1.7937\u001b[0m  0.0121\n",
            "      7        \u001b[36m1.7707\u001b[0m  0.0124\n",
            "      8        \u001b[36m1.7513\u001b[0m  0.0124\n",
            "      9        \u001b[36m1.7344\u001b[0m  0.0127\n",
            "     10        \u001b[36m1.7209\u001b[0m  0.0124\n",
            "Instance [9 8 0 3 7 8 8 7 6 0 3 6 9 8 7 8 6 7 5 4 2 5 8 7 3 8 6 5 5 5]\n",
            "0.7935\n",
            "--- Query no:   10  ----\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2389\u001b[0m  0.0105\n",
            "      2        \u001b[36m2.0319\u001b[0m  0.0126\n",
            "      3        \u001b[36m1.9364\u001b[0m  0.0121\n",
            "      4        \u001b[36m1.8785\u001b[0m  0.0116\n",
            "      5        \u001b[36m1.8322\u001b[0m  0.0125\n",
            "      6        \u001b[36m1.8013\u001b[0m  0.0126\n",
            "      7        \u001b[36m1.7776\u001b[0m  0.0125\n",
            "      8        \u001b[36m1.7573\u001b[0m  0.0124\n",
            "      9        \u001b[36m1.7390\u001b[0m  0.0117\n",
            "     10        \u001b[36m1.7252\u001b[0m  0.0138\n",
            "Instance [4 0 7 7 7 0 8 5 7 1 5 0 4 8 9 7 9 5 8 1 5 8 0 8 2 2 2 3 9 2]\n",
            "0.8013\n",
            "Confusion Matrix After RE-TRAINGING\n",
            "Confusion Matrix:\n",
            "[[849   0   5   3   3  86  27   2  11   1]\n",
            " [  0 955  11   1   1   6   2   1 147   0]\n",
            " [ 11  19 711  29  22   7  38  22 131   3]\n",
            " [ 38  14  22 806   0  12  14  21  73  22]\n",
            " [  1   2   7   0 739   2   8   5  35 175]\n",
            " [ 52   7   5  49  10 564  23   0 151  42]\n",
            " [ 11   4  32   0  11  30 882   0  16   0]\n",
            " [  7   4   5   5  10   2   0 834  30 147]\n",
            " [ 13  15   9  19   1  34   5   2 839  38]\n",
            " [  3   4   2  12  64   3   0  32  38 834]]\n",
            "Accuracy:  0.8013\n",
            "Macro F1-score:  0.8021664167068014\n",
            "Micro F1-score:  0.8013\n",
            "Weighted F1-score:  0.8048012489565923\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# AL_Retrain function with performance tracking\n",
        "def AL_Retrain(n_initial, n_queries, instances, x_train, y_train, x_test, y_test):\n",
        "    # Splitting initial training data\n",
        "    x_initial, x_pool, y_initial, y_pool = train_test_split(x_train, y_train, train_size=n_initial, random_state=0, stratify=y_train)\n",
        "    x_initial = x_initial.reshape(len(x_initial), 1, 28, 28)\n",
        "    x_pool = x_pool.reshape(len(x_pool), 1, 28, 28)\n",
        "\n",
        "    # Load the logistic regression model\n",
        "    filename = \"regression_version1.joblib\"\n",
        "    classifier = joblib.load(filename)\n",
        "\n",
        "    # Initialize Active Learner\n",
        "    learner = ActiveLearner(\n",
        "        estimator=classifier,\n",
        "        query_strategy=uncertainty_sampling,\n",
        "        X_training=x_initial, y_training=y_initial, epochs=10\n",
        "    )\n",
        "\n",
        "    # Track the performance after each query\n",
        "    performance_history = [accuracy_score(y_test, learner.predict(x_test))]\n",
        "\n",
        "    # Active Learning Loop\n",
        "    for idx in range(n_queries):\n",
        "        query_idx, query_instance = learner.query(x_pool, n_instances=instances)\n",
        "        learner.teach(X=x_pool[query_idx], y=y_pool[query_idx])\n",
        "        x_pool = np.delete(x_pool, query_idx, axis=0)\n",
        "        y_pool = np.delete(y_pool, query_idx, axis=0)\n",
        "\n",
        "        # Record the new performance\n",
        "        new_score = accuracy_score(y_test, learner.predict(x_test))\n",
        "        performance_history.append(new_score)\n",
        "\n",
        "    return performance_history\n",
        "\n",
        "# Define the configurations\n",
        "configurations = [\n",
        "    (30, 10, 20),\n",
        "    (30, 10, 30),\n",
        "    (50, 10, 20),\n",
        "    (50, 10, 30),\n",
        "    (100, 10, 20),\n",
        "    (300, 10, 20),\n",
        "    (300, 10, 30)\n",
        "]\n",
        "\n",
        "# Run and plot each configuration\n",
        "plt.figure(figsize=(12, 8))\n",
        "for config in configurations:\n",
        "    n_initial, n_queries, instances = config\n",
        "    performance_history = AL_Retrain(n_initial, n_queries, instances, x_train, y_train, x_test, y_test)\n",
        "    plt.plot(performance_history, label=f'n_initial={n_initial}, n_queries={n_queries}, instances={instances}')\n",
        "\n",
        "plt.title(\"Logistic Regression Performance over Queries\")\n",
        "plt.xlabel(\"Query Number\")\n",
        "plt.ylabel(\"Accuracy on Test Set\")\n",
        "plt.legend()\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C1d85qL0Jwfc",
        "outputId": "49b12f9b-ba65-4fba-aa93-2f298b6f8847"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3072\u001b[0m  0.0032\n",
            "      2        \u001b[36m2.1507\u001b[0m  0.0028\n",
            "      3        \u001b[36m2.0223\u001b[0m  0.0026\n",
            "      4        \u001b[36m1.9191\u001b[0m  0.0041\n",
            "      5        \u001b[36m1.8342\u001b[0m  0.0027\n",
            "      6        \u001b[36m1.7648\u001b[0m  0.0028\n",
            "      7        \u001b[36m1.7094\u001b[0m  0.0038\n",
            "      8        \u001b[36m1.6661\u001b[0m  0.0027\n",
            "      9        \u001b[36m1.6322\u001b[0m  0.0025\n",
            "     10        \u001b[36m1.6050\u001b[0m  0.0028\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2984\u001b[0m  0.0033\n",
            "      2        \u001b[36m2.0950\u001b[0m  0.0042\n",
            "      3        \u001b[36m2.0307\u001b[0m  0.0033\n",
            "      4        \u001b[36m1.9872\u001b[0m  0.0033\n",
            "      5        \u001b[36m1.9443\u001b[0m  0.0035\n",
            "      6        \u001b[36m1.9008\u001b[0m  0.0032\n",
            "      7        \u001b[36m1.8568\u001b[0m  0.0033\n",
            "      8        \u001b[36m1.8159\u001b[0m  0.0037\n",
            "      9        \u001b[36m1.7820\u001b[0m  0.0031\n",
            "     10        \u001b[36m1.7542\u001b[0m  0.0050\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2883\u001b[0m  0.0041\n",
            "      2        \u001b[36m2.1268\u001b[0m  0.0052\n",
            "      3        \u001b[36m2.0597\u001b[0m  0.0051\n",
            "      4        \u001b[36m2.0099\u001b[0m  0.0028\n",
            "      5        \u001b[36m1.9632\u001b[0m  0.0036\n",
            "      6        \u001b[36m1.9170\u001b[0m  0.0052\n",
            "      7        \u001b[36m1.8721\u001b[0m  0.0031\n",
            "      8        \u001b[36m1.8290\u001b[0m  0.0035\n",
            "      9        \u001b[36m1.7869\u001b[0m  0.0033\n",
            "     10        \u001b[36m1.7489\u001b[0m  0.0033\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3031\u001b[0m  0.0024\n",
            "      2        \u001b[36m2.1613\u001b[0m  0.0058\n",
            "      3        \u001b[36m2.0936\u001b[0m  0.0042\n",
            "      4        \u001b[36m2.0416\u001b[0m  0.0039\n",
            "      5        \u001b[36m1.9936\u001b[0m  0.0038\n",
            "      6        \u001b[36m1.9477\u001b[0m  0.0030\n",
            "      7        \u001b[36m1.9033\u001b[0m  0.0029\n",
            "      8        \u001b[36m1.8600\u001b[0m  0.0030\n",
            "      9        \u001b[36m1.8194\u001b[0m  0.0037\n",
            "     10        \u001b[36m1.7846\u001b[0m  0.0034\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3079\u001b[0m  0.0025\n",
            "      2        \u001b[36m2.1842\u001b[0m  0.0055\n",
            "      3        \u001b[36m2.1179\u001b[0m  0.0038\n",
            "      4        \u001b[36m2.0626\u001b[0m  0.0034\n",
            "      5        \u001b[36m2.0092\u001b[0m  0.0034\n",
            "      6        \u001b[36m1.9575\u001b[0m  0.0036\n",
            "      7        \u001b[36m1.9091\u001b[0m  0.0031\n",
            "      8        \u001b[36m1.8663\u001b[0m  0.0039\n",
            "      9        \u001b[36m1.8305\u001b[0m  0.0036\n",
            "     10        \u001b[36m1.7996\u001b[0m  0.0033\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3042\u001b[0m  0.0036\n",
            "      2        \u001b[36m2.1628\u001b[0m  0.0066\n",
            "      3        \u001b[36m2.0974\u001b[0m  0.0053\n",
            "      4        \u001b[36m2.0436\u001b[0m  0.0045\n",
            "      5        \u001b[36m1.9994\u001b[0m  0.0049\n",
            "      6        \u001b[36m1.9534\u001b[0m  0.0048\n",
            "      7        \u001b[36m1.9057\u001b[0m  0.0045\n",
            "      8        \u001b[36m1.8625\u001b[0m  0.0044\n",
            "      9        \u001b[36m1.8263\u001b[0m  0.0047\n",
            "     10        \u001b[36m1.7960\u001b[0m  0.0044\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3130\u001b[0m  0.0040\n",
            "      2        \u001b[36m2.1514\u001b[0m  0.0067\n",
            "      3        \u001b[36m2.0762\u001b[0m  0.0051\n",
            "      4        \u001b[36m2.0294\u001b[0m  0.0048\n",
            "      5        \u001b[36m1.9891\u001b[0m  0.0057\n",
            "      6        \u001b[36m1.9394\u001b[0m  0.0058\n",
            "      7        \u001b[36m1.8884\u001b[0m  0.0060\n",
            "      8        \u001b[36m1.8474\u001b[0m  0.0057\n",
            "      9        \u001b[36m1.8168\u001b[0m  0.0043\n",
            "     10        \u001b[36m1.7928\u001b[0m  0.0054\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3156\u001b[0m  0.0071\n",
            "      2        \u001b[36m2.1400\u001b[0m  0.0059\n",
            "      3        \u001b[36m2.0593\u001b[0m  0.0057\n",
            "      4        \u001b[36m2.0060\u001b[0m  0.0059\n",
            "      5        \u001b[36m1.9519\u001b[0m  0.0068\n",
            "      6        \u001b[36m1.8941\u001b[0m  0.0077\n",
            "      7        \u001b[36m1.8466\u001b[0m  0.0058\n",
            "      8        \u001b[36m1.8123\u001b[0m  0.0080\n",
            "      9        \u001b[36m1.7864\u001b[0m  0.0058\n",
            "     10        \u001b[36m1.7636\u001b[0m  0.0063\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3037\u001b[0m  0.0062\n",
            "      2        \u001b[36m2.1378\u001b[0m  0.0079\n",
            "      3        \u001b[36m2.0685\u001b[0m  0.0058\n",
            "      4        \u001b[36m2.0117\u001b[0m  0.0070\n",
            "      5        \u001b[36m1.9562\u001b[0m  0.0092\n",
            "      6        \u001b[36m1.9038\u001b[0m  0.0099\n",
            "      7        \u001b[36m1.8540\u001b[0m  0.0062\n",
            "      8        \u001b[36m1.8152\u001b[0m  0.0057\n",
            "      9        \u001b[36m1.7876\u001b[0m  0.0061\n",
            "     10        \u001b[36m1.7636\u001b[0m  0.0060\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2937\u001b[0m  0.0045\n",
            "      2        \u001b[36m2.1437\u001b[0m  0.0060\n",
            "      3        \u001b[36m2.0753\u001b[0m  0.0056\n",
            "      4        \u001b[36m2.0078\u001b[0m  0.0053\n",
            "      5        \u001b[36m1.9430\u001b[0m  0.0053\n",
            "      6        \u001b[36m1.8941\u001b[0m  0.0076\n",
            "      7        \u001b[36m1.8508\u001b[0m  0.0055\n",
            "      8        \u001b[36m1.8143\u001b[0m  0.0057\n",
            "      9        \u001b[36m1.7857\u001b[0m  0.0064\n",
            "     10        \u001b[36m1.7608\u001b[0m  0.0051\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3058\u001b[0m  0.0049\n",
            "      2        \u001b[36m2.1592\u001b[0m  0.0080\n",
            "      3        \u001b[36m2.0877\u001b[0m  0.0072\n",
            "      4        \u001b[36m2.0194\u001b[0m  0.0074\n",
            "      5        \u001b[36m1.9539\u001b[0m  0.0063\n",
            "      6        \u001b[36m1.9036\u001b[0m  0.0058\n",
            "      7        \u001b[36m1.8617\u001b[0m  0.0057\n",
            "      8        \u001b[36m1.8239\u001b[0m  0.0052\n",
            "      9        \u001b[36m1.7941\u001b[0m  0.0054\n",
            "     10        \u001b[36m1.7700\u001b[0m  0.0053\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3145\u001b[0m  0.0020\n",
            "      2        \u001b[36m2.1558\u001b[0m  0.0045\n",
            "      3        \u001b[36m2.0270\u001b[0m  0.0023\n",
            "      4        \u001b[36m1.9244\u001b[0m  0.0037\n",
            "      5        \u001b[36m1.8391\u001b[0m  0.0041\n",
            "      6        \u001b[36m1.7686\u001b[0m  0.0029\n",
            "      7        \u001b[36m1.7122\u001b[0m  0.0028\n",
            "      8        \u001b[36m1.6681\u001b[0m  0.0027\n",
            "      9        \u001b[36m1.6338\u001b[0m  0.0022\n",
            "     10        \u001b[36m1.6065\u001b[0m  0.0022\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3001\u001b[0m  0.0022\n",
            "      2        \u001b[36m2.1065\u001b[0m  0.0057\n",
            "      3        \u001b[36m2.0480\u001b[0m  0.0043\n",
            "      4        \u001b[36m2.0005\u001b[0m  0.0042\n",
            "      5        \u001b[36m1.9568\u001b[0m  0.0041\n",
            "      6        \u001b[36m1.9111\u001b[0m  0.0041\n",
            "      7        \u001b[36m1.8617\u001b[0m  0.0042\n",
            "      8        \u001b[36m1.8240\u001b[0m  0.0032\n",
            "      9        \u001b[36m1.8010\u001b[0m  0.0029\n",
            "     10        \u001b[36m1.7782\u001b[0m  0.0029\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3126\u001b[0m  0.0023\n",
            "      2        \u001b[36m2.1519\u001b[0m  0.0055\n",
            "      3        \u001b[36m2.0828\u001b[0m  0.0035\n",
            "      4        \u001b[36m2.0284\u001b[0m  0.0041\n",
            "      5        \u001b[36m1.9770\u001b[0m  0.0088\n",
            "      6        \u001b[36m1.9276\u001b[0m  0.0045\n",
            "      7        \u001b[36m1.8835\u001b[0m  0.0037\n",
            "      8        \u001b[36m1.8479\u001b[0m  0.0042\n",
            "      9        \u001b[36m1.8158\u001b[0m  0.0031\n",
            "     10        \u001b[36m1.7852\u001b[0m  0.0031\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2991\u001b[0m  0.0025\n",
            "      2        \u001b[36m2.1700\u001b[0m  0.0041\n",
            "      3        \u001b[36m2.1006\u001b[0m  0.0058\n",
            "      4        \u001b[36m2.0405\u001b[0m  0.0050\n",
            "      5        \u001b[36m1.9855\u001b[0m  0.0036\n",
            "      6        \u001b[36m1.9405\u001b[0m  0.0051\n",
            "      7        \u001b[36m1.9030\u001b[0m  0.0053\n",
            "      8        \u001b[36m1.8683\u001b[0m  0.0053\n",
            "      9        \u001b[36m1.8363\u001b[0m  0.0048\n",
            "     10        \u001b[36m1.8074\u001b[0m  0.0036\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2971\u001b[0m  0.0039\n",
            "      2        \u001b[36m2.1289\u001b[0m  0.0060\n",
            "      3        \u001b[36m2.0550\u001b[0m  0.0059\n",
            "      4        \u001b[36m2.0037\u001b[0m  0.0059\n",
            "      5        \u001b[36m1.9595\u001b[0m  0.0049\n",
            "      6        \u001b[36m1.9168\u001b[0m  0.0048\n",
            "      7        \u001b[36m1.8745\u001b[0m  0.0049\n",
            "      8        \u001b[36m1.8382\u001b[0m  0.0055\n",
            "      9        \u001b[36m1.8098\u001b[0m  0.0048\n",
            "     10        \u001b[36m1.7865\u001b[0m  0.0045\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2826\u001b[0m  0.0042\n",
            "      2        \u001b[36m2.0952\u001b[0m  0.0076\n",
            "      3        \u001b[36m2.0228\u001b[0m  0.0065\n",
            "      4        \u001b[36m1.9748\u001b[0m  0.0063\n",
            "      5        \u001b[36m1.9368\u001b[0m  0.0069\n",
            "      6        \u001b[36m1.8964\u001b[0m  0.0066\n",
            "      7        \u001b[36m1.8559\u001b[0m  0.0060\n",
            "      8        \u001b[36m1.8202\u001b[0m  0.0064\n",
            "      9        \u001b[36m1.7891\u001b[0m  0.0051\n",
            "     10        \u001b[36m1.7610\u001b[0m  0.0052\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3054\u001b[0m  0.0043\n",
            "      2        \u001b[36m2.1260\u001b[0m  0.0076\n",
            "      3        \u001b[36m2.0426\u001b[0m  0.0046\n",
            "      4        \u001b[36m1.9770\u001b[0m  0.0052\n",
            "      5        \u001b[36m1.9103\u001b[0m  0.0051\n",
            "      6        \u001b[36m1.8524\u001b[0m  0.0051\n",
            "      7        \u001b[36m1.8107\u001b[0m  0.0052\n",
            "      8        \u001b[36m1.7773\u001b[0m  0.0052\n",
            "      9        \u001b[36m1.7494\u001b[0m  0.0051\n",
            "     10        \u001b[36m1.7260\u001b[0m  0.0050\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2821\u001b[0m  0.0049\n",
            "      2        \u001b[36m2.1297\u001b[0m  0.0083\n",
            "      3        \u001b[36m2.0562\u001b[0m  0.0067\n",
            "      4        \u001b[36m1.9846\u001b[0m  0.0069\n",
            "      5        \u001b[36m1.9151\u001b[0m  0.0061\n",
            "      6        \u001b[36m1.8646\u001b[0m  0.0057\n",
            "      7        \u001b[36m1.8233\u001b[0m  0.0057\n",
            "      8        \u001b[36m1.7862\u001b[0m  0.0058\n",
            "      9        \u001b[36m1.7573\u001b[0m  0.0056\n",
            "     10        \u001b[36m1.7351\u001b[0m  0.0056\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2743\u001b[0m  0.0104\n",
            "      2        \u001b[36m2.1114\u001b[0m  0.0108\n",
            "      3        \u001b[36m2.0149\u001b[0m  0.0094\n",
            "      4        \u001b[36m1.9466\u001b[0m  0.0086\n",
            "      5        \u001b[36m1.9015\u001b[0m  0.0088\n",
            "      6        \u001b[36m1.8604\u001b[0m  0.0085\n",
            "      7        \u001b[36m1.8281\u001b[0m  0.0084\n",
            "      8        \u001b[36m1.8019\u001b[0m  0.0089\n",
            "      9        \u001b[36m1.7796\u001b[0m  0.0120\n",
            "     10        \u001b[36m1.7623\u001b[0m  0.0111\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2818\u001b[0m  0.0099\n",
            "      2        \u001b[36m2.1181\u001b[0m  0.0085\n",
            "      3        \u001b[36m2.0298\u001b[0m  0.0108\n",
            "      4        \u001b[36m1.9480\u001b[0m  0.0104\n",
            "      5        \u001b[36m1.8766\u001b[0m  0.0102\n",
            "      6        \u001b[36m1.8316\u001b[0m  0.0104\n",
            "      7        \u001b[36m1.7964\u001b[0m  0.0085\n",
            "      8        \u001b[36m1.7658\u001b[0m  0.0091\n",
            "      9        \u001b[36m1.7403\u001b[0m  0.0087\n",
            "     10        \u001b[36m1.7191\u001b[0m  0.0086\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2942\u001b[0m  0.0068\n",
            "      2        \u001b[36m2.1293\u001b[0m  0.0099\n",
            "      3        \u001b[36m2.0275\u001b[0m  0.0089\n",
            "      4        \u001b[36m1.9486\u001b[0m  0.0088\n",
            "      5        \u001b[36m1.8869\u001b[0m  0.0084\n",
            "      6        \u001b[36m1.8418\u001b[0m  0.0082\n",
            "      7        \u001b[36m1.8042\u001b[0m  0.0083\n",
            "      8        \u001b[36m1.7721\u001b[0m  0.0073\n",
            "      9        \u001b[36m1.7467\u001b[0m  0.0076\n",
            "     10        \u001b[36m1.7267\u001b[0m  0.0072\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3060\u001b[0m  0.0023\n",
            "      2        \u001b[36m2.1537\u001b[0m  0.0034\n",
            "      3        \u001b[36m2.0329\u001b[0m  0.0029\n",
            "      4        \u001b[36m1.9358\u001b[0m  0.0047\n",
            "      5        \u001b[36m1.8558\u001b[0m  0.0037\n",
            "      6        \u001b[36m1.7913\u001b[0m  0.0025\n",
            "      7        \u001b[36m1.7407\u001b[0m  0.0024\n",
            "      8        \u001b[36m1.7006\u001b[0m  0.0024\n",
            "      9        \u001b[36m1.6677\u001b[0m  0.0032\n",
            "     10        \u001b[36m1.6398\u001b[0m  0.0024\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3064\u001b[0m  0.0022\n",
            "      2        \u001b[36m2.1344\u001b[0m  0.0036\n",
            "      3        \u001b[36m2.0609\u001b[0m  0.0031\n",
            "      4        \u001b[36m2.0008\u001b[0m  0.0031\n",
            "      5        \u001b[36m1.9394\u001b[0m  0.0032\n",
            "      6        \u001b[36m1.8826\u001b[0m  0.0032\n",
            "      7        \u001b[36m1.8373\u001b[0m  0.0035\n",
            "      8        \u001b[36m1.8032\u001b[0m  0.0025\n",
            "      9        \u001b[36m1.7767\u001b[0m  0.0024\n",
            "     10        \u001b[36m1.7511\u001b[0m  0.0032\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3047\u001b[0m  0.0029\n",
            "      2        \u001b[36m2.1620\u001b[0m  0.0059\n",
            "      3        \u001b[36m2.0900\u001b[0m  0.0047\n",
            "      4        \u001b[36m2.0264\u001b[0m  0.0045\n",
            "      5        \u001b[36m1.9618\u001b[0m  0.0032\n",
            "      6        \u001b[36m1.9051\u001b[0m  0.0038\n",
            "      7        \u001b[36m1.8616\u001b[0m  0.0041\n",
            "      8        \u001b[36m1.8251\u001b[0m  0.0045\n",
            "      9        \u001b[36m1.7892\u001b[0m  0.0043\n",
            "     10        \u001b[36m1.7574\u001b[0m  0.0030\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3091\u001b[0m  0.0024\n",
            "      2        \u001b[36m2.1757\u001b[0m  0.0065\n",
            "      3        \u001b[36m2.1012\u001b[0m  0.0053\n",
            "      4        \u001b[36m2.0384\u001b[0m  0.0050\n",
            "      5        \u001b[36m1.9798\u001b[0m  0.0061\n",
            "      6        \u001b[36m1.9301\u001b[0m  0.0056\n",
            "      7        \u001b[36m1.8879\u001b[0m  0.0052\n",
            "      8        \u001b[36m1.8488\u001b[0m  0.0059\n",
            "      9        \u001b[36m1.8125\u001b[0m  0.0032\n",
            "     10        \u001b[36m1.7808\u001b[0m  0.0044\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3044\u001b[0m  0.0047\n",
            "      2        \u001b[36m2.1356\u001b[0m  0.0059\n",
            "      3        \u001b[36m2.0810\u001b[0m  0.0054\n",
            "      4        \u001b[36m2.0393\u001b[0m  0.0052\n",
            "      5        \u001b[36m2.0010\u001b[0m  0.0058\n",
            "      6        \u001b[36m1.9607\u001b[0m  0.0059\n",
            "      7        \u001b[36m1.9164\u001b[0m  0.0060\n",
            "      8        \u001b[36m1.8771\u001b[0m  0.0056\n",
            "      9        \u001b[36m1.8466\u001b[0m  0.0051\n",
            "     10        \u001b[36m1.8194\u001b[0m  0.0049\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2811\u001b[0m  0.0050\n",
            "      2        \u001b[36m2.1175\u001b[0m  0.0075\n",
            "      3        \u001b[36m2.0836\u001b[0m  0.0060\n",
            "      4        \u001b[36m2.0604\u001b[0m  0.0059\n",
            "      5        \u001b[36m2.0267\u001b[0m  0.0051\n",
            "      6        \u001b[36m1.9795\u001b[0m  0.0060\n",
            "      7        \u001b[36m1.9281\u001b[0m  0.0053\n",
            "      8        \u001b[36m1.8900\u001b[0m  0.0048\n",
            "      9        \u001b[36m1.8685\u001b[0m  0.0056\n",
            "     10        \u001b[36m1.8493\u001b[0m  0.0055\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2792\u001b[0m  0.0040\n",
            "      2        \u001b[36m2.1248\u001b[0m  0.0083\n",
            "      3        \u001b[36m2.0688\u001b[0m  0.0048\n",
            "      4        \u001b[36m2.0220\u001b[0m  0.0048\n",
            "      5        \u001b[36m1.9721\u001b[0m  0.0049\n",
            "      6        \u001b[36m1.9218\u001b[0m  0.0049\n",
            "      7        \u001b[36m1.8807\u001b[0m  0.0063\n",
            "      8        \u001b[36m1.8453\u001b[0m  0.0055\n",
            "      9        \u001b[36m1.8111\u001b[0m  0.0057\n",
            "     10        \u001b[36m1.7785\u001b[0m  0.0066\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2901\u001b[0m  0.0044\n",
            "      2        \u001b[36m2.1326\u001b[0m  0.0069\n",
            "      3        \u001b[36m2.0694\u001b[0m  0.0062\n",
            "      4        \u001b[36m2.0092\u001b[0m  0.0059\n",
            "      5        \u001b[36m1.9522\u001b[0m  0.0053\n",
            "      6        \u001b[36m1.8994\u001b[0m  0.0068\n",
            "      7        \u001b[36m1.8490\u001b[0m  0.0055\n",
            "      8        \u001b[36m1.8043\u001b[0m  0.0064\n",
            "      9        \u001b[36m1.7741\u001b[0m  0.0054\n",
            "     10        \u001b[36m1.7548\u001b[0m  0.0060\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2740\u001b[0m  0.0046\n",
            "      2        \u001b[36m2.1311\u001b[0m  0.0084\n",
            "      3        \u001b[36m2.0697\u001b[0m  0.0055\n",
            "      4        \u001b[36m2.0110\u001b[0m  0.0066\n",
            "      5        \u001b[36m1.9563\u001b[0m  0.0053\n",
            "      6        \u001b[36m1.9045\u001b[0m  0.0053\n",
            "      7        \u001b[36m1.8595\u001b[0m  0.0054\n",
            "      8        \u001b[36m1.8233\u001b[0m  0.0054\n",
            "      9        \u001b[36m1.7884\u001b[0m  0.0053\n",
            "     10        \u001b[36m1.7592\u001b[0m  0.0053\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2952\u001b[0m  0.0070\n",
            "      2        \u001b[36m2.1512\u001b[0m  0.0096\n",
            "      3        \u001b[36m2.0860\u001b[0m  0.0066\n",
            "      4        \u001b[36m2.0255\u001b[0m  0.0072\n",
            "      5        \u001b[36m1.9690\u001b[0m  0.0086\n",
            "      6        \u001b[36m1.9195\u001b[0m  0.0078\n",
            "      7        \u001b[36m1.8768\u001b[0m  0.0067\n",
            "      8        \u001b[36m1.8372\u001b[0m  0.0070\n",
            "      9        \u001b[36m1.8005\u001b[0m  0.0067\n",
            "     10        \u001b[36m1.7784\u001b[0m  0.0068\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2780\u001b[0m  0.0076\n",
            "      2        \u001b[36m2.1412\u001b[0m  0.0068\n",
            "      3        \u001b[36m2.0732\u001b[0m  0.0071\n",
            "      4        \u001b[36m2.0129\u001b[0m  0.0071\n",
            "      5        \u001b[36m1.9623\u001b[0m  0.0068\n",
            "      6        \u001b[36m1.9165\u001b[0m  0.0072\n",
            "      7        \u001b[36m1.8752\u001b[0m  0.0068\n",
            "      8        \u001b[36m1.8381\u001b[0m  0.0068\n",
            "      9        \u001b[36m1.8043\u001b[0m  0.0072\n",
            "     10        \u001b[36m1.7825\u001b[0m  0.0070\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3095\u001b[0m  0.0022\n",
            "      2        \u001b[36m2.1572\u001b[0m  0.0046\n",
            "      3        \u001b[36m2.0352\u001b[0m  0.0025\n",
            "      4        \u001b[36m1.9376\u001b[0m  0.0025\n",
            "      5        \u001b[36m1.8575\u001b[0m  0.0025\n",
            "      6        \u001b[36m1.7927\u001b[0m  0.0029\n",
            "      7        \u001b[36m1.7418\u001b[0m  0.0028\n",
            "      8        \u001b[36m1.7015\u001b[0m  0.0024\n",
            "      9        \u001b[36m1.6685\u001b[0m  0.0021\n",
            "     10        \u001b[36m1.6406\u001b[0m  0.0023\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3311\u001b[0m  0.0022\n",
            "      2        \u001b[36m2.1417\u001b[0m  0.0058\n",
            "      3        \u001b[36m2.0665\u001b[0m  0.0034\n",
            "      4        \u001b[36m2.0172\u001b[0m  0.0032\n",
            "      5        \u001b[36m1.9686\u001b[0m  0.0030\n",
            "      6        \u001b[36m1.9217\u001b[0m  0.0030\n",
            "      7        \u001b[36m1.8788\u001b[0m  0.0032\n",
            "      8        \u001b[36m1.8371\u001b[0m  0.0061\n",
            "      9        \u001b[36m1.7974\u001b[0m  0.0029\n",
            "     10        \u001b[36m1.7642\u001b[0m  0.0035\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3040\u001b[0m  0.0025\n",
            "      2        \u001b[36m2.1662\u001b[0m  0.0056\n",
            "      3        \u001b[36m2.0994\u001b[0m  0.0034\n",
            "      4        \u001b[36m2.0446\u001b[0m  0.0036\n",
            "      5        \u001b[36m1.9888\u001b[0m  0.0034\n",
            "      6        \u001b[36m1.9349\u001b[0m  0.0034\n",
            "      7        \u001b[36m1.8863\u001b[0m  0.0043\n",
            "      8        \u001b[36m1.8451\u001b[0m  0.0043\n",
            "      9        \u001b[36m1.8110\u001b[0m  0.0042\n",
            "     10        \u001b[36m1.7787\u001b[0m  0.0044\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2997\u001b[0m  0.0038\n",
            "      2        \u001b[36m2.1427\u001b[0m  0.0066\n",
            "      3        \u001b[36m2.0869\u001b[0m  0.0075\n",
            "      4        \u001b[36m2.0290\u001b[0m  0.0044\n",
            "      5        \u001b[36m1.9859\u001b[0m  0.0053\n",
            "      6        \u001b[36m1.9584\u001b[0m  0.0055\n",
            "      7        \u001b[36m1.9206\u001b[0m  0.0061\n",
            "      8        \u001b[36m1.8741\u001b[0m  0.0055\n",
            "      9        \u001b[36m1.8308\u001b[0m  0.0051\n",
            "     10        \u001b[36m1.7954\u001b[0m  0.0081\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3024\u001b[0m  0.0041\n",
            "      2        \u001b[36m2.1377\u001b[0m  0.0076\n",
            "      3        \u001b[36m2.0536\u001b[0m  0.0049\n",
            "      4        \u001b[36m1.9847\u001b[0m  0.0057\n",
            "      5        \u001b[36m1.9220\u001b[0m  0.0053\n",
            "      6        \u001b[36m1.8634\u001b[0m  0.0058\n",
            "      7        \u001b[36m1.8097\u001b[0m  0.0053\n",
            "      8        \u001b[36m1.7737\u001b[0m  0.0052\n",
            "      9        \u001b[36m1.7417\u001b[0m  0.0058\n",
            "     10        \u001b[36m1.7154\u001b[0m  0.0048\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2992\u001b[0m  0.0043\n",
            "      2        \u001b[36m2.1514\u001b[0m  0.0069\n",
            "      3        \u001b[36m2.0620\u001b[0m  0.0058\n",
            "      4        \u001b[36m1.9834\u001b[0m  0.0079\n",
            "      5        \u001b[36m1.9203\u001b[0m  0.0078\n",
            "      6        \u001b[36m1.8646\u001b[0m  0.0073\n",
            "      7        \u001b[36m1.8199\u001b[0m  0.0058\n",
            "      8        \u001b[36m1.7837\u001b[0m  0.0054\n",
            "      9        \u001b[36m1.7523\u001b[0m  0.0094\n",
            "     10        \u001b[36m1.7272\u001b[0m  0.0069\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2945\u001b[0m  0.0046\n",
            "      2        \u001b[36m2.1623\u001b[0m  0.0061\n",
            "      3        \u001b[36m2.0790\u001b[0m  0.0056\n",
            "      4        \u001b[36m1.9984\u001b[0m  0.0063\n",
            "      5        \u001b[36m1.9338\u001b[0m  0.0064\n",
            "      6        \u001b[36m1.8884\u001b[0m  0.0063\n",
            "      7        \u001b[36m1.8415\u001b[0m  0.0055\n",
            "      8        \u001b[36m1.8024\u001b[0m  0.0058\n",
            "      9        \u001b[36m1.7750\u001b[0m  0.0060\n",
            "     10        \u001b[36m1.7506\u001b[0m  0.0064\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2947\u001b[0m  0.0059\n",
            "      2        \u001b[36m2.1499\u001b[0m  0.0094\n",
            "      3        \u001b[36m2.0700\u001b[0m  0.0074\n",
            "      4        \u001b[36m2.0230\u001b[0m  0.0074\n",
            "      5        \u001b[36m1.9688\u001b[0m  0.0080\n",
            "      6        \u001b[36m1.9081\u001b[0m  0.0073\n",
            "      7        \u001b[36m1.8697\u001b[0m  0.0076\n",
            "      8        \u001b[36m1.8393\u001b[0m  0.0065\n",
            "      9        \u001b[36m1.8078\u001b[0m  0.0075\n",
            "     10        \u001b[36m1.7840\u001b[0m  0.0066\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2802\u001b[0m  0.0067\n",
            "      2        \u001b[36m2.1396\u001b[0m  0.0069\n",
            "      3        \u001b[36m2.0710\u001b[0m  0.0077\n",
            "      4        \u001b[36m1.9972\u001b[0m  0.0083\n",
            "      5        \u001b[36m1.9294\u001b[0m  0.0081\n",
            "      6        \u001b[36m1.8810\u001b[0m  0.0081\n",
            "      7        \u001b[36m1.8467\u001b[0m  0.0082\n",
            "      8        \u001b[36m1.8173\u001b[0m  0.0079\n",
            "      9        \u001b[36m1.7909\u001b[0m  0.0079\n",
            "     10        \u001b[36m1.7674\u001b[0m  0.0080\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2792\u001b[0m  0.0069\n",
            "      2        \u001b[36m2.1432\u001b[0m  0.0102\n",
            "      3        \u001b[36m2.0661\u001b[0m  0.0113\n",
            "      4        \u001b[36m1.9846\u001b[0m  0.0090\n",
            "      5        \u001b[36m1.9214\u001b[0m  0.0090\n",
            "      6        \u001b[36m1.8722\u001b[0m  0.0084\n",
            "      7        \u001b[36m1.8331\u001b[0m  0.0089\n",
            "      8        \u001b[36m1.8067\u001b[0m  0.0100\n",
            "      9        \u001b[36m1.7811\u001b[0m  0.0110\n",
            "     10        \u001b[36m1.7581\u001b[0m  0.0090\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2700\u001b[0m  0.0096\n",
            "      2        \u001b[36m2.1407\u001b[0m  0.0125\n",
            "      3        \u001b[36m2.0636\u001b[0m  0.0113\n",
            "      4        \u001b[36m1.9836\u001b[0m  0.0126\n",
            "      5        \u001b[36m1.9266\u001b[0m  0.0123\n",
            "      6        \u001b[36m1.8760\u001b[0m  0.0095\n",
            "      7        \u001b[36m1.8411\u001b[0m  0.0115\n",
            "      8        \u001b[36m1.8140\u001b[0m  0.0118\n",
            "      9        \u001b[36m1.7882\u001b[0m  0.0120\n",
            "     10        \u001b[36m1.7661\u001b[0m  0.0132\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3069\u001b[0m  0.0037\n",
            "      2        \u001b[36m2.1781\u001b[0m  0.0035\n",
            "      3        \u001b[36m2.0729\u001b[0m  0.0034\n",
            "      4        \u001b[36m1.9865\u001b[0m  0.0031\n",
            "      5        \u001b[36m1.9140\u001b[0m  0.0034\n",
            "      6        \u001b[36m1.8545\u001b[0m  0.0033\n",
            "      7        \u001b[36m1.8071\u001b[0m  0.0034\n",
            "      8        \u001b[36m1.7689\u001b[0m  0.0034\n",
            "      9        \u001b[36m1.7370\u001b[0m  0.0033\n",
            "     10        \u001b[36m1.7097\u001b[0m  0.0033\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3075\u001b[0m  0.0027\n",
            "      2        \u001b[36m2.1777\u001b[0m  0.0070\n",
            "      3        \u001b[36m2.0909\u001b[0m  0.0052\n",
            "      4        \u001b[36m2.0177\u001b[0m  0.0050\n",
            "      5        \u001b[36m1.9537\u001b[0m  0.0048\n",
            "      6        \u001b[36m1.9033\u001b[0m  0.0035\n",
            "      7        \u001b[36m1.8639\u001b[0m  0.0042\n",
            "      8        \u001b[36m1.8290\u001b[0m  0.0034\n",
            "      9        \u001b[36m1.7958\u001b[0m  0.0036\n",
            "     10        \u001b[36m1.7642\u001b[0m  0.0048\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3167\u001b[0m  0.0038\n",
            "      2        \u001b[36m2.1227\u001b[0m  0.0077\n",
            "      3        \u001b[36m2.0268\u001b[0m  0.0065\n",
            "      4        \u001b[36m1.9604\u001b[0m  0.0055\n",
            "      5        \u001b[36m1.9056\u001b[0m  0.0050\n",
            "      6        \u001b[36m1.8557\u001b[0m  0.0049\n",
            "      7        \u001b[36m1.8130\u001b[0m  0.0055\n",
            "      8        \u001b[36m1.7796\u001b[0m  0.0049\n",
            "      9        \u001b[36m1.7537\u001b[0m  0.0048\n",
            "     10        \u001b[36m1.7319\u001b[0m  0.0060\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3018\u001b[0m  0.0043\n",
            "      2        \u001b[36m2.1214\u001b[0m  0.0074\n",
            "      3        \u001b[36m2.0329\u001b[0m  0.0052\n",
            "      4        \u001b[36m1.9633\u001b[0m  0.0061\n",
            "      5        \u001b[36m1.8976\u001b[0m  0.0074\n",
            "      6        \u001b[36m1.8420\u001b[0m  0.0059\n",
            "      7        \u001b[36m1.8021\u001b[0m  0.0053\n",
            "      8        \u001b[36m1.7722\u001b[0m  0.0051\n",
            "      9        \u001b[36m1.7462\u001b[0m  0.0049\n",
            "     10        \u001b[36m1.7236\u001b[0m  0.0054\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2971\u001b[0m  0.0042\n",
            "      2        \u001b[36m2.1247\u001b[0m  0.0065\n",
            "      3        \u001b[36m2.0380\u001b[0m  0.0055\n",
            "      4        \u001b[36m1.9602\u001b[0m  0.0059\n",
            "      5        \u001b[36m1.8952\u001b[0m  0.0061\n",
            "      6        \u001b[36m1.8455\u001b[0m  0.0055\n",
            "      7        \u001b[36m1.8063\u001b[0m  0.0061\n",
            "      8        \u001b[36m1.7738\u001b[0m  0.0051\n",
            "      9        \u001b[36m1.7456\u001b[0m  0.0061\n",
            "     10        \u001b[36m1.7221\u001b[0m  0.0058\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2895\u001b[0m  0.0046\n",
            "      2        \u001b[36m2.1289\u001b[0m  0.0066\n",
            "      3        \u001b[36m2.0350\u001b[0m  0.0067\n",
            "      4        \u001b[36m1.9540\u001b[0m  0.0071\n",
            "      5        \u001b[36m1.8913\u001b[0m  0.0065\n",
            "      6        \u001b[36m1.8439\u001b[0m  0.0063\n",
            "      7        \u001b[36m1.8045\u001b[0m  0.0096\n",
            "      8        \u001b[36m1.7719\u001b[0m  0.0062\n",
            "      9        \u001b[36m1.7444\u001b[0m  0.0061\n",
            "     10        \u001b[36m1.7215\u001b[0m  0.0047\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2980\u001b[0m  0.0046\n",
            "      2        \u001b[36m2.1388\u001b[0m  0.0086\n",
            "      3        \u001b[36m2.0408\u001b[0m  0.0079\n",
            "      4        \u001b[36m1.9609\u001b[0m  0.0071\n",
            "      5        \u001b[36m1.8991\u001b[0m  0.0085\n",
            "      6        \u001b[36m1.8508\u001b[0m  0.0083\n",
            "      7        \u001b[36m1.8087\u001b[0m  0.0077\n",
            "      8        \u001b[36m1.7746\u001b[0m  0.0069\n",
            "      9        \u001b[36m1.7481\u001b[0m  0.0066\n",
            "     10        \u001b[36m1.7260\u001b[0m  0.0052\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2924\u001b[0m  0.0048\n",
            "      2        \u001b[36m2.1467\u001b[0m  0.0079\n",
            "      3        \u001b[36m2.0497\u001b[0m  0.0061\n",
            "      4        \u001b[36m1.9703\u001b[0m  0.0059\n",
            "      5        \u001b[36m1.9116\u001b[0m  0.0059\n",
            "      6        \u001b[36m1.8631\u001b[0m  0.0065\n",
            "      7        \u001b[36m1.8219\u001b[0m  0.0066\n",
            "      8        \u001b[36m1.7891\u001b[0m  0.0069\n",
            "      9        \u001b[36m1.7622\u001b[0m  0.0067\n",
            "     10        \u001b[36m1.7389\u001b[0m  0.0061\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2974\u001b[0m  0.0060\n",
            "      2        \u001b[36m2.1362\u001b[0m  0.0087\n",
            "      3        \u001b[36m2.0663\u001b[0m  0.0074\n",
            "      4        \u001b[36m2.0075\u001b[0m  0.0068\n",
            "      5        \u001b[36m1.9481\u001b[0m  0.0074\n",
            "      6        \u001b[36m1.8976\u001b[0m  0.0083\n",
            "      7        \u001b[36m1.8612\u001b[0m  0.0073\n",
            "      8        \u001b[36m1.8314\u001b[0m  0.0071\n",
            "      9        \u001b[36m1.8059\u001b[0m  0.0085\n",
            "     10        \u001b[36m1.7856\u001b[0m  0.0078\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2853\u001b[0m  0.0062\n",
            "      2        \u001b[36m2.1299\u001b[0m  0.0093\n",
            "      3        \u001b[36m2.0489\u001b[0m  0.0090\n",
            "      4        \u001b[36m1.9614\u001b[0m  0.0079\n",
            "      5        \u001b[36m1.9015\u001b[0m  0.0086\n",
            "      6        \u001b[36m1.8627\u001b[0m  0.0083\n",
            "      7        \u001b[36m1.8276\u001b[0m  0.0082\n",
            "      8        \u001b[36m1.8003\u001b[0m  0.0097\n",
            "      9        \u001b[36m1.7752\u001b[0m  0.0080\n",
            "     10        \u001b[36m1.7549\u001b[0m  0.0085\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2795\u001b[0m  0.0061\n",
            "      2        \u001b[36m2.1249\u001b[0m  0.0107\n",
            "      3        \u001b[36m2.0430\u001b[0m  0.0091\n",
            "      4        \u001b[36m1.9597\u001b[0m  0.0093\n",
            "      5        \u001b[36m1.8987\u001b[0m  0.0095\n",
            "      6        \u001b[36m1.8556\u001b[0m  0.0083\n",
            "      7        \u001b[36m1.8221\u001b[0m  0.0083\n",
            "      8        \u001b[36m1.7969\u001b[0m  0.0072\n",
            "      9        \u001b[36m1.7717\u001b[0m  0.0085\n",
            "     10        \u001b[36m1.7510\u001b[0m  0.0071\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2429\u001b[0m  0.0065\n",
            "      2        \u001b[36m1.9786\u001b[0m  0.0083\n",
            "      3        \u001b[36m1.8450\u001b[0m  0.0083\n",
            "      4        \u001b[36m1.7712\u001b[0m  0.0086\n",
            "      5        \u001b[36m1.7260\u001b[0m  0.0074\n",
            "      6        \u001b[36m1.6944\u001b[0m  0.0076\n",
            "      7        \u001b[36m1.6709\u001b[0m  0.0074\n",
            "      8        \u001b[36m1.6530\u001b[0m  0.0083\n",
            "      9        \u001b[36m1.6383\u001b[0m  0.0083\n",
            "     10        \u001b[36m1.6262\u001b[0m  0.0100\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2514\u001b[0m  0.0103\n",
            "      2        \u001b[36m1.9940\u001b[0m  0.0106\n",
            "      3        \u001b[36m1.8846\u001b[0m  0.0143\n",
            "      4        \u001b[36m1.8130\u001b[0m  0.0109\n",
            "      5        \u001b[36m1.7620\u001b[0m  0.0095\n",
            "      6        \u001b[36m1.7268\u001b[0m  0.0096\n",
            "      7        \u001b[36m1.7008\u001b[0m  0.0079\n",
            "      8        \u001b[36m1.6808\u001b[0m  0.0091\n",
            "      9        \u001b[36m1.6674\u001b[0m  0.0096\n",
            "     10        \u001b[36m1.6552\u001b[0m  0.0110\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2474\u001b[0m  0.0066\n",
            "      2        \u001b[36m2.0004\u001b[0m  0.0098\n",
            "      3        \u001b[36m1.8893\u001b[0m  0.0096\n",
            "      4        \u001b[36m1.8162\u001b[0m  0.0078\n",
            "      5        \u001b[36m1.7672\u001b[0m  0.0087\n",
            "      6        \u001b[36m1.7320\u001b[0m  0.0096\n",
            "      7        \u001b[36m1.7054\u001b[0m  0.0085\n",
            "      8        \u001b[36m1.6873\u001b[0m  0.0086\n",
            "      9        \u001b[36m1.6728\u001b[0m  0.0089\n",
            "     10        \u001b[36m1.6584\u001b[0m  0.0087\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2497\u001b[0m  0.0068\n",
            "      2        \u001b[36m2.0126\u001b[0m  0.0088\n",
            "      3        \u001b[36m1.9032\u001b[0m  0.0076\n",
            "      4        \u001b[36m1.8304\u001b[0m  0.0074\n",
            "      5        \u001b[36m1.7819\u001b[0m  0.0083\n",
            "      6        \u001b[36m1.7466\u001b[0m  0.0083\n",
            "      7        \u001b[36m1.7198\u001b[0m  0.0081\n",
            "      8        \u001b[36m1.7011\u001b[0m  0.0118\n",
            "      9        \u001b[36m1.6857\u001b[0m  0.0083\n",
            "     10        \u001b[36m1.6713\u001b[0m  0.0079\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2486\u001b[0m  0.0067\n",
            "      2        \u001b[36m2.0212\u001b[0m  0.0087\n",
            "      3        \u001b[36m1.9143\u001b[0m  0.0078\n",
            "      4        \u001b[36m1.8441\u001b[0m  0.0086\n",
            "      5        \u001b[36m1.7977\u001b[0m  0.0093\n",
            "      6        \u001b[36m1.7620\u001b[0m  0.0080\n",
            "      7        \u001b[36m1.7351\u001b[0m  0.0122\n",
            "      8        \u001b[36m1.7161\u001b[0m  0.0086\n",
            "      9        \u001b[36m1.6998\u001b[0m  0.0082\n",
            "     10        \u001b[36m1.6850\u001b[0m  0.0090\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2494\u001b[0m  0.0084\n",
            "      2        \u001b[36m2.0165\u001b[0m  0.0112\n",
            "      3        \u001b[36m1.9209\u001b[0m  0.0105\n",
            "      4        \u001b[36m1.8535\u001b[0m  0.0106\n",
            "      5        \u001b[36m1.8119\u001b[0m  0.0102\n",
            "      6        \u001b[36m1.7814\u001b[0m  0.0100\n",
            "      7        \u001b[36m1.7583\u001b[0m  0.0103\n",
            "      8        \u001b[36m1.7396\u001b[0m  0.0101\n",
            "      9        \u001b[36m1.7225\u001b[0m  0.0103\n",
            "     10        \u001b[36m1.7068\u001b[0m  0.0101\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2469\u001b[0m  0.0079\n",
            "      2        \u001b[36m2.0079\u001b[0m  0.0107\n",
            "      3        \u001b[36m1.9021\u001b[0m  0.0115\n",
            "      4        \u001b[36m1.8377\u001b[0m  0.0112\n",
            "      5        \u001b[36m1.7967\u001b[0m  0.0101\n",
            "      6        \u001b[36m1.7676\u001b[0m  0.0127\n",
            "      7        \u001b[36m1.7448\u001b[0m  0.0135\n",
            "      8        \u001b[36m1.7259\u001b[0m  0.0099\n",
            "      9        \u001b[36m1.7095\u001b[0m  0.0100\n",
            "     10        \u001b[36m1.6949\u001b[0m  0.0101\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2456\u001b[0m  0.0084\n",
            "      2        \u001b[36m2.0124\u001b[0m  0.0119\n",
            "      3        \u001b[36m1.9057\u001b[0m  0.0170\n",
            "      4        \u001b[36m1.8416\u001b[0m  0.0128\n",
            "      5        \u001b[36m1.7973\u001b[0m  0.0097\n",
            "      6        \u001b[36m1.7657\u001b[0m  0.0104\n",
            "      7        \u001b[36m1.7419\u001b[0m  0.0100\n",
            "      8        \u001b[36m1.7222\u001b[0m  0.0096\n",
            "      9        \u001b[36m1.7052\u001b[0m  0.0095\n",
            "     10        \u001b[36m1.6904\u001b[0m  0.0091\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2395\u001b[0m  0.0136\n",
            "      2        \u001b[36m2.0152\u001b[0m  0.0147\n",
            "      3        \u001b[36m1.9114\u001b[0m  0.0109\n",
            "      4        \u001b[36m1.8481\u001b[0m  0.0104\n",
            "      5        \u001b[36m1.8042\u001b[0m  0.0124\n",
            "      6        \u001b[36m1.7740\u001b[0m  0.0095\n",
            "      7        \u001b[36m1.7501\u001b[0m  0.0094\n",
            "      8        \u001b[36m1.7299\u001b[0m  0.0101\n",
            "      9        \u001b[36m1.7128\u001b[0m  0.0099\n",
            "     10        \u001b[36m1.6980\u001b[0m  0.0109\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2435\u001b[0m  0.0092\n",
            "      2        \u001b[36m2.0230\u001b[0m  0.0116\n",
            "      3        \u001b[36m1.9210\u001b[0m  0.0104\n",
            "      4        \u001b[36m1.8596\u001b[0m  0.0112\n",
            "      5        \u001b[36m1.8162\u001b[0m  0.0110\n",
            "      6        \u001b[36m1.7852\u001b[0m  0.0111\n",
            "      7        \u001b[36m1.7613\u001b[0m  0.0098\n",
            "      8        \u001b[36m1.7409\u001b[0m  0.0104\n",
            "      9        \u001b[36m1.7234\u001b[0m  0.0104\n",
            "     10        \u001b[36m1.7086\u001b[0m  0.0100\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2396\u001b[0m  0.0087\n",
            "      2        \u001b[36m2.0310\u001b[0m  0.0140\n",
            "      3        \u001b[36m1.9315\u001b[0m  0.0106\n",
            "      4        \u001b[36m1.8704\u001b[0m  0.0091\n",
            "      5        \u001b[36m1.8256\u001b[0m  0.0099\n",
            "      6        \u001b[36m1.7939\u001b[0m  0.0095\n",
            "      7        \u001b[36m1.7703\u001b[0m  0.0096\n",
            "      8        \u001b[36m1.7496\u001b[0m  0.0097\n",
            "      9        \u001b[36m1.7317\u001b[0m  0.0095\n",
            "     10        \u001b[36m1.7163\u001b[0m  0.0097\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2413\u001b[0m  0.0066\n",
            "      2        \u001b[36m1.9778\u001b[0m  0.0090\n",
            "      3        \u001b[36m1.8443\u001b[0m  0.0099\n",
            "      4        \u001b[36m1.7709\u001b[0m  0.0076\n",
            "      5        \u001b[36m1.7256\u001b[0m  0.0069\n",
            "      6        \u001b[36m1.6943\u001b[0m  0.0067\n",
            "      7        \u001b[36m1.6710\u001b[0m  0.0069\n",
            "      8        \u001b[36m1.6530\u001b[0m  0.0069\n",
            "      9        \u001b[36m1.6383\u001b[0m  0.0068\n",
            "     10        \u001b[36m1.6262\u001b[0m  0.0074\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2428\u001b[0m  0.0092\n",
            "      2        \u001b[36m1.9893\u001b[0m  0.0123\n",
            "      3        \u001b[36m1.8842\u001b[0m  0.0092\n",
            "      4        \u001b[36m1.8153\u001b[0m  0.0091\n",
            "      5        \u001b[36m1.7651\u001b[0m  0.0090\n",
            "      6        \u001b[36m1.7311\u001b[0m  0.0088\n",
            "      7        \u001b[36m1.7049\u001b[0m  0.0089\n",
            "      8        \u001b[36m1.6828\u001b[0m  0.0090\n",
            "      9        \u001b[36m1.6676\u001b[0m  0.0121\n",
            "     10        \u001b[36m1.6556\u001b[0m  0.0096\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2453\u001b[0m  0.0101\n",
            "      2        \u001b[36m2.0040\u001b[0m  0.0098\n",
            "      3        \u001b[36m1.8962\u001b[0m  0.0095\n",
            "      4        \u001b[36m1.8264\u001b[0m  0.0102\n",
            "      5        \u001b[36m1.7796\u001b[0m  0.0110\n",
            "      6        \u001b[36m1.7452\u001b[0m  0.0118\n",
            "      7        \u001b[36m1.7180\u001b[0m  0.0120\n",
            "      8        \u001b[36m1.6986\u001b[0m  0.0114\n",
            "      9        \u001b[36m1.6838\u001b[0m  0.0071\n",
            "     10        \u001b[36m1.6693\u001b[0m  0.0078\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2524\u001b[0m  0.0091\n",
            "      2        \u001b[36m2.0142\u001b[0m  0.0103\n",
            "      3        \u001b[36m1.9262\u001b[0m  0.0102\n",
            "      4        \u001b[36m1.8619\u001b[0m  0.0128\n",
            "      5        \u001b[36m1.8223\u001b[0m  0.0104\n",
            "      6        \u001b[36m1.7909\u001b[0m  0.0093\n",
            "      7        \u001b[36m1.7662\u001b[0m  0.0092\n",
            "      8        \u001b[36m1.7452\u001b[0m  0.0100\n",
            "      9        \u001b[36m1.7258\u001b[0m  0.0097\n",
            "     10        \u001b[36m1.7086\u001b[0m  0.0090\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2341\u001b[0m  0.0080\n",
            "      2        \u001b[36m1.9975\u001b[0m  0.0115\n",
            "      3        \u001b[36m1.9003\u001b[0m  0.0094\n",
            "      4        \u001b[36m1.8307\u001b[0m  0.0106\n",
            "      5        \u001b[36m1.7858\u001b[0m  0.0095\n",
            "      6        \u001b[36m1.7539\u001b[0m  0.0104\n",
            "      7        \u001b[36m1.7325\u001b[0m  0.0097\n",
            "      8        \u001b[36m1.7140\u001b[0m  0.0096\n",
            "      9        \u001b[36m1.6978\u001b[0m  0.0093\n",
            "     10        \u001b[36m1.6834\u001b[0m  0.0097\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2432\u001b[0m  0.0083\n",
            "      2        \u001b[36m2.0095\u001b[0m  0.0107\n",
            "      3        \u001b[36m1.9004\u001b[0m  0.0105\n",
            "      4        \u001b[36m1.8323\u001b[0m  0.0104\n",
            "      5        \u001b[36m1.7861\u001b[0m  0.0092\n",
            "      6        \u001b[36m1.7519\u001b[0m  0.0099\n",
            "      7        \u001b[36m1.7273\u001b[0m  0.0114\n",
            "      8        \u001b[36m1.7072\u001b[0m  0.0105\n",
            "      9        \u001b[36m1.6905\u001b[0m  0.0107\n",
            "     10        \u001b[36m1.6761\u001b[0m  0.0108\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2462\u001b[0m  0.0086\n",
            "      2        \u001b[36m2.0197\u001b[0m  0.0129\n",
            "      3        \u001b[36m1.9133\u001b[0m  0.0113\n",
            "      4        \u001b[36m1.8466\u001b[0m  0.0105\n",
            "      5        \u001b[36m1.8000\u001b[0m  0.0100\n",
            "      6        \u001b[36m1.7660\u001b[0m  0.0115\n",
            "      7        \u001b[36m1.7416\u001b[0m  0.0132\n",
            "      8        \u001b[36m1.7214\u001b[0m  0.0114\n",
            "      9        \u001b[36m1.7040\u001b[0m  0.0106\n",
            "     10        \u001b[36m1.6890\u001b[0m  0.0098\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2425\u001b[0m  0.0089\n",
            "      2        \u001b[36m2.0229\u001b[0m  0.0110\n",
            "      3        \u001b[36m1.9207\u001b[0m  0.0103\n",
            "      4        \u001b[36m1.8576\u001b[0m  0.0113\n",
            "      5        \u001b[36m1.8133\u001b[0m  0.0111\n",
            "      6        \u001b[36m1.7798\u001b[0m  0.0116\n",
            "      7        \u001b[36m1.7551\u001b[0m  0.0107\n",
            "      8        \u001b[36m1.7349\u001b[0m  0.0100\n",
            "      9        \u001b[36m1.7176\u001b[0m  0.0101\n",
            "     10        \u001b[36m1.7027\u001b[0m  0.0105\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2368\u001b[0m  0.0123\n",
            "      2        \u001b[36m2.0098\u001b[0m  0.0110\n",
            "      3        \u001b[36m1.9128\u001b[0m  0.0129\n",
            "      4        \u001b[36m1.8533\u001b[0m  0.0128\n",
            "      5        \u001b[36m1.8120\u001b[0m  0.0154\n",
            "      6        \u001b[36m1.7832\u001b[0m  0.0126\n",
            "      7        \u001b[36m1.7606\u001b[0m  0.0128\n",
            "      8        \u001b[36m1.7413\u001b[0m  0.0126\n",
            "      9        \u001b[36m1.7243\u001b[0m  0.0131\n",
            "     10        \u001b[36m1.7102\u001b[0m  0.0130\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2452\u001b[0m  0.0102\n",
            "      2        \u001b[36m2.0183\u001b[0m  0.0119\n",
            "      3        \u001b[36m1.9245\u001b[0m  0.0175\n",
            "      4        \u001b[36m1.8621\u001b[0m  0.0130\n",
            "      5        \u001b[36m1.8189\u001b[0m  0.0126\n",
            "      6        \u001b[36m1.7895\u001b[0m  0.0116\n",
            "      7        \u001b[36m1.7660\u001b[0m  0.0136\n",
            "      8        \u001b[36m1.7452\u001b[0m  0.0122\n",
            "      9        \u001b[36m1.7282\u001b[0m  0.0121\n",
            "     10        \u001b[36m1.7143\u001b[0m  0.0126\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2386\u001b[0m  0.0119\n",
            "      2        \u001b[36m2.0259\u001b[0m  0.0120\n",
            "      3        \u001b[36m1.9336\u001b[0m  0.0118\n",
            "      4        \u001b[36m1.8735\u001b[0m  0.0124\n",
            "      5        \u001b[36m1.8294\u001b[0m  0.0150\n",
            "      6        \u001b[36m1.7990\u001b[0m  0.0134\n",
            "      7        \u001b[36m1.7760\u001b[0m  0.0120\n",
            "      8        \u001b[36m1.7557\u001b[0m  0.0129\n",
            "      9        \u001b[36m1.7380\u001b[0m  0.0131\n",
            "     10        \u001b[36m1.7233\u001b[0m  0.0131\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}